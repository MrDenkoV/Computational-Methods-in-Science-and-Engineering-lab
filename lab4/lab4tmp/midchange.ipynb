{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare a lot of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'AA/'\n",
    "files = [\"wiki_0\"+str(i) for i in range(9)] + [\"wiki_\"+str(i) for i in range(10, 14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep():\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        with open(path+file) as fp: \n",
    "            while True:\n",
    "                markers=0\n",
    "                with open('done/page'+str(count)+'.txt', 'a') as the_file:\n",
    "                    while True:\n",
    "                        line = fp.readline() \n",
    "\n",
    "                        if not line: \n",
    "                            break\n",
    "                        if line[0]=='<':\n",
    "                            markers+=1\n",
    "                            if markers==2:\n",
    "                                break\n",
    "                            continue\n",
    "                        the_file.write(line)\n",
    "                count+=1\n",
    "                if not line:\n",
    "                    break\n",
    "# prep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare Bag-Of-Words\n",
    "###### In our case union of all words\n",
    "We will use PyEnchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyenchant\n",
    "import enchant\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'done/'\n",
    "files = ['page'+str(i)+'.txt' for i in range(1401)]\n",
    "bagOfWords = dict()\n",
    "dictionary = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isok(char):\n",
    "    if char >= 'a' and char <= 'z':\n",
    "        return True\n",
    "    if char >= '0' and char <= '9':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 encouraged\n",
      "2000 Impressionism\n",
      "3000 disputed\n",
      "4000 needs\n",
      "5000 struck\n",
      "6000 frequent\n",
      "7000 chairmen\n",
      "8000 skiing\n",
      "9000 1001\n",
      "10000 bag\n",
      "11000 descriptive\n",
      "12000 Mustard\n",
      "13000 tails\n",
      "14000 tolerance\n",
      "15000 concise\n",
      "16000 popularize\n",
      "17000 facilitation\n",
      "18000 provably\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "bagOfWords = dict() # slows down really quick, so remember to clear dict\n",
    "for file in files:\n",
    "    with open(path+file) as fp:\n",
    "        for fileline in fp:\n",
    "            line = re.sub(\"[^\\w]\", \" \", fileline) \n",
    "            for word in line.split():\n",
    "#                 if not isok(word[0].lower()):\n",
    "#                     word = word[1:]\n",
    "#                 for i in range(2):\n",
    "#                     if len(word)>0 and not isok(word[-1].lower()):\n",
    "#                         word = word[:-1]\n",
    "#                 if len(word)==0:\n",
    "#                     continue\n",
    "                if dictionary.check(word.lower()) and word.lower() not in bagOfWords:\n",
    "                    bagOfWords[word.lower()]=count\n",
    "                    count+=1\n",
    "                    if count % 1e3 == 0:\n",
    "                        print(count, word)\n",
    "#                     bagOfWords[word.lower()]+=1\n",
    "#                 else:\n",
    "#                     bagOfWords[word.lower()]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to rather slow execution, print to check if everything is in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. For each document prepare bag-of-words and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 with\n",
      "200000 higher\n",
      "300000 which\n",
      "400000 government\n",
      "500000 transition\n",
      "600000 the\n",
      "700000 2004\n",
      "800000 and\n",
      "900000 sources\n",
      "1000000 of\n",
      "1100000 finished\n",
      "1200000 ease\n",
      "1300000 to\n",
      "1400000 each\n",
      "1500000 all\n",
      "1600000 used\n",
      "1700000 especially\n",
      "1800000 In\n",
      "1900000 report\n",
      "2000000 professional\n",
      "2100000 usually\n",
      "2200000 default\n",
      "2300000 species\n",
      "2400000 plants\n",
      "2500000 amino\n",
      "2600000 different\n",
      "2700000 families\n",
      "2800000 the\n",
      "2900000 so\n",
      "3000000 wholeheartedly\n",
      "3100000 traditional\n",
      "3200000 are\n",
      "3300000 the\n",
      "3400000 determine\n",
      "3500000 to\n",
      "3600000 information\n",
      "3700000 programmable\n",
      "3800000 entertainment\n",
      "3900000 contradictory\n",
      "4000000 as\n",
      "4100000 the\n",
      "4200000 will\n",
      "4300000 including\n",
      "4400000 purpose\n",
      "4500000 not\n",
      "4600000 also\n",
      "4700000 of\n",
      "4800000 sounds\n",
      "4900000 possible\n",
      "5000000 importance\n",
      "5100000 the\n",
      "5200000 successor\n",
      "5300000 resources\n",
      "5400000 water\n",
      "5500000 moons\n",
      "5600000 for\n",
      "5700000 Aryabhata\n",
      "5800000 Kármán\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "wordBags = [dict() for file in files]\n",
    "for ix, file in enumerate(files):\n",
    "    with open(path+file) as fp:\n",
    "        for fileline in fp:\n",
    "            line = re.sub(\"[^\\w]\", \" \", fileline) \n",
    "            for word in line.split():\n",
    "#                 if not isok(word[0].lower()):\n",
    "#                     word = word[1:]\n",
    "#                 for i in range(2):\n",
    "#                     if len(word)>0 and not isok(word[-1].lower()):\n",
    "#                         word = word[:-1]\n",
    "#                 if len(word)==0:\n",
    "#                     continue\n",
    "                count+=1\n",
    "                if count % 1e5 == 0:\n",
    "                    print(count, word)\n",
    "                if word.lower() not in bagOfWords:\n",
    "                    continue\n",
    "                if word.lower() not in wordBags[ix]:\n",
    "                    wordBags[ix][word.lower()]=1\n",
    "                else:\n",
    "                    wordBags[ix][word.lower()]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print to assure process not hang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create sparse term-by-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sparse.lil_matrix((len(bagOfWords), len(files)))\n",
    "for ix, bag in enumerate(wordBags):\n",
    "    for word in bag:\n",
    "        A[bagOfWords[word], ix] = bag[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Calulate Inverse Document Frequency and multiply each matrix element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF=0\n",
    "N=len(files)\n",
    "nw=0\n",
    "summed = A.getnnz(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "japan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summed[0])\n",
    "print(list(bagOfWords.keys())[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for word in bagOfWords:\n",
    "    N="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
