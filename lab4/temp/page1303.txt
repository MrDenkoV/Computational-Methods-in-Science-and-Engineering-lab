Uncanny valley

In aesthetics, the uncanny valley is a hypothesized relationship between the degree of an object's resemblance to a human being and the emotional response to such an object. The concept of the uncanny valley suggests that humanoid objects which imperfectly resemble actual human beings provoke uncanny or strangely familiar feelings of eeriness and revulsion in observers. "Valley" denotes a dip in the human observer's affinity for the replica, a relation that otherwise increases with the replica's human likeness.

Examples can be found in robotics, 3D computer animations, and lifelike dolls among others. With the increasing prevalence of virtual reality, augmented reality, and photorealistic computer animation, the "valley" has been cited in the popular press in reaction to the verisimilitude of the creation as it approaches indistinguishability from reality. The uncanny valley hypothesis predicts that an entity appearing almost human will risk eliciting cold, eerie feelings in viewers.

The concept was identified by the robotics professor Masahiro Mori as "bukimi no tani genshō" () in 1970. The term was first translated as "uncanny valley" in the 1978 book "Robots: Fact, Fiction, and Prediction", written by Jasia Reichardt, thus forging an unintended link to Ernst Jentsch's concept of the "uncanny", introduced in a 1906 essay entitled "On the Psychology of the Uncanny". Jentsch's conception was elaborated by Sigmund Freud in a 1919 essay entitled "The Uncanny" ("Das Unheimliche").

Mori's original hypothesis states that as the appearance of a robot is made more human, some observers' emotional response to the robot becomes increasingly positive and empathetic, until it reaches a point beyond which the response quickly becomes strong revulsion. However, as the robot's appearance continues to become less distinguishable from a human being, the emotional response becomes positive once again and approaches human-to-human empathy levels.

This area of repulsive response aroused by a robot with appearance and motion between a "barely human" and "fully human" entity is the uncanny valley. The name captures the idea that an almost human-looking robot seems overly "strange" to some human beings, produces a feeling of uncanniness, and thus fails to evoke the empathic response required for productive human–robot interaction.

A number of theories have been proposed to explain the cognitive mechanism underlying the phenomenon:

A series of studies experimentally investigated whether uncanny valley effects exist for static images of robot faces. Mathur MB & Reichling DB used two complementary sets of stimuli spanning the range from very mechanical to very human-like: first, a sample of 80 objectively chosen robot face images from Internet searches, and second, a morphometrically and graphically controlled 6-face series set of faces. They asked subjects to explicitly rate the likability of each face. To measure trust toward each face, subjects completed a one-shot investment game to indirectly measure how much money they were willing to "wager" on a robot's trustworthiness. Both stimulus sets showed a robust uncanny valley effect on explicitly-rated likability and a more context-dependent uncanny valley on implicitly-rated trust. Their exploratory analysis of one proposed mechanism for the uncanny valley, perceptual confusion at a category boundary, found that category confusion occurs in the uncanny valley but does not mediate the effect on social and emotional responses.

One study conducted in 2009 examined the evolutionary mechanism behind the aversion associated with the uncanny valley. A group of five monkeys were shown three images: two different 3D monkey faces (realistic, unrealistic), and a real photo of a monkey's face. The monkeys' eye-gaze was used as a proxy for preference or aversion. Since the realistic 3D monkey face was looked at less than either the real photo, or the unrealistic 3D monkey face, this was interpreted as an indication that the monkey participants found the realistic 3D face aversive, or otherwise preferred the other two images. As one would expect with the uncanny valley, more realism can lead to less positive reactions, and this study demonstrated that neither human-specific cognitive processes, nor human culture explain the uncanny valley. In other words, this aversive reaction to realism can be said to be evolutionary in origin.

As of 2011, researchers at University of California, San Diego and California Institute for Telecommunications and Information Technology are measuring human brain activations related to the uncanny valley. In one study using fMRI, a group of cognitive scientists and roboticists found the biggest differences in brain responses for uncanny robots in parietal cortex, on both sides of the brain, specifically in the areas that connect the part of the brain's visual cortex that processes bodily movements with the section of the motor cortex thought to contain mirror neurons. The researchers say they saw, in essence, evidence of mismatch or perceptual conflict. The brain "lit up" when the human-like appearance of the android and its robotic motion "didn’t compute". Ayşe Pınar Saygın, an assistant professor from UCSD, says "The brain doesn’t seem selectively tuned to either biological appearance or biological motion per se. What it seems to be doing is looking for its expectations to be met – for appearance and motion to be congruent."

Viewer perception of facial expression and speech and the uncanny valley in realistic, human-like characters intended for video games and film is being investigated by Tinwell et al., 2011. Consideration is also given by Tinwell et al. (2010) as to how the uncanny may be exaggerated for antipathetic characters in survival horror games. Building on the body of work already undertaken in android science, this research intends to build a conceptual framework of the uncanny valley using 3D characters generated in a real-time gaming engine. The goal is to analyze how cross-modal factors of facial expression and speech can exaggerate the uncanny. Tinwell et al., 2011 have also introduced the notion of an "unscalable" uncanny wall that suggests that a viewer's discernment for detecting imperfections in realism will keep pace with new technologies in simulating realism. A summary of Angela Tinwell's research on the uncanny valley, psychological reasons behind the uncanny valley and how designers may overcome the uncanny in human-like virtual characters is provided in her book, "The Uncanny Valley in Games and Animation" by CRC Press.

A number of design principles have been proposed for avoiding the uncanny valley:

A number of criticisms have been raised concerning whether the uncanny valley exists as a unified phenomenon amenable to scientific scrutiny:

An effect similar to the uncanny valley was noted by Charles Darwin in 1839:
A similar "uncanny valley" effect could, according to the ethical-futurist writer Jamais Cascio, show up when humans begin modifying themselves with transhuman enhancements (cf. body modification), which aim to improve the abilities of the human body beyond what would normally be possible, be it eyesight, muscle strength, or cognition. So long as these enhancements remain within a perceived norm of human behavior, a negative reaction is unlikely, but once individuals supplant normal human variety, revulsion can be expected. However, according to this theory, once such technologies gain further distance from human norms, "transhuman" individuals would cease to be judged on human levels and instead be regarded as separate entities altogether (this point is what has been dubbed "posthuman"), and it is here that acceptance would rise once again out of the uncanny valley. Another example comes from "pageant retouching" photos, especially of children, which some find disturbingly doll-like.

Due to rapid advancements in the areas of artificial intelligence and affective computing, cognitive scientists have also suggested the possibility of an "Uncanny Valley of Mind". Accordingly, people might experience strong feelings of aversion if they encounter highly advanced, emotion-sensitive technology. Among the possible explanations for this phenomenon, both a perceived loss of human uniqueness and expectations of immediate physical harm are discussed by contemporary research.

A number of films that use computer-generated imagery to show characters have been described by reviewers as giving a feeling of revulsion or "creepiness" as a result of the characters looking too realistic. Examples include the following:


An increasingly common practice is to feature virtual actors in films: CGI likenesses of real actors used because the original actor either looks too old for the part or is deceased. Sometimes a virtual actor is created with involvement from the original actor (who may contribute motion capture, audio, etc.), while at other times the actor has no involvement. Reviewers have often criticized the use of virtual actors for its uncanny valley effect, saying it adds an eerie feeling to the movie. Examples of virtual actors that have received such criticism include replicas of Arnold Schwarzenegger in "Terminator Salvation" (2009), Jeff Bridges in "" (2010), Schwarzenegger again in "Terminator Genisys" (2015), Peter Cushing and Carrie Fisher in "Rogue One" (2016), and Will Smith in "Gemini Man" (2019).

The use of virtual actors is in contrast with digital de-aging, which can involve simply removing wrinkles from actors' faces. This practice has generally not faced uncanny valley criticism. One exception is the 2019 film "The Irishman", in which Robert De Niro, Al Pacino and Joe Pesci were all de-aged to try to make them look up to 50 years younger: one reviewer wrote that the actors' "hunched and stiff" body language stood in marked contrast to their facial appearance, while another wrote that when De Niro's character was in his 30s, he looked like he was 50.

Deepfake software, which first began to be widely used in 2017, uses machine learning to graft one person's appearance onto another's facial expressions, thus providing an alternate approach to both creating virtual actors and digital de-aging. Various individuals have created web videos that use deepfake software to re-create some of the notable previous uses of virtual actors and de-aging in film. Journalists have tended to praise these deepfake imitations, calling them "more naturalistic" and "objectively better" than the originals.

In the 2008 "30 Rock" episode "Succession", Frank Rossitano explains the uncanny valley concept, using a graph and "Star Wars" examples, to try to convince Tracy Jordan that his dream of creating a pornographic video game is impossible. He also references the computer-animated film "The Polar Express."




