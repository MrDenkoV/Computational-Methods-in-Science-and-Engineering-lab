<doc id="12825560" url="https://en.wikipedia.org/wiki?curid=12825560" title="Choiceless awareness">
Choiceless awareness

Choiceless awareness is a major topic in the exposition of Indian philosopher Jiddu Krishnamurti (18951986). Beginning in the 1930s, he often commented on the subject, which became a recurring theme in his work. He is considered to have been mainly responsible for the subsequent interest in both the term and the concept.

Krishnamurti held that outside of strictly practical, technical matters, the presence and action of choice indicates confusion and subtle bias: an individual who perceives a given situation in an unbiased manner, without distortion, and therefore with complete awareness, will immediately, naturally, act according to this awarenessthe action will be the manifestation and result of this awareness, rather than the result of choice. Such action (and quality of mind) is inherently without conflict.

He did not offer any method to achieve such awareness; in his view application of technique cannot possibly evolve into, or result in, true choicelessnessjust as unceasing application of effort leads to illusory effortlessness, in reality the action of habit. Additionally, in his opinion all methods introduce potential or actual conflict, generated by the practitioner's efforts to comply. According to this analysis, all practices towards achieving choiceless awareness have the opposite effect: they inhibit its action in the present by treating it as a future, premeditated result, and moreover one that is conditioned by the practitioner's implied or expressed expectations. 

Krishnamurti stated that for true choicelessness to be realized, choiceimplicit or explicithas to simply, irrevocably, stop; however, this ceasing of choice is not the result of decision-making, but implies the ceasing of the functioning of the chooser or self as a psychological entity. He proposed that such a state might be approached through inquiry based on total attentiveness: identity is then dissolved in complete, all-encompassing attention. Therefore, he asserted that choiceless awareness is a natural attribute of non-self-centered perception, which he called "observation without the observer".

Accordingly, Krishnamurti advised against following any doctrine, discipline, teacher, guru, or authority, including himself. He also advised against following one's own psychological knowledge and experience, which he considered integral parts of the observer. He denied the usefulness of all meditation techniques and methods, but not of meditation itself, which he called "perhaps the greatest" art in life; and stated that insight into choiceless awareness could be shared through open dialogue.

Krishnamurti's ideas on choiceless awareness were discussed by among others, influential Hindu spiritual teacher Ramana Maharshi (18791950) and, following wide publication of his books, they attracted the attention of psychologists and psychoanalysts in the 1950s; in subsequent decades Krishnamurti held a number of discussions on this and related subjects with practicing psychotherapists and with researchers in the field. His views on the subject have been included in scholarly papers on existential therapy, education theory, and peace research, but they have also been discussed in less formal or structured settings.

In late1980, almost half a century after he started discussing it, Krishnamurti included the concept in "The Core of Krishnamurti's Teaching", a pivotal statement of his philosophy: "Freedom is found in the choiceless awareness of our daily existence and activity.

In contrast with Krishnamurti's approach, other articulations commonly include choiceless awareness (or related ideas and terms) as part, or as the hoped-for result, of specific methodologies and meditation techniques. Similar concepts and terms appeared or developed in various traditional and contemporary religious or spiritual doctrines and texts, and also within secular disciplines such as psychotherapy, rehabilitation medicine, and counseling. Choiceless awareness has been examined within the context of philosophy of perception and behavior, while studies have cited its possible role in job performance. Other studies have linked meditation based on the concept (among others), with neural activity consistent with increased attentiveness, considered a factor of well-being and happiness.

One term that is often used as a near-synonym is mindfulness, which as a concept has similarities to or may include choiceless awareness. Initially part of Buddhist meditation practice, it has been adapted and utilized for contemporary psychological treatment, and has been applied as a component of integrative medicine programs.

Kindred themes can be found in the doctrine and meditation practices (such as Vipassanā) associated with the Theravada school of Buddhism; and also in 20th-century offshoots such as the Thai Forest Tradition and the Vipassana movement. Within these and similar fields, for example the Shikantaza practice in Zen Buddhism, choiceless (or effortless) awareness is considered to frequently be the result of a mature progression of practice.

The concept has been included in the discourse of transpersonal philosopher Ken Wilber (b. 1949), and also of independent Indian spiritual teacher Osho (Rajneesh) (19311990). Tibetan Buddhism teacher Chögyam Trungpa (19391987), who engaged in dialogue with Krishnamurti, used the term to describe the experience of shunyata (Śūnyatā)in Sanskrit, "emptiness", or "ego-less perception".

Among other fields, the term has appeared in dispute resolution theory and practice, and has found application in artistic endeavors. In dramatic theory, theater criticism, and acting, it has been used to denote spontaneous creativity and related practices or attempts; it has additionally appeared in music works. Author J. D. Salinger (19192010), who was interested in spirituality and alternative religions, was reputedly an adherent of Ramana Maharshi's ideas on choiceless awareness.

Contrary to press reports published in mid-20th-century, later interest in practices related to, or influenced by, choiceless awareness, has resulted in unambiguously favorable mentions in the popular press. Additionally, mass market general interest titles covering the subject have been published.








</doc>
<doc id="6069126" url="https://en.wikipedia.org/wiki?curid=6069126" title="Time perception">
Time perception

Time perception is a field of study within psychology, cognitive linguistics and neuroscience that refers to the subjective experience, or sense, of time, which is measured by someone's own perception of the duration of the indefinite and unfolding of events. The perceived time interval between two successive events is referred to as perceived duration. Though directly experiencing or understanding another person's perception of time is not possible, such a perception can be objectively studied and inferred through a number of scientific experiments. Some temporal illusions help to expose the underlying neural mechanisms of time perception.

Pioneering work, emphasizing species-specific differences, was conducted by Karl Ernst von Baer.

Although there are many theories and computational modeling for time perception mechanism in the brain, followings are a few examples of these theories.

William J. Friedman (1993) also contrasted two theories for a sense of time:


Another theory involves the brain's subconscious tallying of "pulses" during a specific interval, forming a biological stopwatch. This theory alleges that the brain can run multiple biological stopwatches at one time depending on the type of task one is involved in. The location of these pulses and what these pulses actually consist of is unclear. This model is only a metaphor and does not stand up in terms of brain physiology or anatomy.

Moreover, time perception is usually categorized under following three distinct ranges due to the fact that different range of durations are processed in different part of the brain.


The "specious present" is the time duration wherein a state of consciousness is experienced as being in the present. The term was first introduced by the philosopher E. R. Clay in 1882 (E. Robert Kelly), and was further developed by William James. James defined the specious present to be "the prototype of all conceived times... the short duration of which we are immediately and incessantly sensible". In "Scientific Thought" (1930), C. D. Broad further elaborated on the concept of the specious present and considered that the specious present may be considered as the temporal equivalent of a sensory datum. A version of the concept was used by Edmund Husserl in his works and discussed further by Francisco Varela based on the writings of Husserl, Heidegger, and Merleau-Ponty.

Although the perception of time is not associated with a specific sensory system, psychologists and neuroscientists suggest that humans do have a system, or several complementary systems, governing the perception of time. Time perception is handled by a highly distributed system involving the cerebral cortex, cerebellum and basal ganglia. One particular component, the suprachiasmatic nucleus, is responsible for the circadian (or daily) rhythm, while other cell clusters appear to be capable of shorter (ultradian) timekeeping. There is some evidence that very short (millisecond) durations are processed by dedicated neurons in early sensory parts of the brain

Professor Warren Meck devised a physiological model for measuring the passage of time. He found the representation of time to be generated by the oscillatory activity of cells in the upper cortex. The frequency of these cells' activity is detected by cells in the dorsal striatum at the base of the forebrain. His model separated explicit timing and implicit timing. Explicit timing is used in estimating the duration of a stimulus. Implicit timing is used to gauge the amount of time separating one from an impending event that is expected to occur in the near future. These two estimations of time do not involve the same neuroanatomical areas. For example, implicit timing often occurs to achieve a motor task, involving the cerebellum, left parietal cortex, and left premotor cortex. Explicit timing often involves the supplementary motor area and the right prefrontal cortex.

Two visual stimuli, inside someone's field of view, can be successfully regarded as simultaneous up to five milliseconds.

In the popular essay "Brain Time", David Eagleman explains that different types of sensory information (auditory, tactile, visual, etc.) are processed at different speeds by different neural architectures. The brain must learn how to overcome these speed disparities if it is to create a temporally unified representation of the external world: "if the visual brain wants to get events correct timewise, it may have only one choice: wait for the slowest information to arrive. To accomplish this, it must wait about a tenth of a second. In the early days of television broadcasting, engineers worried about the problem of keeping audio and video signals synchronized. Then they accidentally discovered that they had around a hundred milliseconds of slop: As long as the signals arrived within this window, viewers' brains would automatically resynchronize the signals". He goes on to say that "This brief waiting period allows the visual system to discount the various delays imposed by the early stages; however, it has the disadvantage of pushing perception into the past. There is a distinct survival advantage to operating as close to the present as possible; an animal does not want to live too far in the past. Therefore, the tenth-of- a-second window may be the smallest delay that allows higher areas of the brain to account for the delays created in the first stages of the system while still operating near the border of the present. This window of delay means that awareness is retroactive, incorporating data from a window of time after an event and delivering a delayed interpretation of what happened."

Experiments have shown that rats can successfully estimate a time interval of approximately 40 seconds, despite having their cortex entirely removed. This suggests that time estimation may be a low level process.
In recent history, ecologists and psychologists have been interested in whether and how time is perceived by non-human animals, as well as which functional purposes are served by the ability to perceive time. Studies have demonstrated that many species of animals, including both vertebrates and invertebrates, have cognitive abilities that allow them to estimate and compare time intervals and durations in a similar way to humans.

There is empirical evidence that metabolic rate has an impact on animals' ability to perceive time. In general, it is true within and across taxa that animals of smaller size (such as flies), which have a fast metabolic rate, experience time more slowly than animals of larger size, which have a slow metabolic rate. Researchers suppose that this could be the reason why small-bodied animals are generally better at perceiving time on a small scale, and why they are more agile than larger animals.

In a lab experiment, goldfish were conditioned to receive a light stimulus followed shortly by an aversive electric shock, with a constant time interval between the two stimuli. Test subjects showed an increase in general activity around the time of the electric shock. This response persisted in further trials in which the light stimulus was kept but the electric shock was removed. This suggests that goldfish are able to perceive time intervals and to initiate an avoidance response at the time when they expect the distressing stimulus to happen.

In two separate studies, golden shiners and dwarf inangas demonstrated the ability to associate the availability of food sources to specific locations and times of day, called time-place learning. In contrast, when tested for time-place learning based on predation risk, inangas were unable to associate spatiotemporal patterns to the presence or absence of predators.

When presented with the choice between obtaining food at regular intervals (with a fixed delay between feedings) or at stochastic intervals (with a variable delay between feedings), starlings can discriminate between the two types of intervals and consistently prefer getting food at variable intervals. This is true whether the total amount of food is the same for both options or if the total amount of food is unpredictable in the variable option. This suggests that starlings have an inclination for risk-prone behavior.

Pigeons are able to discriminate between different times of day and show time-place learning. After training, lab subjects were successfully able to peck specific keys at different times of day (morning or afternoon) in exchange for food, even after their sleep/wake cycle was artificially shifted. This suggests that to discriminate between different times of day, pigeons can use an internal timer (or circadian timer) that is independent of external cues. However, a more recent study on time-place learning in pigeons suggests that for a similar task, test subjects will switch to a non-circadian timing mechanism when possible to save energy resources. Experimental tests revealed that pigeons are also able to discriminate between cues of various durations (on the order of seconds), but that they are less accurate when timing auditory cues than when timing visual cues.

A study on privately owned dogs revealed that dogs are able to perceive durations ranging from minutes to several hours differently. Dogs reacted with increasing intensity to the return of their owners when they were left alone for longer durations, regardless of the owners' behavior.

After being trained with food reinforcement, female wild boars are able to correctly estimate time intervals of days by asking for food at the end of each interval, but they are unable to accurately estimate time intervals of minutes with the same training method. 

When trained with positive reinforcement, rats can learn to respond to a signal of a certain duration, but not to signals of shorter or longer durations, which demonstrates that they can discriminate between different durations. Rats have demonstrated time-place learning, and can also learn to infer correct timing for a specific task by following an order of events, suggesting that they might be able to use an ordinal timing mechanism. Like pigeons, rats are thought to have the ability to use a circadian timing mechanism for discriminating time of day.

When returning to the hive with nectar, forager honey bees need to know the current ratio of nectar-collecting to nectar-processing rates in the colony. To do so, they estimate the time it takes them to find a food-storer bee, which will unload the forage and store it. The longer it takes them to find one, the busier the food-storer bees are; and therefore the higher the nectar-collecting rate of the colony. Forager bees also assess the quality of nectar by comparing the length of time it takes to unload the forage: a longer unloading time indicates higher quality nectar. They compare their own unloading time to the unloading time of other foragers present in the hive, and adjust their recruiting behavior accordingly. For instance, honey bees reduce the duration of their waggle dance if they judge their own yield to be inferior. Scientists have demonstrated that anesthesia disrupts the circadian clock and impairs the time perception of honey bees, as observed in humans. Experiments revealed that a 6-hour-long general anesthesia significantly delayed the start of the foraging behaviour of honeybees if induced during daytime, but not if induced during nighttime.

Bumble bees can be successfully trained to respond to a stimulus after a certain time interval has elapsed (usually several seconds after the start signal). Studies have shown that they can also learn to simultaneously time multiple interval durations.

In a single study, colonies from three species of ants from the genus Myrmica were trained to associate feeding sessions with different times. The trainings lasted several days, where each day the feeding time was delayed by 20 minutes compared to the previous day. In all three species, at the end of the training, most individuals were present at the feeding spot at the correct expected times, suggesting that ants are able to estimate the time running, keep in memory the expected feeding time and to act anticipatively.

A "temporal illusion" is a distortion in the perception of time. "Time perception" refers to a variety of time-related tasks. For example:

Short list of types of temporal illusions:

The Kappa effect or perceptual time dilation is a form of temporal illusion verifiable by experiment, wherein the temporal duration between a sequence of consecutive stimuli is thought to be relatively longer or shorter than its actual elapsed time, due to the spatial/auditory/tactile separation between each consecutive stimuli. The kappa effect can be displayed when considering a journey made in two parts that take an equal amount of time. Between these two parts, the journey that covers more distance may appear to take longer than the journey covering less distance, even though they take an equal amount of time.

The perception of space and time undergoes distortions during rapid saccadic eye movements.

Chronostasis is a type of temporal illusion in which the first impression following the introduction of a new event or task demand to the brain appears to be extended in time. For example, chronostasis temporarily occurs when fixating on a target stimulus, immediately following a saccade (e.g., quick eye movement). This elicits an overestimation in the temporal duration for which that target stimulus (i.e., postsaccadic stimulus) was perceived. This effect can extend apparent durations by up to 500 ms and is consistent with the idea that the visual system models events prior to perception. The most well-known version of this illusion is known as the stopped-clock illusion, wherein a subject's first impression of the second-hand movement of an analog clock, subsequent to one's directed attention (i.e., saccade) to the clock, is the perception of a slower-than-normal second-hand movement rate (the seconds hand of the clock may seemingly temporarily freeze in place after initially looking at it).

The occurrence of chronostasis extends beyond the visual domain into the auditory and tactile domains. In the auditory domain, chronostasis and duration overestimation occur when observing auditory stimuli. One common example is a frequent occurrence when making telephone calls. If, while listening to the phone's dial tone, research subjects move the phone from one ear to the other, the length of time between rings appears longer. In the tactile domain, chronostasis has persisted in research subjects as they reach for and grasp objects. After grasping a new object, subjects overestimate the time in which their hand has been in contact with this object. In other experiments, subjects turning a light on with a button were conditioned to experience the light before the button press.

In an experiment, participants were told to stare at an "x" symbol on a computer screen whereby a moving blue doughnut-like ring repeatedly circled the fixed "x" point. Occasionally, the ring would display a white flash for a split second that physically overlapped the ring's interior. However, when asked what was perceived, participants responded that they saw the white flash lagging behind the center of the moving ring. In other words, despite the reality that the two retinal images were actually spatially aligned, the flashed object was usually observed to trail a continuously moving object in space — a phenomenon referred to as the flash-lag effect.

The first proposed explanation, called the 'motion extrapolation' hypothesis, is that the visual system extrapolates the position of moving objects but not flashing objects when accounting for neural delays (i.e., the lag time between the retinal image and the observer's perception of the flashing object). The second proposed explanation by David Eagleman and Sejnowski, called the 'latency difference' hypothesis, is that the visual system processes moving objects at a faster rate than flashed objects. In the attempt to disprove the first hypothesis, David Eagleman conducted an experiment in which the moving ring suddenly reverses direction to spin in the other way as the flashed object briefly appears. If the first hypothesis were correct, we would expect that, immediately following reversal, the moving object would be observed as lagging behind the flashed object. However, the experiment revealed the opposite — immediately following reversal, the flashed object was observed as lagging behind the moving object. This experimental result supports of the 'latency difference' hypothesis. A recent study tries to reconcile these different approaches by approaching perception as an inference mechanism aiming at describing what is happening at the present time.

Humans typically overestimate the perceived duration of the initial and final event in a stream of identical events.

The oddball effect may serve an evolutionarily adapted “alerting” function and is consistent with reports of time slowing down in threatening situations. The effect seems to be strongest for images that are expanding in size on the retina, in other words, that are "looming" or approaching the viewer, and the effect can be eradicated for oddballs that are contracting or perceived to be receding from the viewer. The effect is also reduced or reversed with a static oddball presented amongst a stream of expanding stimuli.

Initial studies suggested that this oddball-induced “subjective time dilation” expanded the perceived duration of oddball stimuli by 30–50% but subsequent research has reported more modest expansion of around 10% or less. The direction of the effect, whether the viewer perceives an increase or a decrease in duration, also seems to be dependent upon the stimulus used.

Numerous experimental findings suggest that temporal order judgments of actions preceding effects can be reversed under special circumstances. Experiments have shown that sensory simultaneity judgments can be manipulated by repeated exposure to non-simultaneous stimuli. In an experiment conducted by David Eagleman, a temporal order judgment reversal was induced in subjects by exposing them to delayed motor consequences. In the experiment, subjects played various forms of video games. Unknown to the subjects, the experimenters introduced a fixed delay between the mouse movements and the subsequent sensory feedback. For example, a subject may not see a movement register on the screen until 150 milliseconds after the mouse had moved. Participants playing the game quickly adapted to the delay and felt as though there was less delay between their mouse movement and the sensory feedback. Shortly after the experimenters removed the delay, the subjects commonly felt as though the effect on the screen happened just before they commanded it. This work addresses how the perceived timing of effects is modulated by expectations, and the extent to which such predictions are quickly modifiable. In an experiment conducted by Haggard and colleagues in 2002, participants pressed a button that triggered a flash of light at a distance after a slight delay of 100 milliseconds. By repeatedly engaging in this act, participants had adapted to the delay (i.e., they experienced a gradual shortening in the perceived time interval between pressing the button and seeing the flash of light). The experimenters then showed the flash of light instantly after the button was pressed. In response, subjects often thought that the flash (the effect) had occurred before the button was pressed (the cause). Additionally, when the experimenters slightly reduced the delay, and shortened the spatial distance between the button and the flash of light, participants had often claimed again to have experienced the effect before the cause.

Several experiments also suggest that temporal order judgment of a pair of tactile stimuli delivered in rapid succession, one to each hand, is noticeably impaired (i.e., misreported) by crossing the hands over the midline. However, congenitally blind subjects showed no trace of temporal order judgment reversal after crossing the arms. These results suggest that tactile signals taken in by the congenitally blind are ordered in time without being referred to a visuospatial representation. Unlike the congenitally blind subjects, the temporal order judgments of the late-onset blind subjects were impaired when crossing the arms to a similar extent as non-blind subjects. These results suggest that the associations between tactile signals and visuospatial representation is maintained once it is accomplished during infancy. Some research studies have also found that the subjects showed reduced deficit in tactile temporal order judgments when the arms were crossed behind their back than when they were crossed in front.

Tachypsychia is a neurological condition that alters the perception of time, usually induced by physical exertion, drug use, or a traumatic event. For someone affected by tachypsychia, time perceived by the individual either lengthens, making events appear to slow down, or contracts, objects appearing as moving in a speeding blur.

Some genetic polymorphisms are associated with tachypsychia: COMT Val158Met, DRD2/ANKK1-Taq1A and SLC6A3 3'-UTR VNTR. These gene polymorphisms affect the expression of D2 dopamine receptors primarily in the striatum (DRD2/ANKK1-Taq1A polymorphism).

Research has suggested the feeling of awe has the ability to expand one's perceptions of time availability. Awe can be characterized as an experience of immense perceptual vastness that coincides with an increase in focus. Consequently, it is conceivable that one's temporal perception would slow down when experiencing awe.

Possibly related to the oddball effect, research suggests that time seems to slow down for a person during dangerous events (such as a car accident, a robbery, or when a person perceives a potential predator or mate), or when a person skydives or bungee jumps, where they're capable of complex thoughts in what would normally be the blink of an eye (See Fight-or-flight response). This reported slowing in temporal perception may have been evolutionarily advantageous because it may have enhanced one's ability to intelligibly make quick decisions in moments that were of critical importance to our survival. However, even though observers commonly report that time seems to have moved in slow motion during these events, it is unclear whether this is a function of increased time resolution during the event, or instead an illusion created by the remembering of an emotionally salient event.

A strong time dilation effect has been reported for perception of objects that were looming, but not of those retreating, from the viewer, suggesting that the expanding discs — which mimic an approaching object — elicit self-referential processes which act to signal the presence of a possible danger. Anxious people, or those in great fear, experience greater "time dilation" in response to the same threat stimuli due to higher levels of epinephrine, which increases brain activity (an adrenaline rush). In such circumstances, an illusion of time dilation could assist an efficacious escape. When exposed to a threat, three-year-old children were observed to exhibit a similar tendency to overestimate elapsed time.

Research suggests that the effect appears only at the point of retrospective assessment, rather than occurring simultaneously with events as they happened. Perceptual abilities were tested during a frightening experience — a free fall — by measuring people's sensitivity to flickering stimuli. The results showed that the subjects' temporal resolution was not improved as the frightening event was occurring. Events appear to have taken longer only in retrospect, possibly because memories were being more densely packed during the frightening situation.

People shown extracts from films known to induce fear often overestimated the elapsed time of a subsequently presented visual stimulus, whereas people shown emotionally neutral clips (weather forecasts and stock market updates) or those known to evoke feelings of sadness showed no difference. It is argued that fear prompts a state of arousal in the amygdala, which increases the rate of a hypothesized "internal clock". This could be the result of an evolved defensive mechanism triggered by a threatening situation.

Psychologists have found that the subjective perception of the passing of time tends to speed up with increasing age in humans. This often causes people to increasingly underestimate a given interval of time as they age. This fact can likely be attributed to a variety of age-related changes in the aging brain, such as the lowering in dopaminergic levels with older age; however, the details are still being debated.

Very young children literally "live in time" before gaining an awareness of its passing. A child will first experience the passing of time when he or she can subjectively perceive and reflect on the unfolding of a collection of events. A child's awareness of time develops during childhood when the child's attention and short-term memory capacities form — this developmental process is thought to be dependent on the slow maturation of the prefrontal cortex and hippocampus.

One day to an 11-year-old would be approximately 1/4,000 of their life, while one day to a 55-year-old would be approximately 1/20,000 of their life. This helps to explain why a random, ordinary day may therefore appear longer for a young child than an adult. The short term appears to go faster in proportion to the square root of the perceiver's age. So a year would be experienced by a 55-year-old as passing approximately 2¼ times more quickly than a year experienced by an 11-year-old. If long-term time perception is based solely on the proportionality of a person's age, then the following four periods in life would appear to be quantitatively equal: ages 5–10 (1x), ages 10–20 (2x), ages 20–40 (4x), age 40–80 (8x).

The common explanation is that most external and internal experiences are new for young children but repetitive for adults. Children have to be extremely engaged (i.e. dedicate many neural resources or significant brain power) in the present moment because they must constantly reconfigure their mental models of the world to assimilate it and manage behaviour properly. Adults however may rarely need to step outside mental habits and external routines. When an adult frequently experiences the same stimuli, they seem "invisible" because they have already been sufficiently and effectively mapped by the brain. This phenomenon is known as neural adaptation. Thus, the brain will record fewer densely rich memories during these frequent periods of disengagement from the present moment. Consequently, the subjective perception is often that time passes by at a faster rate with age.

In a 2007 study, psilocybin was found to significantly impair the ability to reproduce interval durations longer than 2.5 seconds, significantly impair synchronizing motor actions (taps on a computer keyboard) with regularly occurring tones, and impair the ability to keep tempo when asked to tap on a key at a self-paced but consistent interval. In 1955, British MP Christopher Mayhew took mescaline hydrochloride in an experiment under the guidance of his friend, Dr Humphry Osmond. On the BBC documentary "The Beyond Within", he described that half a dozen times during the experiment, he had "a period of time that didn't end for [him]".

Stimulants can lead both humans and rats to overestimate time intervals, while depressants can have the opposite effect. The level of activity in the brain of neurotransmitters such as dopamine and norepinephrine may be the reason for this. The dopaminergic system has a particularly strong connection with one's perception of time. Drugs that activate dopamine receptors speed up one's perception of time, while dopamine antagonists cause one to feel that time is passing slowly.

The effect of cannabis on time perception has been studied with inconclusive results.

Time perception may speed up as body temperature rises, and slow down as body temperature lowers. This is especially true during stressful events.

Attention deficit hyperactivity disorder (ADHD) is linked to abnormalities in dopamine levels in the brain as well as to noticeable impairments in time perception.





</doc>
<doc id="26915" url="https://en.wikipedia.org/wiki?curid=26915" title="Linguistic relativity">
Linguistic relativity

The hypothesis of linguistic relativity, part of relativism, also known as the Sapir–Whorf hypothesis , or Whorfianism is a principle claiming that the structure of a language affects its speakers' world view or cognition, and thus people's perceptions are relative to their spoken language. 

The principle is often defined in one of two versions: the "strong hypothesis", which was held by some of the early linguists before World War II, and the "weak hypothesis", mostly held by some of the modern linguists.

The principle had been accepted and then abandoned by linguists during the early 20th century following the changing perceptions of social acceptance for the other especially after World War II. The origin of formulated arguments against the acceptance of linguistic relativity are attributed to Noam Chomsky.

The term "Sapir–Whorf hypothesis" is considered a misnomer by linguists for several reasons: Edward Sapir and Benjamin Lee Whorf never co-authored any works, and never stated their ideas in terms of a hypothesis. The distinction between a weak and a strong version of this hypothesis is also a later invention; Sapir and Whorf never set up such a dichotomy, although often their writings and their views of this relativity principle are phrased in stronger or weaker terms.

The idea was first clearly expressed by 19th-century thinkers, such as Wilhelm von Humboldt, who saw language as the expression of the spirit of a nation. Members of the early 20th-century school of American anthropology headed by Franz Boas and Edward Sapir also embraced forms of the idea to a certain extent, including in a 1928 meeting of the Linguistic Society of America, but Sapir in particular, wrote more often against than in favor of anything like linguistic determinism. Sapir's student, Benjamin Lee Whorf, came to be seen as the primary proponent as a result of his published observations of how he perceived linguistic differences to have consequences in human cognition and behavior. Harry Hoijer, another of Sapir's students, introduced the term "Sapir–Whorf hypothesis", even though the two scholars never formally advanced any such hypothesis. A strong version of relativist theory was developed from the late 1920s by the German linguist Leo Weisgerber. Whorf's principle of linguistic relativity was reformulated as a testable hypothesis by Roger Brown and Eric Lenneberg who conducted experiments designed to find out whether color perception varies between speakers of languages that classified colors differently. As the study of the universal nature of human language and cognition came into focus in the 1960s the idea of linguistic relativity fell out of favor among linguists. A 1969 study by Brent Berlin and Paul Kay demonstrated the existence of universal semantic constraints in the field of colour terminology which were widely seen to discredit the existence of linguistic relativity in this domain, although this conclusion has been disputed by relativist researchers.

From the late 1980s, a new school of linguistic relativity scholars has examined the effects of differences in linguistic categorization on cognition, finding broad support for non-deterministic versions of the hypothesis in experimental contexts. Some effects of linguistic relativity have been shown in several semantic domains, although they are generally weak. Currently, a balanced view of linguistic relativity is espoused by most linguists holding that language influences certain kinds of cognitive processes in non-trivial ways, but that other processes are better seen as arising from connectionist factors. Research is focused on exploring the ways and extent to which language influences thought. The principle of linguistic relativity and the relation between language and thought has also received attention in varying academic fields from philosophy to psychology and anthropology, and it has also inspired and coloured works of fiction and the invention of constructed languages.

The strongest form of the theory is linguistic determinism, which holds that language entirely determines the range of cognitive processes. The hypothesis of linguistic determinism is now generally agreed to be false.

This is the weaker form, proposing that language provides constraints in some areas of cognition, but that it is by no means determinative. Research on weaker forms has produced positive empirical evidence for a relationship.

The idea that language and thought are intertwined is ancient. Plato argued against sophist thinkers such as Gorgias of Leontini, who held that the physical world cannot be experienced except through language; this made the question of truth dependent on aesthetic preferences or functional consequences. Plato held instead that the world consisted of eternal ideas and that language should reflect these ideas as accurately as possible. Following Plato, St. Augustine, for example, held the view that language was merely labels applied to already existing concepts. This view remained prevalent throughout the Middle Ages. Roger Bacon held the opinion that language was but a veil covering up eternal truths, hiding them from human experience. For Immanuel Kant, language was but one of several tools used by humans to experience the world.

In the late 18th and early 19th centuries, the idea of the existence of different national characters, or "Volksgeister", of different ethnic groups was the moving force behind the German romantics school and the beginning ideologies of ethnic nationalism.

Although himself a Swede, Emanuel Swedenborg inspired several of the German Romantics. As early as 1749, he alludes to something along the lines of linguistic relativity in commenting on a passage in the table of nations in the book of Genesis: In 1771 he spelled this out more explicitly: 

Johann Georg Hamann is often suggested to be the first among the actual German Romantics to speak of the concept of "the genius of a language." In his "Essay Concerning an Academic Question," Hamann suggests that a people's language affects their worldview:

In 1820, Wilhelm von Humboldt connected the study of language to the national romanticist program by proposing the view that language is the fabric of thought. Thoughts are produced as a kind of internal dialog using the same grammar as the thinker's native language. This view was part of a larger picture in which the world view of an ethnic nation, their "Weltanschauung", was seen as being faithfully reflected in the grammar of their language. Von Humboldt argued that languages with an inflectional morphological type, such as German, English and the other Indo-European languages, were the most perfect languages and that accordingly this explained the dominance of their speakers over the speakers of less perfect languages. Wilhelm von Humboldt declared in 1820:

The idea that some languages are superior to others and that lesser languages maintained their speakers in intellectual poverty was widespread in the early 20th century. American linguist William Dwight Whitney, for example, actively strove to eradicate Native American languages, arguing that their speakers were savages and would be better off learning English and adopting a "civilized" way of life. The first anthropologist and linguist to challenge this view was Franz Boas. While undertaking geographical research in northern Canada he became fascinated with the Inuit people and decided to become an ethnographer. Boas stressed the equal worth of all cultures and languages, that there was no such thing as a primitive language and that all languages were capable of expressing the same content, albeit by widely differing means. Boas saw language as an inseparable part of culture and he was among the first to require of ethnographers to learn the native language of the culture under study and to document verbal culture such as myths and legends in the original language.

Boas:

Boas' student Edward Sapir reached back to the Humboldtian idea that languages contained the key to understanding the world views of peoples. He espoused the viewpoint that because of the differences in the grammatical systems of languages no two languages were similar enough to allow for perfect cross-translation. Sapir also thought because language represented reality differently, it followed that the speakers of different languages would perceive reality differently.

Sapir:

On the other hand, Sapir explicitly rejected strong linguistic determinism by stating, "It would be naïve to imagine that any analysis of experience is dependent on pattern expressed in language."

Sapir was explicit that the connections between language and culture were neither thoroughgoing nor particularly deep, if they existed at all:

Sapir offered similar observations about speakers of so-called "world" or "modern" languages, noting, "possession of a common language is still and will continue to be a smoother of the way to a mutual understanding between England and America, but it is very clear that other factors, some of them rapidly cumulative, are working powerfully to counteract this leveling influence. A common language cannot indefinitely set the seal on a common culture when the geographical, physical, and economics determinants of the culture are no longer the same throughout the area."

While Sapir never made a point of studying directly how languages affected thought, some notion of (probably "weak") linguistic relativity underlay his basic understanding of language, and would be taken up by Whorf.

Drawing on influences such as Humboldt and Friedrich Nietzsche, some European thinkers developed ideas similar to those of Sapir and Whorf, generally working in isolation from each other. Prominent in Germany from the late 1920s through into the 1960s were the strongly relativist theories of Leo Weisgerber and his key concept of a 'linguistic inter-world', mediating between external reality and the forms of a given language, in ways peculiar to that language. Russian psychologist Lev Vygotsky read Sapir's work and experimentally studied the ways in which the development of concepts in children was influenced by structures given in language. His 1934 work "Thought and Language" has been compared to Whorf's and taken as mutually supportive evidence of language's influence on cognition. Drawing on Nietzsche's ideas of perspectivism Alfred Korzybski developed the theory of general semantics that has been compared to Whorf's notions of linguistic relativity. Though influential in their own right, this work has not been influential in the debate on linguistic relativity, which has tended to center on the American paradigm exemplified by Sapir and Whorf.

More than any linguist, Benjamin Lee Whorf has become associated with what he called the "linguistic relativity principle". Studying Native American languages, he attempted to account for the ways in which grammatical systems and language use differences affected perception. Whorf also examined how a scientific account of the world differed from a religious account, which led him to study the original languages of religious scripture and to write several anti-evolutionist pamphlets. Whorf's opinions regarding the nature of the relation between language and thought remain under contention. Critics such as Lenneberg, Black and Pinker attribute to Whorf a strong linguistic determinism, while Lucy, Silverstein and Levinson point to Whorf's explicit rejections of determinism, and where he contends that translation and commensuration is possible.

Although Whorf lacked an advanced degree in linguistics, his reputation reflects his acquired competence. His peers at Yale University considered the 'amateur' Whorf to be the best man available to take over Sapir's graduate seminar in Native American linguistics while Sapir was on sabbatical in 1937–38. He was highly regarded by authorities such as Boas, Sapir, Bloomfield and Tozzer. Indeed, Lucy wrote, "despite his 'amateur' status, Whorf's work in linguistics was and still is recognized as being of superb professional quality by linguists".

Detractors such as Lenneberg, Chomsky and Pinker criticized him for insufficient clarity in his description of how language influences thought, and for not proving his conjectures. Most of his arguments were in the form of anecdotes and speculations that served as attempts to show how 'exotic' grammatical traits were connected to what were apparently equally exotic worlds of thought. In Whorf's words:

Among Whorf's best-known examples of linguistic relativity are instances where an indigenous language has several terms for a concept that is only described with one word in European languages (Whorf used the acronym SAE "Standard Average European" to allude to the rather similar grammatical structures of the well-studied European languages in contrast to the greater diversity of less-studied languages).

One of Whorf's examples was the supposedly large number of words for 'snow' in the Inuit language, an example which later was contested as a misrepresentation.

Another is the Hopi language's words for water, one indicating drinking water in a container and another indicating a natural body of water. These examples of polysemy served the double purpose of showing that indigenous languages sometimes made more fine grained semantic distinctions than European languages and that direct translation between two languages, even of seemingly basic concepts such as snow or water, is not always possible.

Another example is from Whorf's experience as a chemical engineer working for an insurance company as a fire inspector. While inspecting a chemical plant he observed that the plant had two storage rooms for gasoline barrels, one for the full barrels and one for the empty ones. He further noticed that while no employees smoked cigarettes in the room for full barrels, no-one minded smoking in the room with empty barrels, although this was potentially much more dangerous because of the highly flammable vapors still in the barrels. He concluded that the use of the word "empty" in connection to the barrels had led the workers to unconsciously regard them as harmless, although consciously they were probably aware of the risk of explosion. This example was later criticized by Lenneberg as not actually demonstrating causality between the use of the word "empty" and the action of smoking, but instead was an example of circular reasoning. Pinker in "The Language Instinct" ridiculed this example, claiming that this was a failing of human insight rather than language.

Whorf's most elaborate argument for linguistic relativity regarded what he believed to be a fundamental difference in the understanding of time as a conceptual category among the Hopi. He argued that in contrast to English and other SAE languages, Hopi does not treat the flow of time as a sequence of distinct, countable instances, like "three days" or "five years," but rather as a single process and that consequently it has no nouns referring to units of time as SAE speakers understand them. He proposed that this view of time was fundamental to Hopi culture and explained certain Hopi behavioral patterns. Malotki later claimed that he had found no evidence of Whorf's claims in 1980's era speakers, nor in historical documents dating back to the arrival of Europeans. Malotki used evidence from archaeological data, calendars, historical documents, modern speech and concluded that there was no evidence that Hopi conceptualize time in the way Whorf suggested. Universalist scholars such as Pinker often see Malotki's study as a final refutation of Whorf's claim about Hopi, whereas relativist scholars such as Lucy and Penny Lee criticized Malotki's study for mischaracterizing Whorf's claims and for forcing Hopi grammar into a model of analysis that doesn't fit the data.

Whorf died in 1941 at age 44, leaving multiple unpublished papers. His line of thought was continued by linguists and anthropologists such as Hoijer and Lee who both continued investigations into the effect of language on habitual thought, and Trager, who prepared a number of Whorf's papers for posthumous publishing. The most important event for the dissemination of Whorf's ideas to a larger public was the publication in 1956 of his major writings on the topic of linguistic relativity in a single volume titled "Language, Thought and Reality".

In 1953, Eric Lenneberg criticised Whorf's examples from an objectivist view of language holding that languages are principally meant to represent events in the real world and that even though languages express these ideas in various ways, the meanings of such expressions and therefore the thoughts of the speaker are equivalent. He argued that Whorf's English descriptions of a Hopi speaker's view of time were in fact translations of the Hopi concept into English, therefore disproving linguistic relativity. However Whorf was concerned with how the habitual "use" of language influences habitual behavior, rather than translatability. Whorf's point was that while English speakers may be able to "understand" how a Hopi speaker thinks, they do not "think" in that way.

Lenneberg's main criticism of Whorf's works was that he never showed the connection between a linguistic phenomenon and a mental phenomenon. With Brown, Lenneberg proposed that proving such a connection required directly matching linguistic phenomena with behavior. They assessed linguistic relativity experimentally and published their findings in 1954.

Since neither Sapir nor Whorf had ever stated a formal hypothesis, Brown and Lenneberg formulated their own. Their two tenets were (i) "the world is differently experienced and conceived in different linguistic communities" and (ii) "language causes a particular cognitive structure". Brown later developed them into the so-called "weak" and "strong" formulation:

Brown's formulations became widely known and were retrospectively attributed to Whorf and Sapir although the second formulation, verging on linguistic determinism, was never advanced by either of them.

Since Brown and Lenneberg believed that the objective reality denoted by language was the same for speakers of all languages, they decided to test how different languages codified the same message differently and whether differences in codification could be proven to affect behavior.

They designed experiments involving the codification of colors. In their first experiment, they investigated whether it was easier for speakers of English to remember color shades for which they had a specific name than to remember colors that were not as easily definable by words. This allowed them to compare the linguistic categorization directly to a non-linguistic task. In a later experiment, speakers of two languages that categorize colors differently (English and Zuni) were asked to recognize colors. In this way, it could be determined whether the differing color categories of the two speakers would determine their ability to recognize nuances within color categories. Brown and Lenneberg found that Zuñi speakers who classify green and blue together as a single color did have trouble recognizing and remembering nuances within the green/blue category. Brown and Lenneberg's study began a tradition of investigation of linguistic relativity through color terminology.

Lenneberg was also one of the first cognitive scientists to begin development of the Universalist theory of language that was formulated by Chomsky in the form of Universal Grammar, effectively arguing that all languages share the same underlying structure. The Chomskyan school also holds the belief that linguistic structures are largely innate and that what are perceived as differences between specific languages are surface phenomena that do not affect the brain's universal cognitive processes. This theory became the dominant paradigm in American linguistics from the 1960s through the 1980s, while linguistic relativity became the object of ridicule.

Examples of universalist influence in the 1960s are the studies by Berlin and Kay who continued Lenneberg's color research. They studied color terminology formation and showed clear universal trends in color naming. For example, they found that even though languages have different color terminologies, they generally recognize certain hues as more focal than others. They showed that in languages with few color terms, it is predictable from the number of terms which hues are chosen as focal colors, for example, languages with only three color terms always have the focal colors black, white and red. The fact that what had been believed to be random differences between color naming in different languages could be shown to follow universal patterns was seen as a powerful argument against linguistic relativity. Berlin and Kay's research has since been criticized by relativists such as Lucy, who argued that Berlin and Kay's conclusions were skewed by their insistence that color terms encode only color information. This, Lucy argues, made them blind to the instances in which color terms provided other information that might be considered examples of linguistic relativity.

Other universalist researchers dedicated themselves to dispelling other aspects of linguistic relativity, often attacking Whorf's specific points and examples. For example, Malotki's monumental study of time expressions in Hopi presented many examples that challenged Whorf's "timeless" interpretation of Hopi language and culture, but seemingly failed to address linguistic relativist argument actually posed by Whorf (i.e. that the understanding of time by native Hopi speakers differed from that of speakers of European languages due to the differences in the organization and construction of their respective languages; Whorf never claimed that Hopi speakers lacked any concept of time). Malotki himself acknowledges that the conceptualizations are different, but because he ignores Whorf's use of scare quotes around the word "time" and the qualifier "what we call," takes Whorf to be arguing that the Hopi have no concept of time at all.

Today many followers of the universalist school of thought still oppose linguistic relativity. For example, Pinker argues in "The Language Instinct" that thought is independent of language, that language is itself meaningless in any fundamental way to human thought, and that human beings do not even think in "natural" language, i.e. any language that we actually communicate in; rather, we think in a meta-language, preceding any natural language, called "mentalese." Pinker attacks what he calls "Whorf's radical position," declaring, "the more you examine Whorf's arguments, the less sense they make."

Pinker and other universalists have been accused by relativists of misrepresenting Whorf's views and arguing against strawmen.

Joshua Fishman argued that Whorf's true position was largely overlooked. In 1978, he suggested that Whorf was a "neo-Herderian champion" and in 1982, he proposed "Whorfianism of the third kind" in an attempt to refocus linguists' attention on what he claimed was Whorf's real interest, namely the intrinsic value of "little peoples" and "little languages". Whorf had criticized Ogden's Basic English thus:

Where Brown's weak version of the linguistic relativity hypothesis proposes that language "influences" thought and the strong version that language "determines" thought, Fishman's 'Whorfianism of the third kind' proposes that language "is a key to culture".

In the late 1980s and early 1990s, advances in cognitive psychology and cognitive linguistics renewed interest in the Sapir–Whorf hypothesis. One of those who adopted a more Whorfian approach was George Lakoff. He argued that language is often used metaphorically and that languages use different cultural metaphors that reveal something about how speakers of that language think. For example, English employs conceptual metaphors likening time with money, so that time can be saved and spent and invested, whereas other languages do not talk about time in that way. Other such metaphors are common to many languages because they are based on general human experience, for example, metaphors likening "up" with "good" and "bad" with "down". Lakoff also argued that metaphor plays an important part in political debates such as the "right to life" or the "right to choose"; or "illegal aliens" or "undocumented workers".

In his book "Women, Fire and Dangerous things: What categories reveal about the mind," Lakoff reappraised linguistic relativity and especially Whorf's views about how linguistic categorization reflects and/or influences mental categories. He concluded that the debate had been confused. He described four parameters on which researchers differed in their opinions about what constitutes linguistic relativity:
Lakoff concluded that many of Whorf's critics had criticized him using novel definitions of linguistic relativity, rendering their criticisms moot.

The publication of the 1996 anthology "Rethinking Linguistic Relativity" edited by Gumperz and Levinson began a new period of linguistic relativity studies that focused on cognitive and social aspects. The book included studies on the linguistic relativity and universalist traditions. Levinson documented significant linguistic relativity effects in the linguistic conceptualization of spatial categories between languages. For example, men speaking the Guugu Yimithirr language in Queensland gave accurate navigation instructions using a compass-like system of north, south, east and west, along with a hand gesture pointing to the starting direction.

Separate studies by Bowerman and Slobin treated the role of language in cognitive processes. Bowerman showed that certain cognitive processes did not use language to any significant extent and therefore could not be subject to linguistic relativity. Slobin described another kind of cognitive process that he named "thinking for speaking" – the kind of process in which perceptional data and other kinds of prelinguistic cognition are translated into linguistic terms for communication. These, Slobin argues, are the kinds of cognitive process that are at the root of linguistic relativity.

Researchers such as Boroditsky, Lucy and Levinson believe that language influences thought in more limited ways than the broadest early claims. Researchers examine the interface between thought (or cognition), language and culture and describe the relevant influences. They use experimental data to back up their conclusions. Kay ultimately concluded that "[the] Whorf hypothesis is supported in the right visual field but not the left". His findings show that accounting for brain lateralization offers another perspective.

Psycholinguistic studies explored motion perception, emotion perception, object representation and memory. The gold standard of psycholinguistic studies on linguistic relativity is now finding non-linguistic cognitive differences in speakers of different languages (thus rendering inapplicable Pinker's criticism that linguistic relativity is "circular").

Recent work with bilingual speakers attempts to distinguish the effects of language from those of culture on bilingual cognition including perceptions of time, space, motion, colors and emotion. Researchers described differences between bilinguals and monolinguals in perception of color, representations of time and other elements of cognition.

Lucy identified three main strands of research into linguistic relativity.

The "structure-centered" approach starts with a language's structural peculiarity and examines its possible ramifications for thought and behavior. The defining example is Whorf's observation of discrepancies between the grammar of time expressions in Hopi and English. More recent research in this vein is Lucy's research describing how usage of the categories of grammatical number and of numeral classifiers in the Mayan language Yucatec result in Mayan speakers classifying objects according to material rather than to shape as preferred by English speakers.

The "domain-centered" approach selects a semantic domain and compares it across linguistic and cultural groups. It centered on color terminology, although this domain is acknowledged to be sub-optimal, because color perception, unlike other semantic domains, is hardwired into the neural system and as such is subject to more universal restrictions than other semantic domains.

Space is another semantic domain that has proven fruitful for linguistic relativity studies. Spatial categories vary greatly across languages. Speakers rely on the linguistic conceptualization of space in performing many ordinary tasks. Levinson and others reported three basic spatial categorizations. While many languages use combinations of them, some languages exhibit only one type and related behaviors. For example, Yimithirr only uses absolute directions when describing spatial relations — the position of everything is described by using the cardinal directions. Speakers define a location as "north of the house", while an English speaker may use relative positions, saying "in front of the house" or "to the left of the house".

The "behavior centered" approach starts by comparing behavior across linguistic groups and then searches for causes for that behavior in the linguistic system. Whorf attributed the occurrence of fires at a chemical plant to the workers' use of the word 'empty' to describe the barrels containing only explosive vapors. Bloom noticed that speakers of Chinese had unexpected difficulties answering counter-factual questions posed to them in a questionnaire. He concluded that this was related to the way in which counter-factuality is marked grammatically in Chinese. Other researchers attributed this result to Bloom's flawed translations. Strømnes examined why Finnish factories had a higher occurrence of work related accidents than similar Swedish ones. He concluded that cognitive differences between the grammatical usage of Swedish prepositions and Finnish cases could have caused Swedish factories to pay more attention to the work process while Finnish factory organizers paid more attention to the individual worker.

Everett's work on the Pirahã language of the Brazilian Amazon found several peculiarities that he interpreted as corresponding to linguistically rare features, such as a lack of numbers and color terms in the way those are otherwise defined and the absence of certain types of clauses. Everett's conclusions were met with skepticism from universalists who claimed that the linguistic deficit is explained by the lack of need for such concepts.

Recent research with non-linguistic experiments in languages with different grammatical properties (e.g., languages with and without numeral classifiers or with different gender grammar systems) showed that language differences in human categorization are due to such differences. Experimental research suggests that this linguistic influence on thought diminishes over time, as when speakers of one language are exposed to another.

A study published by the American Psychological Association's Journal of Experimental Psychology claimed that language can influence how one estimates time. The study focused on three groups, those who spoke only Swedish, those who spoke only Spanish and bilingual speakers who spoke both of those languages. Swedish speakers describe time using distance terms like "long" or "short" while Spanish speakers do it using volume related terms like "big" or "small". The researchers asked the participants to estimate how much time had passed while watching a line growing across a screen, or a container being filled, or both. The researchers stated that "When reproducing duration, Swedish speakers were misled by stimulus length, and Spanish speakers were misled by stimulus size/quantity." When the bilinguals were prompted with the word "duración" (the Spanish word for duration) they based their time estimates of how full the containers were, ignoring the growing lines. When prompted with the word "tid" (the Swedish word for duration) they estimated the time elapsed solely by the distance the lines had traveled.

Research continued after Lenneberg/Roberts and Brown/Lenneberg. The studies showed a correlation between color term numbers and ease of recall in both Zuni and English speakers. Researchers attributed this to focal colors having higher codability than less focal colors, and not with linguistic relativity effects. Berlin/Kay found universal typological color principles that are determined by biological rather than linguistic factors. This study sparked studies into typological universals of color terminology. Researchers such as Lucy, Saunders and Levinson argued that Berlin and Kay's study does not refute linguistic relativity in color naming, because of unsupported assumptions in their study (such as whether all cultures in fact have a clearly defined category of "color") and because of related data problems. Researchers such as Maclaury continued investigation into color naming. Like Berlin and Kay, Maclaury concluded that the domain is governed mostly by physical-biological universals.

Linguistic relativity inspired others to consider whether thought could be influenced by manipulating language.

The question bears on philosophical, psychological, linguistic and anthropological questions.

A major question is whether human psychological faculties are mostly innate or whether they are mostly a result of learning, and hence subject to cultural and social processes such as language. The innate view holds that humans share the same set of basic faculties, and that variability due to cultural differences is less important and that the human mind is a mostly biological construction, so that all humans sharing the same neurological configuration can be expected to have similar cognitive patterns.

Multiple alternatives have advocates. The contrary constructivist position holds that human faculties and concepts are largely influenced by socially constructed and learned categories, without many biological restrictions. Another variant is idealist, which holds that human mental capacities are generally unrestricted by biological-material strictures. Another is essentialist, which holds that essential differences may influence the ways individuals or groups experience and conceptualize the world. Yet another is relativist (Cultural relativism), which sees different cultural groups as employing different conceptual schemes that are not necessarily compatible or commensurable, nor more or less in accord with external reality.

Another debate considers whether thought is a form of internal speech or is independent of and prior to language.

In the philosophy of language the question addresses the relations between language, knowledge and the external world, and the concept of truth. Philosophers such as Putnam, Fodor, Davidson, and Dennett see language as representing directly entities from the objective world and that categorization reflect that world. Other philosophers (e.g. Quine, Searle, Foucault) argue that categorization and conceptualization is subjective and arbitrary.

Another question is whether language is a tool for representing and referring to objects in the world, or whether it is a system used to construct mental representations that can be communicated.

Sapir/Whorf contemporary Alfred Korzybski was independently developing his theory of general semantics, which was aimed at using language's influence on thinking to maximize human cognitive abilities. Korzybski's thinking was influenced by logical philosophy such as Russell and Whitehead's "Principia Mathematica" and Wittgenstein's "Tractatus Logico-Philosophicus". Although Korzybski was not aware of Sapir and Whorf's writings, the movement was followed by Whorf-admirer Stuart Chase, who fused Whorf's interest in cultural-linguistic variation with Korzybski's programme in his popular work "The Tyranny of Words". S. I. Hayakawa was a follower and popularizer of Korzybski's work, writing "Language in Thought and Action". The general semantics movement influenced the development of neurolinguistic programming, another therapeutic technique that seeks to use awareness of language use to influence cognitive patterns.

Korzybski independently described a "strong" version of the hypothesis of linguistic relativity.

In their fiction, authors such as Ayn Rand and George Orwell explored how linguistic relativity might be exploited for political purposes. In Rand's "Anthem", a fictive communist society removed the possibility of individualism by removing the word "I" from the language. In Orwell's "1984" the authoritarian state created the language Newspeak to make it impossible for people to think critically about the government, or even to contemplate that they might be impoverished or oppressed, by reducing the number of words to reduce the thought of the locutor.

Others have been fascinated by the possibilities of creating new languages that could enable new, and perhaps better, ways of thinking. Examples of such languages designed to explore the human mind include Loglan, explicitly designed by James Cooke Brown to test the linguistic relativity hypothesis, by experimenting whether it would make its speakers think more logically. Speakers of Lojban, an evolution of Loglan, report that they feel speaking the language enhances their ability for logical thinking. Suzette Haden Elgin, who was involved in the early development of neurolinguistic programming, invented the language Láadan to explore linguistic relativity by making it easier to express what Elgin considered the female worldview, as opposed to Standard Average European languages which she considered to convey a "male centered" world view. John Quijada's language Ithkuil was designed to explore the limits of the number of cognitive categories a language can keep its speakers aware of at once. Similarly, Sonja Lang's Toki Pona was developed according to a Taoist point of view for exploring how (or if) such a language would direct human thought.

APL programming language originator Kenneth E. Iverson believed that the Sapir–Whorf hypothesis applied to computer languages (without actually mentioning it by name). His Turing award lecture, "Notation as a tool of thought", was devoted to this theme, arguing that more powerful notations aided thinking about computer algorithms.

The essays of Paul Graham explore similar themes, such as a conceptual hierarchy of computer languages, with more expressive and succinct languages at the top. Thus, the so-called "blub" paradox (after a hypothetical programming language of average complexity called "Blub") says that anyone preferentially using some particular programming language will "know" that it is more powerful than some, but not that it is less powerful than others. The reason is that "writing" in some language means "thinking" in that language. Hence the paradox, because typically programmers are "satisfied with whatever language they happen to use, because it dictates the way they think about programs".

In a 2003 presentation at an open source convention, Yukihiro Matsumoto, creator of the programming language Ruby, said that one of his inspirations for developing the language was the science fiction novel "Babel-17", based on the Sapir–Whorf Hypothesis.

Ted Chiang's short story "Story of Your Life" developed the concept of the Sapir–Whorf hypothesis as applied to an alien species which visits Earth. The aliens' biology contributes to their spoken and written languages, which are distinct. In the 2016 American film "Arrival", based on Chiang's short story, the Sapir–Whorf hypothesis is the premise. The protagonist explains that "the Sapir–Whorf hypothesis is the theory that the language you speak determines how you think".

In his science fiction novel "The Languages of Pao" the author Jack Vance describes how specialized languages are a major part of a strategy to create specific classes in a society, to enable the population to withstand occupation and develop itself.





</doc>
<doc id="19770" url="https://en.wikipedia.org/wiki?curid=19770" title="Memetics">
Memetics

Memetics is the study of information and culture based on an analogy with Darwinian evolution. Proponents describe memetics as an approach to evolutionary models of cultural information transfer. Memetics describes how an idea can propagate successfully, but doesn't necessarily imply a concept is factual. Critics contend the theory is "untested, unsupported or incorrect".

The term meme was coined in Richard Dawkins' 1976 book "The Selfish Gene," but Dawkins later distanced himself from the resulting field of study. Analogous to a gene, the meme was conceived as a "unit of culture" (an idea, belief, pattern of behaviour, etc.) which is "hosted" in the minds of one or more individuals, and which can reproduce itself in the sense of jumping from the mind of one person to the mind of another. Thus what would otherwise be regarded as one individual influencing another to adopt a belief is seen as an idea-replicator reproducing itself in a new host. As with genetics, particularly under a Dawkinsian interpretation, a meme's success may be due to its contribution to the effectiveness of its host.

The Usenet newsgroup alt.memetics started in 1993 with peak posting years in the mid to late 1990s. The "Journal of Memetics" was published electronically from 1997 to 2005.

In his book "The Selfish Gene" (1976), the evolutionary biologist Richard Dawkins used the term "meme" to describe a unit of human cultural transmission analogous to the gene, arguing that replication also happens in culture, albeit in a different sense. In 1975, Dr. Ted Cloak outlined the "corpuscles of culture" - an inspiring hypothesis that Dawkins referenced. Cultural evolution itself is a much older topic, with a history that dates back at least as far as Darwin's era.

Dawkins (1976) proposed that the meme is a unit of information residing in the brain and is the mutating replicator in human cultural evolution. It is a pattern that can influence its surroundings – that is, it has causal agency – and can propagate. This proposal resulted in debate among sociologists, biologists, and scientists of other disciplines. Dawkins himself did not provide a sufficient explanation of how the replication of units of information in the brain controls human behaviour and ultimately culture, and the principal topic of the book was genetics. Dawkins apparently did not intend to present a comprehensive theory of "memetics" in "The Selfish Gene", but rather coined the term "meme" in a speculative spirit. Accordingly, different researchers came to define the term "unit of information" in different ways.

The evolutionary model of cultural information transfer is based on the concept that units of information, or "memes", have an independent existence, are self-replicating, and are subject to selective evolution through environmental forces. Starting from a proposition put forward in the writings of Richard Dawkins, this model has formed the basis of a new area of study, one that looks at the self-replicating units of culture. It has been proposed that just as memes are analogous to genes, memetics is analogous to genetics.

The modern memetics movement dates from the mid-1980s. A January 1983 "Metamagical Themas" column by Douglas Hofstadter, in "Scientific American", was influential – as was his 1985 book of the same name. "Memeticist" was coined as analogous to "geneticist" – originally in "The Selfish Gene." Later Arel Lucas suggested that the discipline that studies memes and their connections to human and other carriers of them be known as "memetics" by analogy with "genetics". Dawkins' "The Selfish Gene" has been a factor in attracting the attention of people of disparate intellectual backgrounds. Another stimulus was the publication in 1991 of "Consciousness Explained" by Tufts University philosopher Daniel Dennett, which incorporated the meme concept into a theory of the mind. In his 1991 essay "Viruses of the Mind", Richard Dawkins used memetics to explain the phenomenon of religious belief and the various characteristics of organised religions. By then, memetics had also become a theme appearing in fiction (e.g. Neal Stephenson's "Snow Crash").

The idea of "language as a virus" had already been introduced by William S. Burroughs as early as 1962 in his book "The Ticket That Exploded", and later in "The Electronic Revolution", published in 1970 in "". Douglas Rushkoff explored the same concept in "Media Virus: Hidden Agendas in Popular Culture" in 1995.

However, the foundation of memetics in its full modern incarnation originated in the publication in 1996 of two books by authors outside the academic mainstream: "Virus of the Mind: The New Science of the Meme" by former Microsoft executive turned motivational speaker and professional poker-player Richard Brodie, and "Thought Contagion: How Belief Spreads Through Society" by Aaron Lynch, a mathematician and philosopher who worked for many years as an engineer at Fermilab. Lynch claimed to have conceived his theory totally independently of any contact with academics in the cultural evolutionary sphere, and apparently was not aware of "The Selfish Gene" until his book was very close to publication.

Around the same time as the publication of the books by Lynch and Brodie the e-journal Journal of Memetics – "Evolutionary Models of Information Transmission" appeared on the web. It was first hosted by the Centre for Policy Modelling at Manchester Metropolitan University but later taken over by Francis Heylighen of the CLEA research institute at the Vrije Universiteit Brussel. The e-journal soon became the central point for publication and debate within the nascent memeticist community. (There had been a short-lived paper-based memetics publication starting in 1990, the "Journal of Ideas" edited by Elan Moritz.) In 1999, Susan Blackmore, a psychologist at the University of the West of England, published "The Meme Machine", which more fully worked out the ideas of Dennett, Lynch, and Brodie and attempted to compare and contrast them with various approaches from the cultural evolutionary mainstream, as well as providing novel, and controversial, memetics-based theories for the evolution of language and the human sense of individual selfhood.

The term "meme" derives from the Ancient Greek μιμητής ("mimētḗs"), meaning "imitator, pretender". The similar term "mneme" was used in 1904, by the German evolutionary biologist Richard Semon, best known for his development of the engram theory of memory, in his work "Die mnemischen Empfindungen in ihren Beziehungen zu den Originalempfindungen", translated into English in 1921 as "The Mneme". Until Daniel Schacter published "Forgotten Ideas, Neglected Pioneers: Richard Semon and the Story of Memory" in 2000, Semon's work had little influence, though it was quoted extensively in Erwin Schrödinger’s 1956 Tarner Lecture “Mind and Matter”. Richard Dawkins (1976) apparently coined the word "meme" independently of Semon, writing this:
"'Mimeme' comes from a suitable Greek root, but I want a monosyllable that sounds a bit like 'gene'. I hope my classicist friends will forgive me if I abbreviate mimeme to meme. If it is any consolation, it could alternatively be thought of as being related to 'memory', or to the French word même."

The memetics movement split almost immediately into two. The first group were those who wanted to stick to Dawkins' definition of a meme as "a unit of cultural transmission". Gibron Burchett, another memeticist responsible for helping to research and co-coin the term memetic engineering, along with Leveious Rolando and Larry Lottman, has stated that a meme can be defined, more precisely, as "a unit of cultural information that can be copied, located in the brain". This thinking is more in line with Dawkins' second definition of the meme in his book "The Extended Phenotype". The second group wants to redefine memes as observable cultural artifacts and behaviors. However, in contrast to those two positions, Blackmore does not reject either concept of external or internal memes.

These two schools became known as the "internalists" and the "externalists." Prominent internalists included both Lynch and Brodie; the most vocal externalists included Derek Gatherer, a geneticist from Liverpool John Moores University, and William Benzon, a writer on cultural evolution and music. The main rationale for externalism was that internal brain entities are not observable, and memetics cannot advance as a science, especially a quantitative science, unless it moves its emphasis onto the directly quantifiable aspects of culture. Internalists countered with various arguments: that brain states will eventually be directly observable with advanced technology, that most cultural anthropologists agree that culture is about beliefs and not artifacts, or that artifacts cannot be replicators in the same sense as mental entities (or DNA) are replicators. The debate became so heated that a 1998 Symposium on Memetics, organised as part of the 15th International Conference on Cybernetics, passed a motion calling for an end to definitional debates. McNamara demonstrated in 2011 that functional connectivity profiling using neuroimaging tools enables the observation of the processing of internal memes, "i-memes", in response to external "e-memes".

An advanced statement of the internalist school came in 2002 with the publication of "The Electric Meme", by Robert Aunger, an anthropologist from the University of Cambridge. Aunger also organised a conference in Cambridge in 1999, at which prominent sociologists and anthropologists were able to give their assessment of the progress made in memetics to that date. This resulted in the publication of "Darwinizing Culture: The Status of Memetics as a Science", edited by Aunger and with a foreword by Dennett, in 2001.

In 2005, the "Journal of Memetics – Evolutionary Models of Information Transmission" ceased publication and published a set of articles on the future of memetics. The website states that although "there was to be a relaunch...after several years nothing has happened". Susan Blackmore has left the University of the West of England to become a freelance science-writer and now concentrates more on the field of consciousness and cognitive science. Derek Gatherer moved to work as a computer programmer in the pharmaceutical industry, although he still occasionally publishes on memetics-related matters. Richard Brodie is now climbing the world professional poker rankings. Aaron Lynch disowned the memetics community and the words "meme" and "memetics" (without disowning the ideas in his book), adopting the self-description "thought contagionist". He died in 2005.

Susan Blackmore (2002) re-stated the definition of meme as: whatever is copied from one person to another person, whether habits, skills, songs, stories, or any other kind of information. Further she said that memes, like genes, are replicators in the sense as defined by Dawkins.
That is, they are information that is copied. Memes are copied by imitation, teaching and other methods. The copies are not perfect: memes are copied with variation; moreover, they compete for space in our memories and for the chance to be copied again. Only some of the variants can survive. The combination of these three elements (copies; variation; competition for survival) forms precisely the condition for Darwinian evolution, and so memes (and hence human cultures) evolve. Large groups of memes that are copied and passed on together are called co-adapted meme complexes, or "memeplexes". In Blackmore's definition, the way that a meme replicates is through imitation. This requires brain capacity to generally imitate a model or selectively imitate the model. Since the process of social learning varies from one person to another, the imitation process cannot be said to be completely imitated. The sameness of an idea may be expressed with different memes supporting it. This is to say that the mutation rate in memetic evolution is extremely high, and mutations are even possible within each and every iteration of the imitation process. It becomes very interesting when we see that a social system composed of a complex network of microinteractions exists, but at the macro level an order emerges to create culture.

Critics contend that some proponents' assertions are "untested, unsupported or incorrect." Luis Benitez-Bribiesca, a critic of memetics, calls it "a pseudoscientific dogma" and "a dangerous idea that poses a threat to the serious study of consciousness and cultural evolution" among other things. As factual criticism, he refers to the lack of a "code script" for memes, as the DNA is for genes, and to the fact that the meme mutation mechanism (i.e., an idea going from one brain to another) is too unstable (low replication accuracy and high mutation rate), which would render the evolutionary process chaotic. This, however, has been demonstrated (e.g. by Daniel C. Dennett, in "Darwin's Dangerous Idea") to not be the case, in fact, due to the existence of self-regulating correction mechanisms (vaguely resembling those of gene transcription) enabled by the redundancy and other properties of most meme expression languages, which do stabilize information transfer. (E.g. spiritual narratives—including music and dance forms—can survive in full detail across any number of generations even in cultures with oral tradition only.) Memes for which stable copying methods are available will inevitably get selected for survival more often than those which can only have unstable mutations, therefore going extinct.
Another criticism comes from semiotics, (e.g., Deacon, Kull) stating that the concept of meme is a primitivized concept of Sign. Meme is thus described in memetics as a sign without its triadic nature. In other words, meme is a degenerate sign, which includes only its ability of being copied. Accordingly, in the broadest sense, the objects of copying are memes, whereas the objects of translation and interpretation are signs.
Mary Midgley criticizes memetics for at least two reasons: 
Henry Jenkins, Joshua Green, and Sam Ford, in their book "Spreadable Media" (2013), criticize Dawkins' idea of the meme, writing that "while the idea of the meme is a compelling one, it may not adequately account for how content circulates through participatory culture." The three authors also criticize other interpretations of memetics, especially those which describe memes as "self-replicating", because they ignore the fact that "culture is a human product and replicates through human agency."

Like other critics, Maria Kronfeldner has criticized memetics for being based on an allegedly inaccurate analogy with the gene; alternately, she claims it is "heuristically trivial", being a mere redescription of what is already known without offering any useful novelty.








Research methodologies that apply memetics go by many names: Viral marketing, cultural evolution, the history of ideas, social analytics, and more. Many of these applications do not make reference to the literature on memes directly but are built upon the evolutionary lens of idea propagation that treats semantic units of culture as self-replicating and mutating patterns of information that are assumed to be relevant for scientific study. For example, the field of public relations is filled with attempts to introduce new ideas and alter social discourse. One means of doing this is to design a meme and deploy it through various media channels. One historic example of applied memetics is the PR campaign conducted in 1991 as part of the build-up to the first Gulf War in the United States.

The application of memetics to a difficult complex social system problem, environmental sustainability, has recently been attempted at thwink.org Using meme types and memetic infection in several stock and flow simulation models, Jack Harich has demonstrated several interesting phenomena that are best, and perhaps only, explained by memes. One model, The Dueling Loops of the Political Powerplace, argues that the fundamental reason corruption is the norm in politics is due to an inherent structural advantage of one feedback loop pitted against another. Another model, The Memetic Evolution of Solutions to Difficult Problems, uses memes, the evolutionary algorithm, and the scientific method to show how complex solutions evolve over time and how that process can be improved. The insights gained from these models are being used to engineer memetic solution elements to the sustainability problem.

Another application of memetics in the sustainability space is the crowdfunded Climate Meme Project conducted by Joe Brewer and Balazs Laszlo Karafiath in the spring of 2013. This study was based on a collection of 1000 unique text-based expressions gathered from Twitter, Facebook, and structured interviews with climate activists. The major finding was that the global warming meme is not effective at spreading because it causes emotional duress in the minds of people who learn about it. Five central tensions were revealed in the discourse about [climate change], each of which represents a resonance point through which dialogue can be engaged. The tensions were Harmony/Disharmony (whether or not humans are part of the natural world), Survival/Extinction (envisioning the future as either apocalyptic collapse of civilization or total extinction of the human race), Cooperation/Conflict (regarding whether or not humanity can come together to solve global problems), Momentum/Hesitation (about whether or not we are making progress at the collective scale to address climate change), and Elitism/Heretic (a general sentiment that each side of the debate considers the experts of its opposition to be untrustworthy).

Ben Cullen, in his book "Contagious Ideas", brought the idea of the meme into the discipline of archaeology. He coined the term "Cultural Virus Theory", and used it to try to anchor archaeological theory in a neo-Darwinian paradigm. Archaeological memetics could assist the application of the meme concept to material culture in particular.

Francis Heylighen of the Center Leo Apostel for Interdisciplinary Studies has postulated what he calls "memetic selection criteria". These criteria opened the way to a specialized field of "applied memetics" to find out if these selection criteria could stand the test of quantitative analyses. In 2003 Klaas Chielens carried out these tests in a Masters thesis project on the testability of the selection criteria.

In "Selfish Sounds and Linguistic Evolution", Austrian linguist Nikolaus Ritt has attempted to operationalise memetic concepts and use them for the explanation of long term sound changes and change conspiracies in early English. It is argued that a generalised Darwinian framework for handling cultural change can provide explanations where established, speaker centred approaches fail to do so. The book makes comparatively concrete suggestions about the possible material structure of memes, and provides two empirically rich case studies.

Australian academic S.J. Whitty has argued that project management is a memeplex with the language and stories of its practitioners at its core. This radical approach sees a project and its management as an illusion; a human construct about a collection of feelings, expectations, and sensations, which are created, fashioned, and labeled by the human brain. Whitty's approach requires project managers to consider that the reasons for using project management are not consciously driven to maximize profit, and are encouraged to consider project management as naturally occurring, self-serving, evolving process which shapes organizations for its own purpose.

Swedish political scientist Mikael Sandberg argues against "Lamarckian" interpretations of institutional and technological evolution and studies creative innovation of information technologies in governmental and private organizations in Sweden in the 1990s from a memetic perspective. Comparing the effects of active ("Lamarckian") IT strategy versus user–producer interactivity (Darwinian co-evolution), evidence from Swedish organizations shows that co-evolutionary interactivity is almost four times as strong a factor behind IT creativity as the "Lamarckian" IT strategy.




</doc>
<doc id="19312" url="https://en.wikipedia.org/wiki?curid=19312" title="Meme">
Meme

A meme ( ) is an idea, behavior, or style that spreads by means of imitation from person to person within a culture—often with the aim of conveying a particular phenomenon, theme, or meaning represented by the meme. A meme acts as a unit for carrying cultural ideas, symbols, or practices, that can be transmitted from one mind to another through writing, speech, gestures, rituals, or other imitable phenomena with a mimicked theme. Supporters of the concept regard memes as cultural analogues to genes in that they self-replicate, mutate, and respond to selective pressures.

Proponents theorize that memes are a viral phenomenon that may evolve by natural selection in a manner analogous to that of biological evolution. Memes do this through the processes of variation, mutation, competition, and inheritance, each of which influences a meme's reproductive success. Memes spread through the behavior that they generate in their hosts. Memes that propagate less prolifically may become extinct, while others may survive, spread, and (for better or for worse) mutate. Memes that replicate most effectively enjoy more success, and some may replicate effectively even when they prove to be detrimental to the welfare of their hosts.

A field of study called memetics arose in the 1990s to explore the concepts and transmission of memes in terms of an evolutionary model. Criticism from a variety of fronts has challenged the notion that academic study can examine memes empirically. However, developments in neuroimaging may make empirical study possible. Some commentators in the social sciences question the idea that one can meaningfully categorize culture in terms of discrete units, and are especially critical of the biological nature of the theory's underpinnings. Others have argued that this use of the term is the result of a misunderstanding of the original proposal.

The word "meme" is a neologism coined by Richard Dawkins. It originated from Dawkins's 1976 book "The Selfish Gene". Dawkins's own position is somewhat ambiguous: he welcomed N. K. Humphrey's suggestion that "memes should be considered as living structures, not just metaphorically" and proposed to regard memes as "physically residing in the brain". Later, he argued that his original intentions, presumably before his approval of Humphrey's opinion, had been simpler.

The word "meme" is a shortening (modeled on "gene") of "mimeme" (from Ancient Greek "mīmēma", "imitated thing", from "mimeisthai", "to imitate", from "mimos", "mime") coined by British evolutionary biologist Richard Dawkins in "The Selfish Gene" (1976) as a concept for discussion of evolutionary principles in explaining the spread of ideas and cultural phenomena. Examples of memes given in the book included melodies, catchphrases, fashion, and the technology of building arches. Kenneth Pike had in 1954 coined the related terms "emic" and "etic", generalizing the linguistic units of phoneme, morpheme, grapheme, lexeme, and tagmeme (as set out by Leonard Bloomfield), distinguishing insider and outside views of communicative behavior.

The word "meme" originated with Richard Dawkins' 1976 book "The Selfish Gene". Dawkins cites as inspiration the work of geneticist L. L. Cavalli-Sforza, anthropologist F. T. Cloak and ethologist J. M. Cullen. Dawkins wrote that evolution depended not on the particular chemical basis of genetics, but only on the existence of a self-replicating unit of transmission—in the case of biological evolution, the gene. For Dawkins, the meme exemplified another self-replicating unit with potential significance in explaining human behavior and cultural evolution. Although Dawkins invented the term 'meme' and developed meme theory, the possibility that ideas were subject to the same pressures of evolution as were biological attributes was discussed in Darwin's time. T. H. Huxley claimed that 'The struggle for existence holds as much in the intellectual as in the physical world. A theory is a species of thinking, and its right to exist is coextensive with its power of resisting extinction by its rivals.'
Dawkins used the term to refer to any cultural entity that an observer might consider a replicator. He hypothesized that one could view many cultural entities as replicators, and pointed to melodies, fashions and learned skills as examples. Memes generally replicate through exposure to humans, who have evolved as efficient copiers of information and behavior. Because humans do not always copy memes perfectly, and because they may refine, combine or otherwise modify them with other memes to create new memes, they can change over time. Dawkins likened the process by which memes survive and change through the evolution of culture to the natural selection of genes in biological evolution.

Dawkins defined the "meme" as a unit of cultural transmission, or a unit of imitation and replication, but later definitions would vary. The lack of a consistent, rigorous, and precise understanding of what typically makes up one unit of cultural transmission remains a problem in debates about memetics. In contrast, the concept of genetics gained concrete evidence with the discovery of the biological functions of DNA. Meme transmission requires a physical medium, such as photons, sound waves, touch, taste, or smell because memes can be transmitted only through the senses.

Dawkins noted that in a society with culture a person need not have descendants to remain influential in the actions of individuals thousands of years after their death:

But if you contribute to the world's culture, if you have a good idea...it may live on, intact, long after your genes have dissolved in the common pool. Socrates may or may not have a gene or two alive in the world today, as G.C. Williams has remarked, but who cares? The meme-complexes of Socrates, Leonardo, Copernicus and Marconi are still going strong.

Although Dawkins invented the term "meme", he has not claimed that the idea was entirely novel, and there have been other expressions for similar ideas in the past. In 1904, Richard Semon published "Die Mneme" (which appeared in English in 1924 as "The Mneme"). The term "mneme" was also used in Maurice Maeterlinck's "The Life of the White Ant" (1926), with some parallels to Dawkins's concept.

Memes, analogously to genes, vary in their aptitude to replicate; successful memes remain and spread, whereas unfit ones stall and are forgotten. Thus memes that prove more effective at replicating and surviving are selected in the meme pool.

Memes first need retention. The longer a meme stays in its hosts, the higher its chances of propagation are. When a host uses a meme, the meme's life is extended. The reuse of the neural space hosting a certain meme's copy to host different memes is the greatest threat to that meme's copy.

A meme which increases the longevity of its hosts will generally survive longer. On the contrary, a meme which shortens the longevity of its hosts will tend to disappear faster. However, as hosts are mortal, retention is not sufficient to perpetuate a meme in the long term; memes also need transmission.

Life-forms can transmit information both vertically (from parent to child, via replication of genes) and horizontally (through viruses and other means).
Memes can replicate vertically or horizontally within a single biological generation. They may also lie dormant for long periods of time.

Memes reproduce by copying from a nervous system to another one, either by communication or imitation. Imitation often involves the copying of an observed behavior of another individual. Communication may be direct or indirect, where memes transmit from one individual to another through a copy recorded in an inanimate source, such as a book or a musical score. Adam McNamara has suggested that memes can be thereby classified as either internal or external memes (i-memes or e-memes).

Some commentators have likened the transmission of memes to the spread of contagions. Social contagions such as fads, hysteria, copycat crime, and copycat suicide exemplify memes seen as the contagious imitation of ideas. Observers distinguish the contagious imitation of memes from instinctively contagious phenomena such as yawning and laughing, which they consider innate (rather than socially learned) behaviors.

Aaron Lynch described seven general patterns of meme transmission, or "thought contagion":


Dawkins initially defined "meme" as a noun that "conveys the idea of a unit of cultural transmission, or a unit of "imitation"". John S. Wilkins retained the notion of meme as a kernel of cultural imitation while emphasizing the meme's evolutionary aspect, defining the meme as "the least unit of sociocultural information relative to a selection process that has favorable or unfavorable selection bias that exceeds its endogenous tendency to change". The meme as a unit provides a convenient means of discussing "a piece of thought copied from person to person", regardless of whether that thought contains others inside it, or forms part of a larger meme. A meme could consist of a single word, or a meme could consist of the entire speech in which that word first occurred. This forms an analogy to the idea of a gene as a single unit of self-replicating information found on the self-replicating chromosome.

While the identification of memes as "units" conveys their nature to replicate as discrete, indivisible entities, it does not imply that thoughts somehow become quantized or that "atomic" ideas exist that cannot be dissected into smaller pieces. A meme has no given size. Susan Blackmore writes that melodies from Beethoven's symphonies are commonly used to illustrate the difficulty involved in delimiting memes as discrete units. She notes that while the first four notes of Beethoven's Fifth Symphony () form a meme widely replicated as an independent unit, one can regard the entire symphony as a single meme as well.

The inability to pin an idea or cultural feature to quantifiable key units is widely acknowledged as a problem for memetics. It has been argued however that the traces of memetic processing can be quantified utilizing neuroimaging techniques which measure changes in the connectivity profiles between brain regions." Blackmore meets such criticism by stating that memes compare with genes in this respect: that while a gene has no particular size, nor can we ascribe every phenotypic feature directly to a particular gene, it has value because it encapsulates that key unit of inherited expression subject to evolutionary pressures. To illustrate, she notes evolution selects for the gene for features such as eye color; it does not select for the individual nucleotide in a strand of DNA. Memes play a comparable role in understanding the evolution of imitated behaviors.

The 1981 book "Genes, Mind, and Culture: The Coevolutionary Process" by Charles J. Lumsden and E. O. Wilson proposed the theory that genes and culture co-evolve, and that the fundamental biological units of culture must correspond to neuronal networks that function as nodes of semantic memory. They coined their own word, "culturgen", which did not catch on. Coauthor Wilson later acknowledged the term "meme" as the best label for the fundamental unit of cultural inheritance in his 1998 book "", which elaborates upon the fundamental role of memes in unifying the natural and social sciences.

Dawkins noted the three conditions that must exist for evolution to occur:
Dawkins emphasizes that the process of evolution naturally occurs whenever these conditions co-exist, and that evolution does not apply only to organic elements such as genes. He regards memes as also having the properties necessary for evolution, and thus sees meme evolution as not simply analogous to genetic evolution, but as a real phenomenon subject to the laws of natural selection. Dawkins noted that as various ideas pass from one generation to the next, they may either enhance or detract from the survival of the people who obtain those ideas, or influence the survival of the ideas themselves. For example, a certain culture may develop unique designs and methods of tool-making that give it a competitive advantage over another culture. Each tool-design thus acts somewhat similarly to a biological gene in that some populations have it and others do not, and the meme's function directly affects the presence of the design in future generations. In keeping with the thesis that in evolution one can regard organisms simply as suitable "hosts" for reproducing genes, Dawkins argues that one can view people as "hosts" for replicating memes. Consequently, a successful meme may or may not need to provide any benefit to its host.

Unlike genetic evolution, memetic evolution can show both Darwinian and Lamarckian traits. Cultural memes will have the characteristic of Lamarckian inheritance when a host aspires to replicate the given meme through inference rather than by exactly copying it. Take for example the case of the transmission of a simple skill such as hammering a nail, a skill that a learner imitates from watching a demonstration without necessarily imitating every discrete movement modeled by the teacher in the demonstration, stroke for stroke. Susan Blackmore distinguishes the difference between the two modes of inheritance in the evolution of memes, characterizing the Darwinian mode as "copying the instructions" and the Lamarckian as "copying the product."

Clusters of memes, or "memeplexes" (also known as "meme complexes" or as "memecomplexes"), such as cultural or political doctrines and systems, may also play a part in the acceptance of new memes. Memeplexes comprise groups of memes that replicate together and coadapt. Memes that fit within a successful memeplex may gain acceptance by "piggybacking" on the success of the memeplex.
As an example, John D. Gottsch discusses the transmission, mutation and selection of religious memeplexes and the theistic memes contained. Theistic memes discussed include the "prohibition of aberrant sexual practices such as incest, adultery, homosexuality, bestiality, castration, and religious prostitution", which may have increased vertical transmission of the parent religious memeplex. Similar memes are thereby included in the majority of religious memeplexes, and harden over time; they become an "inviolable canon" or set of dogmas, eventually finding their way into secular law. This could also be referred to as the propagation of a taboo.

The discipline of memetics, which dates from the mid-1980s, provides an approach to evolutionary models of cultural information transfer based on the concept of the meme. Memeticists have proposed that just as memes function analogously to genes, memetics functions analogously to genetics. Memetics attempts to apply conventional scientific methods (such as those used in population genetics and epidemiology) to explain existing patterns and transmission of cultural ideas.

Principal criticisms of memetics include the claim that memetics ignores established advances in other fields of cultural study, such as sociology, cultural anthropology, cognitive psychology, and social psychology. Questions remain whether or not the meme concept counts as a validly disprovable scientific theory. This view regards memetics as a theory in its infancy: a protoscience to proponents, or a pseudoscience to some detractors.

An objection to the study of the evolution of memes in genetic terms (although not to the existence of memes) involves a perceived gap in the gene/meme analogy: the cumulative evolution of genes depends on biological selection-pressures neither too great nor too small in relation to mutation-rates. There seems no reason to think that the same balance will exist in the selection pressures on memes.

Luis Benitez-Bribiesca M.D., a critic of memetics, calls the theory a "pseudoscientific dogma" and "a dangerous idea that poses a threat to the serious study of consciousness and cultural evolution". As a factual criticism, Benitez-Bribiesca points to the lack of a "code script" for memes (analogous to the DNA of genes), and to the excessive instability of the meme mutation mechanism (that of an idea going from one brain to another), which would lead to a low replication accuracy and a high mutation rate, rendering the evolutionary process chaotic.

British political philosopher John Gray has characterized Dawkins's memetic theory of religion as "nonsense" and "not even a theory... the latest in a succession of ill-judged Darwinian metaphors", comparable to Intelligent Design in its value as a science.

Another critique comes from semiotic theorists such as Deacon and Kull. This view regards the concept of "meme" as a primitivized concept of "sign". The meme is thus described in memetics as a sign lacking a triadic nature. Semioticians can regard a meme as a "degenerate" sign, which includes only its ability of being copied. Accordingly, in the broadest sense, the objects of copying are memes, whereas the objects of translation and interpretation are signs.

Fracchia and Lewontin regard memetics as reductionist and inadequate. Evolutionary biologist Ernst Mayr disapproved of Dawkins's gene-based view and usage of the term "meme", asserting it to be an "unnecessary synonym" for "concept", reasoning that concepts are not restricted to an individual or a generation, may persist for long periods of time, and may evolve.

Opinions differ as to how best to apply the concept of memes within a "proper" disciplinary framework. One view sees memes as providing a useful philosophical perspective with which to examine cultural evolution. Proponents of this view (such as Susan Blackmore and Daniel Dennett) argue that considering cultural developments from a meme's-eye view—"as if" memes themselves respond to pressure to maximise their own replication and survival—can lead to useful insights and yield valuable predictions into how culture develops over time. Others such as Bruce Edmonds and Robert Aunger have focused on the need to provide an empirical grounding for memetics to become a useful and respected scientific discipline.

A third approach, described by Joseph Poulshock, as "radical memetics" seeks to place memes at the centre of a materialistic theory of mind and of personal identity.

Prominent researchers in evolutionary psychology and anthropology, including Scott Atran, Dan Sperber, Pascal Boyer, John Tooby and others, argue the possibility of incompatibility between modularity of mind and memetics. In their view, minds structure certain communicable aspects of the ideas produced, and these communicable aspects generally trigger or elicit ideas in other minds through inference (to relatively rich structures generated from often low-fidelity input) and not high-fidelity replication or imitation. Atran discusses communication involving religious beliefs as a case in point. In one set of experiments he asked religious people to write down on a piece of paper the meanings of the Ten Commandments. Despite the subjects' own expectations of consensus, interpretations of the commandments showed wide ranges of variation, with little evidence of consensus. In another experiment, subjects with autism and subjects without autism interpreted ideological and religious sayings (for example, "Let a thousand flowers bloom" or "To everything there is a season"). People with autism showed a significant tendency to closely paraphrase and repeat content from the original statement (for example: "Don't cut flowers before they bloom"). Controls tended to infer a wider range of cultural meanings with little replicated content (for example: "Go with the flow" or "Everyone should have equal opportunity"). Only the subjects with autism—who lack the degree of inferential capacity normally associated with aspects of theory of mind—came close to functioning as "meme machines".

In his book "The Robot's Rebellion", Stanovich uses the memes and memeplex concepts to describe a program of cognitive reform that he refers to as a "rebellion". Specifically, Stanovich argues that the use of memes as a descriptor for cultural units is beneficial because it serves to emphasize transmission and acquisition properties that parallel the study of epidemiology. These properties make salient the sometimes parasitic nature of acquired memes, and as a result individuals should be motivated to reflectively acquire memes using what he calls a "Neurathian bootstrap" process.

Although social scientists such as Max Weber sought to understand and explain religion in terms of a cultural attribute, Richard Dawkins called for a re-analysis of religion in terms of the evolution of self-replicating ideas "apart from" any resulting biological advantages they might bestow.
He argued that the role of key replicator in cultural evolution belongs not to genes, but to memes replicating thought from person to person by means of imitation. These replicators respond to selective pressures that may or may not affect biological reproduction or survival.

In her book "The Meme Machine", Susan Blackmore regards religions as particularly tenacious memes. Many of the features common to the most widely practiced religions provide built-in advantages in an evolutionary context, she writes. For example, religions that preach of the value of faith over evidence from everyday experience or reason inoculate societies against many of the most basic tools people commonly use to evaluate their ideas. By linking altruism with religious affiliation, religious memes can proliferate more quickly because people perceive that they can reap societal as well as personal rewards. The longevity of religious memes improves with their documentation in revered religious texts.

Aaron Lynch attributed the robustness of religious memes in human culture to the fact that such memes incorporate multiple modes of meme transmission. Religious memes pass down the generations from parent to child and across a single generation through the meme-exchange of proselytism. Most people will hold the religion taught them by their parents throughout their life. Many religions feature adversarial elements, punishing apostasy, for instance, or demonizing infidels. In "Thought Contagion" Lynch identifies the memes of transmission in Christianity as especially powerful in scope. Believers view the conversion of non-believers both as a religious duty and as an act of altruism. The promise of heaven to believers and threat of hell to non-believers provide a strong incentive for members to retain their belief. Lynch asserts that belief in the Crucifixion of Jesus in Christianity amplifies each of its other replication advantages through the indebtedness believers have to their Savior for sacrifice on the cross. The image of the crucifixion recurs in religious sacraments, and the proliferation of symbols of the cross in homes and churches potently reinforces the wide array of Christian memes.

Although religious memes have proliferated in human cultures, the modern scientific community has been relatively resistant to religious belief. Robertson (2007) reasoned that if evolution is accelerated in conditions of propagative difficulty, then we would expect to encounter variations of religious memes, established in general populations, addressed to scientific communities. Using a memetic approach, Robertson deconstructed two attempts to privilege religiously held spirituality in scientific discourse. Advantages of a memetic approach as compared to more traditional "modernization" and "supply side" theses in understanding the evolution and propagation of religion were explored.

In "Cultural Software: A Theory of Ideology", Jack Balkin argued that memetic processes can explain many of the most familiar features of ideological thought. His theory of "cultural software" maintained that memes form narratives, social networks, metaphoric and metonymic models, and a variety of different mental structures. Balkin maintains that the same structures used to generate ideas about free speech or free markets also serve to generate racistic beliefs. To Balkin, whether memes become harmful or maladaptive depends on the environmental context in which they exist rather than in any special source or manner to their origination. Balkin describes racist beliefs as "fantasy" memes that become harmful or unjust "ideologies" when diverse peoples come together, as through trade or competition.

In "A Theory of Architecture", Nikos Salingaros speaks of memes as "freely propagating clusters of information" which can be beneficial or harmful. He contrasts memes to patterns and true knowledge, characterizing memes as "greatly simplified versions of patterns" and as "unreasoned matching to some visual or mnemonic prototype". Taking reference to Dawkins, Salingaros emphasizes that they can be transmitted due to their own communicative properties, that "the simpler they are, the faster they can proliferate", and that the most successful memes "come with a great psychological appeal".

Architectural memes, according to Salingaros, can have destructive power. "Images portrayed in architectural magazines representing buildings that could not possibly accommodate everyday uses become fixed in our memory, so we reproduce them unconsciously." He lists various architectural memes that circulated since the 1920s and which, in his view, have led to contemporary architecture becoming quite decoupled from human needs. They lack connection and meaning, thereby preventing "the creation of true connections necessary to our understanding of the world". He sees them as no different from antipatterns in software design—as solutions that are false but are re-utilized nonetheless.

An "Internet meme" is a concept that spreads rapidly from person to person via the Internet, largely through Internet-based E-mailing, blogs, forums, imageboards like 4chan, social networking sites like Facebook, Instagram, or Twitter, instant messaging, social news sites or thread sites like Reddit, and video hosting services like YouTube and Twitch.

In 2013, Richard Dawkins characterized an Internet meme as one deliberately altered by human creativity, distinguished from Dawkins's original idea involving mutation "by random change and a form of Darwinian selection".




</doc>
<doc id="630795" url="https://en.wikipedia.org/wiki?curid=630795" title="Ecstasy (emotion)">
Ecstasy (emotion)

Ecstasy (from Ancient Greek ἔκστασις "ékstasis", meaning 'outside of oneself') is a subjective experience of total involvement of the subject, with an object of their awareness. In classical Greek literature it refers to removal of the mind or body "from its normal place of function."

Total involvement with an object of interest is not an ordinary experience because of being aware of other objects, thus ecstasy is an example of an altered state of consciousness characterized by diminished awareness of other objects or the total lack of the awareness of surroundings and everything around the object. The word is also used to refer to any heightened state of consciousness or intensely pleasant experience. It is also used more specifically to denote states of awareness of non-ordinary mental spaces, which may be perceived as spiritual (the latter type of ecstasy often takes the form of religious ecstasy).

From a psychological perspective, ecstasy is a loss of self-control and sometimes a temporary loss of consciousness, which is often associated with religious mysticism, sexual intercourse and the use of certain drugs.
For the duration of the ecstasy the ecstatic is out of touch with ordinary life and is capable neither of communication with other people nor of undertaking normal actions. The experience can be brief in physical time, or it can go on for hours. Subjective perception of time, space or self may strongly change or disappear during ecstasy. For instance, if one is concentrating on a physical task, then any intellectual thoughts may cease. On the other hand, making a spirit journey in an ecstatic trance involves the cessation of voluntary bodily movement.

Ecstasy can be deliberately induced using religious or creative activities, meditation, music, dancing, breathing exercises, physical exercise, sexual intercourse or consumption of psychotropic drugs. The particular technique that an individual uses to induce ecstasy is usually also associated with that individual's particular religious and cultural traditions. Sometimes an ecstatic experience takes place due to occasional contact with something or somebody perceived as extremely beautiful or holy, or without any known reason. "In some cases, a person might obtain an ecstatic experience 'by mistake'. Maybe the person unintentionally triggers one of the, probably many, physiological mechanisms through which such an experience can be reached. In such cases, it is not rare to find that the person later, by reading, looks for an interpretation and maybe finds it within a tradition."

People interpret the experience afterward according to their culture and beliefs (as a revelation from God, a trip to the world of spirits or a psychotic episode). "When a person is using an ecstasy technique, he usually does so within a tradition. When he reaches an experience, a traditional interpretation of it already exists." The experience together with its subsequent interpretation may strongly and permanently change the value system and the worldview of the subject (e.g. to cause religious conversion).

In 1925, James Leuba wrote: "Among most uncivilized populations, as among civilized peoples, certain ecstatic conditions are regarded as divine possession or as union with the Divine. These states are induced by means of drugs, by physical excitement, or by psychical means. But, however produced and at whatever level of culture they may be found, they possess certain common features which suggest even to the superficial observer some profound connection. Always described as delightful beyond expression, these awesome ecstatic experiences end commonly in mental quiescence or even in total unconsciousness." He prepares his readers "... to recognize a continuity of impulse, of purpose, of form and of result between the ecstatic intoxication of the savage and the absorption in God of the Christian mystic."

"In everyday language, the word 'ecstasy' denotes an intense, euphoric experience. For obvious reasons, it is rarely used in a scientific context; it is a concept that is extremely hard to define."




</doc>
<doc id="4849201" url="https://en.wikipedia.org/wiki?curid=4849201" title="Object of the mind">
Object of the mind

An object of the mind is an object that exists in the imagination, but which, in the real world, can only be represented or modeled. Some such objects are abstractions, literary concepts, or fictional scenarios.

Closely related are intentional objects, which are what thoughts and feelings are about, even if they are not about anything real (such as thoughts 
about unicorns, or feelings of apprehension about a dental appointment which is subsequently cancelled). However, intentional objects may coincide with real objects (as in thoughts about horses, or a feeling of regret about a missed appointment).

Mathematics and geometry describe abstract objects that sometimes correspond to familiar shapes, and sometimes do not. Circles, triangles, rectangles, and so forth describe two-dimensional shapes that are often found in the real world. However, mathematical formulas do not describe individual physical circles, triangles, or rectangles. They describe ideal shapes that are objects of the mind. The incredible precision of mathematical expression permits a vast applicability of mental abstractions to real life situations.

Many more mathematical formulas describe shapes that are unfamiliar, or do not necessarily correspond to objects in the real world. For example, the Klein bottle is a one-sided, sealed surface with no inside or outside (in other words, it is the three-dimensional equivalent of the Möbius strip). Such objects can be represented by twisting and cutting or taping pieces of paper together, as well as by computer simulations. To hold them in the imagination, abstractions such as extra or fewer dimensions are necessary.

If-then arguments posit logical sequences that sometimes include objects of the mind. For example, a counterfactual argument proposes a hypothetical or subjunctive possibility which "could" or "would" be true, but "might not" be false. Conditional sequences involving subjunctives use intensional language, which is studied by modal logic, whereas classical logic studies the extensional language of necessary and sufficient conditions.

In general, a logical antecedent is a sufficient condition, and a logical consequent is a necessary condition (or the contingency) in a logical conditional. But logical conditionals accounting only for necessity and sufficiency do not always reflect every day if-then reasoning, and for this reason they are sometimes known as material conditionals. In contrast, indicative conditionals, sometimes known as non-material conditionals, attempt to describe if-then reasoning involving hypotheticals, fictions, or counterfactuals.

Truth tables for if-then statements identify four unique combinations of premises and conclusions: true premises and true conclusions; false premises and true conclusions; true premises and false conclusions; false premises and false conclusions. Strict conditionals assign a positive truth-value to every case except the case of a true premise and a false conclusion. This is sometimes regarded as counterintuitive, but makes more sense when false conditions are understood as objects of the mind.

A false antecedent is a premise known to be false, fictional, imaginary, or unnecessary. In a conditional sequence, a false antecedent may be the basis for any consequence, true or false.

The subjects of literature are sometimes false antecedents. For instance, the contents of false documents, the origins of stand-alone phenomena, or the implications of loaded words. Moreover, artificial sources, personalities, events, and histories. False antecedents are sometimes referred to as "nothing", or "nonexistent", whereas nonexistent referents are not referred to.

Art and acting often portray scenarios without any antecedent other than an artist's imagination. For example, mythical heroes, legendary creatures, gods and goddesses.

A false consequent, in contrast, is a conclusion known to be false, fictional, imaginary, or insufficient. In a conditional statement, a fictional conclusion is known as a non sequitur, which literally means "out of sequence". A conclusion that is out of sequence is not contingent on any premises that precede it, and it does not follow from them, so such a sequence is not conditional. A conditional sequence is a connected series of statements. A false consequent cannot follow from true premises in a connected sequence. But, on the other hand, a false consequent can follow from a false antecedent.

As an example, the name of a team, a genre, or a nation is a collective term applied ex post facto to a group of distinct individuals. None of the individuals on a sports team is the team itself, nor is any musical chord a genre, nor any person America. The name is an identity for a collection that is connected by consensus or reference, but not by sequence. A different name could equally follow, but it would have different social or political significance.

In philosophy, mind-body dualism is the doctrine that mental activities exist apart from the physical body, notably posited by René Descartes in "Meditations on First Philosophy".

Many objects in fiction follow the example of false antecedents or false consequents. For example, "The Lord of the Rings" by J.R.R. Tolkien is based on an imaginary book. In the "Appendices" to "The Lord of the Rings", Tolkien's characters name the "Red Book of Westmarch" as the source material for "The Lord of the Rings", which they describe as a translation. But the "Red Book of Westmarch" is a fictional document that chronicles events in an imaginary world. One might imagine a different translation, by another author.

Social reality is composed of many standards and inventions that facilitate communication, but which are ultimately objects of the mind. For example, money is an object of the mind which currency represents. Similarly, languages signify ideas and thoughts.

Objects of the mind are frequently involved in the roles that people play. For example, acting is a profession which predicates real jobs on fictional premises. Charades is a game people play by guessing imaginary objects from short play-acts.

Imaginary personalities and histories are sometimes invented to enhance the verisimilitude of fictional universes, and/or the immersion of role-playing games. In the sense that they exist independently of extant personalities and histories, they are believed to be fictional characters and fictional time frames.

Science fiction is abundant with future times, alternate times, and past times that are objects of the mind. For example, in the novel "Nineteen Eighty-Four" by George Orwell, the number 1984 represented a year that had not yet passed.

Calendar dates also represent objects of the mind, specifically, past and future times. In "", which was released in 1986, the narration opens with the statement, "It is the year 2005." In 1986, that statement was futuristic. During the year 2005, that reference to the year 2005 was factual. Now, "The Transformers: The Movie" is retro-futuristic. The number 2005 did not change, but the object of the mind that it represents did change.

Deliberate invention also may reference an object of the mind. The intentional invention of fiction for the purpose of deception is usually referred to as lying, in contrast to invention for entertainment or art. Invention is also often applied to problem solving. In this sense the physical invention of materials is associated with the mental invention of fictions.

Convenient fictions also occur in science.

The theoretical posits of one era's scientific theories may be demoted to mere objects of the mind by subsequent discoveries: some standard examples include phlogiston and ptolemaic epicycles.

This raises questions, in the debate between scientific realism and instrumentalism about the status of current posits, such as black holes and quarks. Are they still merely intentional, even if the theory is correct?

The situation is further complicated by the existence in scientific practice of entities which are explicitly held not to be real, but which nonetheless serve a purpose—convenient fictions. Examples include field lines, centers of gravity, and electron holes in semiconductor theory.

A reference that names an imaginary source is in some sense also a self-reference. A self-reference automatically makes a comment about itself. Premises that name themselves as premises are premises by self-reference; conclusions that name themselves as conclusions are conclusions by self-reference.

In their respective imaginary worlds the "Necronomicon", "The Hitchhiker's Guide to the Galaxy", and the "Red Book of Westmarch" are realities, but only because they are referred to as real. Authors use this technique to invite readers to pretend or to make-believe that their imaginary world is real. In the sense that the stories that quote these books are true, the quoted books exist; in the sense that the stories are fiction, the quoted books do not exist.

Austrian philosopher Alexius Meinong (1853–1920) advanced nonexistent objects in the 19th and 20th century within a “theory of objects”. He was interested in intentional states which are directed at nonexistent objects. Starting with the “principle of intentionality”, mental phenomena are intentionally directed towards an object. People may imagine, desire or fear something that does not exist. Other philosophers concluded that intentionality is not a real relation and therefore does not require the existence of an object, while Meinong concluded there is an object for every mental state whatsoever—if not an existent then at least a nonexistent one.




</doc>
<doc id="184483" url="https://en.wikipedia.org/wiki?curid=184483" title="Intentionality">
Intentionality

Intentionality is a philosophical concept defined as "the power of minds to be about, to represent, or to stand for, things, properties and states of affairs". The idea fell out of discussion with the end of the medieval scholastic period, but in recent times was resurrected by Franz Brentano and later adopted by Edmund Husserl. Today, intentionality is a live concern among philosophers of mind and language. The earliest theory of intentionality is associated with St. Anselm's ontological argument for the existence of God, and with his tenets distinguishing between objects that exist in the understanding and objects that exist in reality.

The concept of intentionality was reintroduced in 19th-century contemporary philosophy by Franz Brentano (a German philosopher and psychologist who is generally regarded as the founder of act psychology, also called intentionalism) in his work "Psychology from an Empirical Standpoint" (1874). Brentano described intentionality as a characteristic of all acts of consciousness that are thus "psychical" or "mental" phenomena, by which they may be set apart from "physical" or "natural" phenomena.
Brentano coined the expression "intentional inexistence" to indicate the peculiar ontological status of the contents of mental phenomena. According to some interpreters the "in-" of "in-existence" is to be read as locative, i.e. as indicating that "an intended object ... exists in or has "in-existence", existing not externally but in the psychological state" (Jacquette 2004, p. 102), while others are more cautious, stating: "It is not clear whether in 1874 this ... was intended to carry any ontological commitment" (Chrudzimski and Smith 2004, p. 205).

A major problem within discourse on intentionality is that participants often fail to make explicit whether or not they use the term to imply concepts such as agency or desire, i.e. whether it involves teleology. Dennett (see below) explicitly invokes teleological concepts in the "intentional stance". However, most philosophers use "intentionality" to mean something with no teleological import. Thus, a thought of a chair can be about a chair without any implication of an intention or even a belief relating to the chair. For philosophers of language, what is meant by intentionality is largely an issue of how symbols can have meaning. This lack of clarity may underpin some of the differences of view indicated below.

To bear out further the diversity of sentiment evoked from the notion of intentionality, Husserl followed on Brentano, and gave the concept of intentionality more widespread attention, both in continental and analytic philosophy. In contrast to Brentano's view, French philosopher Jean-Paul Sartre ("Being and Nothingness") identified intentionality with consciousness, stating that the two were indistinguishable. German philosopher Martin Heidegger ("Being and Time"), defined intentionality as "care" ("Sorge"), a sentient condition where an individual's existence, facticity, and being in the world identifies their ontological significance, in contrast to that which is merely ontic ("thinghood").

Other 20th-century philosophers such as Gilbert Ryle and A.J. Ayer were critical of Husserl's concept of intentionality and his many layers of consciousness. Ryle insisted that perceiving is not a process, and Ayer that describing one's knowledge is not to describe mental processes. The effect of these positions is that consciousness is so fully intentional that the mental act has been emptied of all content, and that the idea of pure consciousness is that it is nothing. (Sartre also referred to "consciousness" as "nothing").

Platonist Roderick Chisholm has revived the Brentano thesis through linguistic analysis, distinguishing two parts to Brentano's concept, the ontological aspect and the psychological aspect. Chisholm's writings have attempted to summarize the suitable and unsuitable criteria of the concept since the Scholastics, arriving at a criterion of intentionality identified by the two aspects of Brentano's thesis and defined by the logical properties that distinguish language describing psychological phenomena from language describing non-psychological phenomena. Chisholm's criteria for the intentional use of sentences are: existence independence, truth-value indifference, and referential opacity.

In current artificial intelligence and philosophy of mind, intentionality is sometimes linked with questions of semantic inference, with both skeptical and supportive adherents. John Searle argued for this position with the Chinese room thought experiment, according to which no syntactic operations that occurred in a computer would provide it with semantic content. Others are more skeptical of the human ability to make such an assertion, arguing that the kind of intentionality that emerges from self-organizing networks of automata will always be undecidable because it will never be possible to make our subjective introspective experience of intentionality and decision making coincide with our objective observation of the behavior of a self-organizing machine.

Daniel Dennett offers a taxonomy of the current theories about intentionality in Chapter 10 of his book "The Intentional Stance". Most, if not all, current theories on intentionality accept Brentano's thesis of the irreducibility of intentional idiom. From this thesis the following positions emerge:

Roderick Chisholm (1956), G.E.M. Anscombe (1957), Peter Geach (1957), and Charles Taylor (1964) all adhere to the former position, namely that intentional idiom is problematic and cannot be integrated with the natural sciences. Members of this category also maintain realism in regard to intentional objects, which may imply some kind of dualism (though this is debatable).

The latter position, which maintains the unity of intentionality with the natural sciences, is further divided into three standpoints:

Proponents of the eliminative materialism, understand intentional idiom, such as "belief", "desire", and the like, to be replaceable either with behavioristic language (e.g. Quine) or with the language of neuroscience (e.g. Churchland).

Holders of realism argue that there is a deeper fact of the matter to both translation and belief attribution. In other words, manuals for translating one language into another cannot be set up in different yet behaviorally identical ways and ontologically there are intentional objects. Famously, Fodor has attempted to ground such realist claims about intentionality in a language of thought. Dennett comments on this issue, Fodor "attempt[s] to make these irreducible realities acceptable to the physical sciences by grounding them (somehow) in the 'syntax' of a system of physically realized mental representations" (Dennett 1987, 345).

Those who adhere to the so-called Quinean double standard (namely that "ontologically there is nothing intentional, but that the language of intentionality is indispensable"), accept Quine's thesis of the indeterminacy of radical translation and its implications, while the other positions so far mentioned do not. As Quine puts it, indeterminacy of radical translation is the thesis that "manuals for translating one language into another can be set up in divergent ways, all compatible with the totality of speech dispositions, yet incompatible with one another" (Quine 1960, 27). Quine (1960) and Wilfrid Sellars (1958) both comment on this intermediary position. One such implication would be that there is, in principle, no deeper fact of the matter that could settle two interpretative strategies on what belief to attribute to a physical system. In other words, the behavior (including speech dispositions) of any physical system, in theory, could be interpreted by two different predictive strategies and both would be equally warranted in their belief attribution. This category can be seen to be a medial position between the realists and the eliminativists since it attempts to blend attributes of both into a theory of intentionality. Dennett, for example, argues in "True Believers" (1981) that intentional idiom (or "folk psychology") is a predictive strategy and if such a strategy successfully and voluminously predicts the actions of a physical system, then that physical system can be said to have those beliefs attributed to it. Dennett calls this predictive strategy the intentional stance.

They are further divided into two theses:

Advocates of the former, the Normative Principle, argue that attributions of intentional idioms to physical systems should be the propositional attitudes that the physical system ought to have in those circumstances (Dennett 1987, 342). However, exponents of this view are still further divided into those who make an Assumption of Rationality and those who adhere to the Principle of Charity. Dennett (1969, 1971, 1975), Cherniak (1981, 1986), and the more recent work of Putnam (1983) recommend the Assumption of Rationality, which unsurprisingly assumes that the physical system in question is rational. Donald Davidson (1967, 1973, 1974, 1985) and Lewis (1974) defend the Principle of Charity.

The latter is advocated by Grandy (1973) and Stich (1980, 1981, 1983, 1984), who maintain that attributions of intentional idioms to any physical system (e.g. humans, artifacts, non-human animals, etc.) should be the propositional attitude (e.g. "belief", "desire", etc.) that one would suppose one would have in the same circumstances (Dennett 1987, 343).

Working on the intentionality of vision, belief, and knowledge, Pierre Le Morvan (2005) has distinguished between three basic kinds of intentionality that he dubs "transparent", "translucent", and "opaque" respectively. The threefold distinction may be explained as follows. Let's call the "intendum" what an intentional state is about, and the "intender" the subject who is in the intentional state. An intentional state is transparent if it satisfies the following two conditions: (i) it is genuinely relational in that it entails the existence of not just the intender but the intendum as well, and (ii) substitutivity of identicals applies to the intendum (i.e. if the intentional state is about a, and a = b, then the intentional state is about b as well). An intentional state is translucent if it satisfies (i) but not (ii). An intentional state is opaque if it satisfies neither (i) nor (ii).

The claim that all mental states are intentional is called intentionalism, the contrary being anti-intentionalism.

Some anti-intentionalism, such as that of Ned Block, is based on the argument that phenomenal conscious experience or qualia is also a vital component of consciousness, and that it is not intentional. (The latter claim is itself disputed by Michael Tye.)

Another form of anti-intentionalism associated with John Searle regards phenomenality itself as the "mark of the mental" and sidelines intentionality.

A further form argues that some unusual states of consciousness are non-intentional, although an individual might live a lifetime without experiencing them. Robert K.C. Forman argues that some of the unusual states of consciousness typical of mystical experience are pure consciousness events in which awareness exists, but has no object, is not awareness "of" anything.

Several authors have attempted to construct philosophical models describing how intentionality relates to the human capacity to be self-conscious. Cedric Evans contributed greatly to the discussion with his "The Subject of Self-Consciousness" in 1970. He centered his model on the idea that executive attention need not be propositional in form.





</doc>
<doc id="89532" url="https://en.wikipedia.org/wiki?curid=89532" title="Identity (philosophy)">
Identity (philosophy)

In philosophy, identity, from ("sameness"), is the relation each thing bears only to itself. The notion of identity gives rise to many philosophical problems, including the identity of indiscernibles (if "x" and "y" share all their properties, are they one and the same thing?), and questions about change and personal identity over time (what has to be the case for a person "x" at one time and a person "y" at a later time to be one and the same person?).

The philosophical concept of identity is distinct from the more well-known notion of identity in use in psychology and the social sciences. The philosophical concept concerns a "relation", specifically, a relation that "x" and "y" stand in if, and only if they are one and the same thing, or "identical to" each other (i.e. if, and only if "x" = "y"). The sociological notion of identity, by contrast, has to do with a person's self-conception, social presentation, and more generally, the aspects of a person that make them unique, or qualitatively different from others (e.g. cultural identity, gender identity, national identity, online identity and processes of identity formation).

Metaphysicians and philosophers of language and mind ask other questions:
The law of identity originates from classical antiquity. The modern formulation of identity is that of Gottfried Leibniz, who held that "x" is the same as "y" if and only if every predicate true of "x" is true of "y" as well.

Leibniz's ideas have taken root in the philosophy of mathematics, where they have influenced the development of the predicate calculus as Leibniz's law. Mathematicians sometimes distinguish identity from equality. More mundanely, an "identity" in mathematics may be an "equation" that holds true for all values of a variable. Hegel argued that things are inherently self-contradictory and that the notion of something being self-identical only made sense if it were not also not-identical or different from itself and did not also imply the latter. In Hegel's words, "Identity is the identity of identity and non-identity." More recent metaphysicians have discussed trans-world identity—the notion that there can be the same object in different possible worlds. An alternative to trans-world identity is the counterpart relation in Counterpart theory. It is a similarity relation that rejects trans-world individuals and instead defends an objects counterpart - the most similar object.

Some philosophers have denied that there is such a relation as identity. Thus Ludwig Wittgenstein writes ("Tractatus" 5.5301): "That identity is not a relation between objects is obvious." At 5.5303 he elaborates: "Roughly speaking: to say of two things that they are identical is nonsense, and to say of one thing that it is identical with itself is to say nothing." Bertrand Russell had earlier voiced a worry that seems to be motivating Wittgenstein's point ("The Principles of Mathematics" §64): "[I]dentity, an objector may urge, cannot be anything at all: two terms plainly are not identical, and one term cannot be, for what is it identical with?" Even before Russell, Gottlob Frege, at the beginning of "On Sense and Reference," expressed a worry with regard to identity as a relation: "Equality gives rise to challenging questions which are not altogether easy to answer. Is it a relation?" More recently, C. J. F. Williams has suggested that identity should be viewed as a second-order relation, rather than a relation between objects, and Kai Wehmeier has argued that appealing to a binary relation that every object bears to itself, and to no others, is both logically unnecessary and metaphysically suspect.

Kind-terms, or sortals give a criterion of identity and non-identity among items of their kind.





</doc>
<doc id="1137736" url="https://en.wikipedia.org/wiki?curid=1137736" title="Principle of sufficient reason">
Principle of sufficient reason

The principle of sufficient reason states that everything must have a reason or a cause. The modern formulation of the principle is usually attributed to Gottfried Leibniz, although the idea was conceived of and utilized by various philosophers who preceded him, including Anaximander, Parmenides, Archimedes, Plato and Aristotle, Cicero, Avicenna, Thomas Aquinas, and Spinoza. Some philosophers have associated the principle of sufficient reason with "ex nihilo nihil fit". Hamilton identified the laws of inference modus ponens with the "law of Sufficient Reason, or of Reason and Consequent" and modus tollens with its contrapositive expression.

The principle has a variety of expressions, all of which are perhaps best summarized by the following:


A sufficient explanation may be understood either in terms of "reasons" or "causes," for like many philosophers of the period, Leibniz did not carefully distinguish between the two. The resulting principle is very different, however, depending on which interpretation is given.

It is an open question whether the principle of sufficient reason can be applied to axioms within a logic construction like a mathematical or a physical theory, because axioms are propositions accepted as having no justification possible within the system
The principle declares that all propositions considered to be true within a system should be deducible from the set axioms at the base of the construction (with some theoretical exceptions: see Gödel's theorem).

Leibniz identified two kinds of truth, necessary and contingent truths. He believed necessary mathematical truths to be derived from the law of identity (and the principle of non-contradiction): "Necessary truths are those that can be demonstrated through an analysis of terms, so that in the end they become identities, just as in Algebra an equation expressing an identity ultimately results from the substitution of values [for variables]. That is, necessary truths depend upon the principle of contradiction." Leibniz states that the sufficient reason for necessary truths is that their negation is a contradiction.

Leibniz admitted contingent truths on the basis of infinitary reasons, to which God had access but humans did not:
In contingent truths, even though the predicate is in the subject, this can never be demonstrated, nor can a proposition ever be reduced to an equality or to an identity, but the resolution proceeds to infinity, God alone seeing, not the end of the resolution, of course, which does not exist, but the connection of the terms or the containment of the predicate in the subject, since he sees whatever is in the series.Without this qualification, the principle can be seen as a description of a certain notion of closed system, in which there is no 'outside' to provide unexplained events with causes. It is also in tension with the paradox of Buridan's ass. Leibniz denied that the paradox of Buridan's ass could ever occur, saying:

Leibniz also used the principle of sufficient reason to refute the idea of absolute space:

I say then, that if space is an absolute being, there would be something for which it would be impossible there should be a sufficient reason. Which is against my axiom. And I prove it thus. Space is something absolutely uniform; and without the things placed in it, one point in space does not absolutely differ in any respect whatsoever from another point of space. Now from hence it follows, (supposing space to be something in itself, beside the order of bodies among themselves,) that 'tis impossible that there should be a reason why God, preserving the same situation of bodies among themselves, should have placed them in space after one particular manner, and not otherwise; why everything was not placed the quite contrary way, for instance, by changing East into West.

The principle was one of the four recognised laws of thought, that held a place in European pedagogy of logic and reasoning (and, to some extent, philosophy in general) in the 18th and 19th centuries. It was influential in the thinking of Leo Tolstoy, amongst others, in the elevated form that history could not be accepted as random.

A sufficient reason is sometimes described as the coincidence of every single thing that is needed for the occurrence of an effect (i.e. of the so-called "necessary conditions"). Such view could perhaps be also applied to indeterministic systems, as long as randomness is in a way incorporated in the preconditions.

Here is how Hamilton, circa 1837–1838, expressed his "fourth law" in his LECT. V. LOGIC. 60–61:

According to Schopenhauer's "On the Fourfold Root of the Principle of Sufficient Reason", there are four distinct forms of the principle.

First Form: The Principle of Sufficient Reason of Becoming (principium rationis sufficientis fiendi); appears as the law of causality in the understanding.

Second Form: The Principle of Sufficient Reason of Knowing (principium rationis sufficientis cognoscendi); asserts that if a judgment is to express a piece of knowledge, it must have a sufficient ground or reason, in which case it receives the predicate true.

Third Form: The Principle of Sufficient Reason of Being (principium rationis sufficientis essendi); the law whereby the parts of space and time determine one another as regards those relations. Example in arithmetic: Each number presupposes the preceding numbers as grounds or reasons of its being; "I can reach ten only by going through all the preceding numbers; and only by virtue of this insight into the ground of being, do I know that where there are ten, so are there eight, six, four."

"Now just as the subjective correlative to the first class of representations is the understanding, that to the second the faculty of reason, and that to the third pure sensibility, so is the subjective correlative to this fourth class found to be the inner sense, or generally self-consciousness." 

Fourth Form: The Principle of Sufficient Reason of Acting (principium rationis sufficientis agendi); briefly known as the law of motivation. "Any judgment that does not follow its previously existing ground or reason" or any state that cannot be explained away as falling under the three previous headings "must be produced by an act of will which has a motive." As his proposition in 43 states, "Motivation is causality seen from within."

Several proofs have been prepared in order to demonstrate that the universe is at bottom causal, i.e. works in accord with the principle in question; perhaps not in every single case (randomness might still play a part here and there), but that causality must be the way it works at least "in general", in most of what we see; and that our minds are aware of the principle even before any experience. The two famous arguments or proofs were proposed by Immanuel Kant (from the form of Time, temporal ordering of events and "directionality" of time) and by Arthur Schopenhauer (by demonstrating how all perception depends on causality and the intellect).

Once it is agreed (e.g. from a kind of an "arrow of time") that causal interconnections, as a form of principle of sufficient reason, indeed must in general exist everywhere in the universe (at least in the large scale), "backwards" causality in general might then be precluded using a form of the paradox of free will (i.e. an event that has a future source might cause us to remove that source quick enough and thus causality would not work).




</doc>
<doc id="1442889" url="https://en.wikipedia.org/wiki?curid=1442889" title="Contemplation">
Contemplation

Whilst in the life of the intellect 'contemplation' refers to thinking profoundly about something, in the religious life contemplation is a kind of inner vision or seeing, transcendent of the intellect, facilitated by means of practices such as prayer or meditation.

The word contemplation basically means 'to think about an action before you perform it'.

The word "contemplation" is derived from the Latin word "contemplatio", ultimately from the Latin word "templum", a piece of ground consecrated for the taking of auspices, or a building for worship. The latter either derives from the Proto-Indo-European root "*tem-" ("to cut"), on notion of "place reserved or cut out", or from the root *"temp"- ("to stretch, string"), thus referring to a cleared (measured) space in front of an altar. The Latin word "contemplatio" was used to translate the Greek word "θεωρία" ("theōría").

Contemplation was an important part of the philosophy of Plato; Plato thought that through contemplation, the soul may ascend to knowledge of the Form of the Good or other divine Forms. Plotinus as a (neo)Platonic philosopher also expressed contemplation as the most critical of components for one to reach henosis. 
To Plotinus the highest contemplation was to experience the vision of God, the Monad or the One. Plotinus describes this experience in his works the Enneads. According to his student Porphyry, Plotinus stated that he had this experience of God four times. Plotinus wrote about his experience in Enneads 6.9.

A number of sources have described the importance of contemplation in Jewish traditions, especially in Jewish meditation. Contemplation was central to the teaching of the Jewish philosopher Maimonides, who taught that contemplating God involves recognizing moral perfection, and that one must interrupt contemplation to attend to the poor. Contemplation has also been central to the Musar movement.

In Islamic tradition, it is said that Muhammad would go into the desert, climb a mountain known as Mount Hira, and seclude himself from the world. While on the mountain, he would contemplate life and its meaning.

Baha'u'llah and Abdu'l-Baha wrote about contemplation and meditation in regards to reflecting on beauty, the Kingdom of God, science, and the arts. Abdu'l-Baha stated that "the sign of the intellect is contemplation and the sign of contemplation is silence... he cannot both speak and meditate".

In Eastern Christianity, contemplation (theoria) literally means to see God or to have the Vision of God. The state of beholding God, or union with God, is known as theoria. The process of Theosis which leads to that state of union with God known as theoria is practiced in the ascetic tradition of Hesychasm. Hesychasm is to reconcile the heart and the mind into one thing (see nous).

Contemplation in Eastern Orthodoxy is expressed in degrees as those covered in St John Climacus' Ladder of Divine Ascent. The process of changing from the old man of sin into the newborn child of God and into our true nature as good and divine is called Theosis.

This is to say that once someone is in the presence of God, deified with him, then they can begin to properly understand, and there "contemplate" God. This form of contemplation is to have and pass through an actual experience rather than a rational or reasoned understanding of theory (see Gnosis). Whereas with rational thought one uses logic to understand, one does the opposite with God (see also Apophatic theology).

The anonymously authored 14th century English contemplative work "The Cloud of Unknowing" makes clear that its form of practice is not an act of the intellect, but a kind of transcendent ‘seeing,’ beyond the usual activities of the mind - “The first time you practice contemplation, you'll experience a darkness, like a cloud of unknowing. You won’t know what this is... this darkness and this cloud will always be between you and your God... they will always keep you from seeing him clearly by the light of understanding in your intellect and will block you from feeling Him fully in the sweetness of love in your emotions. So be sure to make your home in this darkness... We can’t think our way to God... that’s why I’m willing to abandon everything I know, to love the one thing I cannot think. He can be loved, but not thought.”

Within Western Christianity contemplation is often related to mysticism as expressed in the works of mystical theologians such as Teresa of Avila and John of the Cross as well as the writings of Margery Kempe, Augustine Baker and Thomas Merton. 

Dom Cuthbert Butler notes that contemplation was the term used in the Latin Church to refer to mysticism, and "'mysticism' is a quite modern word".

In Christianity, contemplation refers to a content-free mind directed towards the awareness of God as a living reality. This corresponds, in some ways, to what in Eastern religion is called samadhi. Meditation, on the other hand, for many centuries in the Western Church, referred to more cognitively active exercises, such as visualizations of Biblical scenes as in the Ignatian exercises or "lectio divina" in which the practitioner "listens to the text of the Bible with the 'ear of the heart', as if he or she is in conversation with God, and God is suggesting the topics for discussion." 

In Catholic Christianity, contemplation is given importance. The Catholic Church's "model theologian", St. Thomas Aquinas wrote: "It is requisite for the good of the human community that there should be persons who devote themselves to the life of contemplation." One of his disciples, Josef Pieper commented: "For it is contemplation which preserves in the midst of human society the truth which is at one and the same time useless and the yardstick of every possible use; so it is also contemplation which keeps the true end in sight, gives meaning to every practical act of life."

According to Aquinas, the highest form of life is the contemplative which communicates the fruits of contemplation to others, since it is based on the abundance of contemplation ("contemplari et contemplata aliis tradere") (ST, III, Q. 40, A. 1, Ad 2).










</doc>
<doc id="270799" url="https://en.wikipedia.org/wiki?curid=270799" title="Instrumentalism">
Instrumentalism

In philosophy of science and in epistemology, instrumentalism is a methodological view that ideas are useful instruments, and that the worth of an idea is based on how effective it is in explaining and predicting phenomena. Instrumentalism is a pragmatic philosophy of John Dewey that thought is an instrument for solving practical problems, and that truth is not fixed but changes as problems change. Instrumentalism is the view that scientific theories are useful tools for predicting phenomena instead of true or approximately true descriptions.

According to instrumentalists, a successful scientific theory reveals nothing known either true or false about nature's unobservable objects, properties or processes. Scientific theory is merely a tool whereby humans "predict" observations in a particular domain of nature by formulating laws, which state or summarize regularities, while theories themselves do not reveal supposedly hidden aspects of nature that somehow "explain" these laws. Initially a novel perspective introduced by Pierre Duhem in 1906, instrumentalism is largely the prevailing theory that underpins the practice of physicists today.

Rejecting scientific realism's ambitions to uncover metaphysical truth about nature, instrumentalism is usually categorized as an "antirealism", although its mere lack of commitment to scientific theory's realism can be termed "nonrealism". Instrumentalism merely bypasses debate concerning whether, for example, a "particle" spoken about in particle physics is a discrete entity enjoying individual existence, or is an "excitation mode" of a region of a field, or is something else altogether. Instrumentalism holds that theoretical terms need only be useful to predict the phenomena, the observed outcomes.

There are multiple versions of instrumentalism. Instrumentalism is a variety of scientific anti-realism.

Newton's theory of motion, whereby any object instantly interacts with all other objects across the universe, motivated the founder of British empiricism, John Locke, to speculate that matter is capable of thought. The next leading British empiricist, George Berkeley, argued that an object's putative primary qualities as recognized by scientists, such as shape, extension, and impenetrability, are inconceivable without the putative secondary qualities of color, hardness, warmth, and so on. He also posed the question how or why an object could be properly conceived to exist independently of any perception of it. Berkeley did not object to everyday talk about the reality of objects, but instead took issue with philosophers' talk, who spoke as if they knew something beyond sensory impressions that ordinary folk did not.

For Berkeley, a scientific theory does not state causes or explanations, but simply identifies perceived types of objects and traces their typical regularities. Berkeley thus anticipated the basis of what Auguste Comte in the 1830s called "positivism", although Comtean positivism added other principles concerning the scope, method, and uses of science that Berkeley would have disavowed. Berkeley also noted the usefulness of a scientific theory having terms that merely serve to aid calculations without their having to refer to anything in particular, so long as they proved useful in practice. Berkeley thus predated the insight that logical positivists—who originated in the late 1920s, but who, by the 1950s, had softened into logical empiricists—would be compelled to accept: theoretical terms in science do not always translate into observational terms.

The last great British empiricist, David Hume, posed a number of challenges to Francis Bacon's inductivism, which had been the prevailing, or at least the professed view concerning the attainment of scientific knowledge. Regarding himself as having placed his own theory of knowledge on par with Newton's theory of motion, Hume supposed that he had championed inductivism over scientific realism. Upon reading Hume's work, Immanuel Kant was "awakened from dogmatic slumber", and thus sought to neutralise any threat to science posed by Humean empiricism. Kant would develop the first stark philosophy of physics.

To save Newton's law of universal gravitation, Immanuel Kant reasoned that the mind is the precondition of experience and so, as the bridge from the noumena, which are how the world's things exist in themselves, to the phenomena, which are humans' recognized experiences. And so mind itself contains the structure that determines "space", "time", and "substance", how mind's own categorization of noumena renders space Euclidean, time constant, and objects' motions exhibiting the very determinism predicted by Newtonian physics. Kant apparently presumed that the human mind, rather than a phenomenon itself that had evolved, had been predetermined and set forth upon the formation of humankind. In any event, the mind also was the veil of appearance that scientific methods could never lift. And yet the mind could ponder itself and discover such truths, although not on a theoretical level, but only by means of ethics. Kant's metaphysics, then, transcendental idealism, secured science from doubt—in that it was a case of "synthetic a priori" knowledge ("universal, necessary and informative")—and yet discarded hope of scientific realism. Meanwhile, it was a watershed for idealist metaphysics, and launched German idealism, most influentially Hegel's absolute idealism or objective idealism, or at least interpretations, often misinterpretations, and political misuses, of it.

Since the mind has virtually no power to know anything beyond direct sensory experience, Ernst Mach's early version of logical positivism (empirio-criticism) verged on idealism. It was alleged to even be a surreptitious solipsism, whereby all that exists is one's own mind. Mach's positivism also strongly asserted the ultimate unity of the empirical sciences. Mach's positivism asserted phenomenalism as to new basis of scientific theory, all scientific terms to refer to either actual or potential sensations, thus eliminating hypotheses while permitting such seemingly disparate scientific theories as physical and psychological to share terms and forms. Phenomenalism was insuperably difficult to implement, yet heavily influenced a new generation of philosophers of science, who emerged in the 1920s while terming themselves "logical positivists" while pursuing a program termed "verificationism". Logical positivists aimed not to instruct or restrict scientists, but to enlighten and structure philosophical discourse to render "scientific philosophy" that would verify philosophical statements as well as scientific theories, and align all human knowledge into a "scientific worldview", freeing humankind from so many of its problems due to confused or unclear language.

The verificationists expected a strict gap between "theory" versus "observation", mirrored by a theory's "theoretical terms" versus "observable terms". Believing a theory's posited unobservables to always correspond to observations, the verificationists viewed a scientific theory's theoretical terms, such as "electron", as metaphorical or elliptical at observations, such as "white streak in cloud chamber". They believed that scientific terms lacked meanings unto themselves, but acquired meanings from the logical structure that was the entire theory that in turn matched "patterns of experience". So by translating theoretical terms into observational terms and then decoding the theory's mathematical/logical structure, one could check whether the statement indeed matched patterns of experience, and thereby verify the scientific theory false or true. Such verification would be possible, as never before in science, since translation of theoretical terms into observational terms would make the scientific theory purely empirical, none metaphysical. Yet the logical positivists ran into insuperable difficulties. Moritz Schlick debated with Otto Neurath over foundationalism—the traditional view traced to Descartes as founder of modern Western philosophy—whereupon only nonfoundationalism was found tenable. Science, then, could not find a secure foundation of indubitable truth.

And since science aims to reveal not private but public truths, verificationists switched from phenomenalism to physicalism, whereby scientific theory refers to objects observable in space and at least in principle already recognizable by physicists. Finding strict empiricism untenable, verificationism underwent "liberalization of empiricism". Rudolf Carnap even suggested that empiricism's basis was pragmatic. Recognizing that verification—proving a theory false or true—was unattainable, they discarded that demand and focused on "confirmation theory". Carnap sought simply to quantify a universal law's "degree of confirmation"—its probable truth—but, despite his great mathematical and logical skill, discovered equations never operable to yield over "zero" degree of confirmation. Carl Hempel found the paradox of confirmation. By the 1950s, the verificationists had established philosophy of science as subdiscipline within academia's philosophy departments. By 1962, verificationists had asked and endeavored to answer seemingly all the great questions about scientific theory. Their discoveries showed that the idealized "scientific worldview" was naively mistaken. By then the leader of the legendary venture, Hempel raised the white flag that signaled verificationism's demise. Suddenly striking Western society, then, was Kuhn's landmark thesis, introduced by none other than Carnap, verificationism's greatest firebrand. Instrumentalism exhibited by "scientists" often does not even discern unobservable from observable entities.

From the 1930s until Thomas Kuhn's 1962 "The Structure of Scientific Revolutions", there were roughly two prevailing views about the nature of science. The popular view was scientific realism, which usually involved a belief that science was progressively unveiling a truer view, and building a better understanding, of nature. The professional approach was logical empiricism, wherein a scientific theory was held to be a logical structure whose terms all ultimately refer to some form of observation, while an objective process neutrally arbiters theory choice, compelling scientists to decide which scientific theory was superior. Physicists knew better, but, busy developing the Standard Model, were so steeped in developing quantum field theory, that their talk, largely metaphorical, perhaps even metaphysical, was unintelligible to the public, while the steep mathematics warded off philosophers of physics. By the 1980s, physicists regarded not "particles", but "fields" as the more fundamental, and no longer even hoped to discover what entities and processes might be truly fundamental to nature, perhaps not even the field. Kuhn had not claimed to have developed a novel thesis, but instead hoped to synthesize more usefully recent developments in the philosophy of science.

In 1906, Duhem had introduced the problem of the underdetermination of theory by data, since any dataset could be consistent with several different explanations, how the success of any prediction does not, by affirming the consequent, a deductive fallacy, logically confirm the truth of the theory in question. In the 1930s, Ludwik Fleck had explained the role of perspectivism (logology) in science whereby scientists are trained in "thought collectives" to adopt particular "thought styles" setting expectations for a proper scientific question, scientific experiment, and scientific data. Scientists manipulate experimental conditions to obtain results that cohere with their own expectations—what the scientists presuppose is realistic—and as a result might be tempted to invoke the experimenter's regress in order to reject unexpected results. They would then redo these experiments under what were supposedly better and more conducive conditions. By the 1960s, physicists recognized two, differing roles of physical theory, "formalism" and "interpretation". Formalism involved mathematical equations and axioms that, upon input of physical data, yielded certain predictions. Interpretation sought to explain "why" they succeeded. 

Widely read, Kuhn's 1962 thesis seemed to shatter logical empiricism, whose paradigmatic science was physics and which championed instrumentalism. Yet scientific realists, who were far more tenacious, responded by attacking Kuhn's thesis, perennially depicted thereafter as either illuminated or infamous. Kuhn later indicated that his thesis had been so widely misunderstood that he himself was not a "Kuhnian". With logical empiricism's demise, Karl Popper's falsificationism was in the ascendancy, and Popper was knighted in 1965. Yet in 1961, the molecular biology research program had made its first major empirical breakthrough in cracking the "genetic code". By the 1970s, molecular genetics' research tools could also be used for genetic engineering. In 1975, philosopher of science Hilary Putnam famously resurrected scientific realism with his "no miracles" argument, whereby the best scientific theories' predictive successes would appear miraculous if those theories were not at least "approximately" true about reality as it exists in and of itself beyond human perception. Antirealist arguments were formulated in response.

By rejecting all variants of positivism via its focus on sensations rather than realism, Karl Popper asserted his commitment to scientific realism, merely via the necessary uncertainty of his own falsificationism. Popper alleged that instrumentalism reduces basic science to what is merely applied science. In his book "The fabric of reality", the British physicist David Deutsch followed Popper's critique of instrumentalism and argued that a scientific theory stripped of its explanatory content would be of strictly limited utility.

Bas van Fraassen's (1980) project of constructive empiricism focuses on belief in the domain of the observable, so for this reason it is described as a form of instrumentalism.

In the philosophy of mind, Instrumentalism is the view that propositional attitudes like beliefs are not actually concepts on which we can base scientific investigations of mind and brain, but that acting as if other beings have beliefs is a successful strategy.

Instrumentalism is closely related to pragmatism, the position that practical consequences is an essential basis for determining meaning, truth or value.





</doc>
<doc id="43854" url="https://en.wikipedia.org/wiki?curid=43854" title="Reality">
Reality

Reality is the sum or aggregate of all that is real or existent within a system, as opposed to that which is only imaginary. The term is also used to refer to the ontological status of things, indicating their existence. In physical terms, reality is the totality of a system, known and unknown. Philosophical questions about the nature of reality or existence or being are considered under the rubric of ontology, which is a major branch of metaphysics in the Western philosophical tradition. Ontological questions also feature in diverse branches of philosophy, including the philosophy of science, philosophy of religion, philosophy of mathematics, and philosophical logic. These include questions about whether only physical objects are real (i.e., Physicalism), whether reality is fundamentally immaterial (e.g., Idealism), whether hypothetical unobservable entities posited by scientific theories exist, whether God exists, whether numbers and other abstract objects exist, and whether possible worlds exist.

A common colloquial usage would have "reality" mean "perceptions, beliefs, and attitudes toward reality", as in "My reality is not your reality." This is often used just as a colloquialism indicating that the parties to a conversation agree, or should agree, not to quibble over deeply different conceptions of what is real. For example, in a religious discussion between friends, one might say (attempting humor), "You might disagree, but in my reality, everyone goes to heaven."

Reality can be defined in a way that links it to worldviews or parts of them (conceptual frameworks): Reality is the totality of all things, structures (actual and conceptual), events (past and present) and phenomena, whether observable or not. It is what a world view (whether it be based on individual or shared human experience) ultimately attempts to describe or map.

Certain ideas from physics, philosophy, sociology, literary criticism, and other fields shape various theories of reality. One such belief is that there simply and literally "is" no reality beyond the perceptions or beliefs we each have about reality. Such attitudes are summarized in the popular statement, "Perception is reality" or "Life is how you perceive reality" or "reality is what you can get away with" (Robert Anton Wilson), and they indicate anti-realism – that is, the view that there is no objective reality, whether acknowledged explicitly or not.

Many of the concepts of science and philosophy are often defined culturally and socially. This idea was elaborated by Thomas Kuhn in his book "The Structure of Scientific Revolutions" (1962). "The Social Construction of Reality", a book about the sociology of knowledge written by Peter L. Berger and Thomas Luckmann, was published in 1966. It explained how knowledge is acquired and used for the comprehension of reality. Out of all the realities, the reality of everyday life is the most important one since our consciousness requires us to be completely aware and attentive to the experience of everyday life.

Philosophy addresses two different aspects of the topic of reality: the nature of reality itself, and the relationship between the mind (as well as language and culture) and reality.

On the one hand, ontology is the study of being, and the central topic of the field is couched, variously, in terms of being, existence, "what is", and reality. The task in ontology is to describe the most general categories of reality and how they are interrelated. If a philosopher wanted to proffer a positive definition of the concept "reality", it would be done under this heading. As explained above, some philosophers draw a distinction between reality and existence. In fact, many analytic philosophers today tend to avoid the term "real" and "reality" in discussing ontological issues. But for those who would treat "is real" the same way they treat "exists", one of the leading questions of analytic philosophy has been whether existence (or reality) is a property of objects. It has been widely held by analytic philosophers that it is "not" a property at all, though this view has lost some ground in recent decades.

On the other hand, particularly in discussions of objectivity that have feet in both metaphysics and epistemology, philosophical discussions of "reality" often concern the ways in which reality is, or is not, in some way "dependent upon" (or, to use fashionable jargon, "constructed" out of) mental and cultural factors such as perceptions, beliefs, and other mental states, as well as cultural artifacts, such as religions and political movements, on up to the vague notion of a common cultural world view, or .

The view that there is a reality independent of any beliefs, perceptions, etc., is called realism. More specifically, philosophers are given to speaking about "realism "about"" this and that, such as realism about universals or realism about the external world. Generally, where one can identify any class of object, the existence or essential characteristics of which is said not to depend on perceptions, beliefs, language, or any other human artifact, one can speak of "realism "about"" that object.

One can also speak of "anti"-realism about the same objects. "Anti-realism" is the latest in a long series of terms for views opposed to realism. Perhaps the first was idealism, so called because reality was said to be in the mind, or a product of our "ideas". Berkeleyan idealism is the view, propounded by the Irish empiricist George Berkeley, that the objects of perception are actually ideas in the mind. In this view, one might be tempted to say that reality is a "mental construct"; this is not quite accurate, however, since, in Berkeley's view, perceptual ideas are created and coordinated by God. By the 20th century, views similar to Berkeley's were called phenomenalism. Phenomenalism differs from Berkeleyan idealism primarily in that Berkeley believed that minds, or souls, are not merely ideas nor made up of ideas, whereas varieties of phenomenalism, such as that advocated by Russell, tended to go farther to say that the mind itself is merely a collection of perceptions, memories, etc., and that there is no mind or soul over and above such mental events. Finally, anti-realism became a fashionable term for "any" view which held that the existence of some object depends upon the mind or cultural artifacts. The view that the so-called external world is really merely a social, or cultural, artifact, called social constructionism, is one variety of anti-realism. Cultural relativism is the view that social issues such as morality are not absolute, but at least partially cultural artifact.

A correspondence theory of knowledge about what exists claims that "true" knowledge of reality represents accurate correspondence of statements about and images of reality with the actual reality that the statements or images are attempting to represent. For example, the scientific method can verify that a statement is true based on the observable evidence that a thing exists. Many humans can point to the Rocky Mountains and say that this mountain range exists, and continues to exist even if no one is observing it or making statements about it.

The nature of being is a perennial topic in metaphysics. For, instance Parmenides taught that reality was a single unchanging Being, whereas Heraclitus wrote that all things flow. The 20th century philosopher Heidegger thought previous philosophers have lost sight the question of Being (qua Being) in favour of the questions of beings (existing things), so that a return to the Parmenidean approach was needed. An ontological catalogue is an attempt to list the fundamental constituents of reality. The question of whether or not existence is a predicate has been discussed since the Early Modern period, not least in relation to the ontological argument for the existence of God. Existence, "that" something is, has been contrasted with "essence", the question of "what" something is.
Since existence without essence seems blank, it associated with nothingness by philosophers such as Hegel. Nihilism represents an extremely negative view of being, the absolute a positive one.

The question of direct or "naïve" realism, as opposed to indirect or "representational" realism, arises in the philosophy of perception and of mind out of the debate over the nature of conscious experience; the epistemological question of whether the world we see around us is the real world itself or merely an internal perceptual copy of that world generated by neural processes in our brain. Naïve realism is known as "direct" realism when developed to counter "indirect" or representative realism, also known as epistemological dualism, the philosophical position that our conscious experience is not of the real world itself but of an internal representation, a miniature virtual-reality replica of the world.

Timothy Leary coined the influential term Reality Tunnel, by which he means a kind of representative realism. The theory states that, with a subconscious set of mental filters formed from their beliefs and experiences, every individual interprets the same world differently, hence "Truth is in the eye of the beholder". His ideas influenced the work of his friend Robert Anton Wilson.

The status of abstract entities, particularly numbers, is a topic of discussion in mathematics.

In the philosophy of mathematics, the best known form of realism about numbers is Platonic realism, which grants them abstract, immaterial existence. Other forms of realism identify mathematics with the concrete physical universe.

Anti-realist stances include formalism and fictionalism.

Some approaches are selectively realistic about some mathematical objects but not others. Finitism rejects infinite quantities. Ultra-finitism accepts finite quantities up to a certain amount. Constructivism and intuitionism are realistic about objects that can be explicitly constructed, but reject the use of the principle of the excluded middle to prove existence by reductio ad absurdum.

The traditional debate has focused on whether an abstract (immaterial, intelligible) realm of numbers has existed "in addition to" the physical (sensible, concrete) world. A recent development is the mathematical universe hypothesis, the theory that "only" a mathematical world exists, with the finite, physical world being an illusion within it.

An extreme form of realism about mathematics is the mathematical multiverse hypothesis advanced by Max Tegmark. Tegmark's sole postulate is: "All structures that exist mathematically also exist physically". That is, in the sense that "in those [worlds] complex enough to contain self-aware substructures [they] will subjectively perceive themselves as existing in a physically 'real' world". The hypothesis suggests that worlds corresponding to different sets of initial conditions, physical constants, or altogether different equations should be considered real. The theory can be considered a form of Platonism in that it posits the existence of mathematical entities, but can also be considered a mathematical monism in that it denies that anything exists except mathematical objects.

The problem of universals is an ancient problem in metaphysics about whether universals exist. Universals are general or abstract qualities, characteristics, properties, kinds or relations, such as being male/female, solid/liquid/gas or a certain colour, that can be predicated of individuals or particulars or that individuals or particulars can be regarded as sharing or participating in. For example, Scott, Pat, and Chris have in common the universal quality of "being human" or "humanity".

The realist school claims that universals are real – they exist and are distinct from the particulars that instantiate them. There are various forms of realism. Two major forms are Platonic realism and Aristotelian realism. "Platonic realism" is the view that universals are real entities and they exist independent of particulars. "Aristotelian realism", on the other hand, is the view that universals are real entities, but their existence is dependent on the particulars that exemplify them.

Nominalism and conceptualism are the main forms of anti-realism about universals.

A traditional realist position in ontology is that time and space have existence apart from the human mind. Idealists deny or doubt the existence of objects independent of the mind. Some anti-realists whose ontological position is that objects outside the mind do exist, nevertheless doubt the independent existence of time and space.

Kant, in the "Critique of Pure Reason", described time as an "a priori" notion that, together with other "a priori" notions such as space, allows us to comprehend sense experience. Kant denies that either space or time are substance, entities in themselves, or learned by experience; he holds rather that both are elements of a systematic framework we use to structure our experience. Spatial measurements are used to quantify how far apart objects are, and temporal measurements are used to quantitatively compare the interval between (or duration of) events. Although space and time are held to be "transcendentally ideal" in this sense, they are also "empirically real", i.e. not mere illusions.

Idealist writers such as J. M. E. McTaggart in "The Unreality of Time" have argued that time is an illusion.

As well as differing about the reality of time as a whole, metaphysical theories of time can differ in their ascriptions of reality to the past, present and future separately.

Time, and the related concepts of process and evolution are central to the system-building metaphysics of A. N. Whitehead and Charles Hartshorne.

The term "possible world" goes back to Leibniz's theory of possible worlds, used to analyse necessity, possibility, and similar modal notions. Modal realism is the view, notably propounded by David Kellogg Lewis, that all possible worlds are as real as the actual world. In short: the actual world is regarded as merely one among an infinite set of logically possible worlds, some "nearer" to the actual world and some more remote. Other theorists may use the Possible World framework to express and explore problems without committing to it ontologically.
Possible world theory is related to alethic logic: a proposition is "necessary" if it is true in all possible worlds, and "possible" if it is true in at least one. The many worlds interpretation of quantum mechanics is a similar idea in science.

The philosophical implications of a physical TOE are frequently debated. For example, if philosophical physicalism is true, a physical TOE will coincide with a philosophical theory of everything.

The "system building" style of metaphysics attempts to answer "all" the important questions in a coherent way, providing a complete picture of the world. Plato and Aristotle could be said to be early examples of comprehensive systems. In the early modern period (17th and 18th centuries), the system-building "scope" of philosophy is often linked to the rationalist "method" of philosophy, that is the technique of deducing the nature of the world by pure "a priori" reason. Examples from the early modern period include the Leibniz's Monadology, Descartes's Dualism, Spinoza's Monism. Hegel's Absolute idealism and Whitehead's Process philosophy were later systems.

Other philosophers do not believe its techniques can aim so high. Some scientists think a more mathematical approach than philosophy is needed for a TOE, for instance Stephen Hawking wrote in "A Brief History of Time" that even if we had a TOE, it would necessarily be a set of equations. He wrote, "What is it that breathes fire into the equations and makes a universe for them to describe?"

On a much broader and more subjective level, private experiences, curiosity, inquiry, and the selectivity involved in personal interpretation of events shapes reality as seen by one and only one individual and hence is called phenomenological. While this
form of reality might be common to others as well, it could at times also be so unique to oneself as to never be experienced or agreed upon by anyone else. Much of the kind of experience deemed spiritual occurs on this level of reality.

Phenomenology is a philosophical method developed in the early years of the twentieth century by Edmund Husserl and a circle of followers at the universities of Göttingen and Munich in Germany. Subsequently, phenomenological themes were taken up by philosophers in France, the United States, and elsewhere, often in contexts far removed from Husserl's work.

The word "phenomenology" comes from the Greek "phainómenon", meaning "that which appears", and "lógos", meaning "study". In Husserl's conception, phenomenology is primarily concerned with making the structures of consciousness, and the phenomena which appear in acts of consciousness, objects of systematic reflection and analysis. Such reflection was to take place from a highly modified "first person" viewpoint, studying phenomena not as they appear to "my" consciousness, but to any consciousness whatsoever. Husserl believed that phenomenology could thus provide a firm basis for all human knowledge, including scientific knowledge, and could establish philosophy as a "rigorous science".

Husserl's conception of phenomenology has been criticised and developed not only by himself, but also by his student and assistant Martin Heidegger, by existentialists, such as Maurice Merleau-Ponty, Jean-Paul Sartre, and by other philosophers, such as Paul Ricoeur, Emmanuel Levinas, and Dietrich von Hildebrand.

Skeptical hypotheses in philosophy suggest that reality is very different from what we think it is; or at least that we cannot prove it is not. Examples include:


Jain philosophy postulates that seven tattva (truths or fundamental principles) constitute reality. These seven "tattva" are:

Scientific realism is, at the most general level, the view that the world described by science (perhaps ideal science) is the real world, as it is, independent of what we might take it to be. Within philosophy of science, it is often framed as an answer to the question "how is the success of science to be explained?" The debate over what the success of science involves centers primarily on the status of entities that are not directly observable discussed by scientific theories. Generally, those who are scientific realists state that one can make reliable claims about these entities (viz., that they have the same ontological status) as directly observable entities, as opposed to instrumentalism. The most used and studied scientific theories today state more or less the truth.

"Realism" in the sense used by physicists does not equate to realism in metaphysics.
The latter is the claim that the world is mind-independent: that even if the results of a measurement do not pre-exist the act of measurement, that does not require that they are the creation of the observer. Furthermore, a mind-independent property does not have to be the value of some physical variable such as position or momentum. A property can be "dispositional" (or potential), i.e. it can be a tendency: in the way that glass objects tend to break, or are disposed to break, even if they do not "actually" break. Likewise, the mind-independent properties of quantum systems could consist of a tendency to respond to particular measurements with particular values with ascertainable probability. Such an ontology would be metaphysically realistic, without being realistic in the physicist's sense of "local realism" (which would require that a single value be produced with certainty).

A closely related term is counterfactual definiteness (CFD), used to refer to the claim that one can meaningfully speak of the definiteness of results of measurements that have not been performed (i.e. the ability to assume the existence of objects, and properties of objects, even when they have not been measured).

Local realism is a significant feature of classical mechanics, of general relativity, and of electrodynamics; but quantum mechanics has shown that quantum entanglement is possible. This was rejected by Einstein, who proposed the EPR paradox, but it was subsequently quantified by Bell's inequalities. If Bell's inequalities are violated, either local realism "or" counterfactual definiteness must be incorrect; but some physicists dispute that experiments have demonstrated Bell's violations, on the grounds that the sub-class of inhomogeneous Bell inequalities has not been tested or due to experimental limitations in the tests. Different interpretations of quantum mechanics violate different parts of local realism and/or counterfactual definiteness.

The quantum mind–body problem refers to the philosophical discussions of the mind–body problem in the context of quantum mechanics. Since quantum mechanics involves quantum superpositions, which are not perceived by observers, some interpretations of quantum mechanics place conscious observers in a special position.

The founders of quantum mechanics debated the role of the observer, and of them, Wolfgang Pauli and Werner Heisenberg believed that it was the observer that produced collapse. This point of view, which was never fully endorsed by Niels Bohr, was denounced as mystical and anti-scientific by Albert Einstein. Pauli accepted the term, and described quantum mechanics as "lucid mysticism".

Heisenberg and Bohr always described quantum mechanics in logical positivist terms. Bohr also took an active interest in the philosophical implications of quantum theories such as his complementarity, for example. He believed quantum theory offers a complete description of nature, albeit one that is simply ill-suited for everyday experiences – which are better described by classical mechanics and probability. Bohr never specified a demarcation line above which objects cease to be quantum and become classical. He believed that it was not a question of physics, but one of philosophy.

Eugene Wigner reformulated the "Schrödinger's cat" thought experiment as "Wigner's friend" and proposed that the consciousness of an observer is the demarcation line which precipitates collapse of the wave function, independent of any realist interpretation. Commonly known as "consciousness causes collapse", this interpretation of quantum mechanics states that observation by a conscious observer is what makes the wave function collapse.

The multiverse is the hypothetical set of multiple possible universes (including the historical universe we consistently experience) that together comprise everything that exists: the entirety of space, time, matter, and energy as well as the physical laws and constants that describe them. The term was coined in 1895 by the American philosopher and psychologist William James. In the many-worlds interpretation (MWI), one of the mainstream interpretations of quantum mechanics, there are an infinite number of universes and every possible quantum outcome occurs in at least one universe.

The structure of the multiverse, the nature of each universe within it and the relationship between the various constituent universes, depend on the specific multiverse hypothesis considered. Multiverses have been hypothesized in cosmology, physics, astronomy, religion, philosophy, transpersonal psychology and fiction, particularly in science fiction and fantasy. In these contexts, parallel universes are also called "alternative universes", "quantum universes", "interpenetrating dimensions", "parallel dimensions", "parallel worlds", "alternative realities", "alternative timelines", and "dimensional planes", among others.

A theory of everything (TOE) is a putative theory of theoretical physics that fully explains and links together all known physical phenomena, and predicts the outcome of "any" experiment that could be carried out "in principle". The theory of everything is also called the final theory. Many candidate theories of everything have been proposed by theoretical physicists during the twentieth century, but none have been confirmed experimentally. The primary problem in producing a TOE is that general relativity and quantum mechanics are hard to unify. This is one of the unsolved problems in physics.

Initially, the term "theory of everything" was used with an ironic connotation to refer to various overgeneralized theories. For example, a great-grandfather of Ijon Tichy, a character from a cycle of Stanisław Lem's science fiction stories of the 1960s, was known to work on the "General Theory of Everything". Physicist John Ellis claims to have introduced the term into the technical literature in an article in "Nature" in 1986. Over time, the term stuck in popularizations of quantum physics to describe a theory that would unify or explain through a single model the theories of all fundamental interactions and of all particles of nature: general relativity for gravitation, and the standard model of elementary particle physics – which includes quantum mechanics – for electromagnetism, the two nuclear interactions, and the known elementary particles.

Current candidates for a theory of everything include string theory, M theory, and loop quantum gravity.

Virtual reality (VR) is a computer-simulated environment that can simulate physical presence in places in the real world, as well as in imaginary worlds.

The Virtuality Continuum is a continuous scale ranging between the completely virtual, a Virtuality, and the completely real: Reality. The reality-virtuality continuum therefore encompasses all possible variations and compositions of real and virtual objects. It has been described as a concept in new media and computer science, but in fact it could be considered a matter of anthropology. The concept was first introduced by Paul Milgram.

The area between the two extremes, where both the real and the virtual are mixed, is the so-called Mixed reality. This in turn is said to consist of both Augmented Reality, where the virtual augments the real, and Augmented virtuality, where the real augments the virtual.
Cyberspace, the world's computer systems considered as an interconnected whole, can be thought of as a virtual reality; for instance, it is portrayed as such in the cyberpunk fiction of William Gibson and others. Second life and MMORPGs such as "World of Warcraft" are examples of artificial environments or virtual worlds (falling some way short of full virtual reality) in cyberspace.

On the Internet, "real life" refers to life in the real world. It generally references life or consensus reality, in contrast to an environment seen as fiction or fantasy, such as virtual reality, lifelike experience, dreams, novels, or movies. Online, the acronym "IRL" stands for "in real life", with the meaning "not on the Internet". Sociologists engaged in the study of the Internet have determined that someday, a distinction between online and real-life worlds may seem "quaint", noting that certain types of online activity, such as sexual intrigues, have already made a full transition to complete legitimacy and "reality". The abbreviation "RL" stands for "real life". For example, one can speak of "meeting in RL" someone whom one has met in a chat or on an Internet forum. It may also be used to express an inability to use the Internet for a time due to "RL problems".






</doc>
<doc id="36189079" url="https://en.wikipedia.org/wiki?curid=36189079" title="Xin (concept)">
Xin (concept)

In Chinese philosophy, xin can refer to one's "disposition" or "feelings" (), or to one's confidence or trust in something or someone (). Literally, "xin" (心) refers to the physical heart, though it is sometimes translated as "mind" as the ancient Chinese believed the heart was the center of human cognition. For this reason, it is also sometimes translated as "heart-mind". It has a connotation of intention, yet can be used to refer to long-term goals. Xunzi, an important early Confucian thinker, considered "xin" (心) to be cultivated during one's life, in contrast to innate qualities of "xing" (), or human nature.

A Daoist view, specifically from the philosopher Zhuangzi, understands "xin" (心) as being socialized, with environmental pressures influencing personal intentions, sometimes in such a way that can provoke disagreements and conflict. While a Confucian might take heart that "xin" (心) may be cultivated in order to develop "de", or moral virtue, Zhuangzi considered this socialization as detrimental to one's personal nature, somewhat along the lines of the later French philosopher, Jean-Jacques Rousseau. However, unlike Rousseau, René Descartes and many other Enlightenment-era European philosophers following the classical example of Plato, emotion and reason were not considered separate entities, but rather as coextensive; "xin" (心) itself is a concept that is as much cognitive as emotional.



</doc>
<doc id="797295" url="https://en.wikipedia.org/wiki?curid=797295" title="Tulpa">
Tulpa

Tulpa is a concept in mysticism and the paranormal of a being or object which is created through spiritual or mental powers. It was adapted by 20th-century theosophists from Tibetan sprul-pa () which means "emanation" or "manifestation". Modern practitioners use the term to refer to a type of willed imaginary friend which practitioners consider to be sentient and relatively autonomous.

One early Buddhist text, the Pali "Samaññaphala Sutta", lists the ability to create a “mind-made body” ("manomāyakāya") as one of the "fruits of the contemplative life". Commentarial texts such as the "Patisambhidamagga" and the "Visuddhimagga" state that this mind-made body is how Gautama Buddha and arhats are able to travel into heavenly realms using the continuum of the mindstream ("cittasaṃtāna") and it is also used to explain the multiplication miracle of the Buddha as illustrated in the "Divyavadana", in which the Buddha multiplied his "nirmita" or emanated human form into countless other bodies which filled the sky. A Buddha or other realized being is able to project many such nirmitas simultaneously in an infinite variety of forms in different realms simultaneously.

The Indian Buddhist philosopher Vasubandhu (fl. 4th to 5th century CE) defined "nirmita" as a siddhi or psychic power (Pali "iddhi", Sankrit: "ṛddhi") developed through Buddhist discipline, concentrated discipline ("samadhi") and wisdom in his seminal work on Buddhist philosophy, the "Abhidharmakośakārikā". Asanga's "Bodhisattvabhūmi" defines nirmāṇa as a magical illusion and "basically, something without a material basis". The Madhyamaka school of philosophy sees all reality as empty of essence; all reality is seen as a form of nirmita or magical illusion.

Emanation bodies—nirmanakaya, sprulsku, sprul-pa and so on—are connected to trikaya, the Buddhist doctrine of the three bodies of the Buddha. They are usually emanation bodies of celestial beings, though "unrealized beings" such as humans may have their own emanation bodies or even "be" emanation bodies. For example, the 14th Dalai Lama is considered by some followers to be an emanation-reincarnation or tulku of Chenrezig, the Bodhisattva of Compassion. The 14th Dalai Lama mentioned in a public statement that his successor might appear via emanation while the current Dalai Lama is still alive.

20th century theosophists adapted the concepts of "emanation body"—nirmita, tulku, sprul-pa and others—into the concepts of "tulpa" and "thoughtform". The term “thoughtform” is used as early as 1927 in Evans-Wentz' translation of the Tibetan Book of the Dead. John Myrdhin Reynolds in a note to his English translation of the life story of Garab Dorje defines a "tulpa" as “an emanation or a manifestation.” 

Spiritualist Alexandra David-Néel claimed to have observed these mystical practices in 20th century Tibet. She described tulpas as "magic formations generated by a powerful concentration of thought." David-Néel believed that tulpas could develop a mind of its own: "Once the tulpa is endowed with enough vitality to be capable of playing the part of a real being, it tends to free itself from its maker's control. This, say Tibetan occultists, happens nearly mechanically, just as the child, when his body is completed and able to live apart, leaves its mother's womb." She claimed to have created such a tulpa in the image of a jolly Friar Tuck-like monk, which later developed a life of its own and had to be destroyed. David-Néel raised the possibility that her experience was illusory: "I may have created my own hallucination", though she claimed that others could see the thoughtforms that she created.

The Western occult understanding of the concept of "thoughtform" is believed by some to have originated as an interpretation of the Tibetan concept of "tulpa". The concept is related to the Western philosophy and practice of magic. Occultist William Walker Atkinson in his book "The Human Aura" described thought-forms as simple ethereal objects emanating from the auras surrounding people, generating from their thoughts and feelings. He further elaborated in "Clairvoyance and Occult Powers" how experienced practitioners of the occult can produce thoughtforms from their auras that serve as astral projections which may or may not look like the person who is projecting them, or as illusions that can only be seen by those with "awakened astral senses". The theosophist Annie Besant, in her book "Thought-forms", divides them into three classes: forms in the shape of the person who creates them, forms that resemble objects or people and may become "ensouled" by "nature spirits" or by the dead, and forms that represent "inherent qualities" from the astral or mental planes, such as emotions.

The concept of tulpa was popularized and secularized in the Western world through fiction, gaining popularity on television in the late 1990s and 2000s. From 2009 onwards, online communities dedicated to tulpas spawned on the 4chan and Reddit websites. These communities collectively refer to themselves as tulpamancers and offer guides and support for other tulpamancers. The communities gained popularity when adult fans of "My Little Pony" created forums for tulpas of characters from the "My Little Pony" television series. The fans attempted to use meditation and lucid dreaming techniques to create imaginary friends. Surveys by Veissière explored this community's demographic, social, and psychological profiles. These individuals, calling themselves "tulpamancers", treat the tulpas as a "real or somewhat-real person". The number of active participants in these online communities is in the low hundreds, and few meetings in person have taken place. They belong to "primarily urban, middle class, Euro-American adolescent and young adult demographics" and they "cite loneliness and social anxiety as an incentive to pick up the practice." 93.7% of respondents expressed that their involvement with the creation of tulpas has "made their condition better", and led to new unusual sensory experiences. Some practitioners have sexual and romantic interactions with their tulpas, though the practice is controversial and trending towards taboo. One survey found that 8.5% support a metaphysical explanation of tulpas, 76.5% support a neurological or psychological explanation, and 14% "other" explanations.


</doc>
<doc id="509995" url="https://en.wikipedia.org/wiki?curid=509995" title="Abstract and concrete">
Abstract and concrete

Abstract and concrete are classifications that denote whether the object that a term describes has physical referents. Abstract objects have no physical referents, whereas concrete objects do. They are most commonly used in philosophy and semantics. Abstract objects are sometimes called abstracta (sing. abstractum) and concrete objects are sometimes called "concreta" (sing. "concretum"). An abstract object is an object that does not exist at any particular time or place, but rather exists as a type of thing—i.e., an idea, or abstraction. The term "abstract object" is said to have been coined by Willard Van Orman Quine. The study of abstract objects is called abstract object theory.

The type–token distinction identifies physical objects that are tokens of a particular type of thing. The "type" of which it is a part is in itself an abstract object. The abstract-concrete distinction is often introduced and initially understood in terms of paradigmatic examples of objects of each kind:

Abstract objects have often garnered the interest of philosophers because they raise problems for popular theories. In ontology, abstract objects are considered problematic for physicalism and some forms of naturalism. Historically, the most important ontological dispute about abstract objects has been the problem of universals. In epistemology, abstract objects are considered problematic for empiricism. If abstracta lack causal powers or spatial location, how do we know about them? It is hard to say how they can affect our sensory experiences, and yet we seem to agree on a wide range of claims about them. 

Some, such as Edward Zalta and arguably, Plato in his Theory of Forms, have held that abstract objects constitute the defining subject matter of metaphysics or philosophical inquiry more broadly. To the extent that philosophy is independent of empirical research, and to the extent that empirical questions do not inform questions about abstracta, philosophy would seem especially suited to answering these latter questions. 

In modern philosophy, the distinction between abstract and concrete was explored by Immanuel Kant and G. W. F. Hegel.

Gottlob Frege said that abstract objects, such as numbers, were members of a third realm, different from the external world or from internal consciousness. 

Another popular proposal for drawing the abstract-concrete distinction contends that an object is abstract if it lacks any causal powers. A causal power has the ability to affect something causally. Thus, the empty set is abstract because it cannot act on other objects. One problem for this view is that it is not clear exactly what it is to have a causal power. For a more detailed exploration of the abstract-concrete distinction, follow the link below to the "Stanford Encyclopedia" article.

Recently, there has been some philosophical interest in the development of a third category of objects known as the quasi-abstract. Quasi-abstract objects have drawn particular attention in the area of social ontology and documentality. Some argue that the over-adherence to the platonist duality of the concrete and the abstract has led to a large category of social objects having been overlooked or rejected as nonexisting because they exhibit characteristics that the traditional duality between concrete and abstract regards as incompatible. Specially, the ability to have temporal location, but not spatial location, and have causal agency (if only by acting through representatives). These characteristics are exhibited by a number of social objects, including states of the international legal system.

Jean Piaget uses the terms "concrete" and "formal" to describe two different types of learning. Concrete thinking involves facts and descriptions about everyday, tangible objects, while abstract (formal operational) thinking involves a mental process.


</doc>
<doc id="169115" url="https://en.wikipedia.org/wiki?curid=169115" title="Preternatural">
Preternatural

The preternatural (or praeternatural) is that which appears outside or beside (Latin: "") the natural. It is "suspended between the mundane and the miraculous".

In theology, the term is often used to distinguish marvels or deceptive trickery, often attributed to witchcraft or demons, from the purely divine power of the genuinely supernatural to violate the laws of nature. In the early modern period, the term was used by scientists to refer to abnormalities and strange phenomena of various kinds that seemed to depart from the norms of nature.

Medieval theologians made a clear distinction between the natural, the preternatural and the supernatural. Thomas Aquinas argued that the supernatural consists in "God’s unmediated actions"; the natural is "what happens always or most of the time"; and the preternatural is "what happens rarely, but nonetheless by the agency of created beings ... Marvels belong, properly speaking, to the realm of the preternatural." Theologians, following Aquinas, argued that only God had the power to disregard the laws of nature that he has created, but that demons could manipulate the laws of nature by a form of trickery, to deceive the unwary into believing they had experienced real miracles. According to historian Lorraine Daston,

By the 16th century, the term "preternatural" was increasingly used to refer to demonic activity comparable to the use of magic by human adepts: The Devil, "being a natural Magician ... may perform many acts in ways above our knowledge, though not transcending our natural power." According to the philosophy of the time, preternatural phenomena were not contrary to divine law, but used hidden, or occult powers that violated the "normal" pattern of natural phenomena.

With the emergence of early modern science, the concept of the preternatural increasingly came to be used to refer to strange or abnormal phenomena that seemed to violate the normal working of nature, but which were not associated with magic and witchcraft. This was a development of the idea that preternatural phenomena were fake miracles. As Daston puts it, "To simplify the historical sequence somewhat: first, preternatural phenomena were demonized and thereby incidentally naturalized; then the demons were deleted, leaving only the natural causes." The use of the term was especially common in medicine, for example in John Brown's "A Compleat Treatise of Preternatural Tumours" (1678), or William Smellie's "A Collection of Preternatural Cases and Observations in Midwifery" (1754).

In the 19th century the term was appropriated in anthropology to refer to folk beliefs about fairies, trolls and other such creatures which were not thought of as demonic, but which were perceived to affect the natural world in unpredictable ways. According to Thorstein Veblen, such preternatural agents were often thought of as forces somewhere between supernatural beings and material processes. "The preternatural agency is not necessarily conceived to be a personal agent in the full sense, but it is an agency which partakes of the attributes of personality to the extent of somewhat arbitrarily influencing the outcome of any enterprise, and especially of any contest."

The linguistic association between individual agents and unexplained or unfortunate circumstances remains. Many people attribute occurrences that are known to be material processes, such as "gremlins in the engine", a "ghost in the machine", or attributing motives to objects: "the clouds are threatening". The anthropomorphism in our daily life is a combination of the above cultural stems, as well as the manifestation of our pattern-projecting minds.

In 2011, Penn State Press began publishing a learned journal titled "Preternature: Critical and Historical Studies on the Preternatural". Edited by Kirsten Uszkalo and Richard Raiswell, the journal is dedicated to publishing articles, reviews and short editions of original texts that deal with conceptions and perceptions of the preternatural in any culture and in any historical period. The journal covers "magics, witchcraft, spiritualism, occultism, prophecy, monstrophy, demonology, and folklore."




</doc>
<doc id="21830" url="https://en.wikipedia.org/wiki?curid=21830" title="Nature">
Nature

Nature, in the broadest sense, is the natural, physical, or material world or universe. "Nature" can refer to the phenomena of the physical world, and also to life in general. The study of nature is a large, if not the only, part of science. Although humans are part of nature, human activity is often understood as a separate category from other natural phenomena.

The word "nature" is derived from the Latin word "natura", or "essential qualities, innate disposition", and in ancient times, literally meant "birth". In ancient philosophy, "Natura" is mostly used as the Latin translation of the Greek word "physis" (φύσις), which originally related to the intrinsic characteristics that plants, animals, and other features of the world develop of their own accord. 
The concept of nature as a whole, the physical universe, is one of several expansions of the original notion; it began with certain core applications of the word φύσις by pre-Socratic philosophers (though this word had a dynamic dimension then, especially for Heraclitus), and has steadily gained currency ever since. During the advent of modern scientific method in the last several centuries, nature became the passive reality, organized and moved by divine laws. With the Industrial revolution, nature increasingly became seen as the part of reality deprived from intentional intervention : it was hence considered as sacred by some traditions (Rousseau, American transcendentalism) or a mere decorum for divine providence or human history (Hegel, Marx). However, a vitalist vision of nature, closer to the presocratic one, got reborn at the same time, especially after Charles Darwin.

Within the various uses of the word today, "nature" often refers to geology and wildlife. Nature can refer to the general realm of living plants and animals, and in some cases to the processes associated with inanimate objects—the way that particular types of things exist and change of their own accord, such as the weather and geology of the Earth. It is often taken to mean the "natural environment" or wilderness—wild animals, rocks, forest, and in general those things that have not been substantially altered by human intervention, or which persist despite human intervention. For example, manufactured objects and human interaction generally are not considered part of nature, unless qualified as, for example, "human nature" or "the whole of nature". This more traditional concept of natural things that can still be found today implies a distinction between the natural and the artificial, with the artificial being understood as that which has been brought into being by a human consciousness or a human mind. Depending on the particular context, the term "natural" might also be distinguished from the or the supernatural.

Earth is the only planet known to support life, and its natural features are the subject of many fields of scientific research. Within the solar system, it is third closest to the sun; it is the largest terrestrial planet and the fifth largest overall. Its most prominent climatic features are its two large polar regions, two relatively narrow temperate zones, and a wide equatorial tropical to subtropical region. Precipitation varies widely with location, from several metres of water per year to less than a millimetre. 71 percent of the Earth's surface is covered by salt-water oceans. The remainder consists of continents and islands, with most of the inhabited land in the Northern Hemisphere.

Earth has evolved through geological and biological processes that have left traces of the original conditions. The outer surface is divided into several gradually migrating tectonic plates. The interior remains active, with a thick layer of plastic mantle and an iron-filled core that generates a magnetic field. This iron core is composed of a solid inner phase, and a fluid outer phase. Convective motion in the core generates electric currents through dynamo action, and these, in turn, generate the geomagnetic field.

The atmospheric conditions have been significantly altered from the original conditions by the presence of life-forms, which create an ecological balance that stabilizes the surface conditions. Despite the wide regional variations in climate by latitude and other geographic factors, the long-term average global climate is quite stable during interglacial periods, and variations of a degree or two of average global temperature have historically had major effects on the ecological balance, and on the actual geography of the Earth.

Geology is the science and study of the solid and liquid matter that constitutes the Earth. The field of geology encompasses the study of the composition, structure, physical properties, dynamics, and history of Earth materials, and the processes by which they are formed, moved, and changed. The field is a major academic discipline, and is also important for mineral and hydrocarbon extraction, knowledge about and mitigation of natural hazards, some Geotechnical engineering fields, and understanding past climates and environments.

The geology of an area evolves through time as rock units are deposited and inserted and deformational processes change their shapes and locations.

Rock units are first emplaced either by deposition onto the surface or intrude into the overlying rock. Deposition can occur when sediments settle onto the surface of the Earth and later lithify into sedimentary rock, or when as volcanic material such as volcanic ash or lava flows, blanket the surface. Igneous intrusions such as batholiths, laccoliths, dikes, and sills, push upwards into the overlying rock, and crystallize as they intrude.

After the initial sequence of rocks has been deposited, the rock units can be deformed and/or metamorphosed. Deformation typically occurs as a result of horizontal shortening, horizontal extension, or side-to-side (strike-slip) motion. These structural regimes broadly relate to convergent boundaries, divergent boundaries, and transform boundaries, respectively, between tectonic plates.

Earth is estimated to have formed 4.54 billion years ago from the solar nebula, along with the Sun and other planets. The moon formed roughly 20 million years later. Initially molten, the outer layer of the Earth cooled, resulting in the solid crust. Outgassing and volcanic activity produced the primordial atmosphere. Condensing water vapor, most or all of which came from ice delivered by comets, produced the oceans and other water sources. The highly energetic chemistry is believed to have produced a self-replicating molecule around 4 billion years ago.

Continents formed, then broke up and reformed as the surface of Earth reshaped over hundreds of millions of years, occasionally combining to make a supercontinent. Roughly 750 million years ago, the earliest known supercontinent Rodinia, began to break apart. The continents later recombined to form Pannotia which broke apart about 540 million years ago, then finally Pangaea, which broke apart about 180 million years ago.

During the Neoproterozoic era, freezing temperatures covered much of the Earth in glaciers and ice sheets. This hypothesis has been termed the "Snowball Earth", and it is of particular interest as it precedes the Cambrian explosion in which multicellular life forms began to proliferate about 530–540 million years ago.

Since the Cambrian explosion there have been five distinctly identifiable mass extinctions. The last mass extinction occurred some 66 million years ago, when a meteorite collision probably triggered the extinction of the non-avian dinosaurs and other large reptiles, but spared small animals such as mammals. Over the past 66 million years, mammalian life diversified.

Several million years ago, a species of small African ape gained the ability to stand upright. The subsequent advent of human life, and the development of agriculture and further civilization allowed humans to affect the Earth more rapidly than any previous life form, affecting both the nature and quantity of other organisms as well as global climate. By comparison, the Great Oxygenation Event, produced by the proliferation of algae during the Siderian period, required about 300 million years to culminate.

The present era is classified as part of a mass extinction event, the Holocene extinction event, the fastest ever to have occurred. Some, such as E. O. Wilson of Harvard University, predict that human destruction of the biosphere could cause the extinction of one-half of all species in the next 100 years. The extent of the current extinction event is still being researched, debated and calculated by biologists.
The Earth's atmosphere is a key factor in sustaining the ecosystem. The thin layer of gases that envelops the Earth is held in place by gravity. Air is mostly nitrogen, oxygen, water vapor, with much smaller amounts of carbon dioxide, argon, etc. The atmospheric pressure declines steadily with altitude. The ozone layer plays an important role in depleting the amount of ultraviolet (UV) radiation that reaches the surface. As DNA is readily damaged by UV light, this serves to protect life at the surface. The atmosphere also retains heat during the night, thereby reducing the daily temperature extremes.

Terrestrial weather occurs almost exclusively in the lower part of the atmosphere, and serves as a convective system for redistributing heat. Ocean currents are another important factor in determining climate, particularly the major underwater thermohaline circulation which distributes heat energy from the equatorial oceans to the polar regions. These currents help to moderate the differences in temperature between winter and summer in the temperate zones. Also, without the redistributions of heat energy by the ocean currents and atmosphere, the tropics would be much hotter, and the polar regions much colder.

Weather can have both beneficial and harmful effects. Extremes in weather, such as tornadoes or hurricanes and cyclones, can expend large amounts of energy along their paths, and produce devastation. Surface vegetation has evolved a dependence on the seasonal variation of the weather, and sudden changes lasting only a few years can have a dramatic effect, both on the vegetation and on the animals which depend on its growth for their food.

Climate is a measure of the long-term trends in the weather. Various factors are known to influence the climate, including ocean currents, surface albedo, greenhouse gases, variations in the solar luminosity, and changes to the Earth's orbit. Based on historical records, the Earth is known to have undergone drastic climate changes in the past, including ice ages.

The climate of a region depends on a number of factors, especially latitude. A latitudinal band of the surface with similar climatic attributes forms a climate region. There are a number of such regions, ranging from the tropical climate at the equator to the polar climate in the northern and southern extremes. Weather is also influenced by the seasons, which result from the Earth's axis being tilted relative to its orbital plane. Thus, at any given time during the summer or winter, one part of the Earth is more directly exposed to the rays of the sun. This exposure alternates as the Earth revolves in its orbit. At any given time, regardless of season, the northern and southern hemispheres experience opposite seasons.

Weather is a chaotic system that is readily modified by small changes to the environment, so accurate weather forecasting is limited to only a few days. Overall, two things are happening worldwide: (1) temperature is increasing on the average; and (2) regional climates have been undergoing noticeable changes.

Water is a chemical substance that is composed of hydrogen and oxygen (H2O) and is vital for all known forms of life. In typical usage, "water" refers only to its liquid form or state, but the substance also has a solid state, ice, and a gaseous state, water vapor, or steam. Water covers 71% of the Earth's surface. On Earth, it is found mostly in oceans and other large bodies of water, with 1.6% of water below ground in aquifers and 0.001% in the air as vapor, clouds, and precipitation. Oceans hold 97% of surface water, glaciers, and polar ice caps 2.4%, and other land surface water such as rivers, lakes, and ponds 0.6%. Additionally, a minute amount of the Earth's water is contained within biological bodies and manufactured products.

An ocean is a major body of saline water, and a principal component of the hydrosphere. Approximately 71% of the Earth's surface (an area of some 361 million square kilometers) is covered by ocean, a continuous body of water that is customarily divided into several principal oceans and smaller seas. More than half of this area is over deep. Average oceanic salinity is around 35 parts per thousand (ppt) (3.5%), and nearly all seawater has a salinity in the range of 30 to 38 ppt. Though generally recognized as several 'separate' oceans, these waters comprise one global, interconnected body of salt water often referred to as the World Ocean or global ocean. This concept of a global ocean as a continuous body of water with relatively free interchange among its parts is of fundamental importance to oceanography.

The major oceanic divisions are defined in part by the continents, various archipelagos, and other criteria: these divisions are (in descending order of size) the Pacific Ocean, the Atlantic Ocean, the Indian Ocean, the Southern Ocean, and the Arctic Ocean. Smaller regions of the oceans are called seas, gulfs, bays and other names. There are also salt lakes, which are smaller bodies of landlocked saltwater that are not interconnected with the World Ocean. Two notable examples of salt lakes are the Aral Sea and the Great Salt Lake.

A lake (from Latin word "lacus") is a terrain feature (or physical feature), a body of liquid on the surface of a world that is localized to the bottom of basin (another type of landform or terrain feature; that is, it is not global) and moves slowly if it moves at all. On Earth, a body of water is considered a lake when it is inland, not part of the ocean, is larger and deeper than a pond, and is fed by a river. The only world other than Earth known to harbor lakes is Titan, Saturn's largest moon, which has lakes of ethane, most likely mixed with methane. It is not known if Titan's lakes are fed by rivers, though Titan's surface is carved by numerous river beds. Natural lakes on Earth are generally found in mountainous areas, rift zones, and areas with ongoing or recent glaciation. Other lakes are found in endorheic basins or along the courses of mature rivers. In some parts of the world, there are many lakes because of chaotic drainage patterns left over from the last Ice Age. All lakes are temporary over geologic time scales, as they will slowly fill in with sediments or spill out of the basin containing them.

A pond is a body of standing water, either natural or man-made, that is usually smaller than a lake. A wide variety of man-made bodies of water are classified as ponds, including water gardens designed for aesthetic ornamentation, fish ponds designed for commercial fish breeding, and solar ponds designed to store thermal energy. Ponds and lakes are distinguished from streams via current speed. While currents in streams are easily observed, ponds and lakes possess thermally driven micro-currents and moderate wind driven currents. These features distinguish a pond from many other aquatic terrain features, such as stream pools and tide pools.

A river is a natural watercourse, usually freshwater, flowing towards an ocean, a lake, a sea or another river. In a few cases, a river simply flows into the ground or dries up completely before reaching another body of water. Small rivers may also be called by several other names, including stream, creek, brook, rivulet, and rill; there is no general rule that defines what can be called a river. Many names for small rivers are specific to geographic location; one example is "Burn" in Scotland and North-east England. Sometimes a river is said to be larger than a creek, but this is not always the case, due to vagueness in the language. A river is part of the hydrological cycle. Water within a river is generally collected from precipitation through surface runoff, groundwater recharge, springs, and the release of stored water in natural ice and snowpacks (i.e., from glaciers).

A stream is a flowing body of water with a current, confined within a bed and stream banks. In the United States, a stream is classified as a watercourse less than wide. Streams are important as conduits in the water cycle, instruments in groundwater recharge, and they serve as corridors for fish and wildlife migration. The biological habitat in the immediate vicinity of a stream is called a riparian zone. Given the status of the ongoing Holocene extinction, streams play an important corridor role in connecting fragmented habitats and thus in conserving biodiversity. The study of streams and waterways in general involves many branches of inter-disciplinary natural science and engineering, including hydrology, fluvial geomorphology, aquatic ecology, fish biology, riparian ecology, and others.

Ecosystems are composed of a variety of biotic and abiotic components that function in an interrelated way. The structure and composition is determined by various environmental factors that are interrelated. Variations of these factors will initiate dynamic modifications to the ecosystem. Some of the more important components are soil, atmosphere, radiation from the sun, water, and living organisms.

Central to the ecosystem concept is the idea that living organisms interact with every other element in their local environment. Eugene Odum, a founder of ecology, stated: "Any unit that includes all of the organisms (ie: the "community") in a given area interacting with the physical environment so that a flow of energy leads to clearly defined trophic structure, biotic diversity, and material cycles (i.e.: exchange of materials between living and nonliving parts) within the system is an ecosystem." Within the ecosystem, species are connected and dependent upon one another in the food chain, and exchange energy and matter between themselves as well as with their environment. The human ecosystem concept is based on the human/nature dichotomy and the idea that all species are ecologically dependent on each other, as well as with the abiotic constituents of their biotope.

A smaller unit of size is called a microecosystem. For example, a microsystem can be a stone and all the life under it. A "macroecosystem" might involve a whole ecoregion, with its drainage basin.

Wilderness is generally defined as areas that have not been significantly modified by human activity. Wilderness areas can be found in preserves, estates, farms, conservation preserves, ranches, , national parks, and even in urban areas along rivers, gulches, or otherwise undeveloped areas. Wilderness areas and protected parks are considered important for the survival of certain species, ecological studies, conservation, and solitude. Some nature writers believe wilderness areas are vital for the human spirit and creativity, and some ecologists consider wilderness areas to be an integral part of the Earth's self-sustaining natural ecosystem (the biosphere). They may also preserve historic genetic traits and that they provide habitat for wild flora and fauna that may be difficult or impossible to recreate in zoos, arboretums, or laboratories.

Although there is no universal agreement on the definition of life, scientists generally accept that the biological manifestation of life is characterized by organization, metabolism, growth, adaptation, response to stimuli, and reproduction. Life may also be said to be simply the characteristic state of organisms.

Properties common to terrestrial organisms (plants, animals, fungi, protists, archaea, and bacteria) are that they are cellular, carbon-and-water-based with complex organization, having a metabolism, a capacity to grow, respond to stimuli, and reproduce. An entity with these properties is generally considered life. However, not every definition of life considers all of these properties to be essential. Human-made analogs of life may also be considered to be life.

The biosphere is the part of Earth's outer shell—including land, surface rocks, water, air and the atmosphere—within which life occurs, and which biotic processes in turn alter or transform. From the broadest geophysiological point of view, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere (rocks), hydrosphere (water), and atmosphere (air). The entire Earth contains over 75 billion tons (150 "trillion" pounds or about 6.8×10 kilograms) of biomass (life), which lives within various environments within the biosphere.

Over nine-tenths of the total biomass on Earth is plant life, on which animal life depends very heavily for its existence. More than 2 million species of plant and animal life have been identified to date, and estimates of the actual number of existing species range from several million to well over 50 million. The number of individual species of life is constantly in some degree of flux, with new species appearing and others ceasing to exist on a continual basis. The total number of species is in rapid decline.

The origin of life on Earth is not well understood, but it is known to have occurred at least 3.5 billion years ago, during the hadean or archean eons on a primordial Earth that had a substantially different environment than is found at present. These life forms possessed the basic traits of self-replication and inheritable traits. Once life had appeared, the process of evolution by natural selection resulted in the development of ever-more diverse life forms.

Species that were unable to adapt to the changing environment and competition from other life forms became extinct. However, the fossil record retains evidence of many of these older species. Current fossil and DNA evidence shows that all existing species can trace a continual ancestry back to the first primitive life forms.

When basic forms of plant life developed the process of photosynthesis the sun's energy could be harvested to create conditions which allowed for more complex life forms. The resultant oxygen accumulated in the atmosphere and gave rise to the ozone layer. The incorporation of smaller cells within larger ones resulted in the development of yet more complex cells called eukaryotes. Cells within colonies became increasingly specialized, resulting in true multicellular organisms. With the ozone layer absorbing harmful ultraviolet radiation, life colonized the surface of Earth.

The first form of life to develop on the Earth were microbes, and they remained the only form of life until about a billion years ago when multi-cellular organisms began to appear. Microorganisms are single-celled organisms that are generally microscopic, and smaller than the human eye can see. They include Bacteria, Fungi, Archaea, and Protista.

These life forms are found in almost every location on the Earth where there is liquid water, including in the Earth's interior.
Their reproduction is both rapid and profuse. The combination of a high mutation rate and a horizontal gene transfer ability makes them highly adaptable, and able to survive in new environments, including outer space. They form an essential part of the planetary ecosystem. However, some microorganisms are pathogenic and can post health risk to other organisms.

Originally Aristotle divided all living things between plants, which generally do not move fast enough for humans to notice, and animals. In Linnaeus' system, these became the kingdoms Vegetabilia (later Plantae) and Animalia. Since then, it has become clear that the Plantae as originally defined included several unrelated groups, and the fungi and several groups of algae were removed to new kingdoms. However, these are still often considered plants in many contexts. Bacterial life is sometimes included in flora, and some classifications use the term "bacterial flora" separately from "plant flora".

Among the many ways of classifying plants are by regional floras, which, depending on the purpose of study, can also include "fossil flora", remnants of plant life from a previous era. People in many regions and countries take great pride in their individual arrays of characteristic flora, which can vary widely across the globe due to differences in climate and terrain.

Regional floras commonly are divided into categories such as "native flora" and "agricultural and garden flora", the lastly mentioned of which are intentionally grown and cultivated. Some types of "native flora" actually have been introduced centuries ago by people migrating from one region or continent to another, and become an integral part of the native, or natural flora of the place to which they were introduced. This is an example of how human interaction with nature can blur the boundary of what is considered nature.

Another category of plant has historically been carved out for "weeds". Though the term has fallen into disfavor among botanists as a formal way to categorize "useless" plants, the informal use of the word "weeds" to describe those plants that are deemed worthy of elimination is illustrative of the general tendency of people and societies to seek to alter or shape the course of nature. Similarly, animals are often categorized in ways such as "domestic", "farm animals", "wild animals", "pests", etc. according to their relationship to human life.

Animals as a category have several characteristics that generally set them apart from other living things. Animals are eukaryotic and usually multicellular (although see Myxozoa), which separates them from bacteria, archaea, and most protists. They are heterotrophic, generally digesting food in an internal chamber, which separates them from plants and algae. They are also distinguished from plants, algae, and fungi by lacking cell walls.

With a few exceptions—most notably the two phyla consisting of sponges and placozoans—animals have bodies that are differentiated into tissues. These include muscles, which are able to contract and control locomotion, and a nervous system, which sends and processes signals. There is also typically an internal digestive chamber. The eukaryotic cells possessed by all animals are surrounded by a characteristic extracellular matrix composed of collagen and elastic glycoproteins. This may be calcified to form structures like shells, bones, and spicules, a framework upon which cells can move about and be reorganized during development and maturation, and which supports the complex anatomy required for mobility.

Although humans comprise only a minuscule proportion of the total living biomass on Earth, the human effect on nature is disproportionately large. Because of the extent of human influence, the boundaries between what humans regard as nature and "made environments" is not clear cut except at the extremes. Even at the extremes, the amount of natural environment that is free of discernible human influence is diminishing at an increasingly rapid pace.

The development of technology by the human race has allowed the greater exploitation of natural resources and has helped to alleviate some of the risk from natural hazards. In spite of this progress, however, the fate of human civilization remains closely linked to changes in the environment. There exists a highly complex feedback loop between the use of advanced technology and changes to the environment that are only slowly becoming understood. Man-made threats to the Earth's natural environment include pollution, deforestation, and disasters such as oil spills. Humans have contributed to the extinction of many plants and animals.

Humans employ nature for both leisure and economic activities. The acquisition of natural resources for industrial use remains a sizable component of the world's economic system. Some activities, such as hunting and fishing, are used for both sustenance and leisure, often by different people. Agriculture was first adopted around the 9th millennium BCE. Ranging from food production to energy, nature influences economic wealth.

Although early humans gathered uncultivated plant materials for food and employed the medicinal properties of vegetation for healing, most modern human use of plants is through agriculture. The clearance of large tracts of land for crop growth has led to a significant reduction in the amount available of forestation and wetlands, resulting in the loss of habitat for many plant and animal species as well as increased erosion.

Beauty in nature has historically been a prevalent theme in art and books, filling large sections of libraries and bookstores. That nature has been depicted and celebrated by so much art, photography, poetry, and other literature shows the strength with which many people associate nature and beauty. Reasons why this association exists, and what the association consists of, are studied by the branch of philosophy called aesthetics. Beyond certain basic characteristics that many philosophers agree about to explain what is seen as beautiful, the opinions are virtually endless. Nature and wildness have been important subjects in various eras of world history. An early tradition of landscape art began in China during the Tang Dynasty (618–907). The tradition of representing nature "as it is" became one of the aims of Chinese painting and was a significant influence in Asian art.

Although natural wonders are celebrated in the Psalms and the Book of Job, wilderness portrayals in art became more prevalent in the 1800s, especially in the works of the Romantic movement. British artists John Constable and J. M. W. Turner turned their attention to capturing the beauty of the natural world in their paintings. Before that, paintings had been primarily of religious scenes or of human beings. William Wordsworth's poetry described the wonder of the natural world, which had formerly been viewed as a threatening place. Increasingly the valuing of nature became an aspect of Western culture. This artistic movement also coincided with the Transcendentalist movement in the Western world. A common classical idea of beautiful art involves the word mimesis, the imitation of nature. Also in the realm of ideas about beauty in nature is that the perfect is implied through perfect mathematical forms and more generally by patterns in nature. As David Rothenburg writes, "The beautiful is the root of science and the goal of art, the highest possibility that humanity can ever hope to see".

Some fields of science see nature as matter in motion, obeying certain laws of nature which science seeks to understand. For this reason the most fundamental science is generally understood to be "physics"—the name for which is still recognizable as meaning that it is the "study of nature".

Matter is commonly defined as the substance of which physical objects are composed. It constitutes the observable universe. The visible components of the universe are now believed to compose only 4.9 percent of the total mass. The remainder is believed to consist of 26.8 percent cold dark matter and 68.3 percent dark energy. The exact arrangement of these components is still unknown and is under intensive investigation by physicists.

The behaviour of matter and energy throughout the observable universe appears to follow well-defined physical laws. These laws have been employed to produce cosmological models that successfully explain the structure and the evolution of the universe we can observe. The mathematical expressions of the laws of physics employ a set of twenty physical constants that appear to be static across the observable universe. The values of these constants have been carefully measured, but the reason for their specific values remains a mystery.

Outer space, also simply called "space", refers to the relatively empty regions of the universe outside the atmospheres of celestial bodies. "Outer" space is used to distinguish it from airspace (and terrestrial locations). There is no discrete boundary between the Earth's atmosphere and space, as the atmosphere gradually attenuates with increasing altitude. Outer space within the Solar System is called interplanetary space, which passes over into interstellar space at what is known as the heliopause.

Outer space is sparsely filled with several dozen types of organic molecules discovered to date by microwave spectroscopy, blackbody radiation left over from the Big Bang and the origin of the universe, and cosmic rays, which include ionized atomic nuclei and various subatomic particles. There is also some gas, plasma and dust, and small meteors. Additionally, there are signs of human life in outer space today, such as material left over from previous manned and unmanned launches which are a potential hazard to spacecraft. Some of this debris re-enters the atmosphere periodically.

Although the Earth is the only body within the solar system known to support life, evidence suggests that in the distant past the planet Mars possessed bodies of liquid water on the surface. For a brief period in Mars' history, it may have also been capable of forming life. At present though, most of the water remaining on Mars is frozen.
If life exists at all on Mars, it is most likely to be located underground where liquid water can still exist.

Conditions on the other terrestrial planets, Mercury and Venus, appear to be too harsh to support life as we know it. But it has been conjectured that Europa, the fourth-largest moon of Jupiter, may possess a sub-surface ocean of liquid water and could potentially host life.

Astronomers have started to discover extrasolar Earth analogs – planets that lie in the habitable zone of space surrounding a star, and therefore could possibly host life as we know it.

Media:
Organizations:
Philosophy:




</doc>
<doc id="35659147" url="https://en.wikipedia.org/wiki?curid=35659147" title="Patterns in nature">
Patterns in nature

Patterns in nature are visible regularities of form found in the natural world. These patterns recur in different contexts and can sometimes be modelled mathematically. Natural patterns include symmetries, trees, spirals, meanders, waves, foams, tessellations, cracks and stripes. Early Greek philosophers studied pattern, with Plato, Pythagoras and Empedocles attempting to explain order in nature. The modern understanding of visible patterns developed gradually over time.

In the 19th century, Belgian physicist Joseph Plateau examined soap films, leading him to formulate the concept of a minimal surface. German biologist and artist Ernst Haeckel painted hundreds of marine organisms to emphasise their symmetry. Scottish biologist D'Arcy Thompson pioneered the study of growth patterns in both plants and animals, showing that simple equations could explain spiral growth. In the 20th century, British mathematician Alan Turing predicted mechanisms of morphogenesis which give rise to patterns of spots and stripes. Hungarian biologist Aristid Lindenmayer and French American mathematician Benoît Mandelbrot showed how the mathematics of fractals could create plant growth patterns.

Mathematics, physics and chemistry can explain patterns in nature at different levels. Patterns in living things are explained by the biological processes of natural selection and sexual selection. Studies of pattern formation make use of computer models to simulate a wide range of patterns.

Early Greek philosophers attempted to explain order in nature, anticipating modern concepts. Pythagoras (c. 570–c. 495 BC) explained patterns in nature like the harmonies of music as arising from number, which he took to be the basic constituent of existence. Empedocles (c. 494–c. 434 BC) to an extent anticipated Darwin's evolutionary explanation for the structures of organisms. Plato (c. 427–c. 347 BC) argued for the existence of natural universals. He considered these to consist of ideal forms ( "eidos": "form") of which physical objects are never more than imperfect copies. Thus, a flower may be roughly circular, but it is never a perfect circle.

Theophrastus (c. 372–c. 287 BC) noted that plants "that have flat leaves have them in a regular series"; Pliny the Elder (23–79 AD) noted their patterned circular arrangement. Centuries later, Leonardo da Vinci (1452–1519) noted the spiral arrangement of leaf patterns, that tree trunks gain successive rings as they age, and proposed a rule purportedly satisfied by the cross-sectional areas of tree-branches. Johannes Kepler (1571–1630) pointed out the presence of the Fibonacci sequence in nature, using it to explain the pentagonal form of some flowers. In 1754, Charles Bonnet observed that the spiral phyllotaxis of plants were frequently expressed in both clockwise and counter-clockwise golden ratio series. Mathematical observations of phyllotaxis followed with Karl Friedrich Schimper and his friend Alexander Braun's 1830 and 1830 work, respectively; Auguste Bravais and his brother Louis connected phyllotaxis ratios to the Fibonacci sequence in 1837, also noting its appearance in pinecones and pineapples. In his 1854 book, German psychologist Adolf Zeising explored the golden ratio expressed in the arrangement of plant parts, the skeletons of animals and the branching patterns of their veins and nerves, as well as in crystals. A. H. Church studied the patterns of phyllotaxis in his 1904 book. In 1917, D'Arcy Thompson published "On Growth and Form"; his description of phyllotaxis and the Fibonacci sequence, the mathematical relationships in the spiral growth patterns of plants showed that simple equations could describe the spiral growth patterns of animal horns and mollusc shells.

In 1202, Leonardo Fibonacci introduced the Fibonacci sequence to the western world with his book "Liber Abaci". Fibonacci presented a thought experiment on the growth of an idealized rabbit population.

In 1658, the English physician and philosopher Sir Thomas Browne discussed "how Nature Geometrizeth" in "The Garden of Cyrus", citing Pythagorean numerology involving the number 5, and the Platonic form of the quincunx pattern. The discourse's central chapter features examples and observations of the quincunx in botany.

The Belgian physicist Joseph Plateau (1801–1883) formulated the mathematical problem of the existence of a minimal surface with a given boundary, which is now named after him. He studied soap films intensively, formulating Plateau's laws which describe the structures formed by films in foams.

Ernst Haeckel (1834–1919) painted beautiful illustrations of marine organisms, in particular Radiolaria, emphasising their symmetry to support his faux-Darwinian theories of evolution.

The American photographer Wilson Bentley took the first micrograph of a snowflake in 1885.
In 1952, Alan Turing (1912–1954), better known for his work on computing and codebreaking, wrote "The Chemical Basis of Morphogenesis", an analysis of the mechanisms that would be needed to create patterns in living organisms, in the process called morphogenesis. He predicted oscillating chemical reactions, in particular the Belousov–Zhabotinsky reaction. These activator-inhibitor mechanisms can, Turing suggested, generate patterns (dubbed "Turing patterns") of stripes and spots in animals, and contribute to the spiral patterns seen in plant phyllotaxis.

In 1968, the Hungarian theoretical biologist Aristid Lindenmayer (1925–1989) developed the L-system, a formal grammar which can be used to model plant growth patterns in the style of fractals. L-systems have an alphabet of symbols that can be combined using production rules to build larger strings of symbols, and a mechanism for translating the generated strings into geometric structures. In 1975, after centuries of slow development of the mathematics of patterns by Gottfried Leibniz, Georg Cantor, Helge von Koch, Wacław Sierpiński and others, Benoît Mandelbrot wrote a famous paper, "How Long Is the Coast of Britain? Statistical Self-Similarity and Fractional Dimension", crystallising mathematical thought into the concept of the fractal.

Living things like orchids, hummingbirds, and the peacock's tail have abstract designs with a beauty of form, pattern and colour that artists struggle to match. The beauty that people perceive in nature has causes at different levels, notably in the mathematics that governs what patterns can physically form, and among living things in the effects of natural selection, that govern how patterns evolve.

Mathematics seeks to discover and explain abstract patterns or regularities of all kinds.
Visual patterns in nature find explanations in chaos theory, fractals, logarithmic spirals, topology and other mathematical patterns. For example, L-systems form convincing models of different patterns of tree growth.

The laws of physics apply the abstractions of mathematics to the real world, often as if it were perfect. For example, a crystal is perfect when it has no structural defects such as dislocations and is fully symmetric. Exact mathematical perfection can only approximate real objects. Visible patterns in nature are governed by physical laws; for example, meanders can be explained using fluid dynamics.

In biology, natural selection can cause the development of patterns in living things for several reasons, including camouflage, sexual selection, and different kinds of signalling, including mimicry and cleaning symbiosis. In plants, the shapes, colours, and patterns of insect-pollinated flowers like the lily have evolved to attract insects such as bees. Radial patterns of colours and stripes, some visible only in ultraviolet light serve as nectar guides that can be seen at a distance.

Symmetry is pervasive in living things. Animals mainly have bilateral or mirror symmetry, as do the leaves of plants and some flowers such as orchids. Plants often have radial or rotational symmetry, as do many flowers and some groups of animals such as sea anemones. Fivefold symmetry is found in the echinoderms, the group that includes starfish, sea urchins, and sea lilies.

Among non-living things, snowflakes have striking sixfold symmetry; each flake's structure forms a record of the varying conditions during its crystallization, with nearly the same pattern of growth on each of its six arms. Crystals in general have a variety of symmetries and crystal habits; they can be cubic or octahedral, but true crystals cannot have fivefold symmetry (unlike quasicrystals). Rotational symmetry is found at different scales among non-living things, including the crown-shaped splash pattern formed when a drop falls into a pond, and both the spheroidal shape and rings of a planet like Saturn.

Symmetry has a variety of causes. Radial symmetry suits organisms like sea anemones whose adults do not move: food and threats may arrive from any direction. But animals that move in one direction necessarily have upper and lower sides, head and tail ends, and therefore a left and a right. The head becomes specialised with a mouth and sense organs (cephalisation), and the body becomes bilaterally symmetric (though internal organs need not be). More puzzling is the reason for the fivefold (pentaradiate) symmetry of the echinoderms. Early echinoderms were bilaterally symmetrical, as their larvae still are. Sumrall and Wray argue that the loss of the old symmetry had both developmental and ecological causes.

The branching pattern of trees was described in the Italian Renaissance by Leonardo da Vinci. He stated that:

All the branches of a tree at every stage of its height when put together are equal in thickness to the trunk [below them].

A more general version states that when a parent branch splits into two or more child branches, the surface areas of the child branches add up to that of the parent branch. An equivalent formulation is that if a parent branch splits into two child branches, then the cross-sectional diameters of the parent and the two child branches form a right-angled triangle. One explanation is that this allows trees to better withstand high winds. Simulations of biomechanical models agree with the rule.

Fractals are infinitely self-similar, iterated mathematical constructs having fractal dimension. Infinite iteration is not possible in nature so all 'fractal' patterns are only approximate. For example, the leaves of ferns and umbellifers (Apiaceae) are only self-similar (pinnate) to 2, 3 or 4 levels. Fern-like growth patterns occur in plants and in animals including bryozoa, corals, hydrozoa like the air fern, "Sertularia argentea", and in non-living things, notably electrical discharges. Lindenmayer system fractals can model different patterns of tree growth by varying a small number of parameters including branching angle, distance between nodes or branch points (internode length), and number of branches per branch point.

Fractal-like patterns occur widely in nature, in phenomena as diverse as clouds, river networks, geologic fault lines, mountains, coastlines, animal coloration, snow flakes, crystals, blood vessel branching, actin cytoskeleton, and ocean waves.

Spirals are common in plants and in some animals, notably molluscs. For example, in the nautilus, a cephalopod mollusc, each chamber of its shell is an approximate copy of the next one, scaled by a constant factor and arranged in a logarithmic spiral. Given a modern understanding of fractals, a growth spiral can be seen as a special case of self-similarity.

Plant spirals can be seen in phyllotaxis, the arrangement of leaves on a stem, and in the arrangement (parastichy) of other parts as in composite flower heads and seed heads like the sunflower or fruit structures like the pineapple and snake fruit, as well as in the pattern of scales in pine cones, where multiple spirals run both clockwise and anticlockwise. These arrangements have explanations at different levels – mathematics, physics, chemistry, biology – each individually correct, but all necessary together. Phyllotaxis spirals can be generated mathematically from Fibonacci ratios: the Fibonacci sequence runs 1, 1, 2, 3, 5, 8, 13... (each subsequent number being the sum of the two preceding ones). For example, when leaves alternate up a stem, one rotation of the spiral touches two leaves, so the pattern or ratio is 1/2. In hazel the ratio is 1/3; in apricot it is 2/5; in pear it is 3/8; in almond it is 5/13. In disc phyllotaxis as in the sunflower and daisy, the florets are arranged in Fermat's spiral with Fibonacci numbering, at least when the flowerhead is mature so all the elements are the same size. Fibonacci ratios approximate the golden angle, 137.508°, which governs the curvature of Fermat's spiral.

From the point of view of physics, spirals are lowest-energy configurations which emerge spontaneously through self-organizing processes in dynamic systems. From the point of view of chemistry, a spiral can be generated by a reaction-diffusion process, involving both activation and inhibition. Phyllotaxis is controlled by proteins that manipulate the concentration of the plant hormone auxin, which activates meristem growth, alongside other mechanisms to control the relative angle of buds around the stem. From a biological perspective, arranging leaves as far apart as possible in any given space is favoured by natural selection as it maximises access to resources, especially sunlight for photosynthesis.

In mathematics, a dynamical system is chaotic if it is (highly) sensitive to initial conditions (the so-called "butterfly effect"), which requires the mathematical properties of topological mixing and dense periodic orbits.

Alongside fractals, chaos theory ranks as an essentially universal influence on patterns in nature. There is a relationship between chaos and fractals—the "strange attractors" in chaotic systems have a fractal dimension. Some cellular automata, simple sets of mathematical rules that generate patterns, have chaotic behaviour, notably Stephen Wolfram's Rule 30.

Vortex streets are zigzagging patterns of whirling vortices created by the unsteady separation of flow of a fluid, most often air or water, over obstructing objects. Smooth (laminar) flow starts to break up when the size of the obstruction or the velocity of the flow become large enough compared to the viscosity of the fluid.

Meanders are sinuous bends in rivers or other channels, which form as a fluid, most often water, flows around bends. As soon as the path is slightly curved, the size and curvature of each loop increases as helical flow drags material like sand and gravel across the river to the inside of the bend. The outside of the loop is left clean and unprotected, so erosion accelerates, further increasing the meandering in a powerful positive feedback loop.

Waves are disturbances that carry energy as they move. Mechanical waves propagate through a medium – air or water, making it oscillate as they pass by. Wind waves are sea surface waves that create the characteristic chaotic pattern of any large body of water, though their statistical behaviour can be predicted with wind wave models. As waves in water or wind pass over sand, they create patterns of ripples. When winds blow over large bodies of sand, they create dunes, sometimes in extensive dune fields as in the Taklamakan desert. Dunes may form a range of patterns including crescents, very long straight lines, stars, domes, parabolas, and longitudinal or seif ('sword') shapes.

Barchans or crescent dunes are produced by wind acting on desert sand; the two horns of the crescent and the slip face point downwind. Sand blows over the upwind face, which stands at about 15 degrees from the horizontal, and falls onto the slip face, where it accumulates up to the angle of repose of the sand, which is about 35 degrees. When the slip face exceeds the angle of repose, the sand avalanches, which is a nonlinear behaviour: the addition of many small amounts of sand causes nothing much to happen, but then the addition of a further small amount suddenly causes a large amount to avalanche. Apart from this nonlinearity, barchans behave rather like solitary waves.

A soap bubble forms a sphere, a surface with minimal area — the smallest possible surface area for the volume enclosed. Two bubbles together form a more complex shape: the outer surfaces of both bubbles are spherical; these surfaces are joined by a third spherical surface as the smaller bubble bulges slightly into the larger one.

A foam is a mass of bubbles; foams of different materials occur in nature. Foams composed of soap films obey Plateau's laws, which require three soap films to meet at each edge at 120° and four soap edges to meet at each vertex at the tetrahedral angle of about 109.5°. Plateau's laws further require films to be smooth and continuous, and to have a constant average curvature at every point. For example, a film may remain nearly flat on average by being curved up in one direction (say, left to right) while being curved downwards in another direction (say, front to back). Structures with minimal surfaces can be used as tents. Lord Kelvin identified the problem of the most efficient way to pack cells of equal volume as a foam in 1887; his solution uses just one solid, the bitruncated cubic honeycomb with very slightly curved faces to meet Plateau's laws. No better solution was found until 1993 when Denis Weaire and Robert Phelan proposed the Weaire–Phelan structure; the Beijing National Aquatics Center adapted the structure for their outer wall in the 2008 Summer Olympics.

At the scale of living cells, foam patterns are common; radiolarians, sponge spicules, silicoflagellate exoskeletons and the calcite skeleton of a sea urchin, "Cidaris rugosa", all resemble mineral casts of Plateau foam boundaries. The skeleton of the Radiolarian, "Aulonia hexagona", a beautiful marine form drawn by Ernst Haeckel, looks as if it is a sphere composed wholly of hexagons, but this is mathematically impossible. The Euler characteristic states that for any convex polyhedron, the number of faces plus the number of vertices (corners) equals the number of edges plus two. A result of this formula is that any closed polyhedron of hexagons has to include exactly 12 pentagons, like a soccer ball, Buckminster Fuller geodesic dome, or fullerene molecule. This can be visualised by noting that a mesh of hexagons is flat like a sheet of chicken wire, but each pentagon that is added forces the mesh to bend (there are fewer corners, so the mesh is pulled in).

Tessellations are patterns formed by repeating tiles all over a flat surface. There are 17 wallpaper groups of tilings. While common in art and design, exactly repeating tilings are less easy to find in living things. The cells in the paper nests of social wasps, and the wax cells in honeycomb built by honey bees are well-known examples. Among animals, bony fish, reptiles or the pangolin, or fruits like the salak are protected by overlapping scales or osteoderms, these form more-or-less exactly repeating units, though often the scales in fact vary continuously in size. Among flowers, the snake's head fritillary, "Fritillaria meleagris", have a tessellated chequerboard pattern on their petals. The structures of minerals provide good examples of regularly repeating three-dimensional arrays. Despite the hundreds of thousands of known minerals, there are rather few possible types of arrangement of atoms in a crystal, defined by crystal structure, crystal system, and point group; for example, there are exactly 14 Bravais lattices for the 7 lattice systems in three-dimensional space.

Cracks are linear openings that form in materials to relieve stress. When an elastic material stretches or shrinks uniformly, it eventually reaches its breaking strength and then fails suddenly in all directions, creating cracks with 120 degree joints, so three cracks meet at a node. Conversely, when an inelastic material fails, straight cracks form to relieve the stress. Further stress in the same direction would then simply open the existing cracks; stress at right angles can create new cracks, at 90 degrees to the old ones. Thus the pattern of cracks indicates whether the material is elastic or not. In a tough fibrous material like oak tree bark, cracks form to relieve stress as usual, but they do not grow long as their growth is interrupted by bundles of strong elastic fibres. Since each species of tree has its own structure at the levels of cell and of molecules, each has its own pattern of splitting in its bark.

Leopards and ladybirds are spotted; angelfish and zebras are striped. These patterns have an evolutionary explanation: they have functions which increase the chances that the offspring of the patterned animal will survive to reproduce. One function of animal patterns is camouflage; for instance, a leopard that is harder to see catches more prey. Another function is signalling — for instance, a ladybird is less likely to be attacked by predatory birds that hunt by sight, if it has bold warning colours, and is also distastefully bitter or poisonous, or mimics other distasteful insects. A young bird may see a warning patterned insect like a ladybird and try to eat it, but it will only do this once; very soon it will spit out the bitter insect; the other ladybirds in the area will remain undisturbed. The young leopards and ladybirds, inheriting genes that somehow create spottedness, survive. But while these evolutionary and functional arguments explain why these animals need their patterns, they do not explain how the patterns are formed.

Alan Turing, and later the mathematical biologist James Murray, described a mechanism that spontaneously creates spotted or striped patterns: a reaction–diffusion system. The cells of a young organism have genes that can be switched on by a chemical signal, a morphogen, resulting in the growth of a certain type of structure, say a darkly pigmented patch of skin. If the morphogen is present everywhere, the result is an even pigmentation, as in a black leopard. But if it is unevenly distributed, spots or stripes can result. Turing suggested that there could be feedback control of the production of the morphogen itself. This could cause continuous fluctuations in the amount of morphogen as it diffused around the body. A second mechanism is needed to create standing wave patterns (to result in spots or stripes): an inhibitor chemical that switches off production of the morphogen, and that itself diffuses through the body more quickly than the morphogen, resulting in an activator-inhibitor scheme. The Belousov–Zhabotinsky reaction is a non-biological example of this kind of scheme, a chemical oscillator.

Later research has managed to create convincing models of patterns as diverse as zebra stripes, giraffe blotches, jaguar spots (medium-dark patches surrounded by dark broken rings) and ladybird shell patterns (different geometrical layouts of spots and stripes, see illustrations). Richard Prum's activation-inhibition models, developed from Turing's work, use six variables to account for the observed range of nine basic within-feather pigmentation patterns, from the simplest, a central pigment patch, via concentric patches, bars, chevrons, eye spot, pair of central spots, rows of paired spots and an array of dots. More elaborate models simulate complex feather patterns in the guineafowl "Numida meleagris" in which the individual feathers feature transitions from bars at the base to an array of dots at the far (distal) end. These require an oscillation created by two inhibiting signals, with interactions in both space and time.

Patterns can form for other reasons in the vegetated landscape of tiger bush and fir waves. Tiger bush stripes occur on arid slopes where plant growth is limited by rainfall. Each roughly horizontal stripe of vegetation effectively collects the rainwater from the bare zone immediately above it. Fir waves occur in forests on mountain slopes after wind disturbance, during regeneration. When trees fall, the trees that they had sheltered become exposed and are in turn more likely to be damaged, so gaps tend to expand downwind. Meanwhile, on the windward side, young trees grow, protected by the wind shadow of the remaining tall trees. Natural patterns are sometimes formed by animals, as in the Mima mounds of the Northwestern United States and some other areas, which appear to be created over many years by the burrowing activities of pocket gophers, while the so-called fairy circles of Namibia appear to be created by the interaction of competing groups of sand termites, along with competition for water among the desert plants.

In permafrost soils with an active upper layer subject to annual freeze and thaw, patterned ground can form, creating circles, nets, ice wedge polygons, steps, and stripes. Thermal contraction causes shrinkage cracks to form; in a thaw, water fills the cracks, expanding to form ice when next frozen, and widening the cracks into wedges. These cracks may join up to form polygons and other shapes.

The fissured pattern that develops on vertebrate brains are caused by a physical process of constrained expansion dependent on two geometric parameters: relative tangential cortical expansion and relative thickness of the cortex. Similar patterns of gyri (peaks) and sulci (troughs) have been demonstrated in models of the brain starting from smooth, layered gels, with the patterns caused by compressive mechanical forces resulting from the expansion of the outer layer (representing the cortex) after the addition of a solvent. Numerical models in computer simulations support natural and experimental observations that the surface folding patterns increase in larger brains.


Footnotes
Citations
Pioneering authors


General books

Patterns from nature (as art)



</doc>
<doc id="14389994" url="https://en.wikipedia.org/wiki?curid=14389994" title="Natural landscape">
Natural landscape

A natural landscape is the original landscape that exists before it is acted upon by human culture. The natural landscape and the cultural landscape are separate parts of the landscape. However, in the twenty-first century landscapes that are totally untouched by human activity no longer exist, so that reference is sometimes now made to degrees of naturalness within a landscape.

In "Silent Spring" (1962) Rachel Carson describes a roadside verge as it used to look: "Along the roads, laurel, viburnum and alder, great ferns and wildflowers delighted the traveler’s eye through much of the year" and then how it looks now following the use of herbicides: "The roadsides, once so attractive, were now lined with browned and withered vegetation as though swept by fire". Even though the landscape before it is sprayed is biologically degraded, and may well contains alien species, the concept of what might constitute a natural landscape can still be deduced from the context.

The phrase "natural landscape" was first used in connection with landscape painting, and landscape gardening, to contrast a formal style with a more natural one, closer to nature. Alexander von Humboldt (1769 – 1859) was to further conceptualize this into the idea of a natural landscape "separate" from the cultural landscape. Then in 1908 geographer Otto Schlüter developed the terms original landscape ("Urlandschaft") and its opposite cultural landscape ("Kulturlandschaft") in an attempt to give the science of geography a subject matter that was different from the other sciences. An early use of the actual phrase "natural landscape" by a geographer can be found in Carl O. Sauer's paper "The Morphology of Landscape" (1925).

The concept of a natural landscape was first developed in connection with landscape painting, though the actual term itself was first used in relation to landscape gardening. In both cases it was used to contrast a formal style with a more natural one, that is closer to nature. Chunglin Kwa suggests, "that a seventeenth-century or early-eighteenth-century person could experience natural scenery ‘just like on a painting,’ and so, with or without the use of the word itself, designate it as a landscape." With regard to landscape gardening John Aikin, commented in 1794: "Whatever, therefore, there be of "novelty" in the singular scenery of an artificial garden, it is soon exhausted, whereas the infinite diversity of a natural landscape presents an inexhaustible flore of new forms". Writing in 1844 the prominent American landscape gardener Andrew Jackson Downing comments: "straight canals, round or oblong pieces of water, and all the regular forms of the geometric mode ... would evidently be in violent opposition to the whole character and expression of natural landscape".

In his extensive travels in South America, Alexander von Humboldt became the first to conceptualize a natural landscape separate from the cultural landscape, though he does not actually use these terms. Andrew Jackson Downing was aware of, and sympathetic to, Humboldt's ideas, which therefore influenced American landscape gardening.

Subsequently, the geographer Otto Schlüter, in 1908, argued that by defining geography as a "Landschaftskunde" (landscape science) would give geography a logical subject matter shared by no other discipline. He defined two forms of landscape: the "Urlandschaft" (original landscape) or landscape that existed before major human induced changes and the "Kulturlandschaft" (cultural landscape) a landscape created by human culture. Schlüter argued that the major task of geography was to trace the changes in these two landscapes.

The term natural landscape is sometimes used as a synonym for wilderness, but for geographers natural landscape is a scientific term which refers to the biological, geological, climatological and other aspects of a landscape, not the cultural values that are implied by the word wilderness.

Matters are complicated by the fact that the words nature and natural have more than one meaning. On the one hand there is the main dictionary meaning for nature: "The phenomena of the physical world collectively, including plants, animals, the landscape, and other features and products of the earth, as opposed to humans or human creations." On the other hand, there is the growing awareness, especially since Charles Darwin, of humanities biological affinity with nature.

The dualism of the first definition has its roots is an "ancient concept", because early people viewed "nature, or the nonhuman world […] as a divine "Other", godlike in its separation from humans." In the West, Christianity's myth of the fall, that is the expulsion of humankind from the Garden of Eden, where all creation lived in harmony, into an imperfect world, has been the major influence. Cartesian dualism, from the seventeenth century on, further reinforced this dualistic thinking about nature. 
With this dualism goes value judgement as to the superiority of the natural over the artificial. Modern science, however, is moving towards a holistic view of nature.

What is meant by natural, within the American conservation movement, has been changing over the last century and a half.

In the mid-nineteenth century American began to realize that the land was becoming more and more domesticated and wildlife was disappearing. This led to the creation of American National Parks and other conservation sites. Initially it was believed that all that was needed to do was to separate what was seen as natural landscape and "avoid disturbances such as logging, grazing, fire and insect outbreaks." This, and subsequent environmental policy, until recently, was influenced by ideas of the wilderness. However, this policy was not consistently applied, and in Yellowstone Park, to take one example, the existing ecology was altered, firstly by the exclusion of Native Americans and later with the virtual extermination of the wolf population.

A century later, in the mid-twentieth century, it began to be believed that the earlier policy of "protection from disturbance was inadequate to preserve park values", and that is that direct human intervention was necessary to restore the landscape of National Parks to its ‘’natural’’ condition. In 1963 the Leopold Report argued that "A national park should represent a vignette of primitive America". This policy change eventually led to the restoration of wolves in Yellowstone Park in the 1990s.

However, recent research in various disciplines indicates that a pristine natural or "primitive" landscape is a myth, and it now realised that people have been changing the natural into a cultural landscape for a long while, and that there are few places untouched in some way from human influence. The earlier conservation policies were now seen as cultural interventions. The idea of what is natural and what artificial or cultural, and how to maintain the natural elements in a landscape, has been further complicated by the discovery of global warming and how it is changing natural landscapes.

Also important is a reaction recently amongst scholars against dualistic thinking about nature and culture. Maria Kaika comments: "Nowadays, we are beginning to see nature and culture as intertwined once again – not ontologically separated anymore […].What I used to perceive as a compartmentalized world, consisting of neatly and tightly sealed, autonomous ‘space envelopes’ (the home, the city, and nature) was, in fact, a messy socio-spatial continuum”. And William Cronon argues against the idea of wilderness because it "involves a dualistic vision in which the human is entirely outside the natural" and affirms that "wildness (as opposed to wilderness) can be found anywhere" even "in the cracks of a Manhattan sidewalk." According to Cronon we have to "abandon the dualism that sees the tree in the garden as artificial […] and the tree in the wilderness as natural […] Both in some ultimate sense are wild." Here he bends somewhat the regular dictionary meaning of wild, to emphasise that nothing natural, even in a garden, is fully under human control.

The landscape of Europe has considerably altered by people and even in an area, like the Cairngorm Mountains of Scotland, with a low population density, only " the high summits of the Cairngorm Mountains, consist entirely of natural elements. These "high summits" are of course only part of the Cairngorms, and there are no longer wolves, bears, wild boar or lynx in Scotland's wilderness. The Scots pine in the form of the Caledonian forest also covered much more of the Scottish landscape than today.

The Swiss National Park, however, represent a more natural landscape. It was founded in 1914, and is one of the earliest national parks in Europe.
Visitors are not allowed to leave the motor road, or paths through the park, make fire or camp. The only building within the park is Chamanna Cluozza, mountain hut. It is also forbidden to disturb the animals or the plants, or to take home anything found in the park. Dogs are not allowed. Due to these strict rules, the Swiss National Park is the only park in the Alps who has been categorized by the IUCN as a strict nature reserve, which is the highest protection level.

No place on the Earth is unaffected by people and their culture. People are part of biodiversity, but human activity affects biodiversity, and this alters the natural landscape. Mankind have altered landscape to such an extent that few places on earth remain pristine, but once free of human influences, the landscape can return to a natural or near natural state.
Even the remote Yukon and Alaskan wilderness, the bi-national Kluane-Wrangell-St. Elias-Glacier Bay-Tatshenshini-Alsek park system comprising Kluane, Wrangell-St Elias, Glacier Bay and Tatshenshini-Alsek parks, a UNESCO World Heritage Site, is not free from human influence, because the Kluane National Park lies within the traditional territories of the Champagne and Aishihik First Nations and Kluane First Nation who have a long history of living in this region. Through their respective Final Agreements with the Canadian Government, they have made into law their rights to harvest in this region.

Cultural forces intentionally or unintentionally, have an influence upon the landscape. Cultural landscapes are places or artifacts created and maintained by people. Examples of cultural intrusions into a landscape are: fences, roads, parking lots, sand pits, buildings, hiking trails, management of plants, including the introduction of invasive species, extraction or removal of plants, management of animals, mining, hunting, natural landscaping, farming and forestry, pollution. Areas that might be confused with a natural landscape include public parks, farms, orchards, artificial lakes and reservoirs, managed forests, golf courses, nature center trails, gardens.



</doc>
<doc id="37205291" url="https://en.wikipedia.org/wiki?curid=37205291" title="Aesthetics of nature">
Aesthetics of nature

Aesthetics of nature is a sub-field of philosophical ethics, and refers to the study of natural objects from their aesthetical perspective.

Aesthetics of nature developed as a sub-field of philosophical ethics. In the 18th and 19th century, the aesthetics of nature advanced the concepts of disinterestedness, the pictures, and the introduction of the idea of positive aesthetics. The first major developments of nature occurred in the 18th century. The concept of disinterestedness had been explained by many thinkers. Anthony Ashley-Cooper introduced the concept as a way of characterizing the notion of the aesthetic, later magnified by Francis Hutcheson, who expanded it to exclude personal and utilitarianism interests and associations of a more general nature from aesthetic experience. This concept was further developed by Archibald Alison who referred it to a particular state of mind.

The theory of disinterestedness opened doors for a better understanding of the aesthetics dimensions of nature in terms of three conceptualizations: 

Objects experienced as beautiful tend to be small, smooth, and fair in color. In contrast, objects viewed as sublime tend to be powerful, intense and terrifying. Picturesque items are a mixture of both, which can be seen as varied and irregular, rich and forceful, and even vibrant.

Cognitive and non-cognitive approaches of nature have directed their focus from natural environments to the consideration of human and human influenced environments and developed aesthetic investigations of everyday life.(Carlson and Lintott, 2007; Parsons 2008a; Carlson 2010)

People may be mistaken by the art object analogy. For instance, a sandhill crane is not an art object; an art object is not a sandhill crane. In fact, an art object should be called an "artifact". The crane is wildlife on its own and is not an art object. This can be related to Satio's definition of the cognitive view. In elaboration, the crane lives through various ecosystems such as Yellowstone. Nature is a living system which includes animals, plants, and Eco-systems. In contrast, an art object has no regeneration, evolutionary history, or metabolism. An individual may be in the forest and perceive it as beautiful because of the plethora of colors such as red, green, and yellow. This is a result of the chemicals interacting with chlorophyll. An individual's aesthetic experience may increase; however, none of the things mentioned have anything to do with what is really going on in the forest. The chlorophyll is capturing solar energy and the residual chemicals protect the trees from insect grazing.

Any color perceived by human visitors for a few hours is entirely different from what is really happening. According to Leopold, the three features of ecosystems that generate land ethic are integrity, stability and beauty. None of the mentioned features are real in nature. Ecosystems are not stable: they are dramatically changing and they have little integration; ergo, beauty is in the eye of the beholder.

In a Post-Modern approach, when an individual engages in aesthetically appreciating a natural thing, we give meaning to the thing we appreciate and in that meaning, we express and develop our own attitudes, values and beliefs. Our interest in natural things are not only a passive reflection of our inclinations, as Croce describes as the appreciation of nature as looking in a mirror, or what we might call our inward life; but may instead be the things we come across in nature that engage and stimulate our imagination. As a result, we are challenged to think differently and apply thoughts and associations to in new situations and ways.
As a characterization of the appreciation of art, nature aestheticists argue that post modernism is a mistaken view because we do not have a case of anything goes. The aesthetics appreciation of art is governed by some normative standards. In the world of art, criticism may take place when people come together and discuss books and films or critics write appraisals for publications. On the contrary, there are not obvious instances of debate and appraisals where different judgments about the aesthetics of character of nature are evaluated.



</doc>
<doc id="3759820" url="https://en.wikipedia.org/wiki?curid=3759820" title="Physis">
Physis

Physis (; ) is a Greek theological, philosophical, and scientific term usually translated into English as "nature".

The term is central to Greek philosophy, and as a consequence to Western philosophy as a whole.
In pre-Socratic usage, "physis" was contrasted with , , "law, human convention".
Since Aristotle, however, the "physical" (the subject matter of "physics", properly "natural things") has more typically been juxtaposed to the "metaphysical".

The word φύσις is a verbal noun based on φύειν "to grow, to appear" (cognate with English "to be"). In Homeric Greek it is used quite literally, of the manner of growth of a particular species of plant. 

In pre-Socratic philosophy, beginning with Heraclitus, "physis" in keeping with its etymology of "growing, becoming" is always used in the sense of the "natural" "development", although the focus might lie either with the origin, or the process, or the end result of the process. There is some evidence that by the 6th century BC, beginning with the Ionian School, the word could also be used 
in the comprehensive sense, as referring to ""all" things", as it were "Nature" in the sense of "Universe".

In the Sophist tradition, the term stood in opposition to "nomos" (), "law" or "custom", in the debate on which parts of human existence are natural, and which are due to convention. 
The contrast of "physis" vs. "nomos" could be applied to any subject, much like the modern contrast of "nature vs. nurture".

In book 10 of "Laws", Plato criticizes those who write works "peri physeōs". The criticism is that such authors tend to focus on a purely "naturalistic" explanation of the world, ignoring the role of "intention" or "technē", and thus becoming prone to the error of naive atheism. Plato accuses even Hesiod of this, for the reason that the gods in Hesiod "grow" out of primordial entities after the physical universe had been established.

"Because those who use the term mean to say that nature is the first creative power; but if the soul turns out to be the primeval element, and not fire or air, then in the truest sense and beyond other things the soul may be said to exist "by" nature; and this would be true if you proved that the soul is older than the body, but not otherwise."

Aristotle sought out the definition of "physis" to prove that there was more than one definition of "physis", and more than one way to interpret nature. "Though Aristotle retains the ancient sense of "physis" as growth, he insists that an adequate definition of "physis" requires the different perspectives of the four causes (aitia): material, efficient, formal, and final." Aristotle believed that nature itself contained its own source of matter (material), power/motion (efficiency), form, and end (final). A unique feature about Aristotle's definition of "physis" was his relationship between art and nature. Aristotle said that "physis" (nature) is dependent on techne (art). "The critical distinction between art and nature concerns their different efficient causes: nature is its own source of motion, whereas techne always requires a source of motion outside itself." What Aristotle was trying to bring to light, was that art does not contain within itself its form or source of motion. Consider the process of an acorn becoming an oak tree. This is a natural process that has its own driving force behind it. There is no external force pushing this acorn to its final state, rather it is progressively developing towards one specific end (telos).
Though φύσις was often used in Hellenistic philosophy, it is used only 14 times in the New Testament (10 of those in the writings of Paul). Its meaning varies throughout Paul's writings. One usage refers to the established or natural order of things, as in "Romans 2:14" where Paul writes "For when Gentiles, who do not have the law, by "nature" do what the law requires, they are a law to themselves, even though they do not have the law." Another use of φύσις in the sense of "natural order" is "Romans 1:26" where he writes "the men likewise gave up "natural" relations with women and were consumed with passion for one another". In "1 Corinthians 11:14", Paul asks "Does not nature itself teach you that if a man wears long hair it is a disgrace for him?"

This use of φύσις as referring to a "natural order" in "Romans 1:26" and "1 Corinthians 11:14" may have been influenced by Stoicism. The Greek philosophers, including Aristotle and the Stoics are credited with distinguishing between man-made laws and a natural law of universal validity, but Gerhard Kittel states that the Stoic philosophers were not able to combine the concepts of νόμος (law) and φύσις (nature) to produce the concept of "natural law" in the sense that was made possible by Judeo-Christian theology.

As part of the Pauline theology of salvation by grace, Paul writes in "Ephesians 2:3" that "we all once lived in the passions of our flesh, carrying out the desires of the body and the mind, and were by "nature" children of wrath, like the rest of mankind. In the next verse he writes, "by grace you have been saved." 

Theologians of the early Christian period differed in the usage of this term. In Antiochene circles, it connoted the humanity or divinity of Christ conceived as a concrete set of characteristics or attributes. In Alexandrine thinking, it meant a concrete individual or independent existent and approximated to hypostasis without being a synonym. While it refers to much the same thing as ousia it is more empirical and descriptive focussing on function while ousia is metaphysical and focuses more on reality. Although found in the context of the Trinitarian debate, it is chiefly important in the Christology of Cyril of Alexandria.

The Greek adjective "physikos" is represented in various forms in modern English:
As "physics" "the study of nature", as "physical" (via Middle Latin "physicalis") referring both to physics (the study of nature, the material universe) and to the human body. The term physiology ("physiologia") is of 16th-century coinage (Jean Fernel). The term "physique", for "the bodily constitution of a person", is a 19th-century loan from French. 

In medicine the suffix "-physis" occurs in such compounds as "symphysis", "epiphysis", and a few others, in the sense of "a growth". The physis also refers to the "growth plate", or site of growth at the end of long bones.



</doc>
<doc id="40159918" url="https://en.wikipedia.org/wiki?curid=40159918" title="Ecosystem health">
Ecosystem health

Ecosystem health is a metaphor used to describe the condition of an ecosystem. Ecosystem condition can vary as a result of fire, flooding, drought, extinctions, invasive species, climate change, mining, overexploitation in fishing, farming or logging, chemical spills, and a host of other reasons. There is no universally accepted benchmark for a healthy ecosystem, rather the apparent health status of an ecosystem can vary depending upon which health metrics are employed in judging it and which societal aspirations are driving the assessment. Advocates of the health metaphor argue for its simplicity as a communication tool. "Policy-makers and the public need simple, understandable concepts like health." Critics worry that ecosystem health, a "value-laden construct", is often "passed off as science to unsuspecting policy makers and the public."

The health metaphor applied to the environment has been in use at least since the early 1800s and the great American conservationist Aldo Leopold (1887–1948) spoke metaphorically of land health, land sickness, mutilation, and violence when describing land use practices. The term "ecosystem management" has been in use at least since the 1950s. The term "ecosystem health" has become widespread in the ecological literature, as a general metaphor meaning something good, and as an environmental quality goal in field assessments of rivers, lakes, seas, and forests.

Recently however this metaphor has been subject of quantitative formulation using complex systems concepts such as criticality, meaning that a healthy ecosystem is in some sort of balance between adaptability (randomness) and robustness (order) . Nevertheless the universality of criticality is still under examination and is known as the Criticality Hypothesis, which states that systems in a dynamic regime shifting between order and disorder, attain the highest level of computational capabilities and achieve an optimal trade-off between robustness and flexibility. Recent results in cell and evolutionary biology, neuroscience and computer science have great interest in the criticality hypothesis, emphasizing its role as a viable candidate general law in the realm of adaptive complex systems (see and references therein).

The term ecosystem health has been employed to embrace some suite of environmental goals deemed desirable. Edward Grumbine's highly cited paper "What is ecosystem management?" surveyed ecosystem management and ecosystem health literature and summarized frequently encountered goal statements:

Grumbine describes each of these goals as a "value statement" and stresses the role of human values in setting ecosystem management goals.

It is the last goal mentioned in the survey, accommodating humans, that is most contentious. "We have observed that when groups of stakeholders work to define … visions, this leads to debate over whether to emphasize ecosystem health or human well-being … Whether the priority is ecosystems or people greatly influences stakeholders' assessment of desirable ecological and social states." and, for example, "For some, wolves are critical to ecosystem health and an essential part of nature, for others they are a symbol of government overreach threatening their livelihoods and cultural values."

Measuring ecosystem health requires extensive goal-driven environmental sampling. For example, a vision for ecosystem health of Lake Superior was developed by a public forum and a series of objectives were prepared for protection of habitat and maintenance of populations of some 70 indigenous fish species. A suite of 80 lake health indicators was developed for the Great Lakes Basin including monitoring native fish species, exotic species, water levels, phosphorus levels, toxic chemicals, phytoplankton, zooplankton, fish tissue contaminants, etc.

Some authors have attempted broad definitions of ecosystem health, such as benchmarking as healthy the historical ecosystem state "prior to the onset of anthropogenic stress." A difficulty is that the historical composition of many human-altered ecosystems is unknown or unknowable. Also, fossil and pollen records indicate that the species that occupy an ecosystem reshuffle through time, so it is difficult to identify one snapshot in time as optimum or "healthy.".

A commonly cited broad definition states that a healthy ecosystem has three attributes:

While this captures significant ecosystem properties, a generalization is elusive as those properties do not necessarily co-vary in nature. For example, there is not necessarily a clear or consistent relationship between productivity and species richness. Similarly, the relationship between resilience and diversity is complex, and ecosystem stability may depend upon one or a few species rather than overall diversity. And some undesirable ecosystems are highly productive.

"Resilience is not desirable per se. There can be highly resilient states of ecosystems which are very undesirable from some human perspectives , such as algal-dominated coral reefs." Ecological resilience is a "capacity" that varies depending upon which properties of the ecosystem are to be studied and depending upon what kinds of disturbances are considered and how they are to be quantified. Approaches to assessing it "face high uncertainties and still require a considerable amount of empirical and theoretical research."

Other authors have sought a numerical index of ecosystem health that would permit quantitative comparisons among ecosystems and within ecosystems over time. One such system employs ratings of the three properties mentioned above: Health = system vigor x system organization x system resilience. Ecologist Glenn Suter argues that such indices employ "nonsense units," the indices have "no meaning; they cannot be predicted, so they are not applicable to most regulatory problems; they have no diagnostic power; effects of one component are eclipsed by responses of other components, and the reason for a high or low index value is unknown."

Health metrics are determined by stakeholder goals, which drive ecosystem definition. An ecosystem is an abstraction. "Ecosystems cannot be identified or found in nature. Instead, they must be delimited by an observer. This can be done in many different ways for the same chunk of nature, depending on the specific perspectives of interest."

Ecosystem definition determines the acceptable range of variability (reference conditions) and determines measurement variables. The latter are used as indicators of ecosystem structure and function, and can be used as indicators of "health".

An indicator is a variable, such as a chemical or biological property, that when measured, is used to infer trends in another (unmeasured) environmental variable or cluster of unmeasured variables (the indicandum). For example, rising mortality rate of canaries in a coal mine is an indicator of rising carbon monoxide levels. Rising chlorophyll-a levels in a lake may signal eutrophication.

Ecosystem assessments employ two kinds of indicators, descriptive indicators and normative indicators. "Indicators can be used descriptively for a scientific purpose or normatively for a political purpose."

Used descriptively, high chlorophyll-a is an indicator of eutrophication, but it may also be used as an ecosystem health indicator. When used as a normative (health) indicator, it indicates a rank on a health scale, a rank that can vary widely depending on societal preferences as to what is desirable. A high chlorophyll-a level in a natural successional wetland might be viewed as healthy whereas a human-impacted wetland with the "same" indicator value may be judged unhealthy.

Estimation of ecosystem health has been criticized for intermingling the two types of environmental indicators. A health indicator is a normative indicator, and if conflated with descriptive indicators "implies that normative values can be measured objectively, which is certainly not true. Thus, implicit values are insinuated to the reader, a situation which has to be avoided."

It can be argued that the very act of selecting indicators of any kind is biased by the observer's perspective but separation of goals from descriptions has been advocated as a step toward transparency: "A separation of descriptive and normative indicators is essential from the perspective of the philosophy of science … Goals and values cannot be deduced directly from descriptions … a fact that is emphasized repeatedly in the literature of environmental ethics … Hence, we advise always specifying the definition of indicators and propose clearly distinguishing ecological indicators in science from policy indicators used for decision-making processes."

And integration of multiple, possibly conflicting, normative indicators into a single measure of "ecosystem health" is problematic. Using 56 indicators, "determining environmental status and assessing marine ecosystems health in an integrative way is still one of the grand challenges in marine ecosystems ecology, research and management"

Another issue with indicators is validity. Good indicators must have an independently validated high predictive value, that is high sensitivity (high probability of indicating a significant change in the indicandum) and high specificity (low probability of wrongly indicating a change). The reliability of various health metrics has been questioned and "what combination of measurements should be used to evaluate ecosystems is a matter of current scientific debate." Most attempts to identify ecological indicators have been correlative rather than derived from prospective testing of their predictive value and the selection process for many indicators has been based upon weak evidence or has been lacking in evidence.

In some cases no reliable indicators are known: "We found no examples of invertebrates successfully used in [forest] monitoring programs. Their richness and abundance ensure that they play significant roles in ecosystem function but thwart focus on a few key species." And, "Reviews of species-based monitoring approaches reveal that no single species, nor even a group of species, accurately reflects entire communities. Understanding the response of a single species may not provide reliable predictions about a group of species even when the group is a few very similar species."

A trade-off between human health and the "health" of nature has been termed the "health paradox" and it illuminates how human values drive perceptions of ecosystem health.

Human health has benefited by sacrificing the "health" of wild ecosystems, such as dismantling and damming of wild valleys, destruction of mosquito-bearing wetlands, diversion of water for irrigation, conversion of wilderness to farmland, timber removal, and extirpation of tigers, whales, ferrets, and wolves.

There has been an acrimonious schism among conservationists and resource managers over the question of whether to "ratchet back human domination of the biosphere" or whether to embrace it. These two perspectives have been characterized as utilitarian vs protectionist.

The utilitarian view treats human health and well-being as criteria of ecosystem health. For example, destruction of wetlands to control malaria mosquitoes "resulted in an improvement in ecosystem health."
The protectionist view treats humans as an invasive species: "If there was ever a species that qualified as an invasive pest, it is "Homo sapiens","

Proponents of the utilitarian view argue that "healthy ecosystems are characterized by their capability to sustain healthy human populations," and "healthy ecosystems must be economically viable," as it is "unhealthy" ecosystems that are likely to result in increases in contamination, infectious diseases, fires, floods, crop failures and fishery collapse.

Protectionists argue that privileging of human health is a conflict of interest as humans have demolished massive numbers of ecosystems to maintain their welfare, also disease and parasitism are historically normal in pre-industrial nature. Diseases and parasites promote ecosystem functioning, driving biodiversity and productivity, and parasites may constitute a significant fraction of ecosystem biomass.

The very choice of the word "health" applied to ecology has been questioned as lacking in neutrality in a BioScience article on responsible use of scientific language: "Some conservationists fear that these terms could endorse human domination of the planet … and could exacerbate the shifting cognitive baseline whereby humans tend to become accustomed to new and often degraded ecosystems and thus forget the nature of the past."

Criticism of ecosystem health largely targets the failure of proponents to explicitly distinguish the normative dimension from the descriptive dimension, and has included the following:

Alternatives have been proposed for the term ecosystem health, including more neutral language such as ecosystem status, ecosystem prognosis, and ecosystem sustainability. Another alternative to the use of a health metaphor is to "express exactly and clearly the public policy and the management objective", to employ habitat descriptors and real properties of ecosystems. An example of a policy statement is "The maintenance of viable natural populations of wildlife and ecological functions always takes precedence over any human use of wildlife." An example of a goal is "Maintain viable populations of all native species in situ." An example of a management objective is "Maintain self-sustaining populations of lake whitefish within the range of abundance observed during 1990-99."

Kurt Jax presented an ecosystem assessment format that avoids imposing a preconceived notion of normality, that avoids the muddling of normative and descriptive, and that gives serious attention to ecosystem definition. (1) Societal purposes for the ecosystem are negotiated by stakeholders, (2) a functioning ecosystem is defined with emphasis on phenomena relevant to stakeholder goals, (3) benchmark reference conditions and permissible variation of the system are established, (4) measurement variables are chosen for use as indicators, and (5) the time scale and spatial scale of assessment are decided.

Ecological health has been used as a medical term in reference to human allergy and multiple chemical sensitivity and as a public health term for programs to modify health risks (diabetes, obesity, smoking, etc.). Human health itself, when viewed in its broadest sense, is viewed as having ecological foundations. It is also an urban planning term in reference to "green" cities (composting, recycling), and has been used loosely with regard to various environmental issues, and as the condition of human-disturbed environmental sites. Ecosystem integrity implies a condition of an ecosystem exposed to a minimum of human influence. Ecohealth is the relationship of human health to the environment, including the effect of climate change, wars, food production, urbanization, and ecosystem structure and function. Ecosystem management and ecosystem-based management refer to the sustainable management of ecosystems and in some cases may employ the terms ecosystem health or ecosystem integrity as a goal.


</doc>
<doc id="52634071" url="https://en.wikipedia.org/wiki?curid=52634071" title="Nature-based solutions">
Nature-based solutions

Nature-based solutions (NBS) refers to the sustainable management and use of nature for tackling socio-environmental challenges. The challenges include issues such as climate change, water security, water pollution, food security, human health, and disaster risk management.

The NBS definition by the European Union states that these solutions are "inspired and supported by nature, which are cost-effective, simultaneously provide environmental, social and economic benefits and help build resilience. Such solutions bring more, and more diverse, nature and natural features and processes into cities, landscapes and seascapes, through locally adapted, resource-efficient and systemic interventions". Research and Innovation projects on NBS funded by the EU Framework Programme need to respond to this definition. The Nature-based Solutions Initiative meanwhile defines them as "actions that work with and enhance nature so as to help people adapt to change and disasters". With NBS, healthy, resilient and diverse ecosystems (whether natural, managed or newly created) can provide solutions for the benefit of societies and overall biodiversity.

For instance, the restoration or protection of mangroves along coastlines utilizes a nature-based solution to accomplish several things. Mangroves moderate the impact of waves and wind on coastal settlements or cities and sequester CO. They also provide safe nurseries for marine life that can be the basis for sustaining populations of fish that local populations may depend on. Additionally, the mangrove forests can help control coastal erosion resulting from sea level rise. Similarly, in cities green roofs or walls are nature-based solutions that can be used to moderate the impact of high temperatures, capture storm water, abate pollution, and act as carbon sinks, while enhancing biodiversity.

Conservation approaches and environment management initiatives have been carried out for decades. What is new is that the benefits of such nature-based solutions to human well-being have been articulated well more recently. Even if the term itself is still being framed, examples of nature-based solutions can be found all over the world, and imitated. Nature-based solutions are on their way to being mainstreamed in national and international policies and programmes (e.g. climate change policy, law, infrastructure investment and financing mechanisms). For example, the theme for World Water Day 2018 was "Nature for water" and by UN-Water's accompanying UN World Water Development Report had the title "Nature-based Solutions for Water". Also, in the 2019 UN Climate Action Summit, nature based solution where one of the main topics, as an effective method to combat climate change. A "Nature Based Solution Coalition" was created, including dozens of countries, led by China and New Zealand.

Societies increasingly face challenges such as climate change, urbanization, jeopardized food security and water resource provision, and disaster risk. One approach to answer these challenges is to singularly rely on technological strategies. An alternative approach is to manage the (socio-)ecological systems in a comprehensive way in order to sustain and potentially increase the delivery of ecosystem services to humans. In this context, nature-based solutions (NBS) have recently been put forward by practitioners and quickly thereafter by policymakers. These solutions stress the sustainable use of nature in solving coupled environmental-social-economic challenges.

While ecosystem services are often valued in terms of immediate benefits to human well-being and economy, NBS focus on the benefits to people and the environment itself, to allow for sustainable solutions that are able to respond to environmental change and hazards in the long-term. NBS go beyond the traditional biodiversity conservation and management principles by "re-focusing" the debate on humans and specifically integrating societal factors such as human well-being and poverty reduction, socio-economic development, and governance principles.

With respect to water issues, NBS can achieve the following, according to the World Water Development Report 2018 by UN-Water: 

In 2015, the European network BiodivERsA highlighted how NBS relate to concepts like ecosystem approaches and ecological engineering. NBS are strongly connected to ideas such as natural systems agriculture, natural solutions, ecosystem-based adaptation, adaptation services, natural infrastructure, green infrastructure and ecological engineering. For instance, ecosystem-based approaches are increasingly promoted for climate change adaptation and mitigation by organisations like United Nations Environment Programme and non-governmental organisations such as The Nature Conservancy. These organisations refer to "policies and measures that take into account the role of ecosystem services in reducing the vulnerability of society to climate change, in a multi-sectoral and multi-scale approach".

Likewise, natural infrastructure is defined as a "strategically planned and managed network of natural lands, such as forests and wetlands, working landscapes, and other open spaces that conserves or enhances ecosystem values and functions and provides associated benefits to human populations"; and green infrastructure refers to an "interconnected network of green spaces that conserves natural systems and provides assorted benefits to human populations".

Similarly, the concept of ecological engineering generally refers to "protecting, restoring (i.e. ecosystem restoration) or modifying ecological systems to increase the quantity, quality and sustainability of particular services they provide, or to build new ecological systems that provide services that would otherwise be provided through more conventional engineering, based on non-renewable resources".

The International Union for the Conservation of Nature (IUCN) defines NBS as actions to protect, sustainably manage, and restore natural or modified ecosystems, that address societal challenges effectively and adaptively, simultaneously providing human well-being and biodiversity benefits, with climate change, food security, disaster risks, water security, social and economic development as well as human health being the common societal challenges.

IUCN proposes to consider NBS as an umbrella concept. Categories and examples of NBS approaches according to IUCN include:

In 2014-2015, the European network BiodivERsA mobilized a range of scientists, research donors and stakeholders and proposed a typology characterizing NBS along two gradients. 1. "how much engineering of biodiversity and ecosystems is involved in NBS", and 2. "how many ecosystem services and stakeholder groups are targeted by a given NBS". The typology highlights that NBS can involve very different actions on ecosystems (from protection to management and even creation of new ecosystems) and is based on the assumption that the higher the number of services and stakeholder groups targeted, the lower the capacity to maximize the delivery of each service and simultaneously fulfil the specific needs of all stakeholder groups. As such, three types of NBS are distinguished (Figure 2):

Type 1 NBS consists of no or minimal intervention in ecosystems, with the objectives of maintaining or improving the delivery of a range of ES both inside and outside of these conserved ecosystems. Examples include the protection of mangroves in coastal areas to limit risks associated to extreme weather conditions and provide benefits and opportunities to local populations; and the establishment of marine protected areas to conserve biodiversity within these areas while exporting biomass into fishing grounds. This type of NBS is connected to, for example, the concept of biosphere reserves which incorporates core protected areas for nature conservation and buffer zones and transition areas where people live and work in a sustainable way.

Type 2 NBS corresponds to management approaches that develop sustainable and multifunctional ecosystems and landscapes (extensively or intensively managed). These types improve the delivery of selected ES compared to what would be obtained with a more conventional intervention. Examples include innovative planning of agricultural landscapes to increase their multi-functionality; and approaches for enhancing tree species and genetic diversity to increase forest resilience to extreme events. This type of NBS is strongly connected to concepts like natural systems agriculture, agro-ecology, and evolutionary-orientated forestry.

Type 3 NBS consists of managing ecosystems in very extensive ways or even creating new ecosystems (e.g., artificial ecosystems with new assemblages of organisms for green roofs and walls to mitigate city warming and clean polluted air). Type 3 is linked to concepts like green and blue infrastructures and objectives like restoration of heavily degraded or polluted areas and greening cities.

Type 1 and 2 would typically fall within the IUCN NBS framework, whereas Type 2 and moreover Type 3 are often exemplified by EC for turning natural capital into a source for green growth and sustainable development.

Hybrid solutions exist along this gradient both in space and time. For instance, at landscape scale, mixing protected and managed areas could be needed to fulfil multi-functionality and sustainability goals. Similarly, a constructed wetland can be developed as a type 3 but, when well established, may subsequently be preserved and surveyed as a type 1.

The general objective of NBS is clear, namely the sustainable management and use of nature for tackling societal challenges. However, different stakeholders view NBS from other perspectives. For instance, IUCN defines NBS as "actions to protect, sustainably manage and restore natural or modified ecosystems, which address societal challenges effectively and adaptively, while simultaneously providing human well-being and biodiversity benefits". This framing puts the need for well-managed and restored ecosystems at the heart of NBS, with the overarching goal of "Supporting the achievement of society's development goals and safeguard human well-being in ways that reflect cultural and societal values and enhance the resilience of ecosystems, their capacity for renewal and the provision of services".

In the context of the ongoing political debate on jobs and growth (main drivers of the current EU policy agenda), the European Commission underlines that NBS can transform environmental and societal challenges into innovation opportunities, by turning natural capital into a source for green growth and sustainable development. In their view, NBS to societal challenges are "solutions that are inspired and supported by nature, which are cost-effective, simultaneously provide environmental, social and economic benefits and help build resilience. Such solutions bring more, and more diverse, nature and natural features and processes into cities, landscapes and seascapes, through locally adapted, resource-efficient and systemic interventions."

This framing is somewhat broader, and puts economy and social assets at the heart of NBS as importantly as sustaining environmental conditions. It shares similarities with the definition proposed by Maes and Jacobs (2015) defining NBS as "any transition to a use of ES with decreased input of non-renewable natural capital and increased investment in renewable natural processes". In their view, development and evaluation of NBS spans three basic requirements: (1) decrease of fossil fuel input per produced unit; (2) lowering of systemic trade-offs and increasing synergies between ES; and (3) increasing labor input and jobs. Here, nature is seen as a tool to inspire more systemic solutions to societal problems.

Whatever definition used, promoting sustainability and the increased role of natural, self-sustained processes relying on biodiversity, are inherent to NBS. They constitute actions easily seen as positive for a wide range of stakeholders, as they bring about benefits at environmental, economic and social levels. As a consequence, the concept of NBS is gaining acceptance outside the conservation community (e.g. urban planning) and is now on its way to be mainstreamed into policies and programmes (climate change policy, law, infrastructure investment and financing mechanisms).

Demonstrating the benefits of nature and healthy ecosystems and showcasing the return on investment they can offer is necessary in order to increase awareness, but also to provide support and guidance on how to implement NBS. A large number of initiatives around the world already highlight the effectiveness of NBS approaches to address a wide range of societal challenges.

The following table shows examples from around the world:

In 2018, The Hindu reported that the East Kolkata wetlands, the world's largest organic sewage treatment facility had been used to clean the sewage of Kolkata in an organic manner by using algae for several decades. In use since the 1930s, the natural system was discovered by Dhrubajyoti Ghosh, an ecologist and a municipal engineer in the 1970s while working in the region. Ghosh worked for decades to protect the wetlands. It had been a practice in Kolkata, one of the five largest cities in India, for the municipal authorities to pump sewage into shallow ponds ("bheris"). Under the heat of the tropical sun, algae proliferated in them, converting the sewage into clean water, which in turn was used by villagers to grow paddy and vegetables. This system has been in use in the region since the 1930s and treats 750 million litres of wastewater per day, giving livelihood to 100,000 people in the vicinity. For his work, Ghosh was included in the UN Global 500 Roll of Honour in 1990 and received the Luc Hoffmann award in 2016.

There is currently no accepted basis on which a government agency, municipality or private company can systematically assess the efficiency, effectiveness and sustainability of a particular nature-based solution. However, a series of principles are proposed to guide effective and appropriate implementation, and thus to upscale NBS in practice. For example, NBS embrace and are not meant to replace nature conservation norms. Also, NBS are determined by site-specific natural and cultural contexts that include traditional, local and scientific knowledge. NBS are an integral part of the overall design of policies, and measure or actions, to address a specific challenges. Finally, NBS can be implemented alone or in an integrated manner with other solutions to societal challenges (e.g. technological and engineering solutions) and they are applied at the landscape scale.

Implementing NBS requires political, economic, and scientific challenges to be tackled. First and foremost, private sector investment is needed, not to replace but to supplement traditional sources of capital such as public funding or philanthropy. The challenge is therefore to provide a robust evidence base for the contribution of nature to economic growth and jobs, and to demonstrate the economic viability of these solutions – compared to technological ones – on a timescale compatible with that of global change. Furthermore, it requires measures like adaptation of economic subsidy schemes, and the creation of opportunities for conservation finance, to name a few. Indeed, such measures will be needed to scale up NBS interventions, and strengthen their impact in mitigating the world's most pressing challenges.

Since 2016, the EU is supporting a multi-stakeholder dialogue platform (called ThinkNature) to promote the co-design, testing and deployment of improved and innovative NBS in an integrated way. Creation of such science-policy-business-society interfaces could promote the market uptake of NBS. The project is part of the EU’s Horizon 2020 – Research and Innovation programme, and will last for 3 years. There are a total of 17 international partners involved, including the Technical University of Crete (Project Leader), the University of Helsinki and BiodivERsA.

In 2017, as part of the Presidency of the Estonian Republic of the Council of the European Union, a conference called “Nature-based Solutions: From Innovation to Common-use” was organized by the Ministry of the Environment of Estonia and the University of Tallinn. This conference aimed to strengthen synergies among various recent initiatives and programs related to NBS launched by the European Commission and by the EU Member States, focusing on policy and governance of NBS, and on research and innovation.

In recognition of the importance of natural ecosystems for mitigation and adaptation, the Paris Agreement calls on all Parties to acknowledge “the importance of the conservation and enhancement, as appropriate, of sinks and reservoirs of the greenhouse gases” and to “note the importance of ensuring the integrity of all ecosystems, including oceans, and the protection of biodiversity, recognized by some cultures as Mother Earth”. It then includes in its Articles several references to nature-based solutions. For example, Article 5.2 encourages Parties to adopt “…policy approaches and positive incentives for activities relating to reducing emissions from deforestation and forest degradation, and the role of conservation and sustainable management of forests and enhancement of forest carbon stocks in developing countries; and alternative policy approaches, such as joint mitigation and adaptation approaches for the integral and sustainable management of forests, while reaffirming the importance of incentivizing, as appropriate, non-carbon benefits associated with such approaches”. Article 7.1 further encourages Parties to build the resilience of socioeconomic and ecological systems, including through economic diversification and sustainable management of natural resources. In total, the Agreement refers to nature (ecosystems, natural resources, forests) in 13 distinct places. An in-depth analysis of all Nationally Determined Contributions submitted to UNFCCC, revealed that around 130 NDCs or 65% of signatories commit to nature-based solutions in their climate pledges, suggesting broad consensus for the role of nature in helping meet climate change goals. However, high-level commitments rarely translate into robust, measurable actions on-the-ground.

In the 2019 UN Climate Action Summit, nature based solution where one of the main topics, as an effective method to combat climate change. A "Nature Based Solution Coalition" was created, including dozens of countries, led by China and New Zealand.

The term NBS was put forward by practitioners in the late 2000s (in particular the International Union for the Conservation of Nature and the World Bank) and thereafter by policymakers in Europe (most notably the European Commission). It was used in the context of finding new solutions to mitigate and adapt to climate change effects, whilst simultaneously protecting biodiversity and improving sustainable livelihoods.

The IUCN referred to NBS in a position paper for the United Nations Framework Convention on Climate Change. The term was also adopted by European policymakers, in particular by the European Commission in a report stressing that NBS can offer innovative means to create jobs and growth as part of a green economy. The term started to make appearances in the mainstream media around the time of the Global Climate Action Summit in California in September 2018 




</doc>
<doc id="558685" url="https://en.wikipedia.org/wiki?curid=558685" title="Natural environment">
Natural environment

The natural environment encompasses all living and non-living things occurring naturally, meaning in this case not artificial. The term is most often applied to the Earth or some parts of Earth. This environment encompasses the interaction of all living species, climate, weather and natural resources that affect human survival and economic activity.
The concept of the "natural environment" can be distinguished as components:

In contrast to the natural environment is the built environment. In such areas where humans have fundamentally transformed landscapes such as urban settings and agricultural land conversion, the natural environment is greatly modified into a simplified human environment. Even acts which seem less extreme, such as building a mud hut or a photovoltaic system in the desert, the modified environment becomes an artificial one. Though many animals build things to provide a better environment for themselves, they are not human, hence beaver dams, and the works of mound-building termites, are thought of as natural.

People seldom find "absolutely natural" environments on Earth, and naturalness usually varies in a continuum, from 100% natural in one extreme to 0% natural in the other. More precisely, we can consider the different aspects or components of an environment, and see that their degree of naturalness is not uniform. If, for instance, in an agricultural field, the mineralogic composition and the structure of its soil are similar to those of an undisturbed forest soil, but the structure is quite different.

"Natural environment" is often used as a synonym for habitat, for instance, when we say that the natural environment of giraffes is the savanna.

Earth science generally recognizes four spheres, the lithosphere, the hydrosphere, the atmosphere, and the biosphere as correspondent to rocks, water, air, and life respectively. Some scientists include as part of the spheres of the Earth, the cryosphere (corresponding to ice) as a distinct portion of the hydrosphere, as well as the pedosphere (corresponding to soil) as an active and intermixed sphere. Earth science (also known as geoscience, the geographical sciences or the Earth Sciences), is an all-embracing term for the sciences related to the planet Earth. There are four major disciplines in earth sciences, namely geography, geology, geophysics and geodesy. These major disciplines use physics, chemistry, biology, chronology and mathematics to build a qualitative and quantitative understanding of the principal areas or "spheres" of Earth.

The Earth's crust, or lithosphere, is the outermost solid surface of the planet and is chemically and mechanically different from underlying mantle. It has been generated greatly by igneous processes in which magma cools and solidifies to form solid rock. Beneath the lithosphere lies the mantle which is heated by the decay of radioactive elements. The mantle though solid is in a state of rheic convection. This convection process causes the lithospheric plates to move, albeit slowly. The resulting process is known as plate tectonics. Volcanoes result primarily from the melting of subducted crust material or of rising mantle at mid-ocean ridges and mantle plumes.

Most water is found in one or another natural kind of body of water.

An ocean is a major body of saline water, and a component of the hydrosphere. Approximately 71% of the Earth's surface (an area of some 362 million square kilometers) is covered by ocean, a continuous body of water that is customarily divided into several principal oceans and smaller seas. More than half of this area is over 3,000 meters (9,800 ft) deep. Average oceanic salinity is around 35 parts per thousand (ppt) (3.5%), and nearly all seawater has a salinity in the range of 30 to 38 ppt. Though generally recognized as several 'separate' oceans, these waters comprise one global, interconnected body of salt water often referred to as the World Ocean or global ocean. The deep seabeds are more than half the Earth's surface, and are among the least-modified natural environments. The major oceanic divisions are defined in part by the continents, various archipelagos, and other criteria: these divisions are (in descending order of size) the Pacific Ocean, the Atlantic Ocean, the Indian Ocean, the Southern Ocean and the Arctic Ocean.

A river is a natural watercourse, usually freshwater, flowing toward an ocean, a lake, a sea or another river. A few rivers simply flow into the ground and dry up completely before reaching another body of water. 
The water in a river is usually in a channel, made up of a stream bed between banks. In larger rivers there is also a wider floodplain shaped by waters over-topping the channel. Flood plains may be very wide in relation to the size of the river channel. Rivers are a part of the hydrological cycle. Water within a river is generally collected from precipitation through surface runoff, groundwater recharge, springs, and the release of water stored in glaciers and snowpacks.

Small rivers may also be termed by several other names, including stream, creek and brook. Their current is confined within a bed and stream banks. Streams play an important corridor role in connecting fragmented habitats and thus in conserving biodiversity. The study of streams and waterways in general is known as "surface hydrology." 

A lake (from Latin "lacus") is a terrain feature, a body of water that is localized to the bottom of basin. A body of water is considered a lake when it is inland, is not part of an ocean, and is larger and deeper than a pond.
Natural lakes on Earth are generally found in mountainous areas, rift zones, and areas with ongoing or recent glaciation. Other lakes are found in endorheic basins or along the courses of mature rivers. In some parts of the world, there are many lakes because of chaotic drainage patterns left over from the last Ice Age. All lakes are temporary over geologic time scales, as they will slowly fill in with sediments or spill out of the basin containing them.

A pond is a body of standing water, either natural or man-made, that is usually smaller than a lake. A wide variety of man-made bodies of water are classified as ponds, including water gardens designed for aesthetic ornamentation, fish ponds designed for commercial fish breeding, and solar ponds designed to store thermal energy. Ponds and lakes are distinguished from streams by their current speed. While currents in streams are easily observed, ponds and lakes possess thermally driven micro-currents and moderate wind driven currents. These features distinguish a pond from many other aquatic terrain features, such as stream pools and tide pools.

Humans impact the water in different ways such as modifying rivers (through dams and stream channelization), urbanization, and deforestation. These impact lake levels, groundwater conditions, water pollution, thermal pollution, and marine pollution. Humans modify rivers by using direct channel manipulation. We are building dams and reservoirs and manipulating the direction of the rivers and water path. Dams are good for us, some communities need the reservoirs to survive. However, reservoirs and dams may negatively impact the environment and wildlife. Dams stops fish migration and the moving of organisms down stream. Urbanization effects the environment because of deforestation and changing lake levels, groundwater conditions, etc. Deforestation and urbanization go hand in hand. Deforestation may cause flooding, declining stream flow, and changes in riverside vegetation. The changing vegetation occurs because when trees cannot get adequate water they start to deteriorate, leading to a decreased food supply for the wildlife in an area.

The atmosphere of the Earth serves as a key factor in sustaining the planetary ecosystem. The thin layer of gases that envelops the Earth is held in place by the planet's gravity. Dry air consists of 78% nitrogen, 21% oxygen, 1% argon and other inert gases, such as carbon dioxide. The remaining gases are often referred to as trace gases, among which are the greenhouse gases such as water vapor, carbon dioxide, methane, nitrous oxide, and ozone. Filtered air includes trace amounts of many other chemical compounds. Air also contains a variable amount of water vapor and suspensions of water droplets and ice crystals seen as clouds. Many natural substances may be present in tiny amounts in an unfiltered air sample, including dust, pollen and spores, sea spray, volcanic ash, and meteoroids. Various industrial pollutants also may be present, such as chlorine (elementary or in compounds), fluorine compounds, elemental mercury, and sulphur compounds such as sulphur dioxide [SO].

The ozone layer of the Earth's atmosphere plays an important role in depleting the amount of ultraviolet (UV) radiation that reaches the surface. As DNA is readily damaged by UV light, this serves to protect life at the surface. The atmosphere also retains heat during the night, thereby reducing the daily temperature extremes.

Earth's atmosphere can be divided into five main layers. These layers are mainly determined by whether temperature increases or decreases with altitude. From highest to lowest, these layers are:

Within the five principal layers determined by temperature there are several layers determined by other properties.

The dangers of global warming are being increasingly studied by a wide global consortium of scientists. These scientists are increasingly concerned about the potential long-term effects of global warming on our natural environment and on the planet. Of particular concern is how climate change and global warming caused by anthropogenic, or human-made releases of greenhouse gases, most notably carbon dioxide, can act interactively, and have adverse effects upon the planet, its natural environment and humans' existence. It is clear the planet is warming, and warming rapidly. This is due to the greenhouse effect, which is caused by greenhouse gases, which trap heat inside the Earth's atmosphere because of their more complex molecular structure which allows them to vibrate and in turn trap heat and release it back towards the Earth. This warming is also responsible for the extinction of natural habitats, which in turn leads to a reduction in wildlife population.The most recent report from the Intergovernmental Panel on Climate Change (the group of the leading climate scientists in the world) concluded that the earth will warm anywhere from 2.7 to almost 11 degrees Fahrenheit (1.5 to 6 degrees Celsius) between 1990 and 2100.
Efforts have been increasingly focused on the mitigation of greenhouse gases that are causing climatic changes, on developing adaptative strategies to global warming, to assist humans, other animal, and plant species, ecosystems, regions and nations in adjusting to the effects of global warming. Some examples of recent collaboration to address climate change and global warming include:

A significantly profound challenge is to identify the natural environmental dynamics in contrast to environmental changes not within natural variances. A common solution is to adapt a static view neglecting natural variances to exist. Methodologically, this view could be defended when looking at processes which change slowly and short time series, while the problem arrives when fast processes turns essential in the object of the study.

Climate looks at the statistics of temperature, humidity, atmospheric pressure, wind, rainfall, atmospheric particle count and other meteorological elements in a given region over long periods of time. Weather, on the other hand, is the present condition of these same elements over periods up to two weeks.

Climates can be classified according to the average and typical ranges of different variables, most commonly temperature and precipitation. The most commonly used classification scheme is the one originally developed by Wladimir Köppen. The Thornthwaite system, in use since 1948, uses evapotranspiration as well as temperature and precipitation information to study animal species diversity and the potential impacts of climate changes.

Weather is a set of all the phenomena occurring in a given atmospheric area at a given time. Most weather phenomena occur in the troposphere, just below the stratosphere. Weather refers, generally, to day-to-day temperature and precipitation activity, whereas climate is the term for the average atmospheric conditions over longer periods of time. When used without qualification, "weather" is understood to be the weather of Earth.

Weather occurs due to density (temperature and moisture) differences between one place and another. These differences can occur due to the sun angle at any particular spot, which varies by latitude from the tropics. The strong temperature contrast between polar and tropical air gives rise to the jet stream. Weather systems in the mid-latitudes, such as extratropical cyclones, are caused by instabilities of the jet stream flow. Because the Earth's axis is tilted relative to its orbital plane, sunlight is incident at different angles at different times of the year. On the Earth's surface, temperatures usually range ±40 °C (100 °F to −40 °F) annually. Over thousands of years, changes in the Earth's orbit have affected the amount and distribution of solar energy received by the Earth and influence long-term climate

Surface temperature differences in turn cause pressure differences. Higher altitudes are cooler than lower altitudes due to differences in compressional heating. Weather forecasting is the application of science and technology to predict the state of the atmosphere for a future time and a given location. The atmosphere is a chaotic system, and small changes to one part of the system can grow to have large effects on the system as a whole. Human attempts to control the weather have occurred throughout human history, and there is evidence that civilized human activity such as agriculture and industry has inadvertently modified weather patterns.

Evidence suggests that life on Earth has existed for about 3.7 billion years. All known life forms share fundamental molecular mechanisms, and based on these observations, theories on the origin of life attempt to find a mechanism explaining the formation of a primordial single cell organism from which all life originates. There are many different hypotheses regarding the path that might have been taken from simple organic molecules via pre-cellular life to protocells and metabolism.

Although there is no universal agreement on the definition of life, scientists generally accept that the biological manifestation of life is characterized by organization, metabolism, growth, adaptation, response to stimuli and reproduction. Life may also be said to be simply the characteristic state of organisms. In biology, the science of living organisms, "life" is the condition which distinguishes active organisms from inorganic matter, including the capacity for growth, functional activity and the continual change preceding death.

A diverse variety of living organisms (life forms) can be found in the biosphere on Earth, and properties common to these organisms—plants, animals, fungi, protists, archaea, and bacteria—are a carbon- and water-based cellular form with complex organization and heritable genetic information. Living organisms undergo metabolism, maintain homeostasis, possess a capacity to grow, respond to stimuli, reproduce and, through natural selection, adapt to their environment in successive generations. More complex living organisms can communicate through various means.

An ecosystem (also called as environment) is a natural unit consisting of all plants, animals and micro-organisms (biotic factors) in an area functioning together with all of the non-living physical (abiotic) factors of the environment.

Central to the ecosystem concept is the idea that living organisms are continually engaged in a highly interrelated set of relationships with every other element constituting the environment in which they exist. Eugene Odum, one of the founders of the science of ecology, stated: "Any unit that includes all of the organisms (i.e.: the "community") in a given area interacting with the physical environment so that a flow of energy leads to clearly defined trophic structure, biotic diversity, and material cycles (i.e.: exchange of materials between living and nonliving parts) within the system is an ecosystem."

The human ecosystem concept is then grounded in the deconstruction of the human/nature dichotomy, and the emergent premise that all species are ecologically integrated with each other, as well as with the abiotic constituents of their biotope.

A greater number or variety of species or biological diversity of an ecosystem may contribute to greater resilience of an ecosystem, because there are more species present at a location to respond to change and thus "absorb" or reduce its effects. This reduces the effect before the ecosystem's structure is fundamentally changed to a different state. This is not universally the case and there is no proven relationship between the species diversity of an ecosystem and its ability to provide goods and services on a sustainable level.

The term ecosystem can also pertain to human-made environments, such as human ecosystems and human-influenced ecosystems, and can describe any situation where there is relationship between living organisms and their environment. Fewer areas on the surface of the earth today exist free from human contact, although some genuine wilderness areas continue to exist without any forms of human intervention.

Biomes are terminologically similar to the concept of ecosystems, and are climatically and geographically defined areas of ecologically similar climatic conditions on the Earth, such as communities of plants, animals, and soil organisms, often referred to as ecosystems. Biomes are defined on the basis of factors such as plant structures (such as trees, shrubs, and grasses), leaf types (such as broadleaf and needleleaf), plant spacing (forest, woodland, savanna), and climate. Unlike ecozones, biomes are not defined by genetic, taxonomic, or historical similarities. Biomes are often identified with particular patterns of ecological succession and climax vegetation.

Global biogeochemical cycles are critical to life, most notably those of water, oxygen, carbon, nitrogen and phosphorus.

Wilderness is generally defined as a natural environment on Earth that has not been significantly modified by human activity. The WILD Foundation goes into more detail, defining wilderness as: "The most intact, undisturbed wild natural areas left on our planet - those last truly wild places that humans do not control and have not developed with roads, pipelines or other industrial infrastructure." Wilderness areas and protected parks are considered important for the survival of certain species, ecological studies, conservation, solitude, and recreation. Wilderness is deeply valued for cultural, spiritual, moral, and aesthetic reasons. Some nature writers believe wilderness areas are vital for the human spirit and creativity.

The word, "wilderness", derives from the notion of wildness; in other words that which is not controllable by humans. The word's etymology is from the Old English "wildeornes", which in turn derives from "wildeor" meaning "wild beast" (wild + deor = beast, deer). From this point of view, it is the wildness of a place that makes it a wilderness. The mere presence or activity of people does not disqualify an area from being "wilderness." Many ecosystems that are, or have been, inhabited or influenced by activities of people may still be considered "wild." This way of looking at wilderness includes areas within which natural processes operate without very noticeable human interference.

Wildlife includes all non-domesticated plants, animals and other organisms. Domesticating wild plant and animal species for human benefit has occurred many times all over the planet, and has a major impact on the environment, both positive and negative. Wildlife can be found in all ecosystems. Deserts, rain forests, plains, and other areas—including the most developed urban sites—all have distinct forms of wildlife. While the term in popular culture usually refers to animals that are untouched by civilized human factors, most scientists agree that wildlife around the world is (now) impacted by human activities.

It is the common understanding of "natural environment" that underlies environmentalism — a broad political, social, and philosophical movement that advocates various actions and policies in the interest of protecting what nature remains in the natural environment, or restoring or expanding the role of nature in this environment. While true wilderness is increasingly rare, "wild" nature (e.g., unmanaged forests, uncultivated grasslands, wildlife, wildflowers) can be found in many locations previously inhabited by humans.

Goals for the benefit of people and natural systems, commonly expressed by environmental scientists and environmentalists include:


In some cultures the term environment is meaningless because there is no separation between people and what they view as the natural world, or their surroundings. Specifically in the United States, many native cultures do not recognize the "environment", or see themselves as environmentalists.



</doc>
<doc id="19468941" url="https://en.wikipedia.org/wiki?curid=19468941" title="Balance of nature">
Balance of nature

The balance of nature (also known as ecological balance) is a theory that proposes that ecological systems are usually in a stable equilibrium or homeostasis, which is to say that a small change (the size of a particular population, for example) will be corrected by some negative feedback that will bring the parameter back to its original "point of balance" with the rest of the system. The balance is sometimes depicted as easily disturbed and delicate, while other times it is inversely portrayed as powerful enough to correct any imbalances by itself. The theory may apply where populations depend on each other, for example in predator/prey systems, or relationships between herbivores and their food source. It is also sometimes applied to the relationship between the Earth's ecosystem, the composition of the atmosphere, and the world's weather. 

The Gaia hypothesis is a controversial theory which suggests that living beings interact with Earth to form a complex system which self-regulates to maintain the balance of nature.

The theory that nature is permanently in balance has been largely discredited by scientists working in ecology, as it has been found that chaotic changes in population levels are common. During the later half of the twentieth century the theory was superseded by catastrophe theory and chaos theory. Nevertheless, the idea continues to be popular in the general public.

The concept that nature maintains its condition is of ancient provenance; Herodotus commented on the wonderful relationship between predator and prey species, which remained in a steady proportion to one another, with predators never excessively consuming their prey populations. The "balance of nature" concept once ruled ecological research, as well as once governing the management of natural resources. This led to a doctrine popular among some conservationists that nature was best left to its own devices, and that human intervention into it was by definition unacceptable. The validity of a "balance of nature" was already questioned in the early 1900s, but the general abandonment of the theory by scientists working in ecology only happened in the last quarter of that century when studies showed that it did not match what could be observed among plant and animal populations.

Predator-prey populations tend to show chaotic behavior within limits, where the sizes of populations change in a way that may appear random, but is in fact obeying deterministic laws based only on the relationship between a population and its food source illustrated by the Lotka–Volterra equation. An experimental example of this was shown in an eight-year study on small Baltic Sea creatures such as plankton, which were isolated from the rest of the ocean. Each member of the food web was shown to take turns multiplying and declining, even though the scientists kept the outside conditions constant. An article in the journal "Nature" stated: "Advanced mathematical techniques proved the indisputable presence of chaos in this food web ... short-term prediction is possible, but long-term prediction is not."

Although some conservationist organizations argue that human activity is incompatible with a balanced ecosystem, there are numerous examples in history showing that several modern day habitats originate from human activity: some of Latin America's rain forests owe their existence to humans planting and transplanting them, while the abundance of grazing animals in the Serengeti plain of Africa is thought by some ecologists to be partly due to human-set fires that created savanna habitats.

One of the best-known and often misunderstood examples of ecosystem balance being enhanced by human activity is the Australian Aboriginal practice of "fire-stick farming". This uses low-intensity fire when there is sufficient humidity to limit its action, to reduce the quantity of ground-level combustible material, to lessen the intensity and devastation of forest fires caused by lightning at the end of the dry season. Several plant species are adapted to fire, some even requiring its extreme heat to germinate their seeds.

Despite being discredited among ecologists, the theory is widely held to be true by the general public, conservationists and environmentalists, with one author calling it an "enduring myth". Environmental and conservation organizations such as the WWF, Sierra Club and Canadian Wildlife Federation continue to promote the theory, as does animal rights organizations such as PETA.

At least in Midwestern America, the "balance of nature" idea was shown to be widely held by both science majors and the general student population. In a study at the University of Patras, educational sciences students were asked to reason about the future of ecosystems which suffered human-driven disturbances. Subjects agreed that it was very likely for the ecosystems to fully recover their initial state, referring to either a 'recovery process' which restores the initial 'balance', or specific 'recovery mechanisms' as an ecosystem's inherent characteristic. In a 2017 study, Ampatzidis and Ergazaki discuss the learning objectives and design criteria that a learning environment for non-biology major students should meet to support them challenge the "balance of nature" idea.

The balance of nature (referred to as "the circle of life") is a major theme of the 1994 film, "The Lion King". In one scene, the character Mufasa describes to his son Simba how everything exists in a state of delicate balance.

The character Agent Smith, in the 1999 film "The Matrix", describes humanity as a virus because humans fail to reach an equilibrium with their surrounding environment; unlike other mammals.

The titular character of the 2014 film "Godzilla" fights other sea monsters known as "MUTOs" in a bid to restore the balance of nature.

In the 2018 film, "", the villain Thanos' home planet Titan has been destroyed by the overexploitation of resources, leading him to seek the restoration of balance to the universe by eliminating half of all living beings.



</doc>
<doc id="3134920" url="https://en.wikipedia.org/wiki?curid=3134920" title="The World We Live In (Life magazine)">
The World We Live In (Life magazine)

The World We Live In appeared in the pages of LIFE magazine from December 8, 1952, to December 20, 1954. A science series, it comprised 13 chapters published on an average of every eight weeks. Written by Lincoln Barnett, "The World We Live In" spanned a diverse range of topics concerning planet Earth and universe, and employed the talents of artists and photographers, including cameramen Alfred Eisenstaedt and Fritz Goro and artists Rudolph Zallinger and Chesley Bonestell. The chapters were illustrated with art and photos, often presented in large gatefolds which showed two sides of a scenario.

Barnett’s first few pages of the first episode expound his philosophy of natural history. It begins in the classical tradition with wonder (Episode I, LIFE p 85), a conventional motivation known as early as the Academics. The peripatetics of the next generation elucidate further that wonder is a perplexity eliciting feelings of ignorance. Barnett’s next assertion departs somewhat from the classical tradition. He supposes that wonder is the specific difference between men and animals, which in evolution "caused him to leave behind the animal forbears from which he sprang." From it "the questioning spirit of man was born."

Tradition had gone in a different direction. Aristotle (and students), author of the earliest surviving work on logic, or reasoning, had defined reason, or rationality, as the ability to apply logic. Furthermore, he asserted, it is the one property that distinguishes man from the other animals. Centuries later, in a study of one of Aristotle’s works, Porphyry recapped the definition of man as a mortal, rational, sensible, animate substance, which survived as the main definition into modern times. Descartes simplified it to rational animal (only to then vainly reject its usage), while Linnaeus devised the neo-Latin name of Homo sapiens, "man the wise."

“Rationality” and “Wonder” are not necessarily mutually contradictory if both are regarded as potencies, or the powers to produce human behavior; that is, all humans have the power to act rationally or experience wonder, but they may not necessarily actually do so. Pythagoras said (reportedly):

But in traditional philosophy; specifically, The Theory of Act and Potency, the perceptible form of rationaity is an act, an "accomplished fact", as opposed to a mere potency, or "possibility" hidden within something else. Some acts, however, retain something of potency about them. These are called active potencies. Those who seek fame and gain in Pythagoras are no doubt rational, and do wonder, but they choose not to pursue philosophic investigation, which is as yet only a possibility within them. Since wonder and rationality are the same type of object and serve the same purpose of being the specific difference of man, one might suspect that they are to some degree the same thing. Philosophy is a rational undertaking and wonder, the source of philosophy, must be under the same umbrella.

Whether of rationality or of wonder, Barnett’s definitions offer a logical problem: man becomes different from the animals because of wonder, but wonder is the difference. Some animal therefore must have wondered. The problem, however, belongs to the concept of evolution, rather than to Barnett. The record of the rocks presents a stepped sequence of species already complete, but the concept of evolution requires continuous change. The transitions between steps are missing.

Their existence was proved subsequently. After the chemical structure of genes and chromosomes was deciphered by and was published in 1953, the ability to reconstruct parts of the genome, or genetic map of a species, ensued. The resulting field of cladistics compares genetic sequences to produce more accurate phylogenetic trees than were possible with only comparative anatomy. Knowing the true lines of descent, the paleontologists have been able to identify many more transitional fossils. Man’s closest living relative is the chimpanzee. The last common ancestor is dated to 6 mya.

Intermediate fossils by the hundreds lie scattered along the evolutionary path from then to now. There is a gradation, suggesting that rationality did develop gradually. It was the anthropologists of the 20th century who began to propose that the specific difference of man is only one or some subdivisions of rationality and that the animals have a share in others. The main suggestions have been culture, tool-using, language, adaptability. Barnett indulges in this sort of speculation himself at the end of the episode on mammals, anatomically selecting the human brain (Episode VI, LIFE p 109):
"a convoluted mass of soft tissue which enables him to perceive the world around him with unique acuity and respond to stimuli with a subtlety and self-consciousness that sets him apart from all other living things. It invests him, moreover, with a power which no other creature ever possessed – the power to modify the environment, to govern and alter the very course of evolution ..."

The passage expresses a studied optimism, but, in the middle of the 2oth century, there is a certain degree of prophetic hypocrisy about it:
“Of the more than one million species of animals on earth man is capable of killing all but a few without recourse to the weapons he ingeniously contrives for his own destruction.”

This expression of unease about the outcome of the wonder story long after Barnett’s death would become shrill cries of warning concerning the human impact on the environment. Amidst doubts about how successful rationality is as a strategy over geologic time, the theorists were finding increasing difficulty in defining it and discovering when it began. Each subdivision of rationality developed its counterpart in animal behavior studies: animal culture, tool use by animals, animal language, and so on.

When all is said and done about rationality, we are left with the problem of finding a complex that is minimally present in some form in animals but gradually grows more complex in humans until it accounts for their great success and power . Apparently, rationality would seem to be a pre-condition for the development of rationality. The paradox is nothing new to evolutionary problems. The answer is generally pre-adaptation, the pre-empting of a feature that evolved for some other reason, such as the use of feathers, which evolved for thermal insulation, for flying. Otherwise, the feathers would present a problem, as they could only evolve in animals that already fly. There is, however, no clear pre-adaptive function of rationality. The differences between human and animal rationality or irrationality are still being experimentally defined, a topic not covered by Barnett. His sequel to the human story in ‘’The Epic of Man’’ concentrates on anatomical development. He presumes, following anthropological tradition, that the growing skills of man are linked to the increase in brain size (a presumption often questioned and still not proved). The documentation of these skills, rather than any theory of wonder or rationality, is his main concern in that series.

"The World We Live In" was introduced to LIFE's readership as "the greatest series of science stories we have ever produced". It promised a "unified, understandable picture story of the planet Earth" authored by Lincoln Barnett, "one of the most literate authors in the field of science". The series itself started two issues later. Each chapter was assigned to a reporter, who was granted eight months to research the subject, organize the data, and oversee the photography and artwork. This opportunity to travel, learn, and explore on company expense was known informally as a "Luce fellowship".


After its successful run at LIFE magazine, "The World we Live in" was released in book form in 1955, abridged in 1956 for younger readers by Jane Werner Watson, and re-released in a three-volume "Family Edition" in 1962.

The 1955 book was not entirely complete. Some minor schematic diagrams were cut to better fit the format of the book. Furthermore, some of Chesley Bonestell's artworks, including the painting illustrating the end of the Earth, were removed, possibly because they were seen as dated by then. Jane Werner Watson's edition for young readers cropped many pictures or removed them altogether; for instance, the Paleocene landscape was removed, while the eroded geological panorama was relegated to the endpapers. This led to some odd situations, with some captions referring to animals that were cropped out of the picture.

Lincoln Barnett's style is populist rather than mathematical. Totally absent are the calculations and traditional proofs of geology and the other natural sciences. He does repeat or summarize some statistics derived from those sciences of the times, without much reference to the sources. His work is a selective summarization of some of the major scientific theories about "the world we live in," greatly enhanced by prize-winning art and photography.

Appealing to the public in general, rather than to any select scientific audience, his text can be criticized of being florid, sometimes to a ludicrous degree. As one reader put it, "[I] Enjoyed "Creatures of the Sea" most of all because of the way Lincoln Barnett slings the King's English around. While Nobel Prizer Sir Winston Churchill had an easier subject, he can't hold a candle to this guy Barnett". The rationale for mammalian dominance of the Earth from Ch. VI is only one example.

"Indeed, it is probable that the mammals may have survived and succeeded to hegemony of the earth not in spite of but by reason of their very weakness and obscurity, their smallness in a world dominated by giants, their nakedness in a world of armor plate -- in particular, by their fear and sensitivity and awareness in a world of unperceiving, insensate, brainless brutes."

There is also marked personification and some bias. Large prehistoric mammals, for instance, are variously described as being "awkward" or "witless". "Tyrannosaurus rex" in Ch. V does not escape this treatment either.

"The apogee of development was attained with the creation of "Tyrannosaurus rex", the mightiest and most fearsome flesh-eater that ever terrorized the land. A towering agent of destruction, endowed with gigantic strength and power, "Tyrannosaurus" spanned 50 feet from nose to tail and carried his terrible head 18 to 20 feet above the ground. His hind legs were superbly muscled, from his thick thighs down to his three-toed, cruelly taloned feet. His main weapon of attack was his murderous mouth which had a gape of incredible size and was armed with rows of six-inch saberlike teeth."

Finally, apparently as part of Barnett's effort to interest a wide audience, the text features quotations from non-scientific literature, including the Judaeo-Christian Bible. For example, each episode includes such an independent quotation just below the title, as is often the practice in scientific works. Concerning the few Biblical quotes, one reader remarked that the "text was written as if the clergy were looking over Mr. Barnett's shoulder and crossing out anything that might be in conflict with the story of Adam and Eve". Whether the statement is to be judged true is a matter of opinion. Certainly, the Bible is not used as justification for any hypothesis in the entire work, which, unlike the Bible, portrays the evolution of the natural world in every episode.

Still, among the scientists, the purple prose does its job of conveying awe at the natural world. Paleontologist George Olshevsky described Lincoln Barnett's text as having "the grandeur of the universe contained in every word".

Much of "The World we Live In" is and always was intentionally out of date, due to differences between the latest theories of modern physics, which are mainly incomprehensible to the general public, and the more popular theories of classical physics. This dichotomy of theory developed in the 20th century and continues today. Faced with it, Barnett chose the more classical theories for his presentation.

Barnett primarily offers the Newtonian universe. At the time of publication, his episodes were up-to-date with contemporary theories on the natural world, but major scientific breakthroughs in astronomy, geology, and biology date the series. For instance, the sections on geology assume geophysical global cooling instead of plate tectonics to explain uplift. The paleontological chapters (V and VI) are especially dated, considering the speed of new discoveries in the field and the Dinosaur Renaissance.

The frontier of research had already dissociated itself from the Newtonian universe in Barnett's time, in favor of the Einsteinian. Writing in the mid-20th century, he was well aware of this development. He copes briefly with Einstein in the last few pages of the last episode as a special topic, but for the most part modern cosmology, quantum mechanics, and advanced particle physics are beyond his chosen classical subject matter. For example, Newton's gravity prevails, but its equivalent relativistic curved space-time is neglected. There is no force of gravity in the relativistic universe; however, it is acceptable to use the language of gravity with relativistic meanings.

The sections on various biomes such as the desert, rainforest, and woodland, which depend on more immediate observation, are still more or less accurate as far as they go, which today is more limited in reach. They reflect the ecology of the time. Neither Barnett nor any other writer had any hint of the massive changes to the biomes caused by climate change, such as the rapid melting of the polar ice caps, the bleaching of most of the world's coral, and the threat to the atmosphere's ozone layer, narrowly placed in abeyance by world collaborative action.

""The World We Live In" ought to be in book form. It is extraordinarily well done, comprehensive and at the same time comprehendible—a great thing."

"To own "The World We Live In" in book form is a not-to-be-missed opportunity for any family—old or young, it's a wonderful and exciting adventure in learning."

"The World We Live In", with its several incarnations, successfully brought the intricacies of science to the baby boom generation. By the time the book version was being published, endorsements were printed by notable people, including paleontologist Roy Chapman Andrews, filmmaker Walt Disney, and Admiral Richard E. Byrd. The "Letters to the Editors" page frequently featured glowing reviews of the series, as well as letters from creationists that either embraced or rejected it.

After publishing chapter XII on Mettler's Woods, LIFE received mail from the Citizens' Committee for the Preservation of Mettler's Woods, which congratulated them for the article and encouraged readers to help save the forest from destruction. Eventually, a letter from the Committee was published announcing that they had "raised to funds to purchase and study these woods and adjoining woodlands", adding that "Life"'s article "not only stimulated several hundred persons to contribute to the fund to save one of the last primeval American forests, but encouraged the United Brotherhood of Carpenters and Joiners of America to contribute $75,000 in memory of W. L. Hutcheson". The forest was renamed the Hutcheson Memorial Forest.

Paleontologist Bob Bakker mentions Zallinger's dinosaurs as the spark that ignited his passion for prehistory; ironically, Bakker himself would later argue against Zallinger's rendition. George Olshevsky also cites "The World We Live In" as introducing him to science, and adds that he suggested authoring an updated version; however, LIFE's editors were not interested. "The World We Live In "was also the basis for a science series by the German comic book Mosaik.

"The World We Live In" was followed closely by "The Epic of Man", in ten parts (all signed by Barnett) beginning with the November 7, 1955 issue, and ending with the May 6, 1957, issue. It focused on the development and history of human civilization, material that is usually covered under Physical Anthropology and Archaeology. The article format is the same: text by Barnett illustrated by many of the same artists and photographers. Panoramic fold-outs depict the ancient tribesmen carrying out their reconstructed cultural activities. These latter were duly compared to the activities of select modern tribesmen of the times. Ironically those ways were permanently altered by the exposure. The 1950s were times of great archaeological changes also, due to the multiplication of sites and discoveries. The magazine series finally presents the ancestors of modern Europe (Celts) and then ends abruptly, without a book edition for the time being. Notably missing from the series are the Far East and the Americas, where agriculture is now known to have been innovated independently.

After helping to produce the various editions of "The World We Live In", Barnett went back to his true passion, natural History. From the June 30, 1958 to the October 19, 1959 issues, an eight-part series, "The Wonders of Life on Earth" traces the development of Darwin’s Theory of evolution, portraying the places and species that influenced his thought in eye-catching color photographs. The "Wonders" name only appears in the first issue. In that issue also and in all subsequent issues the name is "Darwin’s World of Nature".

In those years great changes were being reported by LIFE, which seemed to be obsoleting the series articles as fast as they could be written. For example, the International Geophysical Year of 1957-1958 was duly planned and was duly reported in advance by a single article in LIFE Magazine. Data collected during this international research undertaking unexpectedly proved and resurrected Alfred Wegener's theory of continental drift, the foundation of today's plate tectonics in geology, yet the magazine mentions it no further. Articles on the Space Race were frequent, as well as individual scientific articles on various expeditions and wildlife. Barnett played no part in these, as he was not a regular employee of the magazine. One of its reporters in World War II, he had resigned in 1946 to pursue a career as an independent writer. He did his major writing for LIFE as an independent contractor, bringing the art staff with him.

In 1959, the handwriting appeared on the wall, so to speak, for LIFE Magazine. Circulation began to fall, due to competition with television, and fell even further in 1960. Barnett forged ahead with the book form of the Darwin series, returning to the title and concept of "The Wonders of Life on Earth". Darwin seemed to him to be the true heir to classical science, investigating, like Aristotle and his students, the puzzling circumstances of nature. Unlike "The World We Live in", the "Wonders" book’ rewrote and re-edited much of the magazine material. The first edition appeared in 1960 under the banner of Time, Inc., and was soon followed by others, including a special edition for young people by The Golden Press.

Time’s principal owner and co-founder, Henry Luce, moved in 1961 to restructure his holdings. LIFE Magazine was less successful, but Time Books was very successful. Luce took the advice of a new employee, Jerome (Jerry) Hardy, who had recently come to Time, Inc. from another publishing house. In 1959 he had launched a series of books, "Time Capsules", containing extracts from "Time" with moderate success. In consultation with the LIFE editorial staff he proposed a new division that would publish series of books on specific topics. In 1961 Time Life was created under Hardy’s management. It joined the scientific research assets of LIFE with the book publishing assets of Time Inc. The magazine would now decline, but Time Life would rise to new heights.

Time Life was able to restore and improve many dropped projects from the archives of LIFE. One of the first was the single book based on "Epic of Man". When it appeared in 1961 it was considerably different from the magazine articles. The WorldCat citation for APA lists Barnett as the author along with Time Life. The printed version ignores Barnett, citing the Editors of LIFE as the author and Time Incorporated as the publisher. The book itself is divided into 16 chapters, not 10. China, the Maya, and the Incas have been added, as well as new material on Cultural Anthropology. Many of the chapters correspond to the previous LIFE articles, but the names have been changed, and the material has been rewritten. Barnett has been listed as Senior Writer, and 9 other writers have been added, but none of the chapters are signed.

From 1961 on, Time Life produced hundreds of books in dozens of series, typically about 20 books a series. The one that most closely emulates Barnett’s interest is perhaps the "Life Nature Library" some 24 volumes of Natural History, 1961-1965, each expanding and updating some article or part of an article of "The World We Live In". For example, parallel to the article, "The Age of Mammals", is the book, "The Mammals". The 25th volume is a series index. Barnett, however, does not appear in any of the 25, or in any other series. He has moved on to other books. In his place Time Life has recruited other notable writers and scientists in their fields, such as Willy Ley, Francis Clark Howell, and Niko Tinbergen.


</doc>
<doc id="60842665" url="https://en.wikipedia.org/wiki?curid=60842665" title="Back to nature">
Back to nature

Back to nature or return to nature is a philosophy or style of living which emphasises closeness to nature, rather than artifice and civilisation. In this, the rustic customs and pastoralism of country life are preferred to urban fashion and sophistication. A famous example is Henry David Thoreau who spent two years living a simple life in a log cabin at Walden Pond.




</doc>
<doc id="59818638" url="https://en.wikipedia.org/wiki?curid=59818638" title="Barnacle Geese Myth">
Barnacle Geese Myth

A myth about the origins of the Barnacle goose is that the Barnacle Geese emerge fully formed from the common Barnacle (Cirripedia). The migration patterns of may birds including the Barnacle Geese were not fully known until the late 19th or early 20th centuries. Early medieval accounts of migration often drew on popular myths to explain why some birds seemed to disappear and then reappear during the year. The origins of the myth go back to the 2nd century BCE. The myth was popularised in the early 12th century by Gerald of Wales. Subsequent descriptions in medieval Bestiaries caused may scholars and historians to repeat and enlarge on the myth.

In 1435, Aeneas Silvius Bartholomeus , travelled to Scotland to encourage James I of Scotland to assist the French in the “Hundred Years War”. He spent several months travelling around Britain. and recorded these travels in his book entitled "de Europa". A short section of the book is devoted to Scotland and Ireland. He described James as “ "… a sickly man weighed down by a fat punch .."”. He noted the cold inhospitable climate of Scotland and “ ".. semi-naked paupers who were begging outside churches (and) went away happily after receiving stones as alms…"”. Continuing in this vein, he records the following story:

"" …I … heard that in Scotland there was once a tree growing on the bank of a river which produced fruits shaped like ducks. "When these were nearly ripe, they dropped down of their own accord, some onto the earth, and some into the water. Those that landed on the earth rotted away, but those that sank into the water instantly came to life, swam out from below the water, and immediately flew into the air, equipped with feathers and wings. When I eagerly investigated this matter, I learned that miracles always recede further into the distance and that the famous tree was to be found not in Scotland but in the Orkney islands…""

It is believed that this story from Pope Pius II is the first recorded account of the Barnacle Geese myth in Scotland. 

Some 75 years later, Hector Boece in his "S"cotorum Historiae a Prima Gentis Origine" gave further credence to this story with an account of a discussion he had with his friend and colleague Canon Alexander Galloway on an island in what is now called the Western Isles . The event, if it occurred, was sometime between c.1506x1520. Boece allows Galloway in the narrative to give two contrasting accounts of the geese story. Boece records:

" …. It remains for me (Boece) to discuss those geese commonly called clacks, (claiks) which are commonly but wrongly imagined to be born on trees in these islands, on the basis of what I have learned from my diligent investigation of this thing. ….. I will not hesitate to describe something I myself witnessed seven years ago… Alexander Galloway, parson of Kinkell, who, besides being a man of outstanding probity, is possessed of an unmatched zeal for studying wonders… When he was pulling up some driftwood and saw that seashells were clinging to it from one end to the other, he was surprised by the unusual nature of the thing, and, out of a zeal to understand it, opened them up, whereupon he was more amazed than ever, for within them he discovered, not sea creatures, but rather birds, of a size similar to the shells that contained them …. small shells contained birds of a proportionately small size….. So, he quickly ran to me, whom he knew to be gripped with a great curiosity for investigating suchlike matters and revealed the entire thing to me…..”"
The Claik or Clack Geese as they were known to Boece survived scrutiny during the Scottish Enlightenment. The age of the myth and the lack of empirical evidence on Bird migration led to several other accounts of the origins of Barnacle Geese being common until the 20th century.

There is a comprehensive database of Wikipedia pages relevant to Barnacle Geese starting at Bird migration. 


</doc>
<doc id="9228" url="https://en.wikipedia.org/wiki?curid=9228" title="Earth">
Earth

Earth is the third planet from the Sun and the only astronomical object known to harbor life. According to radiometric dating and other evidence, Earth formed over 4.5 billion years ago. Earth's gravity interacts with other objects in space, especially the Sun and the Moon, which is Earth's only natural satellite. Earth orbits around the Sun in 365.256 solar days, a period known as an Earth sidereal year. During this time, Earth rotates about its axis 366.256 times, that is, a sidereal year has 366.256 sidereal days.

Earth's axis of rotation is tilted with respect to its orbital plane, producing seasons on Earth. The gravitational interaction between Earth and the Moon causes tides, stabilizes Earth's orientation on its axis, and gradually slows its rotation. Earth is the densest planet in the Solar System and the largest and most massive of the four rocky planets.

Earth's outer layer (lithosphere) is divided into several rigid tectonic plates that migrate across the surface over many millions of years. About 29% of Earth's surface is land consisting of continents and islands. The remaining 71% is covered with water, mostly by oceans but also lakes, rivers and other fresh water, which all together constitute the hydrosphere. The majority of Earth's polar regions are covered in ice, including the Antarctic ice sheet and the sea ice of the Arctic ice pack. Earth's interior remains active with a solid iron inner core, a liquid outer core that generates Earth's magnetic field, and a convecting mantle that drives plate tectonics.

Within the first billion years of Earth's history, life appeared in the oceans and began to affect Earth's atmosphere and surface, leading to the proliferation of anaerobic and, later, aerobic organisms. Some geological evidence indicates that life may have arisen as early as 4.1 billion years ago. Since then, the combination of Earth's distance from the Sun, physical properties and geological history have allowed life to evolve and thrive. In the history of life on Earth, biodiversity has gone through long periods of expansion, occasionally punctuated by mass extinctions. Over 99% of all species that ever lived on Earth are extinct. Estimates of the number of species on Earth today vary widely; most species have not been described. Over 7.7 billion humans live on Earth and depend on its biosphere and natural resources for their survival. Politically, the world has around 200 sovereign states.

The modern English word "Earth" developed, via Middle English, from an Old English noun most often spelled '. It has cognates in every Germanic language, and their ancestral root has been reconstructed as *"erþō". In its earliest attestation, the word "eorðe" was already being used to translate the many senses of Latin ' and Greek "gē": the ground, its soil, dry land, the human world, the surface of the world (including the sea), and the globe itself. As with Roman Terra/Tellūs and Greek Gaia, Earth may have been a personified goddess in Germanic paganism: late Norse mythology included Jörð ('Earth'), a giantess often given as the mother of Thor.

Originally, "earth" was written in lowercase, and from early Middle English, its definite sense as "the globe" was expressed as "the earth". By Early Modern English, many nouns were capitalized, and "the earth" became (and often remained) "the Earth", particularly when referenced along with other heavenly bodies. More recently, the name is sometimes simply given as "Earth", by analogy with the names of the other planets. House styles now vary: Oxford spelling recognizes the lowercase form as the most common, with the capitalized form an acceptable variant. Another convention capitalizes "Earth" when appearing as a name (e.g. "Earth's atmosphere") but writes it in lowercase when preceded by "the" (e.g. "the atmosphere of the earth"). It almost always appears in lowercase in colloquial expressions such as "what on earth are you doing?"

Occasionally, the name Terra is used in scientific writing and especially in science fiction to distinguish our inhabited planet from others, while in poetry Tellus has been used to denote personification of the Earth. The Greek poetic name "Gaea" ("Gæa") is rare, though the alternative spelling Gaia has become common due to the Gaia hypothesis, in which case its pronunciation is rather than the more Classical .

There are a number of adjectives for the planet Earth. From "Earth" itself comes "earthly". From Latin "Terra" come "Terran" , Terrestrial , and (via French) Terrene , and from Latin "Tellus" come "Tellurian" and, more rarely, "Telluric" and "Tellural". From Greek "Gaia" and "Gaea" comes "Gaian" and "Gaean". 

An inhabitant of the Earth is an "Earthling", a "Terran", a "Terrestrial", a "Tellurian" or, rarely, an "Earthian".

The oldest material found in the Solar System is dated to (Bya). By the primordial Earth had formed. The bodies in the Solar System formed and evolved with the Sun. In theory, a solar nebula partitions a volume out of a molecular cloud by gravitational collapse, which begins to spin and flatten into a circumstellar disk, and then the planets grow out of that disk with the Sun. A nebula contains gas, ice grains, and dust (including primordial nuclides). According to nebular theory, planetesimals formed by accretion, with the primordial Earth taking 10– (Mys) to form.

A subject of research is the formation of the Moon, some 4.53 Bya. A leading hypothesis is that it was formed by accretion from material loosed from Earth after a Mars-sized object, named Theia, hit Earth. In this view, the mass of Theia was approximately 10 percent of Earth; it hit Earth with a glancing blow and some of its mass merged with Earth. Between approximately 4.1 and , numerous asteroid impacts during the Late Heavy Bombardment caused significant changes to the greater surface environment of the Moon and, by inference, to that of Earth.

Earth's atmosphere and oceans were formed by volcanic activity and outgassing. Water vapor from these sources condensed into the oceans, augmented by water and ice from asteroids, protoplanets, and comets. In this model, atmospheric "greenhouse gases" kept the oceans from freezing when the newly forming Sun had only 70% of its current luminosity. By , Earth's magnetic field was established, which helped prevent the atmosphere from being stripped away by the solar wind.

A crust formed when the molten outer layer of Earth cooled to form a solid. The two models that explain land mass propose either a steady growth to the present-day forms or, more likely, a rapid growth early in Earth history followed by a long-term steady continental area. Continents formed by plate tectonics, a process ultimately driven by the continuous loss of heat from Earth's interior. Over the period of hundreds of millions of years, the supercontinents have assembled and broken apart. Roughly (Mya), one of the earliest known supercontinents, Rodinia, began to break apart. The continents later recombined to form Pannotia , then finally Pangaea, which also broke apart .

The present pattern of ice ages began about , and then intensified during the Pleistocene about . High-latitude regions have since undergone repeated cycles of glaciation and thaw, repeating about every . The last continental glaciation ended ago.

Chemical reactions led to the first self-replicating molecules about four billion years ago. A half billion years later, the last common ancestor of all current life arose. The evolution of photosynthesis allowed the Sun's energy to be harvested directly by life forms. The resultant molecular oxygen () accumulated in the atmosphere and due to interaction with ultraviolet solar radiation, formed a protective ozone layer () in the upper atmosphere. The incorporation of smaller cells within larger ones resulted in the development of complex cells called eukaryotes. True multicellular organisms formed as cells within colonies became increasingly specialized. Aided by the absorption of harmful ultraviolet radiation by the ozone layer, life colonized Earth's surface. Among the earliest fossil evidence for life is microbial mat fossils found in 3.48 billion-year-old sandstone in Western Australia, biogenic graphite found in 3.7 billion-year-old metasedimentary rocks in Western Greenland, and remains of biotic material found in 4.1 billion-year-old rocks in Western Australia. The earliest direct evidence of life on Earth is contained in 3.45 billion-year-old Australian rocks showing fossils of microorganisms.

During the Neoproterozoic, , much of Earth might have been covered in ice. This hypothesis has been termed "Snowball Earth", and it is of particular interest because it preceded the Cambrian explosion, when multicellular life forms significantly increased in complexity. Following the Cambrian explosion, , there have been five mass extinctions. The most recent such event was , when an asteroid impact triggered the extinction of the non-avian dinosaurs and other large reptiles, but spared some small animals such as mammals, which at the time resembled shrews. Mammalian life has diversified over the past , and several million years ago an African ape-like animal such as "Orrorin tugenensis" gained the ability to stand upright. This facilitated tool use and encouraged communication that provided the nutrition and stimulation needed for a larger brain, which led to the evolution of humans. The development of agriculture, and then civilization, led to humans having an influence on Earth and the nature and quantity of other life forms that continues to this day.

Earth's expected long-term future is tied to that of the Sun. Over the next , solar luminosity will increase by 10%, and over the next by 40%. Earth's increasing surface temperature will accelerate the inorganic carbon cycle, reducing concentration to levels lethally low for plants ( for C4 photosynthesis) in approximately . The lack of vegetation will result in the loss of oxygen in the atmosphere, making animal life impossible. About a billion years from now, all surface water will have disappeared and the mean global temperature will reach . Earth is expected to be habitable until the end of photosynthesis about from now, but if nitrogen is removed from the atmosphere, life may continue until a runaway greenhouse effect occurs from now. Anthropogenic emissions are "probably insufficient" to cause a runaway greenhouse at current solar luminosity. Even if the Sun were eternal and stable, 27% of the water in the modern oceans will descend to the mantle in one billion years, due to reduced steam venting from mid-ocean ridges.

The Sun will evolve to become a red giant in about . Models predict that the Sun will expand to roughly , about 250 times its present radius. Earth's fate is less clear. As a red giant, the Sun will lose roughly 30% of its mass, so, without tidal effects, Earth will move to an orbit from the Sun when the star reaches its maximum radius. Most, if not all, remaining life will be destroyed by the Sun's increased luminosity (peaking at about 5,000 times its present level). A 2008 simulation indicates that Earth's orbit will eventually decay due to tidal effects and drag, causing it to enter the Sun's atmosphere and be vaporized.

The shape of Earth is nearly spherical. There is a small flattening at the poles and bulging around the equator due to Earth's rotation. To second order, Earth is approximately an oblate spheroid, whose equatorial diameter is larger than the pole-to-pole diameter, although the variation is less than 1% of the average radius of the Earth.

The point on the surface farthest from Earth's center of mass is the summit of the equatorial Chimborazo volcano in Ecuador (). The average diameter of the reference spheroid is . Local topography deviates from this idealized spheroid, although on a global scale these deviations are small compared to Earth's radius: the maximum deviation of only 0.17% is at the Mariana Trench ( below local sea level), whereas Mount Everest ( above local sea level) represents a deviation of 0.14%.

In geodesy, the exact shape that Earth's oceans would adopt in the absence of land and perturbations such as tides and winds is called the geoid. More precisely, the geoid is the surface of gravitational equipotential at mean sea level.

Earth's mass is approximately (5,970 Yg). It is composed mostly of iron (32.1%), oxygen (30.1%), silicon (15.1%), magnesium (13.9%), sulphur (2.9%), nickel (1.8%), calcium (1.5%), and aluminum (1.4%), with the remaining 1.2% consisting of trace amounts of other elements. Due to mass segregation, the core region is estimated to be primarily composed of iron (88.8%), with smaller amounts of nickel (5.8%), sulphur (4.5%), and less than 1% trace elements.

The most common rock constituents of the crust are nearly all oxides: chlorine, sulphur, and fluorine are the important exceptions to this and their total amount in any rock is usually much less than 1%. Over 99% of the crust is composed of 11 oxides, principally silica, alumina, iron oxides, lime, magnesia, potash and soda.

Earth's interior, like that of the other terrestrial planets, is divided into layers by their chemical or physical (rheological) properties. The outer layer is a chemically distinct silicate solid crust, which is underlain by a highly viscous solid mantle. The crust is separated from the mantle by the Mohorovičić discontinuity. The thickness of the crust varies from about under the oceans to for the continents. The crust and the cold, rigid, top of the upper mantle are collectively known as the lithosphere, and it is of the lithosphere that the tectonic plates are composed. Beneath the lithosphere is the asthenosphere, a relatively low-viscosity layer on which the lithosphere rides. Important changes in crystal structure within the mantle occur at below the surface, spanning a transition zone that separates the upper and lower mantle. Beneath the mantle, an extremely low viscosity liquid outer core lies above a solid inner core. Earth's inner core might rotate at a slightly higher angular velocity than the remainder of the planet, advancing by 0.1–0.5° per year. The radius of the inner core is about one fifth of that of Earth.

Earth's internal heat comes from a combination of residual heat from planetary accretion (about 20%) and heat produced through radioactive decay (80%). The major heat-producing isotopes within Earth are potassium-40, uranium-238, and thorium-232. At the center, the temperature may be up to , and the pressure could reach . Because much of the heat is provided by radioactive decay, scientists postulate that early in Earth's history, before isotopes with short half-lives were depleted, Earth's heat production was much higher. At approximately , twice the present-day heat would have been produced, increasing the rates of mantle convection and plate tectonics, and allowing the production of uncommon igneous rocks such as komatiites that are rarely formed today.

The mean heat loss from Earth is , for a global heat loss of . A portion of the core's thermal energy is transported toward the crust by mantle plumes, a form of convection consisting of upwellings of higher-temperature rock. These plumes can produce hotspots and flood basalts. More of the heat in Earth is lost through plate tectonics, by mantle upwelling associated with mid-ocean ridges. The final major mode of heat loss is through conduction through the lithosphere, the majority of which occurs under the oceans because the crust there is much thinner than that of the continents.

Earth's mechanically rigid outer layer, the lithosphere, is divided into tectonic plates. These plates are rigid segments that move relative to each other at one of three boundaries types: At convergent boundaries, two plates come together; at divergent boundaries, two plates are pulled apart; and at transform boundaries, two plates slide past one another laterally. Along these plate boundaries, earthquakes, volcanic activity, mountain-building, and oceanic trench formation can occur. The tectonic plates ride on top of the asthenosphere, the solid but less-viscous part of the upper mantle that can flow and move along with the plates.

As the tectonic plates migrate, oceanic crust is subducted under the leading edges of the plates at convergent boundaries. At the same time, the upwelling of mantle material at divergent boundaries creates mid-ocean ridges. The combination of these processes recycles the oceanic crust back into the mantle. Due to this recycling, most of the ocean floor is less than old. The oldest oceanic crust is located in the Western Pacific and is estimated to be old. By comparison, the oldest dated continental crust is .

The seven major plates are the Pacific, North American, Eurasian, African, Antarctic, Indo-Australian, and South American. Other notable plates include the Arabian Plate, the Caribbean Plate, the Nazca Plate off the west coast of South America and the Scotia Plate in the southern Atlantic Ocean. The Australian Plate fused with the Indian Plate between . The fastest-moving plates are the oceanic plates, with the Cocos Plate advancing at a rate of and the Pacific Plate moving . At the other extreme, the slowest-moving plate is the Eurasian Plate, progressing at a typical rate of .

The total surface area of Earth is about . Of this, 70.8%, or , is below sea level and covered by ocean water. Below the ocean's surface are much of the continental shelf, mountains, volcanoes, oceanic trenches, submarine canyons, oceanic plateaus, abyssal plains, and a globe-spanning mid-ocean ridge system. The remaining 29.2%, or , not covered by water has terrain that varies greatly from place to place and consists of mountains, deserts, plains, plateaus, and other landforms. Tectonics and erosion, volcanic eruptions, flooding, weathering, glaciation, the growth of coral reefs, and meteorite impacts are among the processes that constantly reshape Earth's surface over geological time.

The continental crust consists of lower density material such as the igneous rocks granite and andesite. Less common is basalt, a denser volcanic rock that is the primary constituent of the ocean floors. Sedimentary rock is formed from the accumulation of sediment that becomes buried and compacted together. Nearly 75% of the continental surfaces are covered by sedimentary rocks, although they form about 5% of the crust. The third form of rock material found on Earth is metamorphic rock, which is created from the transformation of pre-existing rock types through high pressures, high temperatures, or both. The most abundant silicate minerals on Earth's surface include quartz, feldspars, amphibole, mica, pyroxene and olivine. Common carbonate minerals include calcite (found in limestone) and dolomite.

The elevation of the land surface varies from the low point of at the Dead Sea, to a maximum altitude of at the top of Mount Everest. The mean height of land above sea level is about .

The pedosphere is the outermost layer of Earth's continental surface and is composed of soil and subject to soil formation processes. The total arable land is 10.9% of the land surface, with 1.3% being permanent cropland. Close to 40% of Earth's land surface is used for agriculture, or an estimated of cropland and of pastureland.

The abundance of water on Earth's surface is a unique feature that distinguishes the "Blue Planet" from other planets in the Solar System. Earth's hydrosphere consists chiefly of the oceans, but technically includes all water surfaces in the world, including inland seas, lakes, rivers, and underground waters down to a depth of . The deepest underwater location is Challenger Deep of the Mariana Trench in the Pacific Ocean with a depth of .

The mass of the oceans is approximately 1.35 metric tons or about 1/4400 of Earth's total mass. The oceans cover an area of with a mean depth of , resulting in an estimated volume of . If all of Earth's crustal surface were at the same elevation as a smooth sphere, the depth of the resulting world ocean would be .

About 97.5% of the water is saline; the remaining 2.5% is fresh water. Most fresh water, about 68.7%, is present as ice in ice caps and glaciers.

The average salinity of Earth's oceans is about 35 grams of salt per kilogram of sea water (3.5% salt). Most of this salt was released from volcanic activity or extracted from cool igneous rocks. The oceans are also a reservoir of dissolved atmospheric gases, which are essential for the survival of many aquatic life forms. Sea water has an important influence on the world's climate, with the oceans acting as a large heat reservoir. Shifts in the oceanic temperature distribution can cause significant weather shifts, such as the El Niño–Southern Oscillation.

The atmospheric pressure at Earth's sea level averages , with a scale height of about . A dry atmosphere is composed of 78.084% nitrogen, 20.946% oxygen, 0.934% argon, and trace amounts of carbon dioxide and other gaseous molecules. Water vapor content varies between 0.01% and 4% but averages about 1%. The height of the troposphere varies with latitude, ranging between at the poles to at the equator, with some variation resulting from weather and seasonal factors.

Earth's biosphere has significantly altered its atmosphere. Oxygenic photosynthesis evolved , forming the primarily nitrogen–oxygen atmosphere of today. This change enabled the proliferation of aerobic organisms and, indirectly, the formation of the ozone layer due to the subsequent conversion of atmospheric into. The ozone layer blocks ultraviolet solar radiation, permitting life on land. Other atmospheric functions important to life include transporting water vapor, providing useful gases, causing small meteors to burn up before they strike the surface, and moderating temperature. This last phenomenon is known as the greenhouse effect: trace molecules within the atmosphere serve to capture thermal energy emitted from the ground, thereby raising the average temperature. Water vapor, carbon dioxide, methane, nitrous oxide, and ozone are the primary greenhouse gases in the atmosphere. Without this heat-retention effect, the average surface temperature would be , in contrast to the current , and life on Earth probably would not exist in its current form. In May 2017, glints of light, seen as twinkling from an orbiting satellite a million miles away, were found to be reflected light from ice crystals in the atmosphere.

Earth's atmosphere has no definite boundary, slowly becoming thinner and fading into outer space. Three-quarters of the atmosphere's mass is contained within the first of the surface. This lowest layer is called the troposphere. Energy from the Sun heats this layer, and the surface below, causing expansion of the air. This lower-density air then rises and is replaced by cooler, higher-density air. The result is atmospheric circulation that drives the weather and climate through redistribution of thermal energy.

The primary atmospheric circulation bands consist of the trade winds in the equatorial region below 30° latitude and the westerlies in the mid-latitudes between 30° and 60°. Ocean currents are also important factors in determining climate, particularly the thermohaline circulation that distributes thermal energy from the equatorial oceans to the polar regions.

Water vapor generated through surface evaporation is transported by circulatory patterns in the atmosphere. When atmospheric conditions permit an uplift of warm, humid air, this water condenses and falls to the surface as precipitation. Most of the water is then transported to lower elevations by river systems and usually returned to the oceans or deposited into lakes. This water cycle is a vital mechanism for supporting life on land and is a primary factor in the erosion of surface features over geological periods. Precipitation patterns vary widely, ranging from several meters of water per year to less than a millimeter. Atmospheric circulation, topographic features, and temperature differences determine the average precipitation that falls in each region.

The amount of solar energy reaching Earth's surface decreases with increasing latitude. At higher latitudes, the sunlight reaches the surface at lower angles, and it must pass through thicker columns of the atmosphere. As a result, the mean annual air temperature at sea level decreases by about per degree of latitude from the equator. Earth's surface can be subdivided into specific latitudinal belts of approximately homogeneous climate. Ranging from the equator to the polar regions, these are the tropical (or equatorial), subtropical, temperate and polar climates.

This latitudinal rule has several anomalies:

The commonly used Köppen climate classification system has five broad groups (humid tropics, arid, humid middle latitudes, continental and cold polar), which are further divided into more specific subtypes. The Köppen system rates regions of terrain based on observed temperature and precipitation.

The highest air temperature ever measured on Earth was in Furnace Creek, California, in Death Valley, in 1913. The lowest air temperature ever directly measured on Earth was at Vostok Station in 1983, but satellites have used remote sensing to measure temperatures as low as in East Antarctica. These temperature records are only measurements made with modern instruments from the 20th century onwards and likely do not reflect the full range of temperature on Earth.

Above the troposphere, the atmosphere is usually divided into the stratosphere, mesosphere, and thermosphere. Each layer has a different lapse rate, defining the rate of change in temperature with height. Beyond these, the exosphere thins out into the magnetosphere, where the geomagnetic fields interact with the solar wind. Within the stratosphere is the ozone layer, a component that partially shields the surface from ultraviolet light and thus is important for life on Earth. The Kármán line, defined as 100 km above Earth's surface, is a working definition for the boundary between the atmosphere and outer space.

Thermal energy causes some of the molecules at the outer edge of the atmosphere to increase their velocity to the point where they can escape from Earth's gravity. This causes a slow but steady loss of the atmosphere into space. Because unfixed hydrogen has a low molecular mass, it can achieve escape velocity more readily, and it leaks into outer space at a greater rate than other gases. The leakage of hydrogen into space contributes to the shifting of Earth's atmosphere and surface from an initially reducing state to its current oxidizing one. Photosynthesis provided a source of free oxygen, but the loss of reducing agents such as hydrogen is thought to have been a necessary precondition for the widespread accumulation of oxygen in the atmosphere. Hence the ability of hydrogen to escape from the atmosphere may have influenced the nature of life that developed on Earth. In the current, oxygen-rich atmosphere most hydrogen is converted into water before it has an opportunity to escape. Instead, most of the hydrogen loss comes from the destruction of methane in the upper atmosphere.

The gravity of Earth is the acceleration that is imparted to objects due to the distribution of mass within Earth. Near Earth's surface, gravitational acceleration is approximately . Local differences in topography, geology, and deeper tectonic structure cause local and broad, regional differences in Earth's gravitational field, known as gravity anomalies.

The main part of Earth's magnetic field is generated in the core, the site of a dynamo process that converts the kinetic energy of thermally and compositionally driven convection into electrical and magnetic field energy. The field extends outwards from the core, through the mantle, and up to Earth's surface, where it is, approximately, a dipole. The poles of the dipole are located close to Earth's geographic poles. At the equator of the magnetic field, the magnetic-field strength at the surface is , with a magnetic dipole moment of at epoch 2000, decreasing nearly 6% per century. The convection movements in the core are chaotic; the magnetic poles drift and periodically change alignment. This causes secular variation of the main field and field reversals at irregular intervals averaging a few times every million years. The most recent reversal occurred approximately 700,000 years ago.

The extent of Earth's magnetic field in space defines the magnetosphere. Ions and electrons of the solar wind are deflected by the magnetosphere; solar wind pressure compresses the dayside of the magnetosphere, to about 10 Earth radii, and extends the nightside magnetosphere into a long tail. Because the velocity of the solar wind is greater than the speed at which waves propagate through the solar wind, a supersonic bow shock precedes the dayside magnetosphere within the solar wind. Charged particles are contained within the magnetosphere; the plasmasphere is defined by low-energy particles that essentially follow magnetic field lines as Earth rotates; the ring current is defined by medium-energy particles that drift relative to the geomagnetic field, but with paths that are still dominated by the magnetic field, and the Van Allen radiation belt are formed by high-energy particles whose motion is essentially random, but otherwise contained by the magnetosphere.

During magnetic storms and substorms, charged particles can be deflected from the outer magnetosphere and especially the magnetotail, directed along field lines into Earth's ionosphere, where atmospheric atoms can be excited and ionized, causing the aurora.

Earth's rotation period relative to the Sun—its mean solar day—is of mean solar time (). Because Earth's solar day is now slightly longer than it was during the 19th century due to tidal deceleration, each day varies between longer.

Earth's rotation period relative to the fixed stars, called its "stellar day" by the International Earth Rotation and Reference Systems Service (IERS), is of mean solar time (UT1), or Earth's rotation period relative to the precessing or moving mean vernal equinox, misnamed its "sidereal day", is of mean solar time (UT1) . Thus the sidereal day is shorter than the stellar day by about 8.4 ms. The length of the mean solar day in SI seconds is available from the IERS for the periods 1623–2005 and 1962–2005.

Apart from meteors within the atmosphere and low-orbiting satellites, the main apparent motion of celestial bodies in Earth's sky is to the west at a rate of 15°/h = 15'/min. For bodies near the celestial equator, this is equivalent to an apparent diameter of the Sun or the Moon every two minutes; from Earth's surface, the apparent sizes of the Sun and the Moon are approximately the same.

Earth orbits the Sun at an average distance of about every 365.2564 mean solar days, or one sidereal year. This gives an apparent movement of the Sun eastward with respect to the stars at a rate of about 1°/day, which is one apparent Sun or Moon diameter every 12 hours. Due to this motion, on average it takes 24 hours—a solar day—for Earth to complete a full rotation about its axis so that the Sun returns to the meridian. The orbital speed of Earth averages about , which is fast enough to travel a distance equal to Earth's diameter, about , in seven minutes, and the distance to the Moon, , in about 3.5 hours.

The Moon and Earth orbit a common barycenter every 27.32 days relative to the background stars. When combined with the Earth–Moon system's common orbit around the Sun, the period of the synodic month, from new moon to new moon, is 29.53 days. Viewed from the celestial north pole, the motion of Earth, the Moon, and their axial rotations are all counterclockwise. Viewed from a vantage point above the north poles of both the Sun and Earth, Earth orbits in a counterclockwise direction about the Sun. The orbital and axial planes are not precisely aligned: Earth's axis is tilted some 23.44 degrees from the perpendicular to the Earth–Sun plane (the ecliptic), and the Earth–Moon plane is tilted up to ±5.1 degrees against the Earth–Sun plane. Without this tilt, there would be an eclipse every two weeks, alternating between lunar eclipses and solar eclipses.

The Hill sphere, or the sphere of gravitational influence, of Earth is about in radius. This is the maximum distance at which Earth's gravitational influence is stronger than the more distant Sun and planets. Objects must orbit Earth within this radius, or they can become unbound by the gravitational perturbation of the Sun.

Earth, along with the Solar System, is situated in the Milky Way and orbits about 28,000 light-years from its center. It is about 20 light-years above the galactic plane in the Orion Arm.

The axial tilt of Earth is approximately 23.439281° with the axis of its orbit plane, always pointing towards the Celestial Poles. Due to Earth's axial tilt, the amount of sunlight reaching any given point on the surface varies over the course of the year. This causes the seasonal change in climate, with summer in the Northern Hemisphere occurring when the Tropic of Cancer is facing the Sun, and winter taking place when the Tropic of Capricorn in the Southern Hemisphere faces the Sun. During the summer, the day lasts longer, and the Sun climbs higher in the sky. In winter, the climate becomes cooler and the days shorter. In northern temperate latitudes, the Sun rises north of true east during the summer solstice, and sets north of true west, reversing in the winter. The Sun rises south of true east in the summer for the southern temperate zone and sets south of true west.

Above the Arctic Circle, an extreme case is reached where there is no daylight at all for part of the year, up to six months at the North Pole itself, a polar night. In the Southern Hemisphere, the situation is exactly reversed, with the South Pole oriented opposite the direction of the North Pole. Six months later, this pole will experience a midnight sun, a day of 24 hours, again reversing with the South Pole.

By astronomical convention, the four seasons can be determined by the solstices—the points in the orbit of maximum axial tilt toward or away from the Sun—and the equinoxes, when Earth's rotational axis is aligned with its orbital axis. In the Northern Hemisphere, winter solstice currently occurs around 21 December; summer solstice is near 21 June, spring equinox is around 20 March and autumnal equinox is about 22 or 23 September. In the Southern Hemisphere, the situation is reversed, with the summer and winter solstices exchanged and the spring and autumnal equinox dates swapped.

The angle of Earth's axial tilt is relatively stable over long periods of time. Its axial tilt does undergo nutation; a slight, irregular motion with a main period of 18.6 years. The orientation (rather than the angle) of Earth's axis also changes over time, precessing around in a complete circle over each 25,800 year cycle; this precession is the reason for the difference between a sidereal year and a tropical year. Both of these motions are caused by the varying attraction of the Sun and the Moon on Earth's equatorial bulge. The poles also migrate a few meters across Earth's surface. This polar motion has multiple, cyclical components, which collectively are termed quasiperiodic motion. In addition to an annual component to this motion, there is a 14-month cycle called the Chandler wobble. Earth's rotational velocity also varies in a phenomenon known as length-of-day variation.

In modern times, Earth's perihelion occurs around 3 January, and its aphelion around 4 July. These dates change over time due to precession and other orbital factors, which follow cyclical patterns known as Milankovitch cycles. The changing Earth–Sun distance causes an increase of about 6.9% in solar energy reaching Earth at perihelion relative to aphelion. Because the Southern Hemisphere is tilted toward the Sun at about the same time that Earth reaches the closest approach to the Sun, the Southern Hemisphere receives slightly more energy from the Sun than does the northern over the course of a year. This effect is much less significant than the total energy change due to the axial tilt, and most of the excess energy is absorbed by the higher proportion of water in the Southern Hemisphere.

A study from 2016 suggested that Planet Nine tilted all the planets of the Solar System, including Earth, by about six degrees.

A planet that can sustain life is termed habitable, even if life did not originate there. Earth provides liquid water—an environment where complex organic molecules can assemble and interact, and sufficient energy to sustain metabolism. The distance of Earth from the Sun, as well as its orbital eccentricity, rate of rotation, axial tilt, geological history, sustaining atmosphere, and magnetic field all contribute to the current climatic conditions at the surface.

A planet's life forms inhabit ecosystems, whose total is sometimes said to form a "biosphere". Earth's biosphere is thought to have begun evolving about . The biosphere is divided into a number of biomes, inhabited by broadly similar plants and animals. On land, biomes are separated primarily by differences in latitude, height above sea level and humidity. Terrestrial biomes lying within the Arctic or Antarctic Circles, at high altitudes or in extremely arid areas are relatively barren of plant and animal life; species diversity reaches a peak in humid lowlands at equatorial latitudes.

In July 2016, scientists reported identifying a set of 355 genes from the last universal common ancestor (LUCA) of all organisms living on Earth.

Earth has resources that have been exploited by humans. Those termed non-renewable resources, such as fossil fuels, only renew over geological timescales.

Large deposits of fossil fuels are obtained from Earth's crust, consisting of coal, petroleum, and natural gas. These deposits are used by humans both for energy production and as feedstock for chemical production. Mineral ore bodies have also been formed within the crust through a process of ore genesis, resulting from actions of magmatism, erosion, and plate tectonics. These bodies form concentrated sources for many metals and other useful elements.

Earth's biosphere produces many useful biological products for humans, including food, wood, pharmaceuticals, oxygen, and the recycling of many organic wastes. The land-based ecosystem depends upon topsoil and fresh water, and the oceanic ecosystem depends upon dissolved nutrients washed down from the land. In 1980, of Earth's land surface consisted of forest and woodlands, was grasslands and pasture, and was cultivated as croplands. The estimated amount of irrigated land in 1993 was . Humans also live on the land by using building materials to construct shelters.

Large areas of Earth's surface are subject to extreme weather such as tropical cyclones, hurricanes, or typhoons that dominate life in those areas. From 1980 to 2000, these events caused an average of 11,800 human deaths per year. Many places are subject to earthquakes, landslides, tsunamis, volcanic eruptions, tornadoes, sinkholes, blizzards, floods, droughts, wildfires, and other calamities and disasters.

Many localized areas are subject to human-made pollution of the air and water, acid rain and toxic substances, loss of vegetation (overgrazing, deforestation, desertification), loss of wildlife, species extinction, soil degradation, soil depletion and erosion.

There is a scientific consensus linking human activities to global warming due to industrial carbon dioxide emissions. This is predicted to produce changes such as the melting of glaciers and ice sheets, more extreme temperature ranges, significant changes in weather and a global rise in average sea levels.

Cartography, the study and practice of map-making, and geography, the study of the lands, features, inhabitants and phenomena on Earth, have historically been the disciplines devoted to depicting Earth. Surveying, the determination of locations and distances, and to a lesser extent navigation, the determination of position and direction, have developed alongside cartography and geography, providing and suitably quantifying the requisite information.

Earth's human population reached approximately seven billion on 31 October 2011. Projections indicate that the world's human population will reach 9.2 billion in 2050. Most of the growth is expected to take place in developing nations. Human population density varies widely around the world, but a majority live in Asia. By 2020, 60% of the world's population is expected to be living in urban, rather than rural, areas.

68% of the land mass of the world is in the northern hemisphere. Partly due to the predominance of land mass, 90% of humans live in the northern hemisphere.

It is estimated that one-eighth of Earth's surface is suitable for humans to live on – three-quarters of Earth's surface is covered by oceans, leaving one-quarter as land. Half of that land area is desert (14%), high mountains (27%), or other unsuitable terrains. The northernmost permanent settlement in the world is Alert, on Ellesmere Island in Nunavut, Canada. (82°28′N) The southernmost is the Amundsen–Scott South Pole Station, in Antarctica, almost exactly at the South Pole. (90°S)
Independent sovereign nations claim the planet's entire land surface, except for some parts of Antarctica, a few land parcels along the Danube river's western bank, and the unclaimed area of Bir Tawil between Egypt and Sudan. , there are 193 sovereign states that are member states of the United Nations, plus two observer states and 72 dependent territories and states with limited recognition. Earth has never had a sovereign government with authority over the entire globe, although some nation-states have striven for world domination and failed.

The United Nations is a worldwide intergovernmental organization that was created with the goal of intervening in the disputes between nations, thereby avoiding armed conflict. The U.N. serves primarily as a forum for international diplomacy and international law. When the consensus of the membership permits, it provides a mechanism for armed intervention.

The first human to orbit Earth was Yuri Gagarin on 12 April 1961. In total, about 487 people have visited outer space and reached orbit , and, of these, twelve have walked on the Moon. Normally, the only humans in space are those on the International Space Station. The station's crew, made up of six people, is usually replaced every six months. The farthest that humans have traveled from Earth is , achieved during the Apollo 13 mission in 1970.

The Moon is a relatively large, terrestrial, planet-like natural satellite, with a diameter about one-quarter of Earth's. It is the largest moon in the Solar System relative to the size of its planet, although Charon is larger relative to the dwarf planet Pluto. The natural satellites of other planets are also referred to as "moons", after Earth's.

The gravitational attraction between Earth and the Moon causes tides on Earth. The same effect on the Moon has led to its tidal locking: its rotation period is the same as the time it takes to orbit Earth. As a result, it always presents the same face to the planet. As the Moon orbits Earth, different parts of its face are illuminated by the Sun, leading to the lunar phases; the dark part of the face is separated from the light part by the solar terminator.
Due to their tidal interaction, the Moon recedes from Earth at the rate of approximately . Over millions of years, these tiny modifications—and the lengthening of Earth's day by about 23 µs/yr—add up to significant changes. During the Devonian period, for example, (approximately ) there were 400 days in a year, with each day lasting 21.8 hours.

The Moon may have dramatically affected the development of life by moderating the planet's climate. Paleontological evidence and computer simulations show that Earth's axial tilt is stabilized by tidal interactions with the Moon. Some theorists think that without this stabilization against the torques applied by the Sun and planets to Earth's equatorial bulge, the rotational axis might be chaotically unstable, exhibiting chaotic changes over millions of years, as appears to be the case for Mars.

Viewed from Earth, the Moon is just far enough away to have almost the same apparent-sized disk as the Sun. The angular size (or solid angle) of these two bodies match because, although the Sun's diameter is about 400 times as large as the Moon's, it is also 400 times more distant. This allows total and annular solar eclipses to occur on Earth.

The most widely accepted theory of the Moon's origin, the giant-impact hypothesis, states that it formed from the collision of a Mars-size protoplanet called Theia with the early Earth. This hypothesis explains (among other things) the Moon's relative lack of iron and volatile elements and the fact that its composition is nearly identical to that of Earth's crust.

Earth has at least five co-orbital asteroids, including 3753 Cruithne and . A trojan asteroid companion, , is librating around the leading Lagrange triangular point, L4, in Earth's orbit around the Sun.

The tiny near-Earth asteroid makes close approaches to the Earth–Moon system roughly every twenty years. During these approaches, it can orbit Earth for brief periods of time.

, there are 1,886 operational, human-made satellites orbiting Earth. There are also inoperative satellites, including Vanguard 1, the oldest satellite currently in orbit, and over 16,000 pieces of tracked space debris. Earth's largest artificial satellite is the International Space Station.

The standard astronomical symbol of Earth consists of a cross circumscribed by a circle, , representing the four corners of the world.

Human cultures have developed many views of the planet. Earth is sometimes personified as a deity. In many cultures it is a mother goddess that is also the primary fertility deity, and by the mid-20th century, the Gaia Principle compared Earth's environments and life as a single self-regulating organism leading to broad stabilization of the conditions of habitability. Creation myths in many religions involve the creation of Earth by a supernatural deity or deities.

Scientific investigation has resulted in several culturally transformative shifts in people's view of the planet. Initial belief in a flat Earth was gradually displaced in the Greek colonies of southern Italy during the late 6th century BC by the idea of spherical Earth, which was attributed to both the philosophers Pythagoras and Parmenides. By the end of the 5th century BC, the sphericity of Earth was universally accepted among Greek intellectuals. Earth was generally believed to be the center of the universe until the 16th century, when scientists first conclusively demonstrated that it was a moving object, comparable to the other planets in the Solar System. Due to the efforts of influential Christian scholars and clerics such as James Ussher, who sought to determine the age of Earth through analysis of genealogies in Scripture, Westerners before the 19th century generally believed Earth to be a few thousand years old at most. It was only during the 19th century that geologists realized Earth's age was at least many millions of years.

Lord Kelvin used thermodynamics to estimate the age of Earth to be between 20 million and 400 million years in 1864, sparking a vigorous debate on the subject; it was only when radioactivity and radioactive dating were discovered in the late 19th and early 20th centuries that a reliable mechanism for determining Earth's age was established, proving the planet to be billions of years old. The perception of Earth shifted again in the 20th century when humans first viewed it from orbit, and especially with photographs of Earth returned by the Apollo program.

</math>, where "m" is the mass of Earth, "a" is an astronomical unit, and "M" is the mass of the Sun. So the radius in AU is about formula_1.</ref>




</doc>
<doc id="27667" url="https://en.wikipedia.org/wiki?curid=27667" title="Space">
Space

Space is the boundless three-dimensional extent in which objects and events have relative position and direction. Physical space is often conceived in three linear dimensions, although modern physicists usually consider it, with time, to be part of a boundless four-dimensional continuum known as spacetime. The concept of space is considered to be of fundamental importance to an understanding of the physical universe. However, disagreement continues between philosophers over whether it is itself an entity, a relationship between entities, or part of a conceptual framework.

Debates concerning the nature, essence and the mode of existence of space date back to antiquity; namely, to treatises like the "Timaeus" of Plato, or Socrates in his reflections on what the Greeks called "khôra" (i.e. "space"), or in the "Physics" of Aristotle (Book IV, Delta) in the definition of "topos" (i.e. place), or in the later "geometrical conception of place" as "space "qua" extension" in the "Discourse on Place" ("Qawl fi al-Makan") of the 11th-century Arab polymath Alhazen. Many of these classical philosophical questions were discussed in the Renaissance and then reformulated in the 17th century, particularly during the early development of classical mechanics. In Isaac Newton's view, space was absolute—in the sense that it existed permanently and independently of whether there was any matter in the space. Other natural philosophers, notably Gottfried Leibniz, thought instead that space was in fact a collection of relations between objects, given by their distance and direction from one another. In the 18th century, the philosopher and theologian George Berkeley attempted to refute the "visibility of spatial depth" in his "Essay Towards a New Theory of Vision". Later, the metaphysician Immanuel Kant said that the concepts of space and time are not empirical ones derived from experiences of the outside world—they are elements of an already given systematic framework that humans possess and use to structure all experiences. Kant referred to the experience of "space" in his "Critique of Pure Reason" as being a subjective "pure "a priori" form of intuition".

In the 19th and 20th centuries mathematicians began to examine geometries that are non-Euclidean, in which space is conceived as "curved", rather than "flat". According to Albert Einstein's theory of general relativity, space around gravitational fields deviates from Euclidean space. Experimental tests of general relativity have confirmed that non-Euclidean geometries provide a better model for the shape of space.

Galilean and Cartesian theories about space, matter and motion are at the foundation of the Scientific Revolution, which is understood to have culminated with the publication of Newton's "Principia" in 1687. Newton's theories about space and time helped him explain the movement of objects. While his theory of space is considered the most influential in Physics, it emerged from his predecessors' ideas about the same.

As one of the pioneers of modern science, Galilei revised the established Aristotelian and Ptolemaic ideas about a geocentric cosmos. He backed the Copernican theory that the universe was heliocentric, with a stationary sun at the center and the planets—including the Earth—revolving around the sun. If the Earth moved, the Aristotelian belief that its natural tendency was to remain at rest was in question. Galilei wanted to prove instead that the sun moved around its axis, that motion was as natural to an object as the state of rest. In other words, for Galilei, celestial bodies, including the Earth, were naturally inclined to move in circles. This view displaced another Aristotelian idea—that all objects gravitated towards their designated natural place-of-belonging.

Descartes set out to replace the Aristotelian worldview with a theory about space and motion as determined by natural laws. In other words, he sought a metaphysical foundation or a mechanical explanation for his theories about matter and motion. Cartesian space was Euclidean in structure—infinite, uniform and flat. It was defined as that which contained matter; conversely, matter by definition had a spatial extension so that there was no such thing as empty space.

The Cartesian notion of space is closely linked to his theories about the nature of the body, mind and matter. He is famously known for his "cogito ergo sum" (I think therefore I am), or the idea that we can only be certain of the fact that we can doubt, and therefore think and therefore exist. His theories belong to the rationalist tradition, which attributes knowledge about the world to our ability to think rather than to our experiences, as the empiricists believe. He posited a clear distinction between the body and mind, which is referred to as the Cartesian dualism.

Following Galilei and Descartes, during the seventeenth century the philosophy of space and time revolved around the ideas of Gottfried Leibniz, a German philosopher–mathematician, and Isaac Newton, who set out two opposing theories of what space is. Rather than being an entity that independently exists over and above other matter, Leibniz held that space is no more than the collection of spatial relations between objects in the world: "space is that which results from places taken together". Unoccupied regions are those that "could" have objects in them, and thus spatial relations with other places. For Leibniz, then, space was an idealised abstraction from the relations between individual entities or their possible locations and therefore could not be continuous but must be discrete.
Space could be thought of in a similar way to the relations between family members. Although people in the family are related to one another, the relations do not exist independently of the people.
Leibniz argued that space could not exist independently of objects in the world because that implies a difference between two universes exactly alike except for the location of the material world in each universe. But since there would be no observational way of telling these universes apart then, according to the identity of indiscernibles, there would be no real difference between them. According to the principle of sufficient reason, any theory of space that implied that there could be these two possible universes must therefore be wrong.
Newton took space to be more than relations between material objects and based his position on observation and experimentation. For a relationist there can be no real difference between inertial motion, in which the object travels with constant velocity, and non-inertial motion, in which the velocity changes with time, since all spatial measurements are relative to other objects and their motions. But Newton argued that since non-inertial motion generates forces, it must be absolute. He used the example of water in a spinning bucket to demonstrate his argument. Water in a bucket is hung from a rope and set to spin, starts with a flat surface. After a while, as the bucket continues to spin, the surface of the water becomes concave. If the bucket's spinning is stopped then the surface of the water remains concave as it continues to spin. The concave surface is therefore apparently not the result of relative motion between the bucket and the water. Instead, Newton argued, it must be a result of non-inertial motion relative to space itself. For several centuries the bucket argument was considered decisive in showing that space must exist independently of matter.

In the eighteenth century the German philosopher Immanuel Kant developed a theory of knowledge in which knowledge about space can be both "a priori" and "synthetic". According to Kant, knowledge about space is "synthetic", in that statements about space are not simply true by virtue of the meaning of the words in the statement. In his work, Kant rejected the view that space must be either a substance or relation. Instead he came to the conclusion that space and time are not discovered by humans to be objective features of the world, but imposed by us as part of a framework for organizing experience.

Euclid's "Elements" contained five postulates that form the basis for Euclidean geometry. One of these, the parallel postulate, has been the subject of debate among mathematicians for many centuries. It states that on any plane on which there is a straight line "L" and a point "P" not on "L", there is exactly one straight line "L" on the plane that passes through the point "P" and is parallel to the straight line "L". Until the 19th century, few doubted the truth of the postulate; instead debate centered over whether it was necessary as an axiom, or whether it was a theory that could be derived from the other axioms. Around 1830 though, the Hungarian János Bolyai and the Russian Nikolai Ivanovich Lobachevsky separately published treatises on a type of geometry that does not include the parallel postulate, called hyperbolic geometry. In this geometry, an infinite number of parallel lines pass through the point "P". Consequently, the sum of angles in a triangle is less than 180° and the ratio of a circle's circumference to its diameter is greater than pi. In the 1850s, Bernhard Riemann developed an equivalent theory of elliptical geometry, in which no parallel lines pass through "P". In this geometry, triangles have more than 180° and circles have a ratio of circumference-to-diameter that is less than pi.

Although there was a prevailing Kantian consensus at the time, once non-Euclidean geometries had been formalised, some began to wonder whether or not physical space is curved. Carl Friedrich Gauss, a German mathematician, was the first to consider an empirical investigation of the geometrical structure of space. He thought of making a test of the sum of the angles of an enormous stellar triangle, and there are reports that he actually carried out a test, on a small scale, by triangulating mountain tops in Germany.

Henri Poincaré, a French mathematician and physicist of the late 19th century, introduced an important insight in which he attempted to demonstrate the futility of any attempt to discover which geometry applies to space by experiment. He considered the predicament that would face scientists if they were confined to the surface of an imaginary large sphere with particular properties, known as a sphere-world. In this world, the temperature is taken to vary in such a way that all objects expand and contract in similar proportions in different places on the sphere. With a suitable falloff in temperature, if the scientists try to use measuring rods to determine the sum of the angles in a triangle, they can be deceived into thinking that they inhabit a plane, rather than a spherical surface. In fact, the scientists cannot in principle determine whether they inhabit a plane or sphere and, Poincaré argued, the same is true for the debate over whether real space is Euclidean or not. For him, which geometry was used to describe space was a matter of convention. Since Euclidean geometry is simpler than non-Euclidean geometry, he assumed the former would always be used to describe the 'true' geometry of the world.

In 1905, Albert Einstein published his special theory of relativity, which led to the concept that space and time can be viewed as a single construct known as "spacetime". In this theory, the speed of light in a vacuum is the same for all observers—which has the result that two events that appear simultaneous to one particular observer will not be simultaneous to another observer if the observers are moving with respect to one another. Moreover, an observer will measure a moving clock to tick more slowly than one that is stationary with respect to them; and objects are measured to be shortened in the direction that they are moving with respect to the observer.

Subsequently, Einstein worked on a general theory of relativity, which is a theory of how gravity interacts with spacetime. Instead of viewing gravity as a force field acting in spacetime, Einstein suggested that it modifies the geometric structure of spacetime itself. According to the general theory, time goes more slowly at places with lower gravitational potentials and rays of light bend in the presence of a gravitational field. Scientists have studied the behaviour of binary pulsars, confirming the predictions of Einstein's theories, and non-Euclidean geometry is usually used to describe spacetime.

In modern mathematics spaces are defined as sets with some added structure. They are frequently described as different types of manifolds, which are spaces that locally approximate to Euclidean space, and where the properties are defined largely on local connectedness of points that lie on the manifold. There are however, many diverse mathematical objects that are called spaces. For example, vector spaces such as function spaces may have infinite numbers of independent dimensions and a notion of distance very different from Euclidean space, and topological spaces replace the concept of distance with a more abstract idea of nearness.

Space is one of the few fundamental quantities in physics, meaning that it cannot be defined via other quantities because nothing more fundamental is known at the present. On the other hand, it can be related to other fundamental quantities. Thus, similar to other fundamental quantities (like time and mass), space can be explored via measurement and experiment.

Today, our three-dimensional space is viewed as embedded in a four-dimensional spacetime, called Minkowski space (see special relativity). The idea behind space-time is that time is hyperbolic-orthogonal to each of the three spatial dimensions.

Before Einstein's work on relativistic physics, time and space were viewed as independent dimensions. Einstein's discoveries showed that due to relativity of motion our space and time can be mathematically combined into one object–spacetime. It turns out that distances in space or in time separately are not invariant with respect to Lorentz coordinate transformations, but distances in Minkowski space-time along space-time intervals are—which justifies the name.

In addition, time and space dimensions should not be viewed as exactly equivalent in Minkowski space-time. One can freely move in space but not in time. Thus, time and space coordinates are treated differently both in special relativity (where time is sometimes considered an imaginary coordinate) and in general relativity (where different signs are assigned to time and space components of spacetime metric).

Furthermore, in Einstein's general theory of relativity, it is postulated that space-time is geometrically distorted – "curved" – near to gravitationally significant masses.

One consequence of this postulate, which follows from the equations of general relativity, is the prediction of moving ripples of space-time, called gravitational waves. While indirect evidence for these waves has been found (in the motions of the Hulse–Taylor binary system, for example) experiments attempting to directly measure these waves are ongoing at the LIGO and Virgo collaborations. LIGO scientists reported the first such direct observation of gravitational waves on 14 September 2015.

Relativity theory leads to the cosmological question of what shape the universe is, and where space came from. It appears that space was created in the Big Bang, 13.8 billion years ago and has been expanding ever since. The overall shape of space is not known, but space is known to be expanding very rapidly due to the cosmic inflation.

The measurement of "physical space" has long been important. Although earlier societies had developed measuring systems, the International System of Units, (SI), is now the most common system of units used in the measuring of space, and is almost universally used.

Currently, the standard space interval, called a standard meter or simply meter, is defined as the distance traveled by light in a vacuum during a time interval of exactly 1/299,792,458 of a second. This definition coupled with present definition of the second is based on the special theory of relativity in which the speed of light plays the role of a fundamental constant of nature.

Geography is the branch of science concerned with identifying and describing places on Earth, utilizing spatial awareness to try to understand why things exist in specific locations. Cartography is the mapping of spaces to allow better navigation, for visualization purposes and to act as a locational device. Geostatistics apply statistical concepts to collected spatial data of Earth to create an estimate for unobserved phenomena.

Geographical space is often considered as land, and can have a relation to ownership usage (in which space is seen as property or territory). While some cultures assert the rights of the individual in terms of ownership, other cultures will identify with a communal approach to land ownership, while still other cultures such as Australian Aboriginals, rather than asserting ownership rights to land, invert the relationship and consider that they are in fact owned by the land. Spatial planning is a method of regulating the use of space at land-level, with decisions made at regional, national and international levels. Space can also impact on human and cultural behavior, being an important factor in architecture, where it will impact on the design of buildings and structures, and on farming.

Ownership of space is not restricted to land. Ownership of airspace and of waters is decided internationally. Other forms of ownership have been recently asserted to other spaces—for example to the radio bands of the electromagnetic spectrum or to cyberspace.

Public space is a term used to define areas of land as collectively owned by the community, and managed in their name by delegated bodies; such spaces are open to all, while private property is the land culturally owned by an individual or company, for their own use and pleasure.

Abstract space is a term used in geography to refer to a hypothetical space characterized by complete homogeneity. When modeling activity or behavior, it is a conceptual tool used to limit extraneous variables such as terrain.

Psychologists first began to study the way space is perceived in the middle of the 19th century. Those now concerned with such studies regard it as a distinct branch of psychology. Psychologists analyzing the perception of space are concerned with how recognition of an object's physical appearance or its interactions are perceived, see, for example, visual space.

Other, more specialized topics studied include amodal perception and object permanence. The perception of surroundings is important due to its necessary relevance to survival, especially with regards to hunting and self preservation as well as simply one's idea of personal space.

Several space-related phobias have been identified, including agoraphobia (the fear of open spaces), astrophobia (the fear of celestial space) and claustrophobia (the fear of enclosed spaces).

The understanding of three-dimensional space in humans is thought to be learned during infancy using unconscious inference, and is closely related to hand-eye coordination. The visual ability to perceive the world in three dimensions is called depth perception.

Space has been studied in the social sciences from the perspectives of Marxism, feminism, postmodernism, postcolonialism, urban theory and critical geography. These theories account for the effect of the history of colonialism, transatlantic slavery and globalization on our understanding and experience of space and place. The topic has garnered attention since the 1980s, after the publication of Henri Lefebvre's "The Production of Space ." In this book, Lefebvre applies Marxist ideas about the production of commodities and accumulation of capital to discuss space as a social product. His focus is on the multiple and overlapping social processes that produce space.

In his book "The Condition of Postmodernity," David Harvey describes what he terms the "time-space compression." This is the effect of technological advances and capitalism on our perception of time, space and distance. Changes in the modes of production and consumption of capital affect and are affected by developments in transportation and technology. These advances create relationships across time and space, new markets and groups of wealthy elites in urban centers, all of which annihilate distances and affect our perception of linearity and distance.

In his book "Thirdspace," Edward Soja describes space and spatiality as an integral and neglected aspect of what he calls the "trialectics of being," the three modes that determine how we inhabit, experience and understand the world. He argues that critical theories in the Humanities and Social Sciences study the historical and social dimensions of our lived experience, neglecting the spatial dimension. He builds on Henri Lefebvre's work to address the dualistic way in which humans understand space—as either material/physical or as represented/imagined. Lefebvre's "lived space" and Soja's "thridspace" are terms that account for the complex ways in which humans understand and navigate place, which "firstspace" and "Secondspace" (Soja's terms for material and imagined spaces respectively) do not fully encompass.

Postcolonial theorist Homi Bhabha's concept of Third Space is different from Soja's Thirdspace, even though both terms offer a way to think outside the terms of a binary logic. Bhabha's Third Space is the space in which hybrid cultural forms and identities exist. In his theories, the term hybrid describes new cultural forms that emerge through the interaction between colonizer and colonized.


</doc>
<doc id="9649" url="https://en.wikipedia.org/wiki?curid=9649" title="Energy">
Energy

In physics, energy is the quantitative property that must be transferred to an object in order to perform work on, or to heat, the object. Energy is a conserved quantity; the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The SI unit of energy is the joule, which is the energy transferred to an object by the work of moving it a distance of 1 metre against a force of 1 newton.

Common forms of energy include the kinetic energy of a moving object, the potential energy stored by an object's position in a force field (gravitational, electric or magnetic), the elastic energy stored by stretching solid objects, the chemical energy released when a fuel burns, the radiant energy carried by light, and the thermal energy due to an object's temperature.

Mass and energy are closely related. Due to mass–energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. For example, after heating an object, its increase in energy could be measured as a small increase in mass, with a sensitive enough scale.

Living organisms require energy to stay alive, such as the energy humans get from food. Human civilization requires energy to function, which it gets from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The processes of Earth's climate and ecosystem are driven by the radiant energy Earth receives from the sun and the geothermal energy contained within the earth.

The total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object – or the composite motion of the components of an object – and potential energy reflects the potential of an object to have motion, and generally is a function of the position of an object within a field or may be stored in the field itself.

While these two categories are sufficient to describe all forms of energy, it is often convenient to refer to particular combinations of potential and kinetic energy as its own form. For example, macroscopic mechanical energy is the sum of translational and rotational kinetic and potential energy in a system neglects the kinetic energy due to temperature, and nuclear energy which combines utilize potentials from the nuclear force and the weak force), among others.

The word "energy" derives from the , which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.

In the late 17th century, Gottfried Leibniz proposed the idea of the , or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total "vis viva" was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the random motion of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from "vis viva" only by a factor of two.

In 1807, Thomas Young was possibly the first to use the term "energy" instead of "vis viva", in its modern sense. Gustave-Gaspard Coriolis described "kinetic energy" in 1829 in its modern sense, and in 1853, William Rankine coined the term "potential energy". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.

These developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jožef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.

In 1843, Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the "Joule apparatus": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.

In the International System of Units (SI), the unit of energy is the joule, named after James Prescott Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British Thermal Units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.

The SI unit of energy rate (energy per unit time) is the watt, which is a joule per second. Thus, one joule is one watt-second, and 3600 joules equal one watt-hour. The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.

In classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.

Work, a function of energy, is force times distance.

This says that the work (formula_2) is equal to the line integral of the force F along a path "C"; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.

The total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.

Another energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy "minus" the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).

Noether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.

In the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants. A reaction is said to be exothermic or exergonic if the final state is lower on the energy scale than the initial state; in the case of endothermic reactions the situation is the reverse. Chemical reactions are almost invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The "speed" of a chemical reaction (at given temperature "T") is related to the activation energy "E" by the Boltzmann's population factor ethat is the probability of molecule to have energy greater than or equal to "E" at the given temperature "T". This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction can be provided in the form of thermal energy.

In biology, energy is an attribute of all biological systems from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or an organelle of a biological organism. Energy used in respiration is mostly stored in molecular oxygen and can be unlocked by reactions with molecules of substances such as carbohydrates (including sugars), lipids, and proteins stored by cells. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, assuming an average human energy expenditure of 12,500 kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 ÷ 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a "feel" for the use of a given amount of energy.

Sunlight's radiant energy is also captured by plants as "chemical potential energy" in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into carbohydrates, lipids, and proteins and high-energy compounds like oxygen and ATP. Carbohydrates, lipids, and proteins can release the energy of oxygen, which is utilized by living organisms as an electron acceptor. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark, in a forest fire, or it may be made available more slowly for animal or human metabolism, when organic molecules are ingested, and catabolism is triggered by enzyme action.

Any living organism relies on an external source of energy – radiant energy from the Sun in the case of green plants, chemical energy in some form in the case of animals – to be able to grow and reproduce. The daily 1500–2000 Calories (6–8 MJ) recommended for a human adult are taken as a combination of oxygen and food molecules, the latter mostly carbohydrates and fats, of which glucose (CHO) and stearin (CHO) are convenient examples. The food molecules are oxidised to carbon dioxide and water in the mitochondria
and some of the energy is used to convert ADP into ATP.
The rest of the chemical energy in O and the carbohydrate or fat is converted into heat: the ATP is used as a sort of "energy currency", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:

It would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy), and it is true that most real machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe ("the surroundings"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology: to take just the first step in the food chain, of the estimated 124.7 Pg/a of carbon that is fixed by photosynthesis, 64.3 Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.

In geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations brought about by solar energy on the atmosphere of the planet Earth.

Sunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives many weather phenomena, save those generated by volcanic events. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, give up some of their thermal energy suddenly to power a few days of violent air movement.

In a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may be later released to active kinetic energy in landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars created these atoms.

In cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.

In quantum mechanics, energy is defined in terms of the energy operator
as a time derivative of the wave function. The Schrödinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schrödinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schrödinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation: formula_3 (where formula_4 is Planck's constant and formula_5 the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.

When calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically – using Lorentz transformations instead of Newtonian mechanics – Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:

where

For example, consider electron–positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles. This is a reversible process – the inverse process is called pair creation – in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.

In general relativity, the stress–energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.

Energy and mass are manifestations of one and the same underlying physical property of a system. This property is responsible for the inertia and strength of gravitational interaction of the system ("mass manifestations"), and is also responsible for the potential ability of the system to perform work or heating ("energy manifestations"), subject to the limitations of other physical laws.

In classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy–momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of space-time (= boosts).

Energy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery, from chemical energy to electric energy; a dam: gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator; or a heat engine, from heat to work.

Examples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. Our Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that in itself (since it still contains the same total energy even if in different forms), but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.

There are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.

Energy transformations in the universe over time are characterized by various kinds of potential energy that has been available since the Big Bang later being "released" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nuclear decay, in which energy is released that was originally "stored" in heavy isotopes (such as uranium and thorium), by nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae, to store energy in the creation of these heavy elements before they were incorporated into the solar system and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic energy and thermal energy in a very short time. Yet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at maximum. At its lowest point the kinetic energy is at maximum and is equal to the decrease of potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.

Energy is also transferred from potential energy (formula_8) to kinetic energy (formula_9) and then back to potential energy constantly. This is referred to as conservation of energy. In this closed system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:

The equation can then be simplified further since formula_10 (mass times acceleration due to gravity times the height) and formula_11 (half mass times velocity squared). Then the total amount of energy can be found by adding formula_12.

Energy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass-energy equivalence. The formula "E" = "mc"², derived by Albert Einstein (1905) quantifies the relationship between rest-mass and rest-energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J.J. Thomson (1881), Henri Poincaré (1900), Friedrich Hasenöhrl (1904) and others (see Mass-energy equivalence#History for further information).

Part of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since formula_13 is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1 kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~formula_14 joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics.

Thermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another, is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as heat, and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomisation in a crystal).

As the universe evolves in time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or other kinds of increases in disorder). This has been referred to as the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), grows less and less.

The fact that energy can be neither created nor be destroyed is called the law of conservation of energy. In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out by work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.

While heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.

Richard Feynman said during a 1961 lecture:
Most kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.

This law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle - it is impossible to define the exact amount of energy during any definite time interval. The uncertainty principle should not be confused with energy conservation - rather it provides mathematical limits to which energy can in principle be defined and measured.

Each of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appears as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.

In quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by

which is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since "H" and "t" are not dynamically conjugate variables, neither in classical nor in quantum mechanics).

In particle physics, this inequality permits a qualitative understanding of virtual particles which carry momentum, exchange by which and with real particles, is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons (which are simply lowest quantum mechanical energy state of photons) are also responsible for electrostatic interaction between electric charges (which results in Coulomb law), for spontaneous radiative decay of exited atomic and nuclear states, for the Casimir force, for van der Waals bond forces and some other observable phenomena.

Energy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, and the conductive transfer of thermal energy.

Energy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:

where formula_16 is the amount of energy transferred, formula_2  represents the work done on the system, and formula_18 represents the heat flow into the system. As a simplification, the heat term, formula_18, is sometimes ignored, especially when the thermal efficiency of the transfer is high.

This simplified equation is the one used to define the joule, for example.

Beyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (both of these process are illustrated by fueling an auto, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by formula_16, one may write

Internal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.

The first law of thermodynamics asserts that energy (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a "gain" in energy signified by a positive quantity) is given as

where the first term on the right is the heat transferred into the system, expressed in terms of temperature "T" and entropy "S" (in which entropy increases and the change d"S" is positive when the system is heated), and the last term on the right hand side is identified as work done on the system, where pressure is "P" and volume "V" (the negative sign results since compression of the system requires work to be done on it and so the volume change, d"V", is negative when work is done on the system).

This equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and pV-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a "closed" system is expressed in a general form by

where formula_23 is the heat supplied to the system and formula_24 is the work applied to the system.

The energy of a mechanical harmonic oscillator (a mass on a spring) is alternatively kinetic and potential energy. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over the whole cycle, or over many cycles, net energy is thus equally split between kinetic and potential. This is called equipartition principle; total energy of a system with many degrees of freedom is equally split among all available degrees of freedom.

This principle is vitally important to understanding the behaviour of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between "new" and "old" degrees. This mathematical result is called the second law of thermodynamics. The second law of thermodynamics is valid only for systems which are near or in equilibrium state. For non-equilibrium systems, the laws governing system's behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way to maximize its entropy production.




</doc>
<doc id="47353" url="https://en.wikipedia.org/wiki?curid=47353" title="Object (philosophy)">
Object (philosophy)

An object is a philosophy term often used in contrast to the term "subject". A subject is an observer and an object is a thing observed. For modern philosophers like Descartes, consciousness is a state of cognition that includes the subject—which can never be doubted as only it can be the one who doubts—and some object(s) that may be considered as not having real or full existence or value independent of the subject who observes it. Metaphysical frameworks also differ in whether they consider objects existing independently of their properties and, if so, in what way.

The pragmatist Charles S. Peirce defines the broad notion of an object as anything that we can think or talk about. In a general sense it is any entity: the pyramids, Alpha Centauri, the number seven, a disbelief in predestination or the fear of cats. In a strict sense it refers to any definite being.

A related notion is objecthood. Objecthood is the state of being an object. One approach to defining it is in terms of objects' properties and relations. Descriptions of all bodies, minds, and persons must be in terms of their properties and relations. The philosophical question of the nature of objecthood concerns how objects are related to their properties and relations. For example, it seems that the only way to describe an apple is by describing its properties and how it is related to other things. Its properties may include its redness, its size, and its composition, while its relations may include "on the table", "in the room" and "being bigger than other apples".

The notion of an object must address two problems: the change problems and the problems of substances. Two leading theories about objecthood are substance theory, wherein substances (objects) are distinct from their properties, and bundle theory, wherein objects are no more than bundles of their properties.

An attribute of an object is called a property if it can be experienced (e.g. its color, size, weight, smell, taste, and location). Objects manifest themselves through their properties. These manifestations seem to change in a regular and unified way, suggesting that something underlies the properties. The change problem asks what that underlying thing is. According to substance theory, the answer is a substance, that which stands for the change.

Because substances are only experienced through their properties a substance itself is never directly experienced. The problem of substance asks on what basis can one conclude the existence of a substance that cannot be seen or scientifically verified. According to bundle theory, the answer is none; thus an object is merely its properties.

In the "Mūlamadhyamakakārikā" Nagarjuna seizes the dichotomy between objects as collections of properties or as separate from those properties to demonstrate that both assertions fall apart under analysis. By uncovering this paradox he then provides a solution ("pratītyasamutpāda" – "dependent origination") that lies at the very root of Buddhist praxis.

Although "pratītyasamutpāda" is normally limited to caused objects, Nagarjuna extends his argument to objects in general by differentiating two distinct ideas – dependent designation and dependent origination. He proposes that all objects are dependent upon designation, and therefore any discussion regarding the nature of objects can only be made in light of the context. The validity of objects can only be established within those conventions that assert them.

In English the word "object" is derived from the Latin "objectus" (pp. of "obicere") with the meaning "to throw, or put before or against", from "ob"-(pref.) and "jacere", "to throw". As such it is a root for several important words used to derive meaning, such as objectify (to materialize), objective (a future reference), and objectivism (a philosophical doctrine that knowledge is based on objective reality).

Bertrand Russell updated the classical terminology with one more term, the "fact"; "Everything that there is in the world I call a fact." Facts, objects, are opposed to beliefs, which are "subjective" and may be errors on the part of the subject, the knower who is their source and who is certain of himself and little else. All doubt implies the possibility of error and therefore admits the distinction between subjectivity and objectivity. The knower is limited in ability to tell fact from belief, false from true objects and engages in reality testing, an activity that will result in more or less certainty regarding the reality of the object. According to Russell, "we need a description of the fact which would make a given belief true" where "Truth is a property of beliefs." Knowledge is "true beliefs". This framework of presumptions is termed the Theory of the Real.

Until the true-false distinction can be made, every object must be viewed as possibly true, a quasi-object. This extends even to those "objects" that are known to be "subjective"; individuals may determine to create a logical or rational entity that they treat as if real, a corporation, a fund, a population of elves, etc. These are typically the subjects of cultural anthropology.

Value theory concerns the value of objects. When it concerns economic value, it generally deals with physical objects. However, when concerning philosophic or ethic value, an object may be both a physical object and an abstract object (e.g. an action).

Limiting discussions of objecthood to the realm of physical objects may simplify them. However, defining physical objects in terms of fundamental particles (e.g. quarks) leaves open the question of what is the nature of a fundamental particle and thus asks what categories of being can be used to explain physical objects.

Symbols represent objects; how they do so, the map-territory relation, is the basic problem of semantics.




</doc>
<doc id="59414446" url="https://en.wikipedia.org/wiki?curid=59414446" title="Hole">
Hole

A hole is an opening, usually circular, in or through a particular medium, usually a solid body. Holes occur through natural and artificial processes, and may be useful for various purposes, or may represent a problem needing to be addressed in many fields of engineering. Depending on the material and the placement, a hole may be an indentation in a surface (such as a hole in the ground), or may pass completely through that surface (such as a hole created by a hole puncher in a piece of paper). In engineering, a hole may be blind or through if it is partial or complete depth.

Holes can occur for a number of reasons, including natural processes and intentional actions by humans or animals. Holes in the ground that are made intentionally, such as holes made while searching for food, for replanting trees, or postholes made for securing an object, are usually made through the process of digging. Unintentional holes in an object are often a sign of damage. Potholes and sinkholes can damage human settlements.

Holes can occur in a wide variety of materials, and at a wide range of scales. The smallest holes observable by humans include pinholes and perforations, but the smallest phenomenon described as a hole is an electron hole, which is a position in an atom or atomic lattice where an electron is missing. The largest phenomenon described as a hole is a supermassive black hole, an astronomical object which can be billions of times more massive than Earth's sun.

In mathematics, holes are examined in a number of ways. One of these is in homology, which is a general way of associating certain algebraic objects to other mathematical objects such as topological spaces. Homology groups were originally defined in algebraic topology, and homology was originally a rigorous mathematical method for defining and categorizing holes in a mathematical object called a manifold. The initial motivation for defining homology groups was the observation that two shapes can be distinguished by examining their holes. For instance, a circle is not a disk because the circle has a hole through it while the disk is solid, and the ordinary sphere is not a circle because the sphere encloses a two-dimensional hole while the circle encloses a one-dimensional hole. However, because a hole is "not there", it is not immediately obvious how to define a hole or how to distinguish different types of hole.

In geometric topology, however, holes are determined differently. In this field, the genus of a connected, orientable surface is an integer representing the maximum number of cuttings along non-intersecting closed simple curves without rendering the resultant manifold disconnected. In layman's terms, it is the number of "holes" an object has ("holes" interpreted in the sense of doughnut holes; a hollow sphere would be considered as having zero holes in this sense). A doughnut, or torus, has 1 such hole. A sphere has 0.

In physics, antimatter is pervasively described as a hole, a location that, when brought together with ordinary matter to fill the hole, results in both the hole and the matter cancelling each-other out. This is analogous to patching a pothole with asphalt, or filling a bubble below the surface of water with an equal amount of water to cancel it out. The most direct example is the electron hole; a fairly general theoretical description is provided by the Dirac sea, which treats positrons (or anti-particles in general) as holes. Holes provide one of the two primary forms of conduction in a semi-conductor, that is, the material from which transistors are made; without holes, current could not flow, and transistors turn on and off by enabling or disabling the creation of holes.

Animal bodies tend to contain specialized holes which serve various biological functions, such as the intake of oxygen or food, the excretion of waste, and the intake or expulsion of other fluids for reproductive purposes. In some simple animals, however, there is a single hole that serves all of these purposes. The formation of holes is a significant event in the development of an animal:

In engineering, machining, and tooling, a hole may be a blind hole or a through hole (also called a thru-hole or clearance hole). A blind hole is a hole that is reamed, drilled, or milled to a specified depth without breaking through to the other side of the workpiece. A through hole is a hole that is made to go completely through the material of an object. In other words, a through hole is a hole that goes all the way through something. Taps used for through holes are generally tapered since it will tap faster and the chips will be released when the tap exits the hole.

The etymology of the "blind" hole is that it is not possible to see through it. It may also refer to any feature that is taken to a specific depth, more specifically referring to internally threaded hole (tapped holes). Not considering the drill point, the depth of the blind hole, conventionally, may be slightly deeper than that of the threaded depth.

There are three accepted methods of threading blind holes:

At least two U.S. tool manufacturers have manufactured tools for thread milling in blind holes: Ingersoll Cutting Tools of Rockford, Illinois, and Tooling Systems of Houston, Texas, who introduced the Thread Mill in 1977, a device that milled large internal threads in the blind holes of oil well blowout preventers. Today many CNC milling machines can run such a thread milling cycle (see a video of such a cut in the "External links" section).

One use of through holes in electronics is with through-hole technology, a mounting scheme involving the use of leads on the components that are inserted into holes drilled in printed circuit boards (PCB) and soldered to pads on the opposite side either by manual assembly (hand placement) or by the use of automated insertion mount machines.

A pinhole is a small hole, usually made by pressing a thin, pointed object such as a pin through an easily penetrated material such as a fabric or a very thin layer of metal. Similar holes made by other means are also often called pinholes. Pinholes may be intentionally made for various reasons. For example, in optics pinholes are used as apertures to select certain rays of light. This is used in pinhole cameras to form an image without the use of a lens. Pinholes on produce packaging have been used to control the atmosphere and relative humidity within the packaging.

In many fields, however, pinholes are a harmful and unwanted side-effect of manufacturing processes. For example, in the assembly of microcircuits, pinholes in the dielectric insulator layer coating the circuit can cause the circuit to fail. Therefore, "[t]o avoid pinholes that might protrude through the entire thickness of the dielectric layer, it is a common practice to screen several layers of dielectric with drying and firing after each screening", thereby preventing the pinholes from becoming continuous.

It has been noted that holes occupy an unusual ontological position in human psychology, as people tend to refer to them as tangible and countable objects, when in fact they are the absence of something in another object. An example of this reasoning can be found in the Beatles lyric from the song, "A Day in the Life", from their 1967 album "Sgt. Pepper's Lonely Hearts Club Band":

The reference to 4,000 holes was written by John Lennon, and inspired by a "Far & Near" news brief from the same 17 January edition of the "Daily Mail", which had also provided inspiration for previous verses of the song. Under the headline "The holes in our roads", the brief stated: "There are 4,000 holes in the road in Blackburn, Lancashire, or one twenty-sixth of a hole per person, according to a council survey. If Blackburn is typical, there are two million holes in Britain's roads and 300,000 in London". Holes have also been described as "ontologically parasitic" because they can only exist as aspects of another object. The psychological concept of a hole as a physical object is taken to its logical extreme in the fictional concept of a portable hole, exemplified in role playing games and characterized as a "hole" that a person can carry with them, keep things in, and enter themselves as needed.

Some people have an aversion to the sight of irregular patterns or clusters of small holes, a condition called trypophobia. Researchers hypothesize that this is the result of a biological revulsion that associates trypophobic shapes with danger or disease, and may therefore have an evolutionary basis.

Holes can also be referenced metaphorically as existing in non-tangible things. For example, a person who provides an account of an event that lacks important details can be said to have "holes in their story", and a fictional work with unexplained narrative elements can be said to have plot holes. A person who has suffered loss is often referred to as having a "hole in their heart". The concept of a "God-shaped hole" occurs in religious discourse:



</doc>
<doc id="105070" url="https://en.wikipedia.org/wiki?curid=105070" title="Organization">
Organization

An organization or organisation is an entity comprising multiple people, such as an institution or an association, that has a particular purpose.

The word is derived from the Greek word "organon", which means tool or instrument, musical instrument, and organ.

There are a variety of legal types of organisations, including corporations, governments, non-governmental organisations, political organisations, international organisations, armed forces, charities, not-for-profit corporations, partnerships, cooperatives, and educational institutions.

A hybrid organization is a body that operates in both the public sector and the private sector simultaneously, fulfilling public duties and developing commercial market activities.

A voluntary association is an organisation consisting of volunteers. Such organisations may be able to operate without legal formalities, depending on jurisdiction, including informal clubs or coordinating bodies with a goal in mind which they may express in the form of an Manifesto, Mission statement,or in an informal manner reflected in what they do because remember every action done by an organization both legal and illegal reflects a goal in mind.

Organisations may also operate secretly or illegally in the case of secret societies, criminal organisations and resistance movements. And in some cases may have obstacles from other organizations (ex: MLK's organization) but what makes an organization an organization is not the paperwork that makes it official but to be an organization there must be four things:


But what makes an organization recognized by the government is either filling out Incorporation (business) or recognition in the form of either societal pressure (ex: Advocacy group), causing concerns (ex: Resistance movement) or being considered the spokesperson of a group of people subject to negotiation (ex: the Polisario Front being recognized as the sole representative of the Sahawri people and forming a partially recognized state.)

Compare the concept of social groups, which may include non-organizations.

The study of organisations includes a focus on optimising organisational structure. According to management science, most human organisations fall roughly into four types:

These consist of a group of peers who decide as a group, perhaps by voting. The difference between a jury and a committee is that the members of the committee are usually assigned to perform or lead further actions after the group comes to a decision, whereas members of a jury come to a decision. In common law countries, legal juries render decisions of guilt, liability and quantify damages; juries are also used in athletic contests, book awards and similar activities. Sometimes a selection committee functions like a jury. In the Middle Ages, juries in continental Europe were used to determine the law according to consensus among local notables.

Committees are often the most reliable way to make decisions. Condorcet's jury theorem proved that if the average member votes better than a roll of dice, then adding more members increases the number of majorities that can come to a correct vote (however correctness is defined). The problem is that if the average member is subsequently "worse" than a roll of dice, the committee's decisions grow worse, not better; therefore, staffing is crucial.

Parliamentary procedure, such as Robert's Rules of Order, helps prevent committees from engaging in lengthy discussions without reaching decisions.

This organisational structure promotes internal competition. Inefficient components of the organisation starve, while effective ones get more work. Everybody is paid for what they actually do, and so runs a tiny business that has to show a profit, or they are fired.

Companies who utilise this organisation type reflect a rather one-sided view of what goes on in ecology. It is also the case that a natural ecosystem has a natural border - ecoregions do not, in general, compete with one another in any way, but are very autonomous.

The pharmaceutical company GlaxoSmithKline talks about functioning as this type of organisation in this external article from "The Guardian".
By:Bastian Batac De Leon.

This organisational type assigns each worker two bosses in two different hierarchies. One hierarchy is "functional" and assures that each type of expert in the organisation is well-trained, and measured by a boss who is super-expert in the same field. The other direction is "executive" and tries to get projects completed using the experts. Projects might be organised by products, regions, customer types, or some other schemes.

As an example, a company might have an individual with overall responsibility for products X and Y, and another individual with overall responsibility for engineering, quality control, etc. Therefore, subordinates responsible for quality control of project X will have two reporting lines.

A hierarchy exemplifies an arrangement with a leader who leads other individual members of the organisation. This arrangement is often associated with basis that there are enough imagine a real pyramid, if there are not enough stone blocks to hold up the higher ones, gravity would irrevocably bring down the monumental structure. So one can imagine that if the leader does not have the support of his subordinates, the entire structure will collapse. Hierarchies were satirised in "The Peter Principle" (1969), a book that introduced "hierarchiology" and the saying that "in a hierarchy every employee tends to rise to his level of incompetence."

In the social sciences, organisations are the object of analysis for a number of disciplines, such as sociology, economics, political science, psychology, management, and organisational communication. The broader analysis of organisations is commonly referred to as organisational structure, organisational studies, organisational behaviour, or organisation analysis. A number of different perspectives exist, some of which are compatible:

Sociology can be defined as the science of the institutions of modernity; specific institutions serve a function, akin to the individual organs of a coherent body. In the social and political sciences in general, an "organisation" may be more loosely understood as the planned, coordinated and purposeful action of human beings working through collective action to reach a common goal or construct a tangible product. This action is usually framed by formal membership and form (institutional rules). Sociology distinguishes the term organisation into planned formal and unplanned informal (i.e. spontaneously formed) organisations. Sociology analyses organisations in the first line from an institutional perspective. In this sense, organisation is an enduring arrangement of elements. These elements and their actions are determined by rules so that a certain task can be fulfilled through a system of coordinated division of labour.

Economic approaches to organisations also take the division of labour as a starting point. The division of labour allows for (economies of) specialisation. Increasing specialisation necessitates coordination. From an economic point of view, markets and organisations are alternative coordination mechanisms for the execution of transactions.

An organisation is defined by the elements that are part of it (who belongs to the organisation and who does not?), its communication (which elements communicate and how do they communicate?), its autonomy (which changes are executed autonomously by the organisation or its elements?), and its rules of action compared to outside events (what causes an organisation to act as a collective actor?).

By coordinated and planned cooperation of the elements, the organisation is able to solve tasks that lie beyond the abilities of the single elements. The price paid by the elements is the limitation of the degrees of freedom of the elements. Advantages of organisations are enhancement (more of the same), addition (combination of different features) and extension. Disadvantages can be inertness (through co-ordination) and loss of interaction.

Among the theories that are or have been influential are:


A leader in a formal, hierarchical organisation, is appointed to a managerial position and has the right to command and enforce obedience by virtue of the authority of his position. However, he must possess adequate personal attributes to match his authority, because authority is only potentially available to him. In the absence of sufficient personal competence, a manager may be confronted by an emergent leader who can challenge his role in the organisation and reduce it to that of a figurehead. However, only authority of position has the backing of formal sanctions. It follows that whoever wields personal influence and power can legitimise this only by gaining a formal position in the hierarchy, with commensurate authority.

An organisation that is established as a means for achieving defined objectives has been referred to as a formal organisation. Its design specifies how goals are subdivided and reflected in subdivisions of the organisation. Divisions, departments, sections, positions, jobs, and tasks make up this work structure. Thus, the formal organisation is expected to behave impersonally in regard to relationships with clients or with its members. According to Weber's definition, entry and subsequent advancement is by merit or seniority. Each employee receives a salary and enjoys a degree of tenure that safeguards him from the arbitrary influence of superiors or of powerful clients. The higher his position in the hierarchy, the greater his presumed expertise in adjudicating problems that may arise in the course of the work carried out at lower levels of the organisation. It is this bureaucratic structure that forms the basis for the appointment of heads or chiefs of administrative subdivisions in the organisation and endows them with the authority attached to their position.

In contrast to the appointed head or chief of an administrative unit, a leader emerges within the context of the informal organisation that underlies the formal structure. The informal organisation expresses the personal objectives and goals of the individual membership. Their objectives and goals may or may not coincide with those of the formal organisation. The informal organisation represents an extension of the social structures that generally characterise human life – the spontaneous emergence of groups and organisations as ends in themselves.

In prehistoric times, man was preoccupied with his personal security, maintenance, protection, and survival. Now man spends a major portion of his waking hours working for organisations. His need to identify with a community that provides security, protection, maintenance, and a feeling of belonging continues unchanged from prehistoric times. This need is met by the informal organisation and its emergent, or unofficial, leaders.

Leaders emerge from within the structure of the informal organisation. Their personal qualities, the demands of the situation, or a combination of these and other factors attract followers who accept their leadership within one or several overlay structures. Instead of the authority of position held by an appointed head or chief, the emergent leader wields influence or power. Influence is the ability of a person to gain cooperation from others by means of persuasion or control over rewards. Power is a stronger form of influence because it reflects a person's ability to enforce action through the control of a means of punishment.





</doc>
<doc id="3488351" url="https://en.wikipedia.org/wiki?curid=3488351" title="People">
People

A people is a plurality of persons considered as a whole, as is the case with an ethnic group or nation.

Various states govern or claim to govern in the name of "the people". Both the Roman Republic and the Roman Empire used the Latin term "Senatus Populusque Romanus", (the Senate and People of Rome). This term was fixed abbreviated (SPQR) to Roman legionary standards, and even after the Roman Emperors achieved a state of total personal autarchy, they continued to wield their power in the name of the Senate and People of Rome.

A People's Republic is typically a Marxist or socialist one-party state that claims to govern on behalf of the people even if it in practice often turns out to be a dictatorship. Populism is another umbrella term for various political tendencies that claim to represent the people, usually with an implication that they serve the "common people" instead of the elite.

Chapter One, Article One of the Charter of the United Nations states that peoples have the right to self-determination.

In criminal law, in certain jurisdictions, criminal prosecutions are brought in the name of "the People". Several U.S. states, including California, Illinois, and New York, use this style. Citations outside the jurisdictions in question usually substitute the name of the state for the words "the People" in the case captions. Four states — Massachusetts, Virginia, Pennsylvania, and Kentucky — refer to themselves as "the Commonwealth" in case captions and legal process. Other states, such as Indiana, typically refer to themselves as "the State" in case captions and legal process.

Outside the United States, criminal trials in Ireland and the Philippines are prosecuted in the name of the people of their respective states.

The political theory underlying this format is that criminal prosecutions are brought in the name of the sovereign; thus, in these U.S. states, the "people" are judged to be the sovereign, even as in the United Kingdom and other dependencies of the British Crown, criminal prosecutions are typically brought in the name of the Crown. "The people" identifies the entire body of the citizens of a jurisdiction invested with political power or gathered for political purposes.



</doc>
<doc id="219599" url="https://en.wikipedia.org/wiki?curid=219599" title="Person">
Person

A person (plural people or persons) is a being that has certain capacities or attributes such as reason, morality, consciousness or self-consciousness, and being a part of a culturally established form of social relations such as kinship, ownership of property, or legal responsibility. The defining features of personhood and consequently what makes a person count as a person differ widely among cultures and contexts.

In addition to the question of personhood, of what makes a being count as a person to begin with, there are further questions about personal identity and self: both about what makes any particular person that particular person instead of another, and about what makes a person at one time the same person as they were or will be at another time despite any intervening changes.

The plural form "people", is often used to refer to an entire nation or ethnic group (as in "a people"). The plural form "persons" is often used in philosophical and legal writing.

Personhood is the status of being a person. Defining personhood is a controversial topic in philosophy and law, and is closely tied to legal and political concepts of citizenship, equality, and liberty. According to common worldwide general legal practice, only a natural person or legal personality has rights, protections, privileges, responsibilities, and legal liability.
Personhood continues to be a topic of international debate, and has been questioned during the abolition of slavery and the fight for women's rights, in debates about abortion, fetal rights, and in animal rights advocacy.

Various debates have focused on questions about the personhood of different classes of entities. Historically, the personhood of animals, women, and slaves has been a catalyst of social upheaval. In most societies today, living adult humans are usually considered persons, but depending on the context, theory or definition, the category of "person" may be taken to include or not children or such non-human entities as animals, artificial intelligences, or extraterrestrial life, as well as legal entities such as corporations, sovereign states and other polities, or estates in probate.

Personal identity is the unique identity of persons through time. That is to say, the necessary and sufficient conditions under which a person at one time and a person at another time can be said to be the "same" person, persisting through time. In the modern philosophy of mind, this concept of personal identity is sometimes referred to as the "diachronic" problem of personal identity. The "synchronic" problem is grounded in the question of what features or traits characterize a given person at one time.

Identity is an issue for both continental philosophy and analytic philosophy. A key question in continental philosophy is in what sense we can maintain the modern conception of identity, while realizing many of our prior assumptions about the world are incorrect.

Proposed solutions to the problem of personal identity include continuity of the physical body, continuity of an immaterial mind or soul, continuity of consciousness or memory, the bundle theory of self, continuity of personality after the death of the physical body, and proposals that there are actually no persons or selves who persist over time at all.

In ancient Rome, the word "persona" (Latin) or "prosopon" (πρόσωπον; Greek) originally referred to the masks worn by actors on stage. The various masks represented the various "personae" in the stage play.

The concept of person was further developed during the Trinitarian and Christological debates of the 4th and 5th centuries in contrast to the word nature. During the theological debates, some philosophical tools (concepts) were needed so that the debates could be held on common basis to all theological schools. The purpose of the debate was to establish the relation, similarities and differences between the /"Verbum" and God. The philosophical concept of person arose, taking the word "prosopon" () from the Greek theatre. Therefore, Christus (the /"Verbum") and God were defined as different "persons". This concept was applied later to the Holy Ghost, the angels and to all human beings.

Since then, a number of important changes to the word's meaning and use have taken place, and attempts have been made to redefine the word with varying degrees of adoption and influence. According to Noller, at least six approaches can be distinguished:
"(1) The ontological definition of the person as “an individual substance of a rational nature” (Boethius). (2) The self-consciousness-based definition of the person as a being that “can conceive itself as itself” (John Locke). (3) The moral-philosophical definition of the person as “an end in itself” (Immanuel Kant). In current analytical debate, the focus has shifted to the relationship between bodily organism and person. [4.] The theory of animalism (Eric T. Olson) states that persons are essentially animals and that mental or psychological attributes play no role in their identity. [5.] Constitution theory (Lynne Baker), on the other hand, attempts to define the person as a natural and at the same time self-conscious being: the bodily organism constitutes the person without being identical to it. Rather, it forms with it a “unity without identity”. [6.] [... Another idea] for conceiving the natural-rational unity of the person has emerged recently in the concept of the “person life” (Marya Schechtman)."




</doc>
<doc id="1742287" url="https://en.wikipedia.org/wiki?curid=1742287" title="Risk society">
Risk society

Risk society is the manner in which modern society organizes in response to risk. The term is closely associated with several key writers on modernity, in particular Ulrich Beck and Anthony Giddens. The term was coined in the 1980s and its popularity during the 1990s was both as a consequence of its links to trends in thinking about wider modernity, and also to its links to popular discourse, in particular the growing environmental concerns during the period.

According to British sociologist Anthony Giddens, a risk society is "a society increasingly preoccupied with the future (and also with safety), which generates the notion of risk," whilst the German sociologist Ulrich Beck defines it as "a systematic way of dealing with hazards and insecurities induced and introduced by modernisation itself (Beck 1992:21)".

Beck (1992:50) defined modernization as,

Beck and Giddens both approach the risk society firmly from the perspective of modernity, "a shorthand term for modern society or industrial civilization... modernity is vastly more dynamic than any previous type of social order. It is a society... which unlike any preceding culture lives in the future rather than the past." (Anthony Giddens) They also draw heavily on the concept of reflexivity, the idea that as a society examines itself, it in turn changes itself in the process. In classical industrial society, the modernist view is based on assumption of realism in science creating a system in which scientists work in an exclusive, inaccessible environment of modern period.

In 1986, right after the Chernobyl disaster, Ulrich Beck, a sociology professor at the University of Munich, published the original German text, "Risikogesellschaft", of his highly influential and catalytic work (Suhrkamp, Frankfurt 1986). "Risikogesellschaft" was published in English as "Risk Society: Towards a New Modernity" in 1992. The ecological crisis is central to this social analysis of the contemporary period. Beck argued that environmental risks had become the predominant product, not just an unpleasant, manageable side-effect, of industrial society.

Giddens and Beck argued that whilst humans have always been subjected to a level of risk – such as natural disasters – these have usually been perceived as produced by non-human forces. Modern societies, however, are exposed to risks such as pollution, newly discovered illnesses, crime, that are the result of the modernization process itself. Giddens defines these two types of risks as external risks and manufactured risks. Manufactured risks are marked by a high level of human agency involved in both producing, and mitigating such risks.

As manufactured risks are the product of human activity, authors like Giddens and Beck argue that it is possible for societies to assess the level of risk that is being produced, or that is about to be produced. This sort of reflexive introspection can in turn alter the planned activities themselves. As an example, disasters such as Chernobyl and the Love Canal Crisis, public faith in the modern project has declined leaving public distrust in industry, government and experts.

Social concerns led to increased regulation of the nuclear power industry and to the abandonment of some expansion plans, altering the course of modernization itself. This increased critique of modern industrial practices is said to have resulted in a state of reflexive modernization, illustrated by concepts such as sustainability and the precautionary principle that focus on preventive measures to decrease levels of risk.

There are differing opinions as to how the concept of a risk society interacts with social hierarchies and class distinctions. Most agree that social relations have altered with the introduction of manufactured risks and reflexive modernization. Risks, much like wealth, are distributed unevenly in a population and will influence quality of life.

Beck has argued that older forms of class structure – based mainly on the accumulation of wealth – atrophy in a modern, risk society, in which people occupy social risk positions that are achieved through risk aversion. "In some of their dimensions these follow the inequalities of class and strata positions, but they bring a fundamentally different distribution logic into play". Beck contends that widespread risks contain a 'boomerang effect', in that individuals producing risks will also be exposed to them. This argument suggests that wealthy individuals whose capital is largely responsible for creating pollution will also have to suffer when, for example, the contaminants seep into the water supply. This argument may seem oversimplified, as wealthy people may have the ability to mitigate risk more easily by, for example, buying bottled water. Beck, however, has argued that the distribution of this sort of risk is the result of knowledge, rather than wealth. Whilst the wealthy person may have access to resources that enable him or her to avert risk, this would not even be an option were the person unaware that the risk even existed. However, Risks do not only affect those of a certain social class or place, risk is not bias and can affect everybody no matter your class, nobody is free from risk.

By contrast, Giddens has argued that older forms of class structure maintain a somewhat stronger role in a risk society, now being partly defined "in terms of differential access to forms of self-actualization and empowerment". Giddens has also tended to approach the concept of a risk society more positively than Beck, suggesting that there "can be no question of merely taking a negative attitude towards risk. Risk needs to be disciplined, but active risk-taking is a core element of a dynamic economy and an innovative society."




</doc>
<doc id="34407451" url="https://en.wikipedia.org/wiki?curid=34407451" title="Parallel society">
Parallel society

Parallel society refers to the self-organization of an ethnic or religious minority, often but not always immigrant groups, with the intent of a reduced or minimal spatial, social and cultural contact with the majority society into which they immigrate.

The term was introduced into the debate about migration and integration in the early 1990s by the German sociologist Wilhelm Heitmeyer. It rose to prominence in the European public discourse following the murder of Dutch director and critic of Islam Theo van Gogh. In 2004, it was elected by the Association for the German Language second as Word of the year.



</doc>
<doc id="36055387" url="https://en.wikipedia.org/wiki?curid=36055387" title="Planetary consciousness">
Planetary consciousness

Planetary consciousness is the idea that human beings are members of a planetary society of Earth as much as they are members of their nations, provinces, districts, islands, cities or villages.

In his 1906 book "American Character", author Brander Matthews mentions the idea of a "league of nations" and a "planetary consciousness", believing it would be created by American politicians in the coming centuries. Key planetary consciousness events of the 20th century include the creation of the League of Nations, the signing of Kellogg-Briand Pact, the creation of the United Nations, and the creation of the Bretton Woods system. Democratic globalization advocate Abhay Kumar points to the International Corporation of Assigned Names and Numbers (ICANN) board of directors election in 2000, which were conducted globally, as the first example of global democracy. In September 2001, Ervin László and the Dalai Lama wrote an essay titled "Manifesto on Planetary Consciousness", which was adopted at a meeting at the Hungarian Academy of Sciences in Budapest. Its introduction begins:

Andreas Bummel, CEO of the Committee for a Democratic UN, says, "The first step into the direction of a world parliament would be the establishment of a Parliamentary Assembly at the United Nations".

Advocacy for the idea of planetary consciousness is based on the technological advancements made by the mankind in the fields of transport and telecommunications during the 20th century and in the first decade of the 21st century. Kumar claims that these technological advancements have turned the whole planet into an interdependent economic, political and communication community. He specifically cites the invention of the Internet and the mobile phones as key technological achievements of the 20th century which brought humans into more continuous interconnected communication. He believes that these inventions will lead to a second Renaissance and global democracy, just as the Gutenberg press in 1439 led to the first Renaissance, the Age of Enlightenment, and Nation states. Bummel describes planetary consciousness as integral, insofar as it does not conflict with other levels of social identity, but instead is a holistic perspective on humanity and the planet as a whole. Steven Kull writes that while nation states are reluctant to work cooperatively, individuals seem more willing.

Author Shashi Tharoor argues that an Earth Anthem sung by people across the world can inspire planetary consciousness and global citizenship among people.



</doc>
<doc id="14131017" url="https://en.wikipedia.org/wiki?curid=14131017" title="Contemporary society">
Contemporary society

Contemporary society, according to social and political scientists, is characterised by at least three fundamental directions:
These are some examples, but they are many more.

These presentations are the result of a number of fundamental changes that are irreversibly transforming our daily lives, our way of thinking and perceiving the world and our way of living together. Among these fundamental changes are: improvements in life conditions, life expectancy, literacy and gender equality; changes in domestic and international political institutions; and the breakdown of natural equilibria.

The UN estimates that, at the beginning of the 20th century, about 60% of the world population lived in conditions of extreme poverty. In 1981, 40% of the world population lived extreme poverty. In 2001, the percentage had been halved to 20%.
Several developing countries, in particular in Sub-Saharan Africa, still suffer from social and economic backwardness, but life conditions have significantly improved in most regions of the world, in particular in Asia. 
The overall improvement in life conditions and the role of technologies now available have contributed to increase gross domestic product per capita by one and a half times in less than half a century (1960–2005), with peaks of over eight times in Eastern Asia. Only in a few countries, concentrated in Sub-Saharan Africa, growth of per capita income has been very slow.

In 1960, the average life expectancy of the world population was 50 years. Forty-five years later, in 2004, life expectancy had improved by over 30% to 67 years. Improvements in health care and the reduction in child mortality have led to a jump forward in middle-income countries, where life expectancy is now over 70 years. In high-income countries life expectancy is now over 80 years, extending well beyond the traditional length of working life, causing social and economic problems. It has led to people having an extra 4 hours of free-time during working days.

The ability to read and write is next to universal: in 2004, 80% of adult men and 73% of adult women had basic literacy skills. Of great social importance is the rapid growth of female school enrolment and the increasing presence of women in the labour market. These deep changes constitute a primary driver of economic growth in developing countries.
Female literacy has great consequences in terms of fertility. When female school enrollment and employment rates increase, fertility rates decline rapidly and tend to stabilise around the natural rate of reproduction of 2.1 children per women (see E. Todd, "After the Empire"). Several demographers believe that, as a consequence, world population will stabilise over the next few decades, at a level compatible with the resources of the planet [reference].

The world population has a number of "passive" (broadcasting) communication technologies (radio, television) that cover the whole globe. Moreover, a large portion of the population uses "active" communication technologies (telephone, internet). Internet connections are expanding rapidly: in 2004 there were 140 Internet users every 1000 inhabitants (according to data from the "International Communication Union"). The spread of information and communication technologies (ICT) is remodelling the material fundamentals of society. The sociologist Castells believes that these technologies have started a revolution of the productive structures of society and of daily life.

The new communication technologies represent a critical instrument to obtain consensus and as a result they are transforming the organisational models of the State and of politics. The power system becomes less visible but more pervasive in the way it can influence choices and ways of thinking M. Castells, "Galassia Internet", Feltrinelli, 2002).

The economic success of authoritarian regimes, mainly in Asia, suggests that (at least in the short term) economic growth is independent from the democratisation of political institutions. However, economic development favours the development of democratic institutions—but only if economic growth leads to substantial changes in cultural and social structures. (R. Inglehart, "La società postmoderna").
The "World Values Survey", which captures political values in 43 countries, shows that no country with a per capita income below the poverty line has democratic or free institutions. Almost the totality of nations with high per capita income are classified as democratic.

Over the last fifty years, world gross domestic product has increased by about five times, while trade has increased tenfold over the same period. These data suggests that the intensity of the commercial exchange between countries has developed faster than the overall economy. However, globalisation has gone beyond the exchange of physical commodities and it is progressively modelling also the lifestyles and consumption patterns of individuals and societies. The Swiss think-tank KOF has developed a number of globalisation indicators that show the increasing development of global individual, social and commercial networks.

New international flows have diminished the role of traditional political institutions—sometimes with negative consequences for social stability. In many societies, stability (or slow evolution) has been substituted by unstoppable and irreversible transformations.
As a result, individuals and communities perceive a high degree of insecurity—insecurity that touches every aspect of their lives. Growing masses of people feel threatened by the changes that affect their material (work, income, house), psychological (personal relationships), and cultural life (with the need to continuously update knowledge and professional skills).

The social improvement of the masses—resulting from increasing literacy and income, universal means of communication and a new social role of women—has eroded the traditional role of the elites and have weakened the traditional regulatory role of the state.
As the speed of social and cultural evolution sweeps away old life habits, religious beliefs, ancestral moral convictions and radicated political opinions, the anxiety towards a future that is mutating and unknown causes a cultural opposition that is at the root of fundamentalism. Opposition against new life conditions is justified also by increasing economic inequality: "the gap between the wealth of the North and that of the South of the world has increased by a multiple of five since the beginning of the 20th century" ( , "Trois leçons sur la société postindustrielle").

When demographic growth is multiplied by the growth of per capita income and consumption, one can have a measure of the global impact on environmental sustainability. Demographic and economic development is endangering our current forms of civilization and social co-living and our future ability to inhabit our planet.
Alternative scenarios developed by international organizations suggest the possibility of a serious breakdown of natural equilibrium unless political, scientific and economic tools are directed to a correction towards an acceptable equilibrium between humankind and with nature.


2.[(see Contemporay History)Contemporary history]




</doc>
<doc id="37235" url="https://en.wikipedia.org/wiki?curid=37235" title="Society">
Society

A society is a group of individuals involved in persistent social interaction, or a large social group sharing the same spatial or social territory, typically subject to the same political authority and dominant cultural expectations. Societies are characterized by patterns of relationships (social relations) between individuals who share a distinctive culture and institutions; a given society may be described as the sum total of such relationships among its constituent of members. In the social sciences, a larger society often exhibits stratification or dominance patterns in subgroups.

Societies construct patterns of behavior by deeming certain actions or speech as acceptable or unacceptable. These patterns of behavior within a given society are known as societal norms. Societies, and their norms, undergo gradual and perpetual changes.

Insofar as it is collaborative, a society can enable its members to benefit in ways that would otherwise be difficult on an individual basis; both individual and social (common) benefits can thus be distinguished, or in many cases found to overlap. A society can also consist of like-minded people governed by their own norms and values within a dominant, larger society. This is sometimes referred to as a subculture, a term used extensively within criminology.

More broadly, and especially within structuralist thought, a society may be illustrated as an economic, social, industrial or cultural infrastructure, made up of, yet distinct from, a varied collection of individuals. In this regard society can mean the objective relationships people have with the material world and with other people, rather than "other people" beyond the individual and their familiar social environment.

The term "society" came from the Latin word "", which in turn was derived from the noun "socius" ("comrade, friend, ally"; adjectival form "socialis") used to describe a bond or interaction between parties that are friendly, or at least civil. Without an article, the term can refer to the entirety of humanity (also: "society in general", "society at large", etc.), although those who are unfriendly or uncivil to the remainder of society in this sense may be deemed to be "antisocial". However, the Scottish economist, Adam Smith taught instead that a society "may subsist among different men, as among different merchants, from a sense of its utility without any mutual love or affection, if only they refrain from doing injury to each other."

Used in the sense of an association, a society is a body of individuals outlined by the bounds of functional interdependence, possibly comprising characteristics such as national or cultural identity, social solidarity, language, or hierarchical structure.

Society, in general, addresses the fact that an individual has rather limited means as an autonomous unit. The great apes have always been more ("Bonobo", "Homo", "Pan") or less ("Gorilla", "Pongo") social animals, so Robinson Crusoe-like situations are either fictions or unusual corner cases to the ubiquity of social context for humans, who fall between presocial and eusocial in the spectrum of animal ethology.

Cultural relativism as a widespread approach or ethic has largely replaced notions of "primitive", better/worse, or "progress" in relation to cultures (including their material culture/technology and social organization).

According to anthropologist Maurice Godelier, one critical novelty in society, in contrast to humanity's closest biological relatives (chimpanzees and bonobos), is the parental role assumed by the males, which supposedly would be absent in our nearest relatives for whom paternity is not generally determinable.

Societies may also be structured politically. In order of increasing size and complexity, there are bands, tribes, chiefdoms, and state societies. These structures may have varying degrees of political power, depending on the cultural, geographical, and historical environments that these societies must contend with. Thus, a more isolated society with the same level of technology and culture as other societies is more likely to survive than one in close proximity to others that may encroach on their resources. A society that is unable to offer an effective response to other societies it competes with will usually be subsumed into the culture of the competing society.

Sociologist Peter L. Berger defines society as "...a human product, and nothing but a human product, that yet continuously acts upon its producers." According to him, society was created by humans, but this creation turns back and creates or molds humans every day.
Sociologist Gerhard Lenski differentiates societies based on their level of technology, communication, and economy: (1) hunters and gatherers, (2) simple agricultural, (3) advanced agricultural, (4) industrial, and (5) special (e.g. fishing societies or maritime societies). This is similar to the system earlier developed by anthropologists Morton H. Fried, a conflict theorist, and Elman Service, an integration theorist, who have produced a system of classification for societies in all human cultures based on the evolution of social inequality and the role of the state. This system of classification contains four categories:

In addition to this there are:

Over time, some cultures have progressed toward more complex forms of organization and control. This cultural evolution has a profound effect on patterns of community. Hunter-gatherer tribes settled around seasonal food stocks to become agrarian villages. Villages grew to become towns and cities. Cities turned into city-states and nation-states.

Many societies distribute largess at the behest of some individual or some larger group of people. This type of generosity can be seen in all known cultures; typically, prestige accrues to the generous individual or group. Conversely, members of a society may also shun or scapegoat any members of the society who violate its norms. Mechanisms such as gift-giving, joking relationships and scapegoating, which may be seen in various types of human groupings, tend to be institutionalized within a society. Social evolution as a phenomenon carries with it certain elements that could be detrimental to the population it serves.

Some societies bestow status on an individual or group of people when that individual or group performs an admired or desired action. This type of recognition is bestowed in the form of a name, title, manner of dress, or monetary reward. In many societies, adult male or female status is subject to a ritual or process of this type. Altruistic action in the interests of the larger group is seen in virtually all societies. The phenomena of community action, shunning, scapegoating, generosity, shared risk, and reward are common to many forms of society.

Societies are social groups that differ according to subsistence strategies, the ways that humans use technology to provide needs for themselves. Although humans have established many types of societies throughout history, anthropologists tend to classify different societies according to the degree to which different groups within a society have unequal access to advantages such as resources, prestige, or power. Virtually all societies have developed some degree of inequality among their people through the process of social stratification, the division of members of a society into levels with unequal wealth, prestige, or power. Sociologists place societies in three broad categories: pre-industrial, industrial, and postindustrial.

In a pre-industrial society, food production, which is carried out through the use of human and animal labor, is the main economic activity. These societies can be subdivided according to their level of technology and their method of producing food. These subdivisions are hunting and gathering, pastoral, horticultural, agricultural, and feudal.

The main form of food production in such societies is the daily collection of wild plants and the hunting of wild animals. Hunter-gatherers move around constantly in search of food. As a result, they do not build permanent villages or create a wide variety of artifacts, and usually only form small groups such as bands and tribes. However, some hunting and gathering societies in areas with abundant resources (such as people of tlingit) lived in larger groups and formed complex hierarchical social structures such as chiefdom. The need for mobility also limits the size of these societies. They generally consist of fewer than 60 people and rarely exceed 100. Statuses within the tribe are relatively equal, and decisions are reached through general agreement. The ties that bind the tribe are more complex than those of the bands. Leadership is personal—charismatic—and used for special purposes only in tribal society. There are no political offices containing real power, and a chief is merely a person of influence, a sort of adviser; therefore, tribal consolidations for collective action are not governmental. The family forms the main social unit, with most members being related by birth or marriage. This type of organization requires the family to carry out most social functions, including production and education.

Pastoralism is a slightly more efficient form of subsistence. Rather than searching for food on a daily basis, members of a pastoral society rely on domesticated herd animals to meet their food needs. Pastoralists live a nomadic life, moving their herds from one pasture to another. Because their food supply is far more reliable, pastoral societies can support larger populations. Since there are food surpluses, fewer people are needed to produce food. As a result, the division of labor (the specialization by individuals or groups in the performance of specific economic activities) becomes more complex. For example, some people become craftworkers, producing tools, weapons, and jewelry, among other items of value. The production of goods encourages trade. This trade helps to create inequality, as some families acquire more goods than others do. These families often gain power through their increased wealth. The passing on of property from one generation to another helps to centralize wealth and power. Over time emerge hereditary chieftainships, the typical form of government in pastoral societies.

Fruits and vegetables grown in garden plots that have been cleared from the jungle or forest provide the main source of food in a horticultural society. These societies have a level of technology and complexity similar to pastoral societies. Some horticultural groups use the slash-and-burn method to raise crops. The wild vegetation is cut and burned, and ashes are used as fertilizers. Horticulturists use human labor and simple tools to cultivate the land for one or more seasons. When the land becomes barren, horticulturists clear a new plot and leave the old plot to revert to its natural state. They may return to the original land several years later and begin the process again. By rotating their garden plots, horticulturists can stay in one area for a fairly long period of time. This allows them to build semipermanent or permanent villages. The size of a village's population depends on the amount of land available for farming; thus villages can range from as few as 30 people to as many as 2000.

As with pastoral societies, surplus food leads to a more complex division of labor. Specialized roles in horticultural societies include craftspeople, shamans (religious leaders), and traders. This role specialization allows people to create a wide variety of artifacts. As in pastoral societies, surplus food can lead to inequalities in wealth and power within horticultural political systems, developed because of the settled nature of horticultural life.

Agrarian societies use agricultural technological advances to cultivate crops over a large area. Sociologists use the phrase agricultural revolution to refer to the technological changes that occurred as long as 8,500 years ago that led to cultivating crops and raising farm animals. Increases in food supplies then led to larger populations than in earlier communities. This meant a greater surplus, which resulted in towns that became centers of trade supporting various rulers, educators, craftspeople, merchants, and religious leaders who did not have to worry about locating nourishment.

Greater degrees of social stratification appeared in agrarian societies. For example, women previously had higher social status because they shared labor more equally with men. In hunting and gathering societies, women even gathered more food than men. However, as food stores improved and women took on lesser roles in providing food for the family, they increasingly became subordinate to men. As villages and towns expanded into neighboring areas, conflicts with other communities inevitably occurred. Farmers provided warriors with food in exchange for protection against invasion by enemies. A system of rulers with high social status also appeared. This nobility organized warriors to protect the society from invasion. In this way, the nobility managed to extract goods from "lesser" members of society.

Feudalism was a form of society based on ownership of land. Unlike today's farmers, vassals under feudalism were bound to cultivating their lord's land. In exchange for military protection, the lords exploited the peasants into providing food, crops, crafts, homage, and other services to the landowner. The estates of the realm system of feudalism was often multigenerational; the families of peasants may have cultivated their lord's land for generations.

Between the 15th and 16th centuries, a new economic system emerged that began to replace feudalism. Capitalism is marked by open competition in a free market, in which the means of production are privately owned. Europe's exploration of the Americas served as one impetus for the development of capitalism. The introduction of foreign metals, silks, and spices stimulated great commercial activity in European societies.

Industrial societies rely heavily on machines powered by fuels for the production of goods. This produced further dramatic increases in efficiency. The increased efficiency of production of the industrial revolution produced an even greater surplus than before. Now the surplus was not just agricultural goods, but also manufactured goods. This larger surplus caused all of the changes discussed earlier in the domestication revolution to become even more pronounced.

Once again, the population boomed. Increased productivity made more goods available to everyone. However, inequality became even greater than before. The breakup of agricultural-based feudal societies caused many people to leave the land and seek employment in cities. This created a great surplus of labor and gave capitalists plenty of laborers who could be hired for extremely low wages.

Post-industrial societies are societies dominated by information, services, and high technology more than the production of goods. Advanced industrial societies are now seeing a shift toward an increase in service sectors over manufacturing and production. The United States is the first country to have over half of its work force employed in service industries. Service industries include government, research, education, health, sales, law, and banking.

The term "society" is currently used to cover both a number of political and scientific connotations as well as a variety of associations.

The development of the Western world has brought with it the emerging concepts of Western culture, politics, and ideas, often referred to simply as "Western society". Geographically, it covers at the very least the countries of Western Europe, North America, Australia, and New Zealand. It sometimes also includes Eastern Europe, South America, and Israel.

The cultures and lifestyles of all of these stem from Western Europe. They all enjoy relatively strong economies and stable governments, allow freedom of religion, have chosen democracy as a form of governance, favor capitalism and international trade, are heavily influenced by Judeo-Christian values, and have some form of political and military alliance or cooperation.

Although the concept of information society has been under discussion since the 1930s, in the modern world it is almost always applied to the manner in which information technologies have impacted society and culture. It therefore covers the effects of computers and telecommunications on the home, the workplace, schools, government, and various communities and organizations, as well as the emergence of new social forms in cyberspace.

One of the European Union's areas of interest is the information society. Here policies are directed towards promoting an open and competitive digital economy, research into information and communication technologies, as well as their application to improve social inclusion, public services, and quality of life.

The International Telecommunications Union's World Summit on the Information Society in Geneva and Tunis (2003 and 2005) has led to a number of policy and application areas where action is envisaged.

As access to electronic information resources increased at the beginning of the 21st century, special attention was extended from the information society to the knowledge society. An analysis by the Irish government stated, "The capacity to manipulate, store and transmit large quantities of information cheaply has increased at a staggering rate over recent years. The digitisation of information and the associated pervasiveness of the Internet are facilitating a new intensity in the application of knowledge to economic activity, to the extent that it has become the predominant factor in the creation of wealth. As much as 70 to 80 percent of economic growth is now said to be due to new and better knowledge."

People of many nations united by common political and cultural traditions, beliefs, or values are sometimes also said to form a society (such as Judeo-Christian, Eastern, and Western). When used in this context, the term is employed as a means of contrasting two or more "societies" whose members represent alternative conflicting and competing worldviews.

Some academic, professional, and scientific associations describe themselves as "societies" (for example, the American Mathematical Society, the American Society of Civil Engineers, or the Royal Society).

In some countries, e.g. the United States, France, and Latin America, the term "society' is used in commerce to denote a partnership between investors or the start of a business. In the United Kingdom, partnerships are not called societies, but co-operatives or mutuals are often known as societies (such as friendly societies and building societies).





</doc>
<doc id="11033682" url="https://en.wikipedia.org/wiki?curid=11033682" title="Societal marketing">
Societal marketing

The societal marketing is a marketing concept that holds that a company should make marketing decisions not only by considering consumers' wants, the company's requirements, but also society's long-term interests.

The societal marketing concept holds that the organization's task is to determine the needs, wants, and interests of a target market and to deliver the desired satisfactions more effectively and efficiently than competitors in a way that preserves or enhances the well being of both the individual consumer and society in general. Therefore, marketers must endeavor to satisfy the needs and wants of their target markets in ways that preserve and enhance the well-being of consumers and society as a whole. It is closely linked with the principles of corporate social responsibility and of sustainable development.

Societal marketing can be defined as a "marketing with a social dimension or marketing that includes non-economic criteria". Societal marketing "concerns for society's long term interests". It is about "the direct benefits for the organization and secondary benefit for the community". Societal marketing distinguishes between the consumer's immediate satisfaction and longer term consumer and social benefits. Accordingly, Andreas Kaplan defines societal management as "management that takes into account society's overall welfare in addition to mere profitability considerations." It is a 3 dimensional concept of marketing – social welfare, individual welfare, company profits..

Various attempts to define the objectives of societal marketing have been noted, such as:

The concept of societal marketing emerged in the early 1970s, promoting a more socially responsible, moral and ethical model of marketing in an effort to counter some of the more serious criticisms of marketing that had arisen out of the consumerist movement around that time. 

Philip Kotler is generally credited with introducing the societal marketing concept to the literature in a 1972 article "What Consumerism Means for Marketers" in the "Harvard Business Review" of 1972. Certainly Kotler believed that he had coined the term, "societal marketing" and was the first to codify it within the marketing literature. Some marketing historians, notably Wilkie and Moore, have argued that a societal perspective was not new, and that evidence for it could be found in marketing theory and in marketing texts, since the discipline's inception in the early 1900s. Kotler introduced both the concept of social marketing (extending marketing technologies into non-business areas) and societal marketing, arguing that the marketing concept and its technologies must be tempered and ultimately revised by adopting a more explicit social orientation. The novelty of Kotler's concept was the idea of "long-run consumer welfare", emphasizing that the short-term desires might not support the consumer's long term interests or be good for the society as a whole.

The societal marketing concept adopts the position that marketers have a greater social responsibility than simply satisfying customers and providing them with superior value. Instead, marketing activities should strive to benefit society's overall well-being. Marketing organisations that have embraced the societal marketing concept typically identify key stakeholder groups including: employees, customers, local communities, the wider public and government and consider the impact of their activities on all stakeholders. They ensure that marketing activities do not damage the environment and are not hazardous to broader society. Societal marketing developed into sustainable marketing. Societal marketing requires businesses to include social, ethical and ecological considerations in product and market planning. 

Kotler identified four categories of products, classified in terms of long term benefits and immediate satisfaction: 


Kotler's concept of societal marketing suggested that for the well-being of society, deficient products should be eliminated from the market, pleasing and salutary products should go through a product modification process to acquire desirable status, by incorporating missing short term benefits into salutary products and long term benefits into pleasing products, and the companies' ultimate goal should be to develop desirable products. Rather than focusing on selling products, which can be good or bad for the consumers, companies should focus on consumer and society's well-being.

Most companies recognize that socially responsible activities improve their image among customers, stockholders, the financial community, and other relevant publics. Ethical and socially responsible practices are simply good business, resulting not only in favorable image, but ultimately in increased sales.


Societal marketing should not be confused with social marketing. Societal marketing is a philosophy or mindset that informs marketing decisions whereas social marketing is a distinct branch within the marketing discipline. Societal marketing is concerned with the consideration of the social and ethical aspects of marketing planning. Social marketing is concerned with facilitating social change. A key difference is that the greater 'social good' is the "principal" consideration in social marketing while social benefits are one of a number of considerations in societal marketing. 

On the other hand, social marketing is a sub-branch of marketing that began in 1971, with the publication of an article by Kotler and Zaltman, emphasising a planned approach to achieving social change. It is primarily concerned with encouraging pro-social behaviours (e.g. recycling, sun-safety, safe driving practices) and discouraging anti-social behaviours (e.g. littering, drink-driving). It is defined as an "adaptation of commercial marketing technologies to programs designed to influence the voluntary behavior of target audiences to improve their personal welfare and that of the society of which they are a part". 

Social marketing uses more traditional commercial techniques and strategies, focusing on persuasion, to achieve goals for the greater social good. Its campaigns can either encourage merit goods, as for example fundraising for not-for-profit organizations or dissuade the use of demerit goods promoting society's well being, as non-smoking campaigns or promote the use of seat belts. Another characteristic of social marketing is that is planned to influence individual behaviour to improve well-being. It includes more than just advertising in traditional mass media, and may extend to educational programs and formal enforcement regimes in the case of road safety campaigns. It planned campaigns, implemented by governmental and non-governmental organisations. A clear example that differentiates societal from social marketing is a marketing campaign on non-smoking. A smoking cessation advertisement is an example of social marketing, but if the marketing strategies and techniques used in that campaign focus on increasing the well-being of society, that same campaign can be an example of societal marketing.

The societal marketing concept was a forerunner of sustainable marketing in integrating issues of social responsibility into commercial marketing strategies. In contrast to that, social marketing uses commercial marketing theories, tools and techniques to influence social change. Social marketing applies a "customer orientated" approach and uses the concepts and tools used by commercial marketers in pursuit of social goals like Anti-Smoking-Campaigns or fundraising for NGOs.

Unlike societal marketing, CSR has existed for many years. Another difference is that CSR "focuses more in a corporate level and stakeholders", while societal marketing is more concerned about the consumer and their long term benefits. CSR social and environmental concerns are integrated into all business operations. CSR is mainly run by companies, while social marketing mainly by government or non-profit organizations. One example of CSR among companies is what Häagen-Dazs is doing with their "microsite" to raise awareness to the general public about the preservation of the honeybee.

Corporations are the one who are striving during the whole time for improvements. They are turning to all kind of forms of corporate societal marketing programs to help build and repair their brand images.

Corporate Social Marketing, or CSM, usually refers to marketing efforts that have at least one social related objective, such as charity founding, among its goals. Typical examples are releasing a certain percentage of the final sale product to a charity related to the product, or sponsoring events that encourage social well-being such as the Olympic Games. Corporate Social Marketing benefits a company in many ways, but its main goal is to improve the image the public has of the company. A company that appears committed to improving the lives of others, the environment or other worthy causes is seen in a better light than one who doesn't, and more and more business are hoping to benefit from that.

So, it can be so, that CSM programs are becoming extremely popular because the leaders believe that it is a good business to be viewed as a socially responsible company. However, even though past research suggests that CSM may be effective in improving brand equity and increasing market share, there are limits to the effectiveness of these initiatives.

An example of his is how corporate social initiatives adversely affected purchase intentions if consumers perceived that the company would forgo product quality in order to be socially responsible.

Depending on the nature of the CSM program, the intent of the corporation may not be as obvious to the consumers. This happens if the benefits to the corporation are not apparent or conflicts with what the consumer already believes about a specific firm or industry.

Since firms exist to make a profit, consumers may spend considerable energy in an attempt to infer motives related to the profit-oriented goals. As an example, a consumer may be suspicious of a tobacco company that undertakes a campaign to prevent underage smoking. If this is successful, the company would be affected and the cigarette sales will be lowered. So, in this situation, consumers' suspicions may lead them to infer motives that would actually protect the companies financial condition – as they are trying to improve their image to sell more cigarettes to adults. However, if a tobacco company undertook a CSM Campaign, that would sustain their business, consumers may be able to infer profit motives more easily and then have a more favorable attitude toward the partnership. Therefore, it can be concluded that the attitude of the consumers could be better if they knew more about the motives of the companies and they were more obvious.

Another aspect that may cause suspicion with consumers is the amount of harm that a company has already done, either because of unsafe products or harmful production practices. It is logical that consumers are more suspicious to companies that sell harmful products. Again examples are the tobacco companies and alcohol companies as well. They will meet resistance from consumers when they undertake socially-oriented campaigns aimed at mitigating the effects of their products. That is why when different industries are separated, two very general dimensions are used – the harmful nature of the products and the harmful nature of the production methods.

This classification can briefly show how consumers are influenced by the various CSM efforts. Companies that work in this "dangerous" industries are not that successful always, because the consumers may be suspicious of any societal efforts the company attempts to undertake. Consumers will infer less society-serving motives and more self-serving motives for corporate societal marketing programs undertaken by firms that operate in mixed or sin industries.

Based on how easily consumers could infer profit-driven motives, are classified the types of CSM campaigns: Positively tied to product sales, positively tied to product sales, not directly tied to sales but aimed at sustaining the company's business, completely unrelated.

Societal marketing has been the subject of a number of criticisms: 

A key issue concerns the question of who decides what is in the public's best interests. The moral agenda implicit in the societal marketing concept is underdeveloped and often implicit. Gaski argued that marketers should step away from their classic goal of customer satisfaction and profit maximization while respecting the minimum governmental standards imposed by law and enter this public policy area, since marketers themselves would have to decide what actions are consistent with public welfare. Marketers might have neither the competence nor the right to determine the "public interest." Instead, it should be the customers who decide what is good for them, or their political representatives and dictate that to the industry. 

Some scholars have argued that societal marketing is not a distinct concept, but rather it is a mere extension of the marketing concept. Others have pointed out that the literature in the field is vague, poorly defined and underdeveloped. The societal marketing concept has become an excellent strategy for promotions with social dimensions and for exploring consumers' behavioural response to such corporate 'doing good'.

Societal marketing is gaining the marketers and consumer attention and there is every reason to expect it to continue to evolve in practice. It focuses on providing win-win opportunities to companies, consumers and society. But achieving the compelling benefits for each party involved is very complicated. So much more research is needed. To achieve a win situation for organization involved, is dependent largely upon how the key constituents react. In this context, anticipating consumer reaction is really challenging which can be affected by number of factors that often vary across different segments. The several research questions remain to be answered like how different factors affects reaction to societal marketing and how do the various factors interact? How can societal initiatives be designed to leverage positive reaction and mitigate negative ones? 

For consumers to win, societal marketing must provide them with compelling benefits that increase their overall welfare. What benefits did societal marketing initiative actually provided to consumers? Are there direct benefits such as increased satisfaction with their interaction with commercial or nonprofit organization?
Determining whether there is a win situation for society by societal marketing initiative is the most difficult question to be answered. We turn to the two questions proposed by Bloom, Hussien and Szykmann (1995): Is the society better off because of this program? Does corporate involvement result in better performance than if it would have been managed by NGOs or government agencies? 
Societal marketing is becoming globally popular but there exists a scarcity of research in this field. Therefore, extensive future research is needed particularly investigating questions with respect to its impact on consumer attitudes to corporate image, product image and their purchase intention or brand choice as well as on positive impact on society.




</doc>
<doc id="251368" url="https://en.wikipedia.org/wiki?curid=251368" title="Power structure">
Power structure

A power structure is an overall system of influence between any individual and every other individual within any selected group of people. A description of a power structure would capture the way in which power or authority is distributed between people within groups such as a government, nation, institution, organization, or a society. Such structures are of interest to various fields, including sociology, government, economics, and business. A power structure may be formal and intentionally constructed to maximize values like fairness or efficiency, as in a hierarchical organization wherein every entity, except one, is subordinate to a single other entity. Conversely, a power structure may be an informal set of roles, such as those found in a dominance hierarchy in which members of a social group interact, often aggressively, to create a ranking system. A culture that is organised in a dominance hierarchy is a dominator culture, the opposite of an egalitarian culture of partnership. A visible, dominant group or elite that holds power or authority within a power structure is often referred to as being the Establishment. Power structures are fluid, with changes occurring constantly, either slowly or rapidly, evolving or revolutionary, peacefully or violently.



</doc>
<doc id="273856" url="https://en.wikipedia.org/wiki?curid=273856" title="Industrial society">
Industrial society

In sociology, industrial society is a society driven by the use of technology to enable mass production, supporting a large population with a high capacity for division of labour. Such a structure developed in the Western world in the period of time following the Industrial Revolution, and replaced the agrarian societies of the pre-modern, pre-industrial age. Industrial societies are generally mass societies, and may be succeeded by an information society. They are often contrasted with traditional societies.

Industrial societies use external energy sources, such as fossil fuels, to increase the rate and scale of production. The production of food is shifted to large commercial farms where the products of industry, such as combine harvesters and fossil fuel-based fertilizers, are used to decrease required human labor while increasing production. No longer needed for the production of food, excess labor is moved into these factories where mechanization is utilized to further increase efficiency. As populations grow, and mechanization is further refined, often to the level of automation, many workers shift to expanding service industries.

Industrial society makes urbanization desirable, in part so that workers can be closer to centers of production, and the service industry can provide labor to workers and those that benefit financially from them, in exchange for a piece of production profits with which they can buy goods. This leads to the rise of very large cities and surrounding suburb areas with a high rate of economic activity.

These urban centers require the input of external energy sources in order to overcome the diminishing returns of agricultural consolidation, due partially to the lack of nearby arable land, associated transportation and storage costs, and are otherwise unsustainable. This makes the reliable availability of the needed energy resources high priority in industrial government policies.

Some theoreticians (namely Ulrich Beck, Anthony Giddens, and Manuel Castells) argue that we are located in the middle of a transformation or transition from industrial societies to post-industrial societies. The triggering technology for the change from an agricultural to an industrial organization was steam power, allowing mass production and reducing the agricultural work necessary. Thus, many industrial cities have been built around rivers. Identified as catalyst or trigger for the transition to post-modern or informational society is global information technology.

Some, such as Theodore Kaczynski, have argued that an industrialized society leads to psychological pain and that citizens must actively work to return to a more primitive society. His essay, "Industrial Society and Its Future", describes different political factions and laments the direction of technology and the modern world.




</doc>
<doc id="33524705" url="https://en.wikipedia.org/wiki?curid=33524705" title="Origins of society">
Origins of society

The origins of society — the evolutionary emergence of distinctively human social organization — is an important topic within evolutionary biology, anthropology, prehistory and palaeolithic archaeology. While little is known for certain, debates since Hobbes and Rousseau have returned again and again to the philosophical, moral and evolutionary questions posed.

Arguably the most influential theory of human social origins is that of Thomas Hobbes, who in his "Leviathan" argued that without strong government, society would collapse into "Bellum omnium contra omnes" — "the war of all against all":

If Hobbes' idea is accepted, it follows that society could not have emerged prior to the state. This school of thought has remained influential to this day. Prominent in this respect is British archaeologist Colin Renfrew (Baron Renfrew of Kaimsthorn), who points out that the state did not emerge until long after the evolution of "Homo sapiens". The earliest representatives of our species, according to Renfrew, may well have been "anatomically" modern, but they were not yet "cognitively" or "behaviourally" modern. For example, they lacked political leadership, large-scale cooperation, food production, organised religion, law or symbolic artefacts. Humans were simply hunter-gatherers, who — much like extant apes — ate whatever food they could find in the vicinity. Renfrew controversially suggests that hunter-gatherers to this day think and socialise along lines not radically different from those of their nonhuman primate counterparts. In particular, he says that they do not "ascribe symbolic meaning to material objects" and for that reason "lack fully developed 'mind.'"

However, hunter-gatherer ethnographers emphasise that extant foraging peoples certainly do have social institutions — notably institutionalised rights and duties codified in formal systems of kinship. Elaborate rituals such as initiation ceremonies serve to cement contracts and commitments, quite independently of the state. Other scholars would add that insofar as we can speak of "human revolutions" — "major transitions" in human evolution — the first was not the Neolithic Revolution but the rise of symbolic culture that occurred toward the end of the Middle Stone Age.

Arguing the exact opposite of Hobbes's position, anarchist anthropologist Pierre Clastres views the state and society as mutually incompatible: genuine society is always struggling to survive "against" the state.

Like Hobbes, Jean-Jacques Rousseau argued that society was born in a social contract. In Rousseau's case, however, sovereignty is vested in the entire populace, who enter into the contract directly with one another. "The problem", he explained, "is to find a form of association which will defend and protect with the whole common force the person and goods of each associate, and in which each, while uniting himself with all, may still obey himself alone, and remain as free as before." This is the fundamental problem of which the Social Contract provides the solution. The contract's clauses, Rousseau continued, may be reduced to one — "the total alienation of each associate, together with all his rights, to the whole community. Each man, in giving himself to all, gives himself to nobody; and as there is no associate over whom he does not acquire the same right as he yields others over himself, he gains an equivalent for everything he loses, and an increase of force for the preservation of what he has". In other words: "Each of us puts his person and all his power in common under the supreme direction of the general will, and, in our corporate capacity, we receive each member as an indivisible part of the whole." At once, in place of the individual personality of each contracting party, this act of association creates a moral and collective body, composed of as many members as the assembly contains votes, and receiving from this act its unity, its common identity, its life and its will. By this means, each member of the community acquires not only the capacities of the whole but also, for the first time, rational mentality:

In his influential book, "Ancient Law" (1861), Maine argued that in early times, the basic unit of human social organisation was the patriarchal family:

Hostile to French revolutionary and other radical social ideas, Maine's motives were partly political. He sought to undermine the legacy of Rousseau and other advocates of man's natural rights by asserting that originally, no one had any rights at all – ‘every man, living during the greater part of his life under the patriarchal despotism, was practically controlled in all his actions by a regimen not of law but of caprice’. Not only were the patriarch's children subject to what Maine calls his ‘despotism’: his wife and his slaves were equally affected. The very notion of kinship, according to Maine, was simply a way of categorizing those who were forcibly subjected to the despot's arbitrary rule. Maine later added a Darwinian strand to this argument. In his "The Descent of Man," Darwin had cited reports that a wild-living male gorilla would monopolise for itself as large a harem of females as it could violently defend. Maine endorsed Darwin's speculation that ‘primeval man’ probably 'lived in small communities, each with as many wives as he could support and obtain, whom he would have jealously guarded against all other men’. Under pressure to spell out exactly what he meant by the term 'patriarchy', Maine clarified that ‘sexual jealousy, indulged through power, might serve as a definition of the Patriarchal Family’.

In his influential book, "Ancient Society" (1877), its title echoing Maine's "Ancient Law," Lewis Henry Morgan proposed a very different theory. Morgan insisted that throughout the earlier periods of human history, neither the state nor the family existed.

Friedrich Engels built on Morgan's ideas in his 1884 essay, "The Origin of the Family, Private Property and the State in the light of the researches of Lewis Henry Morgan." His primary interest was the position of women in early society, and — in particular — Morgan's insistence that the matrilineal clan preceded the family as society's fundamental unit. 'The mother-right gens', wrote Engels in his survey of contemporary historical materialist scholarship, 'has become the pivot around which the entire science turns...' Engels argued that the matrilineal clan represented a principle of self-organization so vibrant and effective that it allowed no room for patriarchal dominance or the territorial state.

Emile Durkheim considered that in order to exist, any human social system must counteract the natural tendency for the sexes to promiscuously conjoin. He argued that social order presupposes sexual morality, which is expressed in prohibitions against sex with certain people or during certain periods — in traditional societies particularly during menstruation.

The incest taboo, wrote Durkheim in 1898, is no more than a particular example of something more basic and universal - the ritualistic setting apart of 'the sacred' from 'the profane'. This begins as the segregation of the sexes, each of which - at least on important occasions - is 'sacred' or 'set apart' from the other. 'The two sexes', as Durkheim explains, 'must avoid each other with the same care as the profane flees from the sacred and the sacred from the profane.' Women as sisters act out the role of 'sacred' beings invested 'with an isolating power of some sort, a power which holds the masculine population at a distance.' Their menstrual blood in particular sets them in a category apart, exercising a 'type of repulsing action which keeps the other sex far from them'. In this way, the earliest ritual structure emerges — establishing morally regulated 'society' for the first time.

Charles Darwin pictured early human society as resembling that of apes, with one or more dominant males jealously guarding a harem of females. In his myth of the 'Primal Horde', Sigmund Freud later took all this as his starting point but then postulated an insurrection mounted by the tyrant's own sons: Following this, the band of brothers were about to take sexual possession of their mothers and sisters when suddenly they were overcome with remorse. In their contradictory emotional state, their dead father now became stronger than the living one had been. In memory of him, the brothers revoked their deed by forbidding the killing and eating of the 'totem' (as their father had now become) and renouncing their claim to the women who had just been set free. In this way, the two fundamental taboos of primitive society – not to eat the totem and not to marry one's sisters – were established for the first time.

A related but less dramatic version of Freud's 'sexual revolution' idea was proposed in 1960 by American social anthropologist Marshall Sahlins. Somehow, he writes, the world of primate brute competition and sexual dominance was turned upside-down: 

If we accept Rousseau's line of reasoning, no single dominant individual is needed to embody society, to guarantee security or to enforce social contracts. The people themselves can do these things, combining to enforce the general will. A modern origins theory along these lines is that of evolutionary anthropologist Christopher Boehm. Boehm argues that ape social organisation tends to be despotic, typically with one or more dominant males monopolising access to the locally available females. But wherever there is dominance, we can also expect resistance. In the human case, resistance to being personally dominated intensified as humans used their social intelligence to form coalitions. Eventually, a point was reached when the costs of attempting to impose dominance became so high that the strategy was no longer evolutionarily stable, whereupon social life tipped over into 'reverse dominance' — defined as a situation in which only the entire community, on guard against primate-style individual dominance, is permitted to use force to suppress deviant behaviour.

Human beings, writes social anthropologist Ernest Gellner, are not genetically programmed to be members of this or that social order. You can take a human infant and place it into any kind of social order and it will function acceptably. What makes human society so distinctive is the fabulous range of quite different forms it takes across the world. Yet in any given society, the range of permitted behaviours is quite narrowly constrained. This is not owing to the existence of any externally imposed system of rewards and punishments. The constraints come from within — from certain compulsive moral concepts which members of the social order have internalised. The society installs these concepts in each individual's psyche in the manner first identified by Emile Durkheim, namely, by means of collective rituals such as initiation rites. Therefore, the problem of the origins of society boils down to the problem of the origins of collective ritual.

Feminist scholars — among them palaeoanthropologists Leslie Aiello and Camilla Power — take similar arguments a step further, arguing that any reform or revolution which overthrew male dominance must surely have been led by women. Evolving human females, Power and Aiello suggest, actively separated themselves from males on a periodic basis, using their own blood (and/or pigments such as red ochre) to mark themselves as fertile and defiant: In similar vein, anthropologist Chris Knight argues that Boehm's idea of a 'coalition of everyone' is hard to envisage, unless — along the lines of a modern industrial picket line — it was formed to co-ordinate 'sex-strike' action against badly behaving males: In virtually all hunter-gatherer ethnographies, according to Knight, a persistent theme is that 'women like meat', and that they determinedly use their collective bargaining power to motivate men to hunt for them and bring home their kills — on pain of exclusion from sex. Arguments about women's crucial role in domesticating males — motivating them to cooperate — have also been advanced by anthropologists Kristen Hawkes, Sarah Hrdy and Bruce Knauft among others. Meanwhile, other evolutionary scientists continue to envisage uninterrupted male dominance, continuity with primate social systems and the emergence of society on a gradualist basis without revolutionary leaps.

In his 1985 book, "Social Evolution", Robert Trivers outlines the theoretical framework used today by most evolutionary biologists to understand how and why societies are established. Trivers sets out from the fundamental fact that genes survive beyond the death of the bodies they inhabit, because copies of the same gene may be replicated in multiple different bodies. From this, it follows that a creature should behave altruistically to the extent that those benefiting carry the same genes — 'inclusive fitness', as this source of cooperation in nature is termed. Where animals are unrelated, cooperation should be limited to 'reciprocal altruism' or 'tit-for-tat'.
Where previously, biologists took parent-offspring cooperation for granted, Trivers predicted on theoretical grounds both cooperation and conflict — as when a mother needs to wean an existing baby (even against its will) in order to make way for another. Previously, biologists had interpreted male infanticidal behaviour as aberrant and inexplicable or, alternatively, as a necessary strategy for culling excess population. Trivers was able to show that such behaviour was a logical strategy by males to enhance their own reproductive success at the expense of conspecifics including rival males. Ape or monkey females whose babies are threatened have directly opposed interests, often forming coalitions to defend themselves and their offspring against infanticidal males.
Human society, according to Trivers, is unusual in that it involves the male of the species investing parental care in his own offspring — a rare pattern for a primate. Where such cooperation occurs, it's not enough to take it for granted: in Trivers' view we need to "explain" it using an overarching theoretical framework applicable to humans and nonhumans alike.

Robin Dunbar originally studied gelada baboons in the wild in Ethiopia, and has done much to synthesise modern primatological knowledge with Darwinian theory into a comprehensive overall picture. The components of primate social systems 'are essentially alliances of a political nature aimed at enabling the animals concerned to achieve more effective solutions to particular problems of survival and reproduction'. Primate societies are in essence 'multi-layered sets of coalitions'. Although physical fights are ultimately decisive, the social mobilisation of allies usually decides matters and requires skills that go beyond mere fighting ability. The manipulation and use of coalitions demands sophisticated social — more precisely "political" — intelligence.
Usually but not always, males exercise dominance over females. Even where male despotism prevails, females typically gang up with one another to pursue agendas of their own. When a male gelada baboon attacks a previously dominant rival so as to take over his harem, the females concerned may insist on their own say in the outcome. At various stages during the fighting, the females may 'vote' among themselves on whether to accept the provisional outcome. Rejection is signalled by refusing to groom the challenger; acceptance is signalled by going up to him and grooming him. According to Dunbar, the ultimate outcome of an inter-male 'sexual fight' always depends on the female 'vote'.
Dunbar points out that in a primate social system, lower-ranking females will typically suffer the most intense harassment. Consequently, they will be the first to form coalitions in self-defence. But maintaining commitment from coalition allies involves much time-consuming manual grooming, putting pressure on time-budgets. In the case of evolving humans, who were living in increasingly large groups, the costs would soon have outweighed the benefits — unless some more efficient way of maintaining relationships could be found. Dunbar argues that 'vocal grooming' — using the voice to signal commitment — was the time-saving solution adopted, and that this led eventually to speech. Dunbar goes on to suggest (citing evolutionary anthropologist Chris Knight) that "distinctively human" society may have been evolved under pressure from female ritual and 'gossiping' coalitions established to dissuade males from fighting one another and instead cooperate in hunting for the benefit of the whole camp: Dunbar stresses that this is currently a minority theory among specialists in human origins — most still support the 'bison-down-at-the-lake' theory attributing early language and cooperation to the imperatives of men's activities such as hunting. Despite this, he argues that 'female bonding may have been a more powerful force in human evolution than is sometimes supposed'. Although still controversial, the idea that female coalitions may have played a decisive role has subsequently received strong support from a number of anthropologists including Sarah Hrdy, Camilla Power, Ian Watts. and Jerome Lewis. It is also consistent with recent studies by population geneticists (see Verdu et al. 2013 for Central African Pygmies; Schlebusch 2010 for Khoisan) showing a deep-time tendency to matrilocality among African hunter-gatherers.




</doc>
<doc id="4228181" url="https://en.wikipedia.org/wiki?curid=4228181" title="Stateless society">
Stateless society

A stateless society is a society that is not governed by a state, or, especially in common American English, has no government. In stateless societies, there is little concentration of authority; most positions of authority that do exist are very limited in power and are generally not permanently held positions; and social bodies that resolve disputes through predefined rules tend to be small. Stateless societies are highly variable in economic organization and cultural practices.

While stateless societies were the norm in human prehistory, few stateless societies exist today; almost the entire global population resides within the jurisdiction of a sovereign state. In some regions nominal state authorities may be very weak and wield little or no actual power. Over the course of history most stateless peoples have been integrated into the state-based societies around them.

Some political philosophies, particularly anarchism, consider the state an unwelcome institution and stateless societies the ideal.

In archaeology, cultural anthropology and history, a stateless society denotes a less complex human community without a state, such as a tribe, a clan, a band society or a chiefdom. The main criterion of "complexity" used is the extent to which a division of labor has occurred such that many people are permanently "specialized" in particular forms of production or other activity, and depend on others for goods and services through trade or sophisticated reciprocal obligations governed by custom and laws. An additional criterion is population size. The bigger the population, the more relationships have to be reckoned with.

Evidence of the earliest known city-states has been found in ancient Mesopotamia around 3700 BC, suggesting that the history of the state is less than 6,000 years old; thus, for most of human prehistory the state did not exist.

Generally speaking, the archaeological evidence suggests that the state emerged from stateless communities only when a fairly large population (at least tens of thousands of people) was more or less settled together in a particular territory, and practiced agriculture. Indeed, one of the typical functions of the state is the defense of territory. Nevertheless, there are exceptions: Lawrence Krader for example describes the case of the Tatar state, a political authority arising among confederations of clans of nomadic or semi-nomadic herdsmen.

Characteristically the state functionaries (royal dynasties, soldiers, scribes, servants, administrators, lawyers, tax collectors, religious authorities etc.) are mainly not self-supporting, but rather materially supported and financed by taxes and tributes contributed by the rest of the working population. This assumes a sufficient level of labor-productivity per capita which at least makes possible a "permanent" surplus product (principally foodstuffs) appropriated by the state authority to sustain the activities of state functionaries. Such permanent surpluses were generally not produced on a significant scale in smaller tribal or clan societies.

The archaeologist Gregory Possehl has argued that there is no evidence that the relatively sophisticated, urbanized Harappan civilization, which flourished from about 2,500 to 1,900 BC in the Indus region, featured anything like a centralized state apparatus. No evidence has yet been excavated locally of palaces, temples, a ruling sovereign or royal graves, a centralized administrative bureaucracy keeping records, or a state religion—all of which are elsewhere usually associated with the existence of a state apparatus.

Similarly, in the earliest large-scale human settlements of the stone age which have been discovered, such as Çatal Höyük and Jericho, no evidence was found of the existence of a state authority. The Çatal Höyük settlement of a farming community (7,300 BC to circa 6,200 BC) spanned circa 13 hectares (32 acres) and probably had about 5,000 to 10,000 inhabitants.

Modern state-based societies regularly pushed out stateless indigenous populations as their settlements expanded, or attempted to make those populations come under the control of a state structure. This was particularly the case on the African continent during European colonisation, where there was much confusion about the best way to govern societies who, prior to European arrival, had been stateless. Tribal societies, on first glance appearing to be chaotic, often had well-organised societal structures that were based on multiple undefined cultural factors - including the ownership of cattle and arable land, patrilineal descent structures, honour gained from success in conflict etc.

Uncontacted peoples may be considered remnants of prehistoric stateless societies. To varying extents they may be unaware of and unaffected by the states that have nominal authority over their territory.

Some political philosophies consider the state undesirable, and thus consider the formation of a stateless society a goal to be achieved.

A central tenet of anarchism is the advocacy of society without states. The type of society sought for varies significantly between anarchist schools of thought, ranging from extreme individualism to complete collectivism.

In Marxism, Marx's theory of the state considers that in a post-capitalist society the state, an undesirable institution, would be unnecessary and wither away. A related concept is that of stateless communism, a phrase sometimes used to describe Marx's anticipated post-capitalist society.

Anthropologists have found that social stratification is not the standard among all societies. John Gowdy writes, "Assumptions about human behaviour that members of market societies believe to be universal, that humans are naturally competitive and acquisitive, and that social stratification is natural, do not apply to many hunter-gatherer peoples."

The economies of stateless agricultural societies tend to focus and organize subsistence agriculture at the community level, and tend to diversify their production rather than specializing in a particular crop.

In many stateless societies, conflicts between families or individuals are resolved by appealing to the community. Each of the sides of the dispute will voice their concerns, and the community, often voicing its will through village elders, will reach a judgment on the situation. Even when there is no legal or coercive authority to enforce these community decisions, people tend to adhere to them, due to a desire to be held in esteem by the community.



</doc>
<doc id="13831" url="https://en.wikipedia.org/wiki?curid=13831" title="Human rights">
Human rights

Human rights are moral principles or norms that describe certain standards of human behaviour and are regularly protected as natural and legal rights in municipal and international law. They are commonly understood as inalienable, fundamental rights "to which a person is inherently entitled simply because she or he is a human being" and which are "inherent in all human beings", regardless of their age, ethnic origin, location, language, religion, ethnicity, or any other status. They are applicable everywhere and at every time in the sense of being universal, and they are egalitarian in the sense of being the same for everyone. They are regarded as requiring empathy and the rule of law and imposing an obligation on persons to respect the human rights of others, and it is generally considered that they should not be taken away except as a result of due process based on specific circumstances; for example, human rights may include freedom from unlawful imprisonment, torture, and execution.

The doctrine of human rights has been highly influential within international law and global and regional institutions. Actions by states and non-governmental organisations form a basis of public policy worldwide. The idea of human rights suggests that "if the public discourse of peacetime global society can be said to have a common moral language, it is that of human rights". The strong claims made by the doctrine of human rights continue to provoke considerable scepticism and debates about the content, nature and justifications of human rights to this day. The precise meaning of the term "right" is controversial and is the subject of continued philosophical debate; while there is consensus that human rights encompasses a wide variety of rights such as the right to a fair trial, protection against enslavement, prohibition of genocide, free speech or a right to education, there is disagreement about which of these particular rights should be included within the general framework of human rights; some thinkers suggest that human rights should be a minimum requirement to avoid the worst-case abuses, while others see it as a higher standard.

Many of the basic ideas that animated the human rights movement developed in the aftermath of the Second World War and the events of the Holocaust, culminating in the adoption of the Universal Declaration of Human Rights in Paris by the United Nations General Assembly in 1948. Ancient peoples did not have the same modern-day conception of universal human rights. The true forerunner of human rights discourse was the concept of natural rights which appeared as part of the medieval natural law tradition that became prominent during the European Enlightenment with such philosophers as John Locke, Francis Hutcheson and Jean-Jacques Burlamaqui and which featured prominently in the political discourse of the American Revolution and the French Revolution. From this foundation, the modern human rights arguments emerged over the latter half of the 20th century, possibly as a reaction to slavery, torture, genocide and war crimes, as a realisation of inherent human vulnerability and as being a precondition for the possibility of a just society.

Ancient peoples did not have the same modern-day conception of universal human rights. The true forerunner of human-rights discourse was the concept of natural rights which appeared as part of the medieval natural law tradition that became prominent during the European Enlightenment. From this foundation, the modern human rights arguments emerged over the latter half of the 20th century.
17th-century English philosopher John Locke discussed natural rights in his work, identifying them as being "life, liberty, and estate (property)", and argued that such fundamental rights could not be surrendered in the social contract. In Britain in 1689, the English Bill of Rights and the Scottish Claim of Right each made illegal a range of oppressive governmental actions. Two major revolutions occurred during the 18th century, in the United States (1776) and in France (1789), leading to the United States Declaration of Independence and the French Declaration of the Rights of Man and of the Citizen respectively, both of which articulated certain human rights. Additionally, the Virginia Declaration of Rights of 1776 encoded into law a number of fundamental civil rights and civil freedoms.

Philosophers such as Thomas Paine, John Stuart Mill and Hegel expanded on the theme of universality during the 18th and 19th centuries. In 1831 William Lloyd Garrison wrote in a newspaper called "The Liberator" that he was trying to enlist his readers in "the great cause of human rights" so the term "human rights" probably came into use sometime between Paine's "The Rights of Man" and Garrison's publication. In 1849 a contemporary, Henry David Thoreau, wrote about human rights in his treatise "On the Duty of Civil Disobedience" which was later influential on human rights and civil rights thinkers. United States Supreme Court Justice David Davis, in his 1867 opinion for Ex Parte Milligan, wrote "By the protection of the law, human rights are secured; withdraw that protection and they are at the mercy of wicked rulers or the clamor of an excited people."

Many groups and movements have managed to achieve profound social changes over the course of the 20th century in the name of human rights. In Western Europe and North America, labour unions brought about laws granting workers the right to strike, establishing minimum work conditions and forbidding or regulating child labour. The women's rights movement succeeded in gaining for many women the right to vote. National liberation movements in many countries succeeded in driving out colonial powers. One of the most influential was Mahatma Gandhi's movement to free his native India from British rule. Movements by long-oppressed racial and religious minorities succeeded in many parts of the world, among them the civil rights movement, and more recent diverse identity politics movements, on behalf of women and minorities in the United States.

The foundation of the International Committee of the Red Cross, the 1864 Lieber Code and the first of the Geneva Conventions in 1864 laid the foundations of International humanitarian law, to be further developed following the two World Wars.

The League of Nations was established in 1919 at the negotiations over the Treaty of Versailles following the end of World War I. The League's goals included disarmament, preventing war through collective security, settling disputes between countries through negotiation, diplomacy and improving global welfare. Enshrined in its Charter was a mandate to promote many of the rights which were later included in the Universal Declaration of Human Rights.

The League of Nations had mandates to support many of the former colonies of the Western European colonial powers during their transition from colony to independent state.

Established as an agency of the League of Nations, and now part of United Nations, the International Labour Organization also had a mandate to promote and safeguard certain of the rights later included in the Universal Declaration of Human Rights (UDHR):

On the issue of "universal", the declarations did not apply to domestic discrimination or racism. Henry J. Richardson III has argued:

The Universal Declaration of Human Rights (UDHR) is a non-binding declaration adopted by the United Nations General Assembly in 1948, partly in response to the barbarism of World War II. The UDHR urges member states to promote a number of human, civil, economic and social rights, asserting these rights are part of the "foundation of freedom, justice and peace in the world". The declaration was the first international legal effort to limit the behavior of states and press upon them duties to their citizens following the model of the rights-duty duality.

The UDHR was framed by members of the Human Rights Commission, with Eleanor Roosevelt as Chair, who began to discuss an "International Bill of Rights" in 1947. The members of the Commission did not immediately agree on the form of such a bill of rights, and whether, or how, it should be enforced. The Commission proceeded to frame the UDHR and accompanying treaties, but the UDHR quickly became the priority. Canadian law professor John Humprey and French lawyer Rene Cassin were responsible for much of the cross-national research and the structure of the document respectively, where the articles of the declaration were interpretative of the general principle of the preamble. The document was structured by Cassin to include the basic principles of dignity, liberty, equality and brotherhood in the first two articles, followed successively by rights pertaining to individuals; rights of individuals in relation to each other and to groups; spiritual, public and political rights; and economic, social and cultural rights. The final three articles place, according to Cassin, rights in the context of limits, duties and the social and political order in which they are to be realized. Humphrey and Cassin intended the rights in the UDHR to be legally enforceable through some means, as is reflected in the third clause of the preamble:

Some of the UDHR was researched and written by a committee of international experts on human rights, including representatives from all continents and all major religions, and drawing on consultation with leaders such as Mahatma Gandhi. The inclusion of both civil and political rights and economic, social and cultural rights was predicated on the assumption that basic human rights are indivisible and that the different types of rights listed are inextricably linked. Though this principle was not opposed by any member states at the time of adoption (the declaration was adopted unanimously, with the abstention of the Soviet bloc, Apartheid South Africa and Saudi Arabia), this principle was later subject to significant challenges.

The onset of the Cold War soon after the UDHR was conceived brought to the fore divisions over the inclusion of both economic and social rights and civil and political rights in the declaration. Capitalist states tended to place strong emphasis on civil and political rights (such as freedom of association and expression), and were reluctant to include economic and social rights (such as the right to work and the right to join a union). Socialist states placed much greater importance on economic and social rights and argued strongly for their inclusion.

Because of the divisions over which rights to include, and because some states declined to ratify any treaties including certain specific interpretations of human rights, and despite the Soviet bloc and a number of developing countries arguing strongly for the inclusion of all rights in a so-called "Unity Resolution", the rights enshrined in the UDHR were split into two separate covenants, allowing states to adopt some rights and derogate others. Though this allowed the covenants to be created, it denied the proposed principle that all rights are linked which was central to some interpretations of the UDHR.

Although the UDHR is a non-binding resolution, it is now considered to be a central component of international customary law which may be invoked under appropriate circumstances by state judiciaries and other judiciaries.

In 1966, the International Covenant on Civil and Political Rights (ICCPR) and the International Covenant on Economic, Social and Cultural Rights (ICESCR) were adopted by the United Nations, between them making the rights contained in the UDHR binding on all states. However, they came into force only in 1976, when they were ratified by a sufficient number of countries (despite achieving the ICCPR, a covenant including no economic or social rights, the US only ratified the ICCPR in 1992). The ICESCR commits 155 state parties to work toward the granting of economic, social, and cultural rights (ESCR) to individuals. 
Since then numerous other treaties (pieces of legislation) have been offered at the international level. They are generally known as "human rights instruments". Some of the most significant are:


The United Nations (UN) is the only multilateral governmental agency with universally accepted international jurisdiction for universal human rights legislation. All UN organs have advisory roles to the United Nations Security Council and the United Nations Human Rights Council, and there are numerous committees within the UN with responsibilities for safeguarding different human rights treaties. The most senior body of the UN with regard to human rights is the Office of the High Commissioner for Human Rights. The United Nations has an international mandate to:

The UN Human Rights Council, created in 2005, has a mandate to investigate alleged human rights violations. 47 of the 193 UN member states sit on the Council, elected by simple majority in a secret ballot of the United Nations General Assembly. Members serve a maximum of six years and may have their membership suspended for gross human rights abuses. The Council is based in Geneva, and meets three times a year; with additional meetings to respond to urgent situations.

Independent experts ("rapporteurs") are retained by the Council to investigate alleged human rights abuses and to report to the Council.

The Human Rights Council may request that the Security Council refer cases to the International Criminal Court (ICC) even if the issue being referred is outside the normal jurisdiction of the ICC.

In addition to the political bodies whose mandate flows from the UN charter, the UN has set up a number of "treaty-based" bodies, comprising committees of independent experts who monitor compliance with human rights standards and norms flowing from the core international human rights treaties. They are supported by and are created by the treaty that they monitor, With the exception of the CESCR, which was established under a resolution of the Economic and Social Council to carry out the monitoring functions originally assigned to that body under the Covenant, they are technically autonomous bodies, established by the treaties that they monitor and accountable to the state parties of those treaties – rather than subsidiary to the United Nations, though in practice they are closely intertwined with the United Nations system and are supported by the UN High Commissioner for Human Rights (UNHCHR) and the UN Centre for Human Rights.

Each treaty body receives secretariat support from the Human Rights Council and Treaties Division of Office of the High Commissioner on Human Rights (OHCHR) in Geneva except CEDAW, which is supported by the Division for the Advancement of Women (DAW). CEDAW formerly held all its sessions at United Nations headquarters in New York but now frequently meets at the United Nations Office in Geneva; the other treaty bodies meet in Geneva. The Human Rights Committee usually holds its March session in New York City.

There are many regional agreements and organizations promoting and governing human rights.

The African Union (AU) is a supranational union consisting of fifty-five African states. Established in 2001, the AU's purpose is to help secure Africa's democracy, human rights, and a sustainable economy, especially by bringing an end to intra-African conflict and creating an effective common market.

The African Commission on Human and Peoples' Rights (ACHPR) is a quasi-judicial organ of the African Union tasked with promoting and protecting human rights and collective (peoples') rights throughout the African continent as well as interpreting the African Charter on Human and Peoples' Rights and considering individual complaints of violations of the Charter. The Commission has three broad areas of responsibility:


In pursuit of these goals, the Commission is mandated to "collect documents, undertake studies and researches on African problems in the field of human and peoples, rights, organise seminars, symposia and conferences, disseminate information, encourage national and local institutions concerned with human and peoples' rights and, should the case arise, give its views or make recommendations to governments" (Charter, Art. 45).

With the creation of the African Court on Human and Peoples' Rights (under a protocol to the Charter which was adopted in 1998 and entered into force in January 2004), the Commission will have the additional task of preparing cases for submission to the Court's jurisdiction. In a July 2004 decision, the AU Assembly resolved that the future Court on Human and Peoples' Rights would be integrated with the African Court of Justice.

The Court of Justice of the African Union is intended to be the "principal judicial organ of the Union" (Protocol of the Court of Justice of the African Union, Article 2.2). Although it has not yet been established, it is intended to take over the duties of the African Commission on Human and Peoples' Rights, as well as act as the supreme court of the African Union, interpreting all necessary laws and treaties. The Protocol establishing the African Court on Human and Peoples' Rights entered into force in January 2004 but its merging with the Court of Justice has delayed its establishment. The Protocol establishing the Court of Justice will come into force when ratified by 15 countries.

There are many countries in Africa accused of human rights violations by the international community and NGOs.

The Organization of American States (OAS) is an international organization, headquartered in Washington, D.C., United States. Its members are the thirty-five independent states of the Americas. Over the course of the 1990s, with the end of the Cold War, the return to democracy in Latin America, and the thrust toward globalization, the OAS made major efforts to reinvent itself to fit the new context. Its stated priorities now include the following:


The Inter-American Commission on Human Rights (the IACHR) is an autonomous organ of the Organization of American States, also based in Washington, D.C. Along with the Inter-American Court of Human Rights, based in San José, Costa Rica, it is one of the bodies that comprise the inter-American system for the promotion and protection of human rights. The IACHR is a permanent body which meets in regular and special sessions several times a year to examine allegations of human rights violations in the hemisphere. Its human rights duties stem from three documents:


The Inter-Americal Court of Human Rights was established in 1979 with the purpose of enforcing and interpreting the provisions of the American Convention on Human Rights. Its two main functions are thus adjudicatory and advisory. Under the former, it hears and rules on the specific cases of human rights violations referred to it. Under the latter, it issues opinions on matters of legal interpretation brought to its attention by other OAS bodies or member states.

There are no Asia-wide organisations or conventions to promote or protect human rights. Countries vary widely in their approach to human rights and their record of human rights protection.

The Association of Southeast Asian Nations (ASEAN) is a geo-political and economic organization of 10 countries located in Southeast Asia, which was formed in 1967 by Indonesia, Malaysia, the Philippines, Singapore and Thailand. The organisation now also includes Brunei Darussalam, Vietnam, Laos, Myanmar and Cambodia. In October 2009, the ASEAN Intergovernmental Commission on Human Rights was inaugurated, and subsequently, the ASEAN Human Rights Declaration was adopted unanimously by ASEAN members on 18 November 2012.

The Arab Charter on Human Rights (ACHR) was adopted by the Council of the League of Arab States on 22 May 2004.

The Council of Europe, founded in 1949, is the oldest organisation working for European integration. It is an international organisation with legal personality recognised under public international law and has observer status with the United Nations. The seat of the Council of Europe is in Strasbourg in France. The Council of Europe is responsible for both the European Convention on Human Rights and the European Court of Human Rights. These institutions bind the Council's members to a code of human rights which, though strict, are more lenient than those of the United Nations charter on human rights. The Council also promotes the European Charter for Regional or Minority Languages and the European Social Charter. Membership is open to all European states which seek European integration, accept the principle of the rule of law and are able and willing to guarantee democracy, fundamental human rights and freedoms.

The Council of Europe is an organisation that is not part of the European Union, but the latter is expected to accede to the European Convention and potentially the Council itself. The EU has its own human rights document; the Charter of Fundamental Rights of the European Union.

The European Convention on Human Rights defines and guarantees since 1950 human rights and fundamental freedoms in Europe. All 47 member states of the Council of Europe have signed this Convention and are therefore under the jurisdiction of the European Court of Human Rights in Strasbourg. In order to prevent torture and inhuman or degrading treatment (Article 3 of the Convention), the European Committee for the Prevention of Torture was established.

Several theoretical approaches have been advanced to explain how and why human rights become part of social expectations.

One of the oldest Western philosophies on human rights is that they are a product of a natural law, stemming from different philosophical or religious grounds.

Other theories hold that human rights codify moral behavior which is a human social product developed by a process of biological and social evolution (associated with Hume). Human rights are also described as a sociological pattern of rule setting (as in the sociological theory of law and the work of Weber). These approaches include the notion that individuals in a society accept rules from legitimate authority in exchange for security and economic advantage (as in Rawls) – a social contract.

Natural law theories base human rights on a "natural" moral, religious or even biological order which is independent of transitory human laws or traditions.

Socrates and his philosophic heirs, Plato and Aristotle, posited the existence of natural justice or natural right ("dikaion physikon", "δικαιον φυσικον", Latin "ius naturale"). Of these, Aristotle is often said to be the father of natural law, although evidence for this is due largely to the interpretations of his work of Thomas Aquinas.

The development of this tradition of natural justice into one of natural law is usually attributed to the Stoics.

Some of the early Church fathers sought to incorporate the until then pagan concept of natural law into Christianity. Natural law theories have featured greatly in the philosophies of Thomas Aquinas, Francisco Suárez, Richard Hooker, Thomas Hobbes, Hugo Grotius, Samuel von Pufendorf, and John Locke.

In the Seventeenth Century Thomas Hobbes founded a contractualist theory of legal positivism on what all men could agree upon: what they sought (happiness) was subject to contention, but a broad consensus could form around what they feared (violent death at the hands of another). The natural law was how a rational human being, seeking to survive and prosper, would act. It was discovered by considering humankind's natural rights, whereas previously it could be said that natural rights were discovered by considering the natural law. In Hobbes' opinion, the only way natural law could prevail was for men to submit to the commands of the sovereign. In this lay the foundations of the theory of a social contract between the governed and the governor.

Hugo Grotius based his philosophy of international law on natural law. He wrote that "even the will of an omnipotent being cannot change or abrogate" natural law, which "would maintain its objective validity even if we should assume the impossible, that there is no God or that he does not care for human affairs." ("De iure belli ac pacis", Prolegomeni XI). This is the famous argument "etiamsi daremus" ("non-esse Deum"), that made natural law no longer dependent on theology.

John Locke incorporated natural law into many of his theories and philosophy, especially in "Two Treatises of Government". Locke turned Hobbes' prescription around, saying that if the ruler went against natural law and failed to protect "life, liberty, and property," people could justifiably overthrow the existing state and create a new one.

The Belgian philosopher of law Frank van Dun is one among those who are elaborating a secular conception of natural law in the liberal tradition. There are also emerging and secular forms of natural law theory that define human rights as derivative of the notion of universal human dignity.

The term "human rights" has replaced the term "natural rights" in popularity, because the rights are less and less frequently seen as requiring natural law for their existence.

The philosopher John Finnis argues that human rights are justifiable on the grounds of their instrumental value in creating the necessary conditions for human well-being. Interest theories highlight the duty to respect the rights of other individuals on grounds of self-interest:

The biological theory considers the comparative reproductive advantage of human social behavior based on empathy and altruism in the context of natural selection.

The most common categorization of human rights is to split them into civil and political rights, and economic, social and cultural rights.

Civil and political rights are enshrined in articles 3 to 21 of the Universal Declaration of Human Rights and in the ICCPR. Economic, social and cultural rights are enshrined in articles 22 to 28 of the Universal Declaration of Human Rights and in the ICESCR. The UDHR included both economic, social and cultural rights and civil and political rights because it was based on the principle that the different rights could only successfully exist in combination:

This is held to be true because without civil and political rights the public cannot assert their economic, social and cultural rights. Similarly, without livelihoods and a working society, the public cannot assert or make use of civil or political rights (known as the "full belly thesis")

Although accepted by the signaturies to the UDHR, most of them do not in practice give equal weight to the different types of rights. Western cultures have often given priority to civil and political rights, sometimes at the expense of economic and social rights such as the right to work, to education, health and housing. For example, in the United States there is no universal access to healthcare free at the point of use. That is not to say that Western cultures have overlooked these rights entirely (the welfare states that exist in Western Europe are evidence of this). Similarly the ex Soviet bloc countries and Asian countries have tended to give priority to economic, social and cultural rights, but have often failed to provide civil and political rights.

Another categorization, offered by Karel Vasak, is that there are "three generations of human rights": first-generation civil and political rights (right to life and political participation), second-generation economic, social and cultural rights (right to subsistence) and third-generation solidarity rights (right to peace, right to clean environment). Out of these generations, the third generation is the most debated and lacks both legal and political recognition. This categorisation is at odds with the indivisibility of rights, as it implicitly states that some rights can exist without others. Prioritisation of rights for pragmatic reasons is however a widely accepted necessity. Human rights expert Philip Alston argues:

He, and others, urge caution with prioritisation of rights:

Some human rights are said to be "inalienable rights." The term inalienable rights (or unalienable rights) refers to "a set of human rights that are fundamental, are not awarded by human power, and cannot be surrendered."

The adherence to the principle of indivisibility by the international community was reaffirmed in 1995:

This statement was again endorsed at the 2005 World Summit in New York (paragraph 121).

The UDHR enshrines, by definition, rights that apply to all humans equally, whichever geographical location, state, race or culture they belong to.

Proponents of cultural relativism suggest that human rights are not all universal, and indeed conflict with some cultures and threaten their survival.

Rights which are most often contested with relativistic arguments are the rights of women. For example, Female genital mutilation occurs in different cultures in Africa, Asia and South America. It is not mandated by any religion, but has become a tradition in many cultures. It is considered a violation of women's and girl's rights by much of the international community, and is outlawed in some countries.

Universalism has been described by some as cultural, economic or political imperialism. In particular, the concept of human rights is often claimed to be fundamentally rooted in a politically liberal outlook which, although generally accepted in Europe, Japan or North America, is not necessarily taken as standard elsewhere.

For example, in 1981, the Iranian representative to the United Nations, Said Rajaie-Khorassani, articulated the position of his country regarding the Universal Declaration of Human Rights by saying that the UDHR was "a secular understanding of the Judeo-Christian tradition", which could not be implemented by Muslims without trespassing the Islamic law. The former Prime Ministers of Singapore, Lee Kuan Yew, and of Malaysia, Mahathir bin Mohamad both claimed in the 1990s that "Asian values" were significantly different from western values and included a sense of loyalty and foregoing personal freedoms for the sake of social stability and prosperity, and therefore authoritarian government is more appropriate in Asia than democracy. This view is countered by Mahathir's former deputy:

and also by Singapore's opposition leader Chee Soon Juan who states that it is racist to assert that Asians do not want human rights.

An appeal is often made to the fact that influential human rights thinkers, such as John Locke and John Stuart Mill, have all been Western and indeed that some were involved in the running of Empires themselves.

Relativistic arguments tend to neglect the fact that modern human rights are new to all cultures, dating back no further than the UDHR in 1948. They also don't account for the fact that the UDHR was drafted by people from many different cultures and traditions, including a US Roman Catholic, a Chinese Confucian philosopher, a French Zionist and a representative from the Arab League, amongst others, and drew upon advice from thinkers such as Mahatma Gandhi.

Michael Ignatieff has argued that cultural relativism is almost exclusively an argument used by those who wield power in cultures which commit human rights abuses, and that those whose human rights are compromised are the powerless. This reflects the fact that the difficulty in judging universalism versus relativism lies in who is claiming to represent a particular culture.

Although the argument between universalism and relativism is far from complete, it is an academic discussion in that all international human rights instruments adhere to the principle that human rights are universally applicable. The 2005 World Summit reaffirmed the international community's adherence to this principle:

Companies, NGOs, political parties, informal groups, and individuals are known as "non-State actors". Non-State actors can also commit human rights abuses, but are not subject to human rights law other than International Humanitarian Law, which applies to individuals.

Multi-national companies play an increasingly large role in the world, and are responsible for a large number of human rights abuses. Although the legal and moral environment surrounding the actions of governments is reasonably well developed, that surrounding multi-national companies is both controversial and ill-defined. Multi-national companies' primary responsibility is to their shareholders, not to those affected by their actions. Such companies are often larger than the economies of the states in which they operate, and can wield significant economic and political power. No international treaties exist to specifically cover the behavior of companies with regard to human rights, and national legislation is very variable. Jean Ziegler, Special Rapporteur of the UN Commission on Human Rights on the right to food stated in a report in 2003:

In August 2003 the Human Rights Commission's Sub-Commission on the Promotion and Protection of Human Rights produced draft "Norms on the responsibilities of transnational corporations and other business enterprises with regard to human rights". These were considered by the Human Rights Commission in 2004, but have no binding status on corporations and are not monitored.

Realism and national loyalties have been described as a destructive influence on the human rights movement because they deny people's innately similar human qualities.

With the exception of non-derogable human rights (international conventions class the right to life, the right to be free from slavery, the right to be free from torture and the right to be free from retroactive application of penal laws as non-derogable), the UN recognises that human rights can be limited or even pushed aside during times of national emergency – although

Rights that cannot be derogated for reasons of national security in any circumstances are known as peremptory norms or "jus cogens". Such International law obligations are binding on all states and cannot be modified by treaty.

The human rights enshrined in the UDHR, the Geneva Conventions and the various enforced treaties of the United Nations are enforceable in law. In practice, many rights are very difficult to legally enforce due to the absence of consensus on the application of certain rights, the lack of relevant national legislation or of bodies empowered to take legal action to enforce them.

There exist a number of internationally recognized organisations with worldwide mandate or jurisdiction over certain aspects of human rights:


The ICC and other international courts (see Regional human rights above exist to take action where the national legal system of a state is unable to try the case itself. If national law is able to safeguard human rights and punish those who breach human rights legislation, it has primary jurisdiction by complementarity. Only when all "local remedies" have been exhausted does international law take effect.

In over 110 countries National human rights institutions (NHRIs) have been set up to protect, promote or monitor human rights with jurisdiction in a given country. Although not all NHRIs are compliant with the Paris Principles, the number and effect of these institutions is increasing. The Paris Principles were defined at the first International Workshop on National Institutions for the Promotion and Protection of Human Rights in Paris on 7–9 October 1991, and adopted by United Nations Human Rights Commission Resolution 1992/54 of 1992 and the General Assembly Resolution 48/134 of 1993. The Paris Principles list a number of responsibilities for national institutions.

Universal jurisdiction is a controversial principle in international law whereby states claim criminal jurisdiction over persons whose alleged crimes were committed outside the boundaries of the prosecuting state, regardless of nationality, country of residence, or any other relation with the prosecuting country. The state backs its claim on the grounds that the crime committed is considered a crime against all, which any state is authorized to punish. The concept of universal jurisdiction is therefore closely linked to the idea that certain international norms are erga omnes, or owed to the entire world community, as well as the concept of jus cogens. In 1993 Belgium passed a "law of universal jurisdiction" to give its courts jurisdiction over crimes against humanity in other countries, and in 1998 Augusto Pinochet was arrested in London following an indictment by Spanish judge Baltasar Garzon under the universal jurisdiction principle. The principle is supported by Amnesty International and other human rights organisations as they believe certain crimes pose a threat to the international community as a whole and the community has a moral duty to act, but others, including Henry Kissinger (who has himself been accused of war crimes by several commentators), argue that state sovereignty is paramount, because breaches of rights committed in other countries are outside states' sovereign interest and because states could use the principle for political reasons.

Human rights violations occur when any state or non-state actor breaches any of the terms of the UDHR or other international human rights or humanitarian law. In regard to human rights violations of United Nations laws. Article 39 of the United Nations Charter designates the UN Security Council (or an appointed authority) as the only tribunal that may determine UN human rights violations.

Human rights abuses are monitored by United Nations committees, national institutions and governments and by many independent non-governmental organizations, such as Amnesty International, Human Rights Watch, World Organisation Against Torture, Freedom House, International Freedom of Expression Exchange and Anti-Slavery International. These organisations collect evidence and documentation of human rights abuses and apply pressure to promote human rights

Wars of aggression, war crimes and crimes against humanity, including genocide, are breaches of International humanitarian law.




</doc>
<doc id="1728007" url="https://en.wikipedia.org/wiki?curid=1728007" title="Foodservice">
Foodservice

Food service (US English) or catering industry (British English) defines those businesses, institutions, and companies responsible for any meal prepared outside the home. This industry includes restaurants, school and hospital cafeterias, catering operations, and many other formats.

The companies that supply foodservice operators are called foodservice distributors. Foodservice distributors sell goods like small wares (kitchen utensils) and foods. Some companies manufacture products in both consumer and foodservice versions. The consumer version usually comes in individual-sized packages with elaborate label design for retail sale. The foodservice version is packaged in a much larger industrial size and often lacks the colorful label designs of the consumer version.

The food system, including food service and food retailing supplied $1.24 trillion worth of food in 2010 in the US, $594 billion of which was supplied by food service facilities, defined by the USDA as any place which prepares food for immediate consumption on site, including locations that are not primarily engaged in dispensing meals such as recreational facilities and retail stores. Full-service and Fast-food restaurants account for 77% of all foodservice sales, with full-service restaurants accounting for just slightly more than fast food in 2010. The shifts in the market shares between fast food and full-service restaurants to market demand changes the offerings of both foods and services of both types of restaurants.

According to the National Restaurant Association a growing trend among US consumers for the foodservice industry is global cuisine with 66% of US consumers eating more widely in 2015 than in 2010, 80% of consumers eating 'ethnic' cuisines at least once a month, and 29% trying a new 'ethnic' cuisine within the last year.

The Foodservice distributor market size is as of 2015 $231 billion in the US; the national broadline market is controlled by US Foods and Sysco which combined have 60-70% share of the market and were blocked from merging by the FTC for reasons of market power.

Foodservice foods tends to be, on average, higher in calories and lower in key nutrients than foods prepared at home. Many restaurants, including fast food, have added more salads and fruit offerings and either by choice or in response to local legislation provided nutrition labeling.

In the US, the FDA is moving towards establishing uniform guidelines for fast food and restaurant labeling, proposed rules were published in 2011 and final regulations published on 1 December 2014 which supersede State and local menu-labeling provisions, going into effect 1 December 2015. Research has shown that the new labels may influence consumer choices, but primarily if it provides unexpected information and that health-conscious consumers are resistant to changing behaviors based on menu labeling Fast food restaurants are expected by the ERS to do better under the new menu labeling than full service restaurants as full-service restaurants tend to offer much more calorie-dense foods, with 50% of fast food meals being between 400 and 800 calories and less than 20% above 1000 calories, in contrast, full-service restaurants 20% of meals are above 1,400 calories. When consumers are aware of the calorie counts at full-service restaurants 20% choose lower calorie options and consumers also reduce their calorie intake over the rest of the day.

Eating one meal away from home each week translates to 2 extra pounds each year or a daily increase of 134 calories and a decrease in diet quality by 2 points on the Healthy Eating Index.

In addition; the likelihood of contracting a food-borne illness (such as typhoid and hepatitis B, or diseases caused by E. coli, H. pylori, Listeria, Salmonella, and Norovirus) is greatly increased due to food not being kept below or cooked to a temperature of higher than , not washing hands for at least 20 seconds for food handlers or not washing contaminated cutting boards and other kitchen tools in hot water.

Counter service is food ordered by the customer at the counter and either picked up at the counter by the customer or delivered to the table by restaurant staff. It is common in fast food restaurants in the United States, and in pubs and bars in the United Kingdom.

Table service is food ordered by the customer at the table and served to the customer's table by waiters and waitresses, also known as "servers". Table service is common in most restaurants. With table service, the customer generally pays at the end of meal. Various methods of table service can be provided, such as silver service.

Gueridon service is a form of food service provided by restaurants to their customers. This type of service encompasses preparing food (primarily salads, main dishes such as beef tartare, or desserts) in direct view of the guests, using a gueridon. A gueridon typically consists of a trolley that is equipped to transport, prepare, cook and serve food. There is a gas hob, chopping board, cutlery drawer, cold store (depending on the trolley type), and general working area.



</doc>
<doc id="29678" url="https://en.wikipedia.org/wiki?curid=29678" title="Trade">
Trade

Trade involves the transfer of goods or services from one person or entity to another, often in exchange for money. Economists refer to a system or network that allows trade as a market.

An early form of trade, barter, saw the direct exchange of goods and services for other goods and services. Barter involves trading things without the use of money. When either bartering party started to involve precious metals, these gained symbolic as well as practical importance. Modern traders generally negotiate through a medium of exchange, such as money. As a result, buying can be separated from selling, or earning. The invention of money (and later of credit, paper money and non-physical money) greatly simplified and promoted trade. Trade between two traders is called bilateral trade, while trade involving more than two traders is called multilateral trade.

In one modern view, trade exists due to specialization and the division of labor, a predominant form of economic activity in which individuals and groups concentrate on a small aspect of production, but use their output in trades for other products and needs. Trade exists between regions because different regions may have a comparative advantage (perceived or real) in the production of some trade-able commodity—including production of natural resources scarce or limited elsewhere. For example: different regions' sizes may encourage mass production. In such circumstances, trade at market prices between locations can benefit both locations.

Retail trade consists of the sale of goods or merchandise from a very fixed location (such as a department store, boutique or kiosk), online or by mail, in small or individual lots for direct consumption or use by the purchaser. Wholesale trade is defined as traffic in goods that are sold as merchandise to retailers, or to industrial, commercial, institutional, or other professional business users, or to other wholesalers and related subordinated services.

Historically, openness to free trade substantially increased in some areas from 1815 to the outbreak of World War I in 1914. Trade openness increased again during the 1920s, but collapsed (in particular in Europe and North America) during the Great Depression of the 1930s. Trade openness increased substantially again from the 1950s onwards (albeit with a slowdown during the oil crisis of the 1970s). Economists and economic historians contend that current levels of trade openness are the highest they have ever been.

"Trade" is from Middle English "trade" ("path, course of conduct"), introduced into English by Hanseatic merchants, from Middle Low German "trade" ("track, course"), from Old Saxon "trada" ("spoor, track"), from Proto-Germanic "*tradō" ("track, way"), and cognate with Old English "tredan" ("to tread").

"Commerce" is derived from the Latin "commercium", from "cum" "together" and "merx", "merchandise."

Trade originated with human communication in prehistoric times. Trading was the main facility of prehistoric people, who bartered goods and services from each other before the innovation of modern-day currency. Peter Watson dates the history of long-distance commerce from circa 150,000 years ago.

In the Mediterranean region the earliest contact between cultures involved members of the species "Homo sapiens", principally using the Danube river, at a time beginning 35,000–30,000 BP.

Some trace the origins of commerce to the very start of transactions in prehistoric times. Apart from traditional self-sufficiency, trading became a principal facility of prehistoric people, who bartered what they had for goods and services from each other.

Trade is believed to have taken place throughout much of recorded human history. There is evidence of the exchange of obsidian and flint during the stone age. Trade in obsidian is believed to have taken place in New Guinea from 17,000 BCE.
Robert Carr Bosanquet investigated trade in the Stone Age by excavations in 1901. Trade is believed to have first begun in south west Asia.

Archaeological evidence of obsidian use provides data on how this material was increasingly the preferred choice rather than chert from the late Mesolithic to Neolithic, requiring exchange as deposits of obsidian are rare in the Mediterranean region.

Obsidian is thought to have provided the material to make cutting utensils or tools, although since other more easily obtainable materials were available, use was found exclusive to the higher status of the tribe using "the rich man's flint".

Obsidian was traded at distances of 900 kilometres within the Mediterranean region.

Trade in the Mediterranean during the Neolithic of Europe was greatest in this material. Networks were in existence at around 12,000 BCE Anatolia was the source primarily for trade with the Levant, Iran and Egypt according to Zarins study of 1990. Melos and Lipari sources produced among the most widespread trading in the Mediterranean region as known to archaeology.

The Sari-i-Sang mine in the mountains of Afghanistan was the largest source for trade of lapis lazuli. The material was most largely traded during the Kassite period of Babylonia beginning 1595 BCE.

Ebla was a prominent trading centre during the third millennia, with a network reaching into Anatolia and north Mesopotamia.

Materials used for creating jewelry were traded with Egypt since 3000 BCE. Long-range trade routes first appeared in the 3rd millennium BCE, when Sumerians in Mesopotamia traded with the Harappan civilization of the Indus Valley. The Phoenicians were noted sea traders, traveling across the Mediterranean Sea, and as far north as Britain for sources of tin to manufacture bronze. For this purpose they established trade colonies the Greeks called emporia.

From the beginning of Greek civilization until the fall of the Roman empire in the 5th century, a financially lucrative trade brought valuable spice to Europe from the far east, including India and China. Roman commerce allowed its empire to flourish and endure. The latter Roman Republic and the Pax Romana of the Roman empire produced a stable and secure transportation network that enabled the shipment of trade goods without fear of significant piracy, as Rome had become the sole effective sea power in the Mediterranean with the conquest of Egypt and the near east.

In ancient Greece Hermes was the god of trade (commerce) and weights and measures, for Romans "Mercurius" also god of merchants, whose festival was celebrated by traders on the 25th day of the fifth month. The concept of free trade was an antithesis to the will and economic direction of the sovereigns of the ancient Greek states. Free trade between states was stifled by the need for strict internal controls (via taxation) to maintain security within the treasury of the sovereign, which nevertheless enabled the maintenance of a "" of civility within the structures of functional community life.

The fall of the Roman empire, and the succeeding Dark Ages brought instability to Western Europe and a near collapse of the trade network in the western world. Trade however continued to flourish among the kingdoms of Africa, Middle East, India, China and Southeast Asia. Some trade did occur in the west. For instance, Radhanites were a medieval guild or group (the precise meaning of the word is lost to history) of Jewish merchants who traded between the Christians in Europe and the Muslims of the Near East.

The first true maritime trade network in the Indian Ocean was by the Austronesian peoples of Island Southeast Asia, who built the first ocean-going ships. They established trade routes with Southern India and Sri Lanka as early as 1500 BC, ushering an exchange of material culture (like catamarans, outrigger boats, sewn-plank boats, and paan) and cultigens (like coconuts, sandalwood, bananas, and sugarcane); as well as connecting the material cultures of India and China. Indonesians, in particular were trading in spices (mainly cinnamon and cassia) with East Africa using catamaran and outrigger boats and sailing with the help of the Westerlies in the Indian Ocean. This trade network expanded to reach as far as Africa and the Arabian Peninsula, resulting in the Austronesian colonization of Madagascar by the first half of the first millennium AD. It continued up to historic times, later becoming the Maritime Silk Road.
The emergence of exchange networks in the Pre-Columbian societies of and near to Mexico are known to have occurred within recent years before and after 1500 BCE.

Trade networks reached north to Oasisamerica. There is evidence of established maritime trade with the cultures of northwestern South America and the Caribbean.

During the Middle Ages, commerce developed in Europe by trading luxury goods at trade fairs. Wealth became converted into movable wealth or capital. Banking systems developed where money on account was transferred across national boundaries. Hand to hand markets became a feature of town life, and were regulated by town authorities.

Western Europe established a complex and expansive trade network with cargo ships being the main workhorse for the movement of goods, Cogs and Hulks are two examples of such cargo ships. Many ports would develop their own extensive trade networks. The English port city of Bristol traded with peoples from what is modern day Iceland, all along the western coast of France, and down to what is now Spain.

During the Middle Ages, Central Asia was the economic center of the world. The Sogdians dominated the East-West trade route known as the Silk Road after the 4th century CE up to the 8th century CE, with Suyab and Talas ranking among their main centers in the north. They were the main caravan merchants of Central Asia.

From the 8th to the 11th century, the Vikings and Varangians traded as they sailed from and to Scandinavia. Vikings sailed to Western Europe, while Varangians to Russia. The Hanseatic League was an alliance of trading cities that maintained a trade monopoly over most of Northern Europe and the Baltic, between the 13th and 17th centuries.

Vasco da Gama pioneered the European Spice trade in 1498 when he reached Calicut after sailing around the Cape of Good Hope at the southern tip of the African continent. Prior to this, the flow of spice into Europe from India was controlled by Islamic powers, especially Egypt. The spice trade was of major economic importance and helped spur the Age of Discovery in Europe. Spices brought to Europe from the Eastern world were some of the most valuable commodities for their weight, sometimes rivaling gold.

From 1070 onward, kingdoms in West Africa became significant members of global trade. This came initially through the movement of gold and other resources sent out by Muslim traders on the Trans-Saharan trading network. Later, West Africa exported gold, spices, cloth, and slaves to European traders such as the Portuguese, Dutch, and English. This was often in exchange for cloth, iron, or cowrie shells which were used locally as currency.

Founded in 1352, the Bengal Sultanate was a major trading nation in the world and often referred to by the Europeans as the richest country to trade with.

In the 16th and 17th centuries, the Portuguese gained economic advantage in the Kingdom of Kongo due to different philosophies of trade. Whereas Portuguese traders concentrated on the accumulation of capital, in Kongo spiritual meaning was attached to many objects of trade. According to economic historian Toby Green, in Kongo "giving more than receiving was a symbol of spiritual and political power, and privilege."

In the 16th century, the Seventeen Provinces were the centre of free trade, imposing no exchange controls, and advocating the free movement of goods. Trade in the East Indies was dominated by Portugal in the 16th century, the Dutch Republic in the 17th century, and the British in the 18th century. The Spanish Empire developed regular trade links across both the Atlantic and the Pacific Oceans.
In 1776, Adam Smith published the paper "An Inquiry into the Nature and Causes of the Wealth of Nations". It criticised Mercantilism, and argued that economic specialisation could benefit nations just as much as firms. Since the division of labour was restricted by the size of the market, he said that countries having access to larger markets would be able to divide labour more efficiently and thereby become more productive. Smith said that he considered all rationalisations of import and export controls "dupery", which hurt the trading nation as a whole for the benefit of specific industries.

In 1799, the Dutch East India Company, formerly the world's largest company, became bankrupt, partly due to the rise of competitive free trade.
In 1817, David Ricardo, James Mill and Robert Torrens showed that free trade would benefit the industrially weak as well as the strong, in the famous theory of comparative advantage. In Principles of Political Economy and Taxation Ricardo advanced the doctrine still considered the most counterintuitive in economics:

The ascendancy of free trade was primarily based on national advantage in the mid 19th century. That is, the calculation made was whether it was in any particular country's self-interest to open its borders to imports.

John Stuart Mill proved that a country with monopoly pricing power on the international market could manipulate the terms of trade through maintaining tariffs, and that the response to this might be reciprocity in trade policy. Ricardo and others had suggested this earlier. This was taken as evidence against the universal doctrine of free trade, as it was believed that more of the economic surplus of trade would accrue to a country following "reciprocal", rather than completely free, trade policies. This was followed within a few years by the infant industry scenario developed by Mill promoting the theory that government had the duty to protect young industries, although only for a time necessary for them to develop full capacity. This became the policy in many countries attempting to industrialise and out-compete English exporters. Milton Friedman later continued this vein of thought, showing that in a few circumstances tariffs might be beneficial to the host country; but never for the world at large.

The Great Depression was a major economic recession that ran from 1929 to the late 1930s. During this period, there was a great drop in trade and other economic indicators.

The lack of free trade was considered by many as a principal cause of the depression causing stagnation and inflation. Only during the World War II the recession ended in the United States. Also during the war, in 1944, 44 countries signed the Bretton Woods Agreement, intended to prevent national trade barriers, to avoid depressions. It set up rules and institutions to regulate the international political economy: the International Monetary Fund and the International Bank for Reconstruction and Development (later divided into the World Bank and Bank for International Settlements). These organisations became operational in 1946 after enough countries ratified the agreement. In 1947, 23 countries agreed to the General Agreement on Tariffs and Trade to promote free trade.

The European Union became the world's largest exporter of manufactured goods and services, the biggest export market for around 80 countries.

Today, trade is merely a subset within a complex system of companies which try to maximize their profits by offering products and services to the market (which consists both of individuals and other companies) at the lowest production cost. A system of international trade has helped to develop the world economy but, in combination with bilateral or multilateral agreements to lower tariffs or to achieve free trade, has sometimes harmed third-world markets for local products.

Free trade advanced further in the late 20th century and early 2000s:

Protectionism is the policy of restraining and discouraging trade between states and contrasts with the policy of free trade. This policy often takes of form of tariffs and restrictive quotas. Protectionist policies were particularly prevalent in the 1930s, between the Great Depression and the onset of World War II.

Islamic teachings encourage trading (and condemn usury or interest).

Judeao-Christian teachings prohibit fraud and dishonest measures, and historically also forbade the charging of interest on loans.

The first instances of money were objects with intrinsic value. This is called commodity money and includes any commonly available commodity that has intrinsic value; historical examples include pigs, rare seashells, whale's teeth, and (often) cattle. In medieval Iraq, bread was used as an early form of money. In Mexico under Montezuma cocoa beans were money. 

Currency was introduced as a standardised money to facilitate a wider exchange of goods and services. This first stage of currency, where metals were used to represent stored value, and symbols to represent commodities, formed the basis of trade in the Fertile Crescent for over 1500 years.

Numismatists have examples of coins from the earliest large-scale societies, although these were initially unmarked lumps of precious metal.

The Doha round of World Trade Organization negotiations aimed to lower barriers to trade around the world, with a focus on making trade fairer for developing countries. Talks have been hung over a divide between the rich developed countries, represented by the G20, and the major developing countries. Agricultural subsidies are the most significant issue upon which agreement has been hardest to negotiate. By contrast, there was much agreement on trade facilitation and capacity building. The Doha round began in Doha, Qatar, and negotiations were continued in: Cancún, Mexico; Geneva, Switzerland; and Paris, France and Hong Kong.

Beginning around 1978, the government of the People's Republic of China (PRC) began an experiment in economic reform. In contrast to the previous Soviet-style centrally planned economy, the new measures progressively relaxed restrictions on farming, agricultural distribution and, several years later, urban enterprises and labor. The more market-oriented approach reduced inefficiencies and stimulated private investment, particularly by farmers, that led to increased productivity and output. One feature was the establishment of four (later five) Special Economic Zones located along the South-east coast.

The reforms proved spectacularly successful in terms of increased output, variety, quality, price and demand. In real terms, the economy doubled in size between 1978 and 1986, doubled again by 1994, and again by 2003. On a real per capita basis, doubling from the 1978 base took place in 1987, 1996 and 2006. By 2008, the economy was 16.7 times the size it was in 1978, and 12.1 times its previous per capita levels. International trade progressed even more rapidly, doubling on average every 4.5 years. Total two-way trade in January 1998 exceeded that for all of 1978; in the first quarter of 2009, trade exceeded the full-year 1998 level. In 2008, China's two-way trade totaled US$2.56 trillion.

In 1991 China joined the Asia-Pacific Economic Cooperation group, a trade-promotion forum.

International trade is the exchange of goods and services across national borders. In most countries, it represents a significant part of GDP. While international trade has been present throughout much of history (see Silk Road, Amber Road), its economic, social, and political importance have increased in recent centuries, mainly because of Industrialization, advanced transportation, globalization, multinational corporations, and outsourcing.

Empirical evidence for the success of trade can be seen in the contrast between countries such as South Korea, which adopted a policy of export-oriented industrialization, and India, which historically had a more closed policy. South Korea has done much better by economic criteria than India over the past fifty years, though its success also has to do with effective state institutions.

Trade sanctions against a specific country are sometimes imposed, in order to punish that country for some action. An embargo, a severe form of externally imposed isolation, is a blockade of all trade by one country on another. For example, the United States has had an embargo against Cuba for over 40 years.

International trade, which is governed by the World Trade Organization, can be restricted by both tariff and non-tariff barriers. International trade is usually regulated by governmental quotas and restrictions, and often taxed by tariffs. Tariffs are usually on imports, but sometimes countries may impose export tariffs or subsidies. Non-tariff barriers include Sanitary and Phytosanitary rules, labeling requirements and food safety regulations. All of these are called "trade barriers". If a government removes all trade barriers, a condition of free trade exists. A government that implements a protectionist policy establishes trade barriers. There are usually few trade restrictions within countries although a common feature of many developing countries is police and other road blocks along main highways, that primarily exist to extract bribes.

The "fair trade" movement, also known as the "trade justice" movement, promotes the use of labour, environmental and social standards for the production of commodities, particularly those exported from the Third and Second Worlds to the First World. Such ideas have also sparked a debate on whether trade itself should be codified as a human right.. 

Importing firms voluntarily adhere to fair trade standards or governments may enforce them through a combination of employment and commercial law. Proposed and practiced fair trade policies vary widely, ranging from the common prohibition of goods made using slave labour to minimum price support schemes such as those for coffee in the 1980s. Non-governmental organizations also play a role in promoting fair trade standards by serving as independent monitors of compliance with labeling requirements. As such, it is a form of Protectionism.




</doc>
<doc id="228047" url="https://en.wikipedia.org/wiki?curid=228047" title="Human communication">
Human communication

Human communication, or anthroposemiotics, is the field dedicated to understanding how humans communicate. Human communication is grounded in cooperative and shared intentions.

Humans have communication abilities that other animals do not. Being able to communicate aspects like time and place as though they were solid objects are a few examples. It is said that humans communicate to request help, to inform others, and to share attitudes as a way of bonding. Communication is a joint activity which largely depends on the ability to keep common attention, to share the relevant background knowledge and joint experience in order to get the content across and make sense in the exchanges.

The current study of human communication can be branched off into two major categories; rhetorical and relational. The focus of rhetorical communication is primarily on the study of influence; the art of rhetorical communication is based on the idea of persuasion. The relational approach examines communication from a transactional perspective; two or more people interact to reach an agreed perspective.

In its early stages, rhetoric was developed to help ordinary people prove their claims in court; this shows how persuasion is key in this form of communication. Aristotle stated that effective rhetoric is based on argumentation. As explained in the text, rhetoric involves a dominant party and a submissive party or a party that succumbs to that of the most dominant party. While the rhetorical approach stems from Western societies, the relational approach stems from Eastern societies. Eastern societies hold higher standards for cooperation, which makes sense as to why they would sway more toward a relational approach for that matter. "Maintaining valued relationships is generally seen as more important than exerting influence and control over others". "The study of human communication today is more diversified than ever before in its history".

Classification of human communication can be found in the workplace, especially for group work. Co-workers need to argue with each other to gain the best solutions for their projects, while they also need to nurture their relationship to maintain their collaboration. For example, in their group work, they may use the communication tactic of "saving face".

Spoken language involves speech, a mostly human quality to acquire. For example, chimpanzees are humans' closest relative, but they are unable to produce speech. Chimpanzees are the closest living species to humans. Chimpanzees are closer to humans, in genetic and evolutionary terms, than they are to gorillas or other apes. The fact that a chimpanzee will not acquire speech, even when raised in a human home with all the environmental input of a normal human child, is one of the central puzzles we face when contemplating the biology of our species. In repeated experiments, starting in the 1910s, chimpanzees raised in close contact with humans have universally failed to speak, or even to try to speak, despite their rapid progress in many other intellectual and motor domains. Each normal human is born with a capacity to rapidly and unerringly acquire their mother tongue, with little explicit teaching or coaching. In contrast, no nonhuman primate has spontaneously produced even a word of the local language.

Human communication can be subdivided into a variety of types:



</doc>
<doc id="10401954" url="https://en.wikipedia.org/wiki?curid=10401954" title="Family">
Family

In the context of human society, a family (from ) is a group of people related either by consanguinity (by recognized birth) or affinity (by marriage or other relationship). The purpose of families is to maintain the well-being of its members and of society. Ideally, families would offer predictability, structure, and safety as members mature and participate in the community. In most societies, it is within families that children acquire socialization for life outside the family. Additionally, as the basic unit for meeting the basic needs of its members, it provides a sense of boundaries for performing tasks in a safe environment, ideally builds a person into a functional adult, transmits culture, and ensures continuity of humankind with precedents of knowledge.

Anthropologists generally classify most family organizations as matrifocal (a mother and her children); patrifocal (a father and his children); conjugal (a wife, her husband, and children, also called the nuclear family); avuncular (for example, a grandparent, a brother, his sister, and her children); or extended (parents and children co-reside with other members of one parent's family).

Members of the immediate family may include spouses, parents, grandparents, brothers, sisters, sons, and daughters. Members of the extended family may include aunts, uncles, cousins, nephews, nieces, and siblings-in-law. Sometimes these are also considered members of the immediate family, depending on an individual's specific relationship with them, and the legal definition of "immediate family" varies. Sexual relations with family members are regulated by rules concerning incest such as the incest taboo.

The field of genealogy aims to trace family lineages through history. The family is also an important economic unit studied in family economics. The word "families" can be used metaphorically to create more inclusive categories such as community, nationhood, global village, and humanism.

One of the primary functions of the family involves providing a framework for the production and reproduction of persons biologically and socially. This can occur through the sharing of material substances (such as food); the giving and receiving of care and nurture (nurture kinship); jural rights and obligations; and moral and sentimental ties. Thus, one's experience of one's family shifts over time. From the perspective of children, the family is a "family of orientation": the family serves to locate children socially and plays a major role in their enculturation and socialization. From the point of view of the parent(s), the family is a "family of procreation", the goal of which is to produce, enculturate and socialize children. However, producing children is not the only function of the family; in societies with a sexual division of labor, marriage, and the resulting relationship between two people, it is necessary for the formation of an economically productive household.

Christopher Harris notes that the western conception of family is ambiguous and confused with the household, as revealed in the different contexts in which the word is used. Olivia Harris states this confusion is not accidental, but indicative of the familial ideology of capitalist, western countries that pass social legislation that insists members of a nuclear family should live together, and that those not so related should not live together; despite the ideological and legal pressures, a large percentage of families do not conform to the ideal nuclear family type.

The total fertility rate of women varies from country to country, from a high of 6.76 children born/woman in Niger to a low of 0.81 in Singapore (as of 2015). Fertility is low in most Eastern European and Southern European countries; and high in most Sub-Saharan African countries.

In some cultures, the mother's preference of family size influences that of the children through early adulthood. A parent's number of children strongly correlates with the number of children that their children will eventually have.

Although early western cultural anthropologists and sociologists considered family and kinship to be universally associated with relations by "blood" (based on ideas common in their own cultures) later research has shown that many societies instead understand family through ideas of living together, the sharing of food (e.g. milk kinship) and sharing care and nurture. Sociologists have a special interest in the function and status of family forms in stratified (especially capitalist) societies.

According to the work of scholars Max Weber, Alan Macfarlane, Steven Ozment, Jack Goody and Peter Laslett, the huge transformation that led to modern marriage in Western democracies was "fueled by the religio-cultural value system provided by elements of Judaism, early Christianity, Roman Catholic canon law and the Protestant Reformation".

Much sociological, historical and anthropological research dedicates itself to the understanding of this variation, and of changes in the family that form over time. Levitan claims:
"Times have changed; it is more acceptable and encouraged for mothers to work and fathers to spend more time at home with the children. The way roles are balanced between the parents will help children grow and learn valuable life lessons. There is [the] great importance of communication and equality in families, in order to avoid role strain."
The term "nuclear family" is commonly used, especially in the United States of America, to refer to conjugal families. A "conjugal" family includes only the spouses and unmarried children who are not of age. Some sociologists distinguish between conjugal families (relatively independent of the kindred of the parents and of other families in general) and nuclear families (which maintain relatively close ties with their kindred).
Other family structures - with (for example) blended parents, single parents, and domestic partnerships – have begun to challenge the normality of the nuclear family.

A "single-parent family" consists of one parent together with their children, where the parent is either widowed, divorced (and not remarried), or never married. The parent may have sole custody of the children, or separated parents may have a shared-parenting arrangement where the children divide their time (possibly equally) between two different single-parent families or between one single-parent family and one blended family. As compared to sole custody, physical, mental and social well-being of children may be improved by shared-parenting arrangements and by children having greater access to both parents. The number of single-parent families have been increasing, and about half of all children in the United States will live in a single-parent family at some point before they reach the age of 18. Most single-parent families are headed by a mother, but the number of single-parent families headed by fathers is increasing.

A "matrifocal" family consists of a mother and her children. Generally, these children are her biological offspring, although adoption of children is a practice in nearly every society. This kind of family occurs commonly where women have the resources to rear their children by themselves, or where men are more mobile than women. As a definition, "a family or domestic group is matrifocal when it is centred on a woman and her children. In this case, the father(s) of these children are intermittently present in the life of the group and occupy a secondary place. The children's mother is not necessarily the wife of one of the children's fathers."

The term "extended family" is also common, especially in the United States. This term has two distinct meanings:


These types refer to ideal or normative structures found in particular societies. Any society will exhibit some variation in the actual composition and conception of families.

The term "family of choice," also sometimes referred to as "chosen family," is common within the LGBT community, veterans, individuals who have suffered abuse, and those who have no contact with biological "parents". It refers to the group of people in an individual's life that satisfies the typical role of family as a support system. The term differentiates between the "family of origin" (the biological family or that in which people are raised) and those that actively assume that ideal role.
The family of choice may or may not include some or all of the members of the family of origin. This terminology stems from the fact that many LGBT individuals, upon coming out, face rejection or shame from the families they were raised in. The term family of choice is also used by individuals in the 12 step communities, who create close-knit "family" ties through the recovery process.

The term "blended family" or "stepfamily" describes families with mixed parents: one or both parents remarried, bringing children of the former family into the new family. Also in sociology, particularly in the works of social psychologist Michael Lamb, "traditional family" refers to "a middle-class family with a bread-winning father and a stay-at-home mother, married to each other and raising their biological children," and "nontraditional" to exceptions to this rule. Most of the US households are now non-traditional under this definition. Critics of the term "traditional family" point out that in most cultures and at most times, the extended family model has been most common, not the nuclear family, though it has had a longer tradition in England than in other parts of Europe and Asia which contributed large numbers of immigrants to the Americas. The nuclear family became the most common form in the U.S. in the 1960s and 1970s.

In terms of communication patterns in families, there are a certain set of beliefs within the family that reflect how its members should communicate and interact. These family communication patterns arise from two underlying sets of beliefs. One being conversation orientation (the degree to which the importance of communication is valued) and two, conformity orientation (the degree to which families should emphasize similarities or differences regarding attitudes, beliefs, and values).

A monogamous family is based on a legal or social monogamy. In this case, an individual has only one (official) partner during their lifetime or at any one time (i.e. serial monogamy). This means that a person may not have several different legal spouses at the same time, as this is usually prohibited by bigamy laws, in jurisdictions that require monogamous marriages.

Polygamy is a marriage that includes more than two partners. When a man is married to more than one wife at a time, the relationship is called polygyny; and when a woman is married to more than one husband at a time, it is called polyandry. If a marriage includes multiple husbands and wives, it can be called polyamory, group or conjoint marriage.

Polygyny is a form of plural marriage, in which a man is allowed more than one wife . In modern countries that permit polygamy, polygyny is typically the only form permitted. Polygyny is practiced primarily (but not only) in parts of the Middle East and Africa; and is often associated with Islam, however, there are certain conditions in Islam that must be met to perform polygyny.

Polyandry is a form of marriage whereby a woman takes two or more husbands at the same time.<ref name="Starkweather/Hames 2012"></ref> Fraternal polyandry, where two or more brothers are married to the same wife, is a common form of polyandry. Polyandry was traditionally practiced in areas of the Himalayan mountains, among Tibetans in Nepal, in parts of China and in parts of northern India. Polyandry is most common in societies marked by high male mortality or where males will often be apart from the rest of the family for a considerable period of time.

A first-degree relative is one who shares 50% of your DNA through direct inheritance, such as a full sibling, parent or progeny.

There is another measure for the degree of relationship, which is determined by counting up generations to the first common ancestor and back down to the target individual, which is used for various genealogical and legal purposes. 

In his book "Systems of Consanguinity and Affinity of the Human Family", anthropologist Lewis Henry Morgan (1818–1881) performed the first survey of kinship terminologies in use around the world. Although much of his work is now considered dated, he argued that kinship terminologies reflect different sets of distinctions. For example, most kinship terminologies distinguish between sexes (the difference between a brother and a sister) and between generations (the difference between a child and a parent). Moreover, he argued, kinship terminologies distinguish between relatives by blood and marriage (although recently some anthropologists have argued that many societies define kinship in terms other than "blood").

Morgan made a distinction between kinship systems that use "classificatory" terminology and those that use "descriptive" terminology. Classificatory systems are generally and erroneously understood to be those that "class together" with a single term relatives who actually do not have the same type of relationship to ego. (What defines "same type of relationship" under such definitions seems to be genealogical relationship. This is problematic given that any genealogical description, no matter how standardized, employs words originating in a folk understanding of kinship.) What Morgan's terminology actually differentiates are those (classificatory) kinship systems that do not distinguish lineal and collateral relationships and those (descriptive) kinship systems that do. Morgan, a lawyer, came to make this distinction in an effort to understand Seneca inheritance practices. A Seneca man's effects were inherited by his sisters' children rather than by his own children. Morgan identified six basic patterns of kinship terminologies:

Most Western societies employ Eskimo kinship terminology. This kinship terminology commonly occurs in societies based on conjugal (or nuclear) families, where nuclear families have a degree of relative mobility. Members of the nuclear use descriptive kinship terms:

Such systems generally assume that the mother's husband is also the biological father. In some families, a woman may have children with more than one man or a man may have children with more than one woman. The system refers to a child who shares only one parent with another child as a "half-brother" or "half-sister". For children who do not share biological or adoptive parents in common, English-speakers use the term "stepbrother" or "stepsister" to refer to their new relationship with each other when one of their biological parents marries one of the other child's biological parents. Any person (other than the biological parent of a child) who marries the parent of that child becomes the "stepparent" of the child, either the "stepmother" or "stepfather". The same terms generally apply to children adopted into a family as to children born into the family. In the United States, one in five mothers has children by different fathers; among mothers with two or more children the figure is higher, with 28% having children with at least two different men. Such families are more common among Blacks and Hispanics and among the lower socioeconomic class.

Typically, societies with conjugal families also favor neolocal residence; thus upon marriage, a person separates from the nuclear family of their childhood (family of orientation) and forms a new nuclear family (family of procreation). However, in western society, the single parent family has been growing more accepted and has begun to make an impact on culture. Single parent families are more commonly single mother families than single father. These families sometimes face difficult issues besides the fact that they have to rear their children on their own, for example, low income making it difficult to pay for rent, child care, and other necessities for a healthy and safe home. Members of the nuclear families of members of one's own (former) nuclear family may class as lineal or as collateral. Kin who regard them as lineal refer to them in terms that build on the terms used within the nuclear family:

For collateral relatives, more classificatory terms come into play, terms that do not build on the terms used within the nuclear family:

When additional generations intervene (in other words, when one's collateral relatives belong to the same generation as one's grandparents or grandchildren), the prefixes "great-" or "grand-" modifies these terms. Also, as with grandparents and grandchildren, as more generations intervene the prefix becomes "great-grand-," adding another "great-" for each additional generation. Most collateral relatives have never had membership of the nuclear family of the members of one's own nuclear family.


Cousins of an older generation (in other words, one's parents' first cousins), although technically first cousins once removed, are often classified with "aunts" and "uncles." English-speakers mark relationships by marriage (except for wife/husband) with the tag "-in-law." The mother and father of one's spouse become one's mother-in-law and father-in-law; the wife of one's son becomes one's daughter-in-law and the husband of one's daughter becomes one's son-in-law. The term "sister-in-law" refers to three essentially different relationships, either the wife of one's brother, or the sister of one's spouse. "Brother-in-law" is the husband of one's sister, or the brother of one's spouse. The terms "half-brother" and "half-sister" indicate siblings who share only one biological parent. The term "aunt-in-law" is the wife of one's uncle, or the aunt of one's spouse. "Uncle-in-law" is the husband of one's aunt, or the uncle of one's spouse. "Cousin-in-law" is the spouse of one's cousin, or the cousin of one's spouse. The term "niece-in-law" is the wife of one's nephew, or the niece of one's spouse. "Nephew-in-law" is the husband of one's niece, or the nephew of one's spouse. The grandmother and grandfather of one's spouse become one's grandmother-in-law and grandfather-in-law; the wife of one's grandson becomes one's granddaughter-in-law and the husband of one's granddaughter becomes one's grandson-in-law. The term "co-sister-in-law" is the wife of one's brother of one's spouse. "Co-brother-in-law" is the husband of one's sister of one's spouse. The term "co-aunt-in-law" is the wife of one's uncle of one's spouse. "Co-uncle-in-law" is the husband of one's aunt of one's spouse. "Co-cousin-in-law" is the spouse of one's cousin of one's spouse. The term "co-niece-in-law" is the wife of one's nephew of one's spouse. "Co-nephew-in-law" is the husband of one's niece of one's spouse. The mother and father of one's child-in-law become one's "co-mother-in-law" and "co-father-in-law".

Patrilineality, also known as "the male line" or "agnatic kinship", is a form of kinship system in which an individual's family membership derives from and is traced through his or her father's lineage. It generally involves the inheritance of property, rights, names, or titles by persons related through male kin.

A patriline ("father line") is a person's father, and additional ancestors that are traced only through males. One's patriline is thus a record of descent from a man in which the individuals in all intervening generations are male. In cultural anthropology, a patrilineage is a consanguineal male and female kinship group, each of whose members is descended from the common ancestor through male forebears.

Matrilineality is a form of kinship system in which an individual's family membership derives from and is traced through his or her mother's lineage.

It may also correlate with a societal system in which each person is identified with their matriline—their mother's lineage—and which can involve the inheritance of property and titles. A matriline is a line of descent from a female ancestor to a descendant in which the individuals in all intervening generations are mothersin other words, a "mother line".

In a matrilineal descent system, an individual is considered to belong to the same descent group as her or his mother. This matrilineal descent pattern is in contrasts to the more common pattern of patrilineal descent pattern.

Bilateral descent is a form of kinship system in which an individual's family membership derives from and is traced through both the paternal and maternal sides. The relatives on the mother's side and father's side are equally important for emotional ties or for transfer of property or wealth. It is a family arrangement where descent and inheritance are passed equally through both parents. Families who use this system trace descent through both parents simultaneously and recognize multiple ancestors, but unlike with cognatic descent it is not used to form descent groups.

Traditionally, this is found among some groups in West Africa, India, Australia, Indonesia, Melanesia, Malaysia and Polynesia. Anthropologists believe that a tribal structure based on bilateral descent helps members live in extreme environments because it allows individuals to rely on two sets of families dispersed over a wide area.

Early scholars of family history applied Darwin's biological theory of evolution in their theory of evolution of family systems. American anthropologist Lewis H. Morgan published "Ancient Society" in 1877 based on his theory of the three stages of human progress from Savagery through Barbarism to Civilization. Morgan's book was the "inspiration for Friedrich Engels' book" "The Origin of the Family, Private Property and the State" published in 1884.

Engels expanded Morgan's hypothesis that economical factors caused the transformation of primitive community into a class-divided society. Engels' theory of resource control, and later that of Karl Marx, was used to explain the cause and effect of change in family structure and function. The popularity of this theory was largely unmatched until the 1980s, when other sociological theories, most notably structural functionalism, gained acceptance.

Contemporary society generally views the family as a haven from the world, supplying absolute fulfillment. Zinn and Eitzen discuss the image of the "family as haven [...] a place of intimacy, love and trust where individuals may escape the competition of dehumanizing forces in modern society".
During industrialization, "[t]he family as a repository of warmth and tenderness (embodied by the mother) stands in opposition to the competitive and aggressive world of commerce (embodied by the father). The family's task was to protect against the outside world." However, Zinn and Eitzen note, "The protective image of the family has waned in recent years as the ideals of family fulfillment have taken shape. Today, the family is more compensatory than protective. It supplies what is vitally needed but missing in other social arrangements."

"The popular wisdom", according to Zinn and Eitzen, sees the family structures of the past as superior to those today, and families as more stable and happier at a time when they did not have to contend with problems such as illegitimate children and divorce. They respond to this, saying, "there is no golden age of the family gleaming at us in the far back historical past." "Desertion by spouses, illegitimate children, and other conditions that are considered characteristics of modern times existed in the past as well."

Others argue that whether or not one views the family as "declining" depends on one's definition of "family". "Married couples have dropped below half of all American households. This drop is shocking from traditional forms of the family system. Only a fifth of households were following traditional ways of having married couples raising a family together." In the Western World, marriages are no longer arranged for economic, social or political gain, and children are no longer expected to contribute to family income. Instead, people choose mates based on love. This increased role of love indicates a societal shift toward favoring emotional fulfilment and relationships within a family, and this shift necessarily weakens the institution of the family.

Margaret Mead considers the family as a main safeguard to continuing human progress. Observing, "Human beings have learned, laboriously, to be human", she adds: "we hold our present form of humanity on trust, [and] it is possible to lose it" ... "It is not without significance that the most successful large-scale abrogations of the family have occurred not among simple savages, living close to the subsistence edge, but among great nations and strong empires, the resources of which were ample, the populations huge, and the power almost unlimited"

Many countries (particularly Western) have, in recent years, changed their family laws in order to accommodate diverse family models. For instance, in the United Kingdom, in Scotland, the "Family Law (Scotland) Act 2006" provides cohabitants with some limited rights. In 2010, Ireland enacted the Civil Partnership and Certain Rights and Obligations of Cohabitants Act 2010. There have also been moves at an international level, most notably, the Council of Europe "European Convention on the Legal Status of Children Born out of Wedlock" which came into force in 1978. Countries which ratify it must ensure that children born outside marriage are provided with legal rights as stipulated in the text of this Convention. The Convention was ratified by the UK in 1981 and by Ireland in 1988.

Domestic violence (DV) is violence that happens within the family. The legal and social understanding of the concept of DV differs by culture. The definition of the term "domestic violence" varies, depending on the context in which it is used. It may be defined differently in medical, legal, political or social contexts. The definitions have varied over time, and vary in different parts of the world.

The Convention on preventing and combating violence against women and domestic violence states that:

In 1993, the United Nations Declaration on the Elimination of Violence against Women identified domestic violence as one of three contexts in which violence against women occurs, describing it as:

Family violence is a broader definition, often used to include child abuse, elder abuse, and other violent acts between family members.

Child abuse is defined by the WHO as:

Elder abuse is, according to the WHO: "a single, or repeated act, or lack of appropriate action, occurring within any relationship where there is an expectation of trust which causes harm or distress to an older person".

Child abuse is the physical, sexual or emotional maltreatment or neglect of a child or children. In the United States, the Centers for Disease Control and Prevention (CDC) and the Department for Children and Families (DCF) define child maltreatment as any act or series of acts of commission or omission by a parent or other caregiver that results in harm, potential for harm, or threat of harm to a child. Child abuse can occur in a child's home, or in the organizations, schools or communities the child interacts with. There are four major categories of child abuse: neglect, physical abuse, psychological or emotional abuse, and sexual abuse.

Abuse of parents by their children is a common but under reported and under researched subject. Parents are quite often subject to levels of childhood aggression in excess of normal childhood aggressive outbursts, typically in the form of verbal or physical abuse. Parents feel a sense of shame and humiliation to have that problem, so they rarely seek help and there is usually little or no help available anyway.

Elder abuse is "a single, or repeated act, or lack of appropriate action, occurring within any relationship where there is an expectation of trust, which causes harm or distress to an older person." This definition has been adopted by the World Health Organization from a definition put forward by Action on Elder Abuse in the UK. Laws protecting the elderly from abuse are similar to, and related to, laws protecting dependent adults from abuse.

The core element to the harm of elder abuse is the "expectation of trust" of the older person toward their abuser. Thus, it includes harms by people the older person knows or with whom they have a relationship, such as a spouse, partner or family member, a friend or neighbor, or people that the older person relies on for services. Many forms of elder abuse are recognized as types of domestic violence or family violence.

Forced and child marriages are practiced in certain regions of the world, particularly in Asia and Africa, and these types of marriages are associated with a high rate of domestic violence.

A forced marriage is a marriage where one or both participants are married without their freely given consent. The line between forced marriage and consensual marriage may become blurred, because the social norms of many cultures dictate that one should never oppose the desire of one's parents/relatives in regard to the choice of a spouse; in such cultures it is not necessary for violence, threats, intimidation etc. to occur, the person simply "consents" to the marriage even if he/she doesn't want it, out of the implied social pressure and duty. The customs of bride price and dowry, that exist in parts of the world, can lead to buying and selling people into marriage.

A child marriage is a marriage where one or both spouses are under 18. Child marriage was common throughout history but is today condemned by international human rights organizations. Child marriages are often arranged between the families of the future bride and groom, sometimes as soon as the girl is born. Child marriages can also occur in the context of marriage by abduction.

Family honor is an abstract concept involving the perceived quality of worthiness and respectability that affects the social standing and the self-evaluation of a group of related people, both corporately and individually. The family is viewed as the main source of honor and the community highly values the relationship between honor and the family. The conduct of family members reflects upon family honor and the way the family perceives itself, and is perceived by others. In cultures of honor maintaining the family honor is often perceived as more important than either individual freedom, or individual achievement. In extreme cases, engaging in acts that are deemed to tarnish the honor of the family results in honor killings. An honor killing is the homicide of a member of a family or social group by other members, due to the perpetrators' belief that the victim has brought shame or dishonor upon the family or community, usually for reasons such as refusing to enter an arranged marriage, being in a relationship that is disapproved by their relatives, having sex outside marriage, becoming the victim of rape, dressing in ways which are deemed inappropriate, or engaging in homosexual relations.

A family is often part of a sharing economy with common ownership.

Dowry is property (money, goods, or estate) that a wife or wife's family gives to her husband when the wife and husband marry. Offering dowry was common in many cultures historically (including in Europe and North America), but this practice today is mostly restricted to some areas primarily in the Indian subcontinent.

Bride price, (also bridewealth or bride token), is property paid by the groom or his family to the parents of a woman upon the marriage of their daughter to the groom. It is practiced mostly in Sub-Saharan Africa, parts of South-East Asia (Thailand, Cambodia), and parts of Central Asia.

Dower is property given to the bride herself by the groom at the time of marriage, and which remains under her ownership and control.

In some countries married couples benefit from various taxation advantages not available to a single person or to unmarried couples. For example, spouses may be allowed to average their combined incomes. Some jurisdictions recognize common law marriage or "de facto" relations for this purposes. In some jurisdictions there is also an option of civil partnership or domestic partnership.

Different property regimes exist for spouses. In many countries, each marriage partner has the choice of keeping their property separate or combining properties. In the latter case, called community property, when the marriage ends by divorce each owns half. In lieu of a will or trust, property owned by the deceased generally is inherited by the surviving spouse.

Reproductive rights are legal rights and freedoms relating to reproduction and reproductive health. These include the right to decide on issues regarding the number of children born, family planning, contraception, and private life, free from coercion and discrimination; as well as the right to access health services and adequate information. According to UNFPA, reproductive rights "include the right to decide the number, timing and spacing of children, the right to voluntarily marry and establish a family, and the right to the highest attainable standard of health, among others". Family planning refers to the factors that may be considered by individuals and couples in order for them to control their fertility, anticipate and attain the desired number of children and the spacing and timing of their births.

The state and church have been, and still are in some countries, involved in controlling the size of families, often using coercive methods, such as bans on contraception or abortion (where the policy is a natalist one—for example through tax on childlessness) or conversely, discriminatory policies against large families or even forced abortions (e.g., China's one-child policy in place from 1978 to 2015). Forced sterilization has often targeted ethnic minority groups, such as Roma women in Eastern Europe, or indigenous women in Peru (during the 1990s).

The parents' rights movement is a movement whose members are primarily interested in issues affecting parents and children related to family law, specifically parental rights and obligations. Mothers' rights movements focus on maternal health, workplace issues such as labor rights, breastfeeding, and rights in family law. The fathers' rights movement is a movement whose members are primarily interested in issues related to family law, including child custody and child support, that affect fathers and their children.

Children's rights are the human rights of children, with particular attention to the rights of special protection and care afforded to minors, including their right to association with both parents, their right to human identity, their right to be provided in regard to their other basic needs, and their right to be free from violence and abuse.

Each jurisdiction has its own marriage laws. These laws differ significantly from country to country; and these laws are often controversial. Areas of controversy include women's rights as well as same-sex marriage.

Legal reforms to family laws have taken place in many countries during the past few decades. These dealt primarily with gender equality within marriage and with divorce laws. Women have been given equal rights in marriage in many countries, reversing older family laws based on the dominant legal role of the husband. Coverture, which was enshrined in the common law of England and the US for several centuries and throughout most of the 19th century, was abolished. In some European countries the changes that lead to gender equality were slower. The period of 1975–1979 saw a major overhaul of family laws in countries such as Italy, Spain, Austria, West Germany, and Portugal. In 1978, the Council of Europe passed the "Resolution (78) 37 on equality of spouses in civil law". Among the last European countries to establish full gender equality in marriage were Switzerland. In 1985, a referendum guaranteed women legal equality with men within marriage. The new reforms came into force in January 1988. In Greece, in 1983, legislation was passed guaranteeing equality between spouses, abolishing dowry, and ending legal discrimination against illegitimate children. In 1981, Spain abolished the requirement that married women must have their husbands’ permission to initiate judicial proceedings the Netherlands, and France in the 1980s. In recent decades, the marital power has also been abolished in African countries that had this doctrine, but many African countries that were former French colonies still have discriminatory laws in their marriages regulations, such regulations originating in the Napoleonic Code that has inspired these laws. In some countries (predominantly Roman Catholic) divorce was legalized only recently (e.g. Italy (1970), Portugal (1975), Brazil (1977), Spain (1981), Argentina (1987), Ireland (1996), Chile (2004) and Malta (2011)) although annulment and legal separation were options. Philippines still does not allow divorce. (see Divorce law by country). The laws pertaining to the situation of children born outside marriage have also been revised in many countries (see Legitimacy (family law)).

Family medicine is a medical specialty devoted to comprehensive health care for people of all ages; it is based on knowledge of the patient in the context of the family and the community, emphasizing disease prevention and health promotion. The importance of family medicine is being increasingly recognized.

Maternal mortality or maternal death is defined by WHO as "the death of a woman while pregnant or within 42 days of termination of pregnancy, irrespective of the duration and site of the pregnancy, from any cause related to or aggravated by the pregnancy or its management but not from accidental or incidental causes." Historically, maternal mortality was a major cause of women's death. In recent decades, advances in healthcare have resulted in rates of maternal mortality having dropped dramatically, especially in Western countries. Maternal mortality however remains a serious problem in many African and Asian counties.

Infant mortality is the death of a child less than one year of age. Child mortality is the death of a child before the child's fifth birthday. Like maternal mortality, infant and child mortality were common throughout history, but have decreased significantly in modern times.

While in many parts of the world family policies seek to promote a gender-equal organization of the family life, in others the male-dominated family continues to be the official policy of the authorities, which is also supported by law. For instance, the Civil Code of Iran states at Article 1105: "In relations between husband and wife; the position of the head of the family is the exclusive right of the husband".

In some parts of the world, some governments promote a specific form of family, such as that based on traditional family values. The term "family values" is often used in political discourse in some countries, its general meaning being that of traditional or cultural values that pertain to the family's structure, function, roles, beliefs, attitudes, and ideals, usually involving the "traditional family"—a middle-class family with a breadwinner father and a homemaker mother, raising their biological children. Any deviation from this family model is considered a "nontraditional family". These family ideals are often advanced through policies such as marriage promotion. Some jurisdictions outlaw practices which they deem as socially or religiously unacceptable, such as fornication, cohabitation or adultery.

Work-family balance is a concept involving proper prioritizing between work/career and family life. It includes issues relating to the way how work and families intersect and influence each other. At a political level, it is reflected through policies such maternity leave and paternity leave. Since the 1950s, social scientists as well as feminists have increasingly criticized gendered arrangements of work and care, and the male breadwinner role, and policies are increasingly targeting men as fathers, as a tool of changing gender relations.

Article 8 of the European Convention on Human Rights provides a right to respect for one's "private and family life, his home and his correspondence", subject to certain restrictions that are "in accordance with law" and "necessary in a democratic society".

Certain social scientists have advocated the abolition of the family. An early opponent of the family was Socrates whose position was outlined by Plato in "The Republic". In Book 5 of "The Republic", Socrates tells his interlocutors that a just city is one in which citizens have no family ties.

The family being such a deep-rooted and much-venerated institution, few intellectuals have ventured to speak against it. Familialism has been atypically defined as a “social structure where ... a family's values are held in higher esteem than the values of the individual members of the family.” Favoritism granted to relatives regardless of merit is called nepotism.

The Russian-American rationalist and individualist philosopher, novelist and playwright Ayn Rand compared partiality towards consanguinity with racism, as a small-scale manifestation of the latter. “The worship of the family is merely racism, like a crudely primitive first installment on the worship of the tribe. It places the accident of birth above a man's values and duty to the tribe above a man's right to his own life.” Additionally, she spoke in favor of childfree lifestyle, while following it herself.

The British social critic, poet, mountaineer and occultist Aleister Crowley censured the institution of family in his works: “Horrid word, family! Its very etymology accuses it of servility and stagnation. / Latin, "famulus", a servant; Oscan, "Faamat", he dwells. … [T]hink what horrid images it evokes from the mind. Not only Victorian; wherever the family has been strong, it has always been an engine of tyranny. Weak members or weak neighbours: it is the mob spirit crushing genius, or overwhelming opposition by brute arithmetic. … In every Magical, or similar system, it is invariably the first condition which the Aspirant must fulfill: he must once and for all and for ever put his family outside his magical circle.”

One of the controversies regarding the family is the application of the concept of social justice to the private sphere of family relations, in particular with regard to the rights of women and children. Throughout much of the history, most philosophers who advocated for social justice focused on the public political arena, not on the family structures; with the family often being seen as a separate entity which needed to be protected from outside state intrusion. One notable exception was John Stuart Mill, who, in his work "The Subjection of Women", advocated for greater rights for women within marriage and family. Second wave feminists argued that the personal is political, stating that there are strong connections between personal experiences and the larger social and political structures. In the context of the feminist movement of the 1960s and 1970s, this was a challenge to the nuclear family and family values, as they were understood then. Feminists focused on domestic violence, arguing that the reluctance—in law or in practice—of the state to intervene and offer protection to women who have been abused within the family, is in violation of women's human rights, and is the result of an ideology which places family relations outside the conceptual framework of human rights.

In 2015, Nicholas Eberstadt, political economist at the American Enterprise Institute in Washington, described a "global flight from family" in an opinion piece in the "Wall Street Journal". Statistics from an infographic by Olivier Ballou showed that,

However, Swedish statisticians reported in 2013 that, in contrast to many countries, since the 2000s, fewer children have experienced their parents' separation, childlessness had decreased in Sweden and marriages had increased. It had also become more common for couples to have a third child suggesting that the nuclear family was no longer in decline in Sweden.




</doc>
<doc id="25778403" url="https://en.wikipedia.org/wiki?curid=25778403" title="Sport">
Sport

Sport includes all forms of competitive physical activity or games which, through casual or organized participation, at least in part aim to use, maintain or improve physical ability and skills while providing enjoyment to participants, and in some cases, entertainment for spectators. Sports can bring positive results to one's physical health. Hundreds of sports exist, from those between single contestants, through to those with hundreds of simultaneous participants, either in teams or competing as individuals. In certain sports such as racing, many contestants may compete, simultaneously or consecutively, with one winner; in others, the contest (a "match") is between two sides, each attempting to exceed the other. Some sports allow a "tie" or "draw", in which there is no single winner; others provide tie-breaking methods to ensure one winner and one loser. A number of contests may be arranged in a tournament producing a champion. Many sports leagues make an annual champion by arranging games in a regular sports season, followed in some cases by playoffs.

Sport is generally recognised as system of activities which are based in physical athleticism or physical dexterity, with the largest major competitions such as the Olympic Games admitting only sports meeting this definition, and other organisations such as the Council of Europe using definitions precluding activities without a physical element from classification as sports. However, a number of competitive, but non-physical, activities claim recognition as mind sports. The International Olympic Committee (through ARISF) recognises both chess and bridge as "bona fide" sports, and SportAccord, the international sports federation association, recognises five non-physical sports: bridge, chess, draughts (checkers), Go and xiangqi, and limits the number of mind games which can be admitted as sports.

Sport is usually governed by a set of rules or customs, which serve to ensure fair competition, and allow consistent adjudication of the winner. Winning can be determined by physical events such as scoring goals or crossing a line first. It can also be determined by judges who are scoring elements of the sporting performance, including objective or subjective measures such as technical performance or artistic impression.

Records of performance are often kept, and for popular sports, this information may be widely announced or reported in sport news. Sport is also a major source of entertainment for non-participants, with spectator sport drawing large crowds to sport venues, and reaching wider audiences through broadcasting. Sport betting is in some cases severely regulated, and in some cases is central to the sport.

According to A.T. Kearney, a consultancy, the global sporting industry is worth up to $620 billion as of 2013. The world's most accessible and practised sport is running, while association football is the most popular spectator sport.

The word "sport" comes from the Old French "desport" meaning "leisure", with the oldest definition in English from around 1300 being "anything humans find amusing or entertaining".

Other meanings include gambling and events staged for the purpose of gambling; hunting; and games and diversions, including ones that require exercise. Roget's defines the noun sport as an "activity engaged in for relaxation and amusement" with synonyms including diversion and recreation.

The singular term "sport" is used in most English dialects to describe the overall concept (e.g. "children taking part in sport"), with "sports" used to describe multiple activities (e.g. "football and rugby are the most popular sports in England"). American English uses "sports" for both terms.

The precise definition of what separates a sport from other leisure activities varies between sources. The closest to an international agreement on a definition is provided by SportAccord, which is the association for all the largest international sports federations (including association football, athletics, cycling, tennis, equestrian sports, and more), and is therefore the "de facto" representative of international sport.

SportAccord uses the following criteria, determining that a sport should:

They also recognise that sport can be primarily physical (such as rugby or athletics), primarily mind (such as chess or Go), predominantly motorised (such as Formula 1 or powerboating), primarily co-ordination (such as billiard sports), or primarily animal-supported (such as equestrian sport).

The inclusion of mind sports within sport definitions has not been universally accepted, leading to legal challenges from governing bodies in regards to being denied funding available to sports. Whilst SportAccord recognises a small number of mind sports, it is not open to admitting any further mind sports.

There has been an increase in the application of the term "sport" to a wider set of non-physical challenges such as video games, also called esports, especially due to the large scale of participation and organised competition, but these are not widely recognised by mainstream sports organisations. According to Council of Europe, European Sports Charter, article 2.i, Sport' means all forms of physical activity which, through casual or organised participation, aim at expressing or improving physical fitness and mental well-being, forming social relationships or obtaining results in competition at all levels."

There are opposing views on the necessity of competition as a defining element of a sport, with almost all professional sport involving competition, and governing bodies requiring competition as a prerequisite of recognition by the International Olympic Committee (IOC) or SportAccord.

Other bodies advocate widening the definition of sport to include all physical activity. For instance, the Council of Europe include all forms of physical exercise, including those competed just for fun.

In order to widen participation, and reduce the impact of losing on less able participants, there has been an introduction of non-competitive physical activity to traditionally competitive events such as school sports days, although moves like this are often controversial.

In competitive events, participants are graded or classified based on their "result" and often divided into groups of comparable performance, (e.g. gender, weight and age). The measurement of the result may be objective or subjective, and corrected with "handicaps" or penalties. In a race, for example, the time to complete the course is an objective measurement. In gymnastics or diving the result is decided by a panel of judges, and therefore subjective. There are many shades of judging between boxing and mixed martial arts, where victory is assigned by judges if neither competitor has lost at the end of the match time.

Artifacts and structures suggest sport in China as early as 2000 BC. Gymnastics appears to have been popular in China's ancient past. Monuments to the Pharaohs indicate that a number of sports, including swimming and fishing, were well-developed and regulated several thousands of years ago in ancient Egypt. Other Egyptian sports included javelin throwing, high jump, and wrestling. Ancient Persian sports such as the traditional Iranian martial art of Zourkhaneh had a close connection to warfare skills. Among other sports that originated in ancient Persia are polo and jousting.

A wide range of sports were already established by the time of Ancient Greece and the military culture and the development of sport in Greece influenced one another considerably. Sport became such a prominent part of their culture that the Greeks created the Olympic Games, which in ancient times were held every four years in a small village in the Peloponnesus called Olympia.

Sports have been increasingly organised and regulated from the time of the ancient Olympics up to the present century. Industrialisation has brought increased leisure time, letting people attend and follow spectator sports and participate in athletic activities. These trends continued with the advent of mass media and global communication. Professionalism became prevalent, further adding to the increase in sport's popularity, as sports fans followed the exploits of professional athletes – all while enjoying the exercise and competition associated with amateur participation in sports. Since the turn of the 21st century, there has been increasing debate about whether transgender sportspersons should be able to participate in sport events that conform with their post-transition gender identity.

Sportsmanship is an attitude that strives for fair play, courtesy toward teammates and opponents, ethical behaviour and integrity, and grace in victory or defeat.

Sportsmanship expresses an aspiration or ethos that the activity will be enjoyed for its own sake. The well-known sentiment by sports journalist Grantland Rice, that it's "not that you won or lost but how you played the game", and the modern Olympic creed expressed by its founder Pierre de Coubertin: "The most important thing... is not winning but taking part" are typical expressions of this sentiment.

Key principles of sport include that the result should not be predetermined, and that both sides should have equal opportunity to win. Rules are in place to ensure fair play, but participants can break these rules in order to gain advantage.

Participants may cheat in order to unfairly increase their chance of winning, or in order to achieve other advantages such as financial gains. The widespread existence of gambling on the results of sports fixtures creates a motivation for match fixing, where a participant or participants deliberately work to ensure a given outcome rather than simply playing to win.

The competitive nature of sport encourages some participants to attempt to enhance their performance through the use of medicines, or through other means such as increasing the volume of blood in their bodies through artificial means.

All sports recognised by the IOC or SportAccord are required to implement a testing programme, looking for a list of banned drugs, with suspensions or bans being placed on participants who test positive for banned substances.

Violence in sports involves crossing the line between fair competition and intentional aggressive violence. Athletes, coaches, fans, and parents sometimes unleash violent behaviour on people or property, in misguided shows of loyalty, dominance, anger, or celebration. Rioting or hooliganism by fans in particular is a problem at some national and international sporting contests.

Female participation in sports continues to rise alongside the opportunity for involvement and the value of sports for child development and physical fitness. Despite gains during the last three decades, a gap persists in the enrollment figures between male and female players. Female players account for 39% of the total participation in US interscholastic athletics. Gender balance has been accelerating from a 32% increase in 1973–74 to a 63% increase in 1994–95. Hessel (2000).

Youth sport presents children with opportunities for fun, socialisation, forming peer relationships, physical fitness, and athletic scholarships. Activists for education and the war on drugs encourage youth sport as a means to increase educational participation and to fight the illegal drug trade. According to the Center for Injury Research and Policy at Nationwide Children's Hospital, the biggest risk for youth sport is death or serious injury including concussion. These risks come from running, basketball, association football, volleyball, gridiron, gymnastics, and ice hockey. Youth sport in the US is a $15 billion industry including equipment up to private coaching.

Disabled sports also adaptive sports or parasports, are sports played by persons with a disability, including physical and intellectual disabilities. As many of these are based on existing sports modified to meet the needs of persons with a disability, they are sometimes referred to as "adapted sports". However, not all disabled sports are adapted; several sports that have been specifically created for persons with a disability have no equivalent in able-bodied sports.

The competition element of sport, along with the aesthetic appeal of some sports, result in the popularity of people attending to watch sport being played. This has led to the specific phenomenon of spectator sport.

Both amateur and professional sports attract spectators, both in person at the sport venue, and through broadcast media including radio, television and internet broadcast. Both attendance in person and viewing remotely can incur a sometimes substantial charge, such as an entrance ticket, or pay-per-view television broadcast.

It is common for popular sports to attract large broadcast audiences, leading to rival broadcasters bidding large amounts of money for the rights to show certain fixtures. The football World Cup attracts a global television audience of hundreds of millions; the 2006 final alone attracted an estimated worldwide audience of well over 700 million and the 2011 Cricket World Cup Final attracted an estimated audience of 135 million in India alone.

In the United States, the championship game of the NFL, the Super Bowl, has become one of the most watched television broadcasts of the year.
Super Bowl Sunday is a "de facto" national holiday in America; the viewership being so great that in 2015, advertising space was reported as being sold at $4.5m for a 30-second slot.

Sport can be undertaken on an amateur, professional or semi-professional basis, depending on whether participants are incentivised for participation (usually through payment of a wage or salary). Amateur participation in sport at lower levels is often called "grassroots sport".

The popularity of spectator sport as a recreation for non-participants has led to sport becoming a major business in its own right, and this has incentivised a high paying professional sport culture, where high performing participants are rewarded with pay far in excess of average wages, which can run into millions of dollars.

Some sports, or individual competitions within a sport, retain a policy of allowing only amateur sport. The Olympic Games started with a principle of amateur competition with those who practised a sport professionally considered to have an unfair advantage over those who practised it merely as a hobby. From 1971, Olympic athletes were allowed to receive compensation and sponsorship, and from 1986, the IOC decided to make all professional athletes eligible for the Olympics, with the exceptions of boxing, and wrestling.

Technology plays an important part in modern sport. With it being a necessary part of some sports (such as motorsport), it is used in others to improve performance. Some sports also use it to allow off-field decision making.

Sports science is a widespread academic discipline, and can be applied to areas including athlete performance, such as the use of video analysis to fine-tune technique, or to equipment, such as improved running shoes or competitive swimwear. Sports engineering emerged as a discipline in 1998 with an increasing focus not just on materials design but also the use of technology in sport, from analytics and big data to wearable technology. In order to control the impact of technology on fair play, governing bodies frequently have specific rules that are set to control the impact of technical advantage between participants. For example, in 2010, full-body, non-textile swimsuits were banned by FINA, as they were enhancing swimmers' performances.

The increase in technology has also allowed many decisions in sports matches to be taken, or reviewed, off-field, with another official using instant replays to make decisions. In some sports, players can now challenge decisions made by officials. In Association football, goal-line technology makes decisions on whether a ball has crossed the goal line or not. The technology is not compulsory, but was used in the 2014 FIFA World Cup in Brazil, and the 2015 FIFA Women's World Cup in Canada, as well as in the Premier League from 2013–14, and the Bundesliga from 2015–16. In the NFL, a referee can ask for a review from the replay booth, or a head coach can issue a challenge to review the play using replays. The final decision rests with the referee. A video referee (commonly known as a Television Match Official or TMO) can also use replays to help decision-making in rugby (both league and union). In international cricket, an umpire can ask the Third umpire for a decision, and the third umpire makes the final decision. Since 2008, a decision review system for players to review decisions has been introduced and used in ICC-run tournaments, and optionally in other matches. Depending on the host broadcaster, a number of different technologies are used during an umpire or player review, including instant replays, Hawk-Eye, Hot Spot and Real Time Snickometer. Hawk-Eye is also used in tennis to challenge umpiring decisions.

Research suggests that sports have the capacity to connect youth to positive adult role models and provide positive development opportunities, as well as promote the learning and application of life skills. In recent years the use of sport to reduce crime, as well as to prevent violent extremism and radicalization, has become more widespread, especially as a tool to improve self-esteem, enhance social bonds and provide participants with a feeling of purpose.

Benito Mussolini used the 1934 FIFA World Cup, which was held in Italy, to showcase Fascist Italy. Adolf Hitler also used the 1936 Summer Olympics held in Berlin, and the 1936 Winter Olympics held in Garmisch-Partenkirchen, to promote the Nazi ideology of the superiority of the Aryan race, and inferiority of the Jews and other "undesirables". Germany used the Olympics to give of itself a peaceful image while it was very actively preparing the war.

When apartheid was the official policy in South Africa, many sports people, particularly in rugby union, adopted the conscientious approach that they should not appear in competitive sports there. Some feel this was an effective contribution to the eventual demolition of the policy of apartheid, others feel that it may have prolonged and reinforced its worst effects.

In the history of Ireland, Gaelic sports were connected with cultural nationalism. Until the mid-20th century a person could have been banned from playing Gaelic football, hurling, or other sports administered by the Gaelic Athletic Association (GAA) if she/he played or supported Association football, or other games seen to be of British origin. Until recently the GAA continued to ban the playing of football and rugby union at Gaelic venues. This ban, also known as Rule 42, is still enforced, but was modified to allow football and rugby to be played in Croke Park while Lansdowne Road was redeveloped into Aviva Stadium. Until recently, under Rule 21, the GAA also banned members of the British security forces and members of the RUC from playing Gaelic games, but the advent of the Good Friday Agreement in 1998 led to the eventual removal of the ban.

Nationalism is often evident in the pursuit of sport, or in its reporting: people compete in national teams, or commentators and audiences can adopt a partisan view. On occasion, such tensions can lead to violent confrontation among players or spectators within and beyond the sporting venue, as in the Football War. These trends are seen by many as contrary to the fundamental ethos of sport being carried on for its own sake and for the enjoyment of its participants.

Sport and politics collided in the 1972 Olympics in Munich. Masked men entered the hotel of the Israeli Olympic team and killed many of their men. This was known as the Munich massacre.

A study of US elections has shown that the result of sports events can affect the results. A study published in the Proceedings of the National Academy of Sciences showed that when the home team wins the game before the election, the incumbent candidates can increase their share of the vote by 1.5 percent. A loss had the opposite effect, and the effect is greater for higher-profile teams or unexpected wins and losses. Also, when Washington Redskins win their final game before an election, then the incumbent President is more likely to win, and if the Redskins lose, then the opposition candidate is more likely to win; this has become known as the Redskins Rule.

Étienne de La Boétie, in his essay "Discourse on Voluntary Servitude" describes athletic spectacles as means for tyrants to control their subjects by distracting them.

Do not imagine that there is any bird more easily caught by decoy, nor any fish sooner fixed on the hook by wormy bait, than are all these poor fools neatly tricked into servitude by the slightest feather passed, so to speak, before their mouths. Truly it is a marvelous thing that they let themselves be caught so quickly at the slightest tickling of their fancy. Plays, farces, spectacles, gladiators, strange beasts, medals, pictures, and other such opiates, these were for ancient peoples the bait toward slavery, the price of their liberty, the instruments of tyranny. By these practices and enticements the ancient dictators so successfully lulled their subjects under the yoke, that the stupefied peoples, fascinated by the pastimes and vain pleasures flashed before their eyes, learned subservience as naïvely, but not so creditably, as little children learn to read by looking at bright picture books.

Sport was an important form of worship in Ancient Greek religion. The ancient Olympic Games, called the Olympiad, were held in honour of the head deity, Zeus, and featured various forms of religious dedication to him and other gods. As many Greeks travelled to see the games, this combination of religion and sport also served as a way of uniting them.

The practice of athletic competitions has been criticised by some Christian thinkers as a form of idolatry, in which "human beings extol themselves, adore themselves, sacrifice themselves and reward themselves." Sports are seen by these critics as a manifestation of "collective pride" and "national self-deification" in which feats of human power are idolized at the expense of divine worship.

Tertullian condemns the athletic performances of his day, insisting "the entire apparatus of the shows is based upon idolatry." The shows, says Tertullian, excite passions foreign to the calm temperament cultivated by the Christian:

God has enjoined us to deal calmly, gently, quietly, and peacefully with the Holy Spirit, because these things are alone in keeping with the goodness of His nature, with His tenderness and sensitiveness. ... Well, how shall this be made to accord with the shows? For the show always leads to spiritual agitation, since where there is pleasure, there is keenness of feeling giving pleasure its zest; and where there is keenness of feeling, there is rivalry giving in turn its zest to that. Then, too, where you have rivalry, you have rage, bitterness, wrath and grief, with all bad things which flow from them – the whole entirely out of keeping with the religion of Christ.
Popularity in 2018 of major sports by size of fan base:




</doc>
<doc id="25806331" url="https://en.wikipedia.org/wiki?curid=25806331" title="List of professional sports">
List of professional sports

This is a list of professional sports – that is, sports (and, more broadly, non-sport games subject to organized competition) that support one or more systems of professional sports players, sportspeople by "occupation". Such sports also have a vibrant community of amateur players, from whom the best rise to become professionals.

Rugby football in Canada had its origins in the early 1860s, and over time, a unique code of football known as Canadian football developed. Both the Canadian Football League (CFL), the sport's top professional league, and Football Canada, the governing body for amateur play, trace their roots to 1882 and the founding of the Canadian Rugby Football Union (later reorganized as the Canadian Rugby Union). In 1909, the Grey Cup was donated by the then Governor General of Canada Albert Grey, 4th Earl Grey, to recognize the top amateur rugby football team in Canada. From the 1930s to the 1950s, the two senior leagues of the CRU (the Interprovincial Rugby Football Union and the Western Interprovincial Football Union) gradually evolved from amateur to professional leagues, and found they had less and less in common with the amateur leagues, and consequently in 1956 formed a new umbrella organization, the Canadian Football Council. In 1958, the CFC left the CRU altogether and was renamed the Canadian Football League. By this time, teams from the amateur Ontario Rugby Football Union had stopped challenging for the Grey Cup, and ever since, it has been exclusively awarded to CFL teams. Since 1965, university teams have competed for the Vanier Cup.

Unlike other sports, Australian rules football has not resisted becoming a professional sport.

Although the sport began as amateur competition, the Australian Football League is an elite professional league and has been for nearly 80 years since its initial formation as the Victorian Football Association and then the Victorian Football League in 1897. The league changed its name to the Australian Football League (AFL) in 1990 amid the increasing professionalism and national expansion of the game.

Bandy is played professionally in Russia, Sweden, and Kazakhstan.

The game was invented in the United States in the 1890s, in Springfield, Massachusetts. The first professional basketball leagues emerged in the 1920s in the United States. Prominent among these were the American Basketball League, which formed in 1925, and the National Basketball League, which was launched in 1937 by General Electric, Firestone and Goodyear as a way to improve their national profile. In 1946 the Basketball Association of America was founded by the owners of major sports arenas, particularly the Madison Square Garden. The BAA later merged with the NBL in 1949 to become the National Basketball Association, the preeminent league in the world with 29 teams in the United States and one in Canada. The American Basketball Association, founded in 1967, subsequently joined the NBA in the 1976 ABA-NBA merger.

The second-oldest professional basketball league in the world is the Philippine Basketball Association. The PBA was long considered to be the best league in Asia, but the Chinese Basketball Association has grown tremendously in recent years. The league was born on April 9, 1975 at the Araneta Coliseum, Cubao, Quezon City, Philippines.

Outside of the NBA, the top professional leagues in the world are those of FIBA Europe. According to the official league rankings produced by Euroleague Basketball, the body that conducts the continent-wide Euroleague, the top five national domestic leagues on the continent (from 1 to 5) are those Liga ACB (Spain), the Russian Professional Basketball League, the Greek Basket League, Lega Basket Serie A (Italy), and the Turkish Basketball League.

European basketball is also characterized by its long established and well-developed transnational club competitions, most notably the Euroleague, which features top clubs from as many as 18 different domestic leagues. Two other continental club competitions, the ULEB Eurocup and EuroChallenge, are also conducted annually. Europe also has transnational regional leagues, such as the Liga ABA (Adriatic League, formerly Yugoslavian League), and Baltic Basketball League (originally limited to the Baltic states, now also including Kazakhstan).

Notable figures in professional bowling would include Walter Ray Williams, Jr., Chris Barnes and Rafael "Paeng" Nepomuceno.

Cricket at the highest level has developed into a fully professional international sport from which leading players can earn a large income. However professionalism has a long history in English cricket. The first professionals had appeared by the first half of the eighteenth century, when heavy gambling on the game encouraged wealthy patrons to draft the best players into their teams. They would often offer these players full-time employment as gardeners or gamekeepers on their estates. In the second half of the century, the famous Hambledon Club paid its players match fees.

In the middle of the nineteenth century William Clarke's All-England Eleven was a highly successful all-professional venture which did much to popularise the game. The earliest overseas tours were also all-professional affairs.

In the early 21st century cricket is as lucrative as some other sports, and domestic cricketers typically earn several times the average salary in their country. Regular members of the English cricket team earn several hundred thousand pounds a year. However, the highest paid cricketers in the world are the star members of the Australian cricket team or the Indian cricket team who make most of their income from endorsement contracts.


Professional darts players perform in the Professional Darts Corporation or the World Darts Federation.
Professional Disc Golfers compete in Professional Disc Golf Association (PDGA) sanctioned events. Disc golf is among the fastest growing sports in the world. Its rules are similar to ball golf, with the throwing of discs replacing the hitting of balls and a specialty chain link network suspended above a basket replacing the cup. 

Pro gamers compete in many leagues and tournaments throughout the world.

Main article: Horse racing

It is played with two teams, while 5 skaters and 1 goalie are allowed on the ice at a time. In NHL rules, the periods are 20 minutes long. There are three periods.

The 81-member governing body is the International Ice Hockey Federation, (IIHF). Ice hockey has been played at the Winter Olympics since 1924, and was in the 1920 Summer Olympics. North America's National Hockey League is the strongest professional ice hockey league, drawing top ice hockey players from around the globe. The NHL rules are slightly different from those used in Olympic hockey.

Ice hockey sticks are long L-shaped sticks made of wood, graphite, or composites with a blade at the bottom that can lie flat on the playing surface when the stick is held upright and can curve either way as to help a left- or right-handed player gain an advantage.

There are early representations and reports of hockey-type games being played on ice in the Netherlands, and reports from Canada from the beginning of the nineteenth century, but the modern game was initially organized by students at McGill University, Montreal in 1875 and, by two years later, codified the first set of ice hockey rules and organized the first teams.

Lacrosse is played mainly in North America, however, countries such as the United Kingdom and Australia have small lacrosse leagues. It has also expanded into both Europe and Asia, with the latter forming the Asia Pacific Lacrosse Union (APLU) in May 2012. The United States currently has three top-level professional lacrosse leagues in operation, Major League Lacrosse, the Premier Lacrosse League, and the National Lacrosse League.

Rugby league came into existence due to the very issue of professionalism. Rugby football split into 'union' and 'league' over the issue of payment to player. Rugby league favoured payments and has thus been a professional sport since its beginnings in 1895, when 22 clubs based in northern England split from the more amateur-minded Rugby Football Union. The officially amateur RFU had previously brought charges of professionalism against some clubs for their use of "broken time" payments to compensate players for missing work due to matches or injuries received whilst playing. On August 29, 1895 in a meeting at the George Hotel, Huddersfield, the clubs decided to break away and form the Northern Rugby Union, which later would become the Rugby Football League. The rules of rugby league were gradually changed so that now it and rugby union are distinctly different games, however rugby union has since turned professional as well. On 17 December 1967 the first professional Sunday matches of rugby league were played.

Rugby union continued with its amateur ideals past the schism between union and league and throughout much of the 20th century. This position changed in 1995. The threat of big payments from professional rugby league clubs in countries where rugby league had a significant following was becoming too great. A committee conclusion decided that the only way to end this threat, the hypocrisy of Shamateurism and keep control of rugby union was to make the sport professional. On August 26, 1995 the International Rugby Board declared rugby union an "open" game and thus removed all restrictions on payments or benefits to those connected with the game.

The PBR is different from the classic rodeo as it consists of only bull riding. It was founded in 1992 because a group of bull riders decided that their sport should be separated from the classic rodeo and could, as it was easily the most popular event. Riders and bulls are judged on a 50-point scale. Riders are only given a score if they stay on for the mandatory 8 seconds, while bull scores are given regardless of what the rider does.

See "American Ultimate Disc League" and "Major League Ultimate"



</doc>
<doc id="356978" url="https://en.wikipedia.org/wiki?curid=356978" title="List of sports">
List of sports

The following is a list of sports/games, divided by category. 

According to the "World Sports Encyclopedia" (2003), there are 8,000 indigenous sports and sporting games.






 


Sports that are played with some sort of board as the primary equipment.



Sports using bicycles or unicycles.




A combat sport is a competitive contact sport where two combatants fight against each other using certain rules of engagement.

Sports using a horse.




Sometimes considered blood sports.



Decathlon, heptathlon, and the pentathlons consist of ten, seven, and five component contests that are scored together using one points system.



Sport Parkour and Freerunning are empirically measured competitions of skill, speed or style on an obstacle based course. Self expression, demonstration of control and power are measured. 



Sports that have originated from rodeos in the old Western Americas.






Sports using guns (firearms, air guns, etc.).











Games involving opponents hitting a ball against a wall/walls using a racket, or other piece of equipment, or merely gloved/barehanded.
These sports use water (a river, pool, etc.).















Sports seen in movies, literature, etc.



Sports falling into two or more categories.


Requiring little or no physical exertion or agility, mind sports are often not considered true sports. Some mind sports are recognised by sporting federations.
The following list is intended to represent anything that is likely to be referred to as a mind sport, not to argue their validity as sports.






Potentially other sports are listed here.



Sports played using electronic devices.


Sports in which the method of scoring is through goals.




See #Skiing

Sports mainly based on sheer power.



Sports where the main objective is to hit a certain target.
Sports that involve teams.

Sports which use the wind (apart from sailing):





</doc>
<doc id="17062218" url="https://en.wikipedia.org/wiki?curid=17062218" title="Product teardown">
Product teardown

A product teardown, or simply teardown, is the act of disassembling a product, such that it helps to identify its component parts, chip & system functionality, and component costing information. For products having 'secret' technology, such as the Mikoyan-Gurevich MiG-25, the process may be secret. For others, including consumer electronics, the results are typically disseminated through photographs and component lists so that others can make use of the information without having to disassemble the product themselves. This information is important to designers of semiconductors, displays, batteries, packaging companies, integrated design firms, and semiconductor fabs, and the systems they operate within.

This information can be of interest to hobbyists, but can also be used commercially by the technical community to find out, for example, what semiconductor components are being utilized in consumer electronic products, such as the Wii video game console or Apple's iPhone. Such knowledge can aid understanding of how the product works, including innovative design features, and can facilitate estimating the bill of materials (BOM). The financial community, therefore, has an interest in teardowns, as knowing how a company's products are built can help guide a stock valuation. Manufacturers are often not allowed to announce what components are present in a product due to non-disclosure agreements (NDA). Teardowns can also play a part in evidence of use in court and litigation proceedings where a company's parts may have been used without their permission, counterfeited, or to show where intellectual property or patents might be infringed by another firm's part or system.

Identifying semiconductor components in systems has become more difficult over the past years. The most notable change started with Apple's 8GB iPod nano, which were repackaged with Apple branding. This makes it more difficult to identify the actual device manufacturer and function of the component without performing a 'decap' – removing the outer packaging to analyze the die within it. Typically there are markings on the die inside the package that can lead experienced engineers to see who actually created the device and what functionality it performs in the system.



</doc>
<doc id="13549505" url="https://en.wikipedia.org/wiki?curid=13549505" title="Technology fusion">
Technology fusion

Technology fusion involves a transformation of core technologies through a combination process facilitated by technological advances such as the phone and the Internet, which ensure that labs are no longer isolated. This results in profitable advances that can be made cheaply by combining knowledge from different fields, companies, industries, and geographies. The technological fusion is distinguished from the so-called breakthrough approach, which is the linear technological development that replaces an older generation of technology through its focus on combining existing technologies into hybrid products that can revolutionize markets.

The fusion of technologies goes beyond mere combination. Fusion is more than complementarism, because it creates a new market and new growth opportunities for each participant in the innovation. It blends incremental improvements from several (often previously separate) fields to create a product.

An example is the fusion of mechanical and electronic engineering to create mechatronics. There is also the case of fusing chemical and electronics technology to produce the Liquid Crystal display (LCD) technology.



</doc>
<doc id="74007" url="https://en.wikipedia.org/wiki?curid=74007" title="Technology assessment">
Technology assessment

Technology assessment (TA, German: , French: ) is a scientific, interactive, and communicative process that aims to contribute to the formation of public and political opinion on societal aspects of science and technology. This is a means of assessing and rating the new technology from the time when it was first developed to the time when it is potentially accepted by the public and authorities for further use. In essence, TA could be defined as "as a form of policy research that examines short- and long term consequences (for example, societal, economic, ethical, legal) of the application of technology."

TA is the study and evaluation of new technologies. It is a way of trying to forecast and prepare for the upcoming technological advancements and their repercussions to the society, and then make decisions based on the judgments. It is based on the conviction that new developments within, and discoveries by, the scientific community are relevant for the world at large rather than just for the scientific experts themselves, and that technological progress can never be free of ethical implications. Technology assessment was initially practiced in the 1960s in the United States where it would focus on analyzing the significance of "supersonic transportation, pollution of the environment and ethics of genetic screening." 

Also, technology assessment recognizes the fact that scientists normally are not trained ethicists themselves and accordingly ought to be very careful when passing ethical judgement on their own, or their colleagues, new findings, projects, or work in progress. TA is a very broad phenomenon which also includes aspects such as "diffusion of technology (and technology transfer), factors leading to rapid acceptance of new technology, and the role of technology and society."

Technology assessment assumes a global perspective and is future-oriented, not anti-technological. TA considers its task as an interdisciplinary approach to solving already existing problems and preventing potential damage caused by the uncritical application and the commercialization of new technologies.

Therefore, any results of technology assessment studies must be published, and particular consideration must be given to communication with political decision-makers.

An important problem concerning technology assessment is the so-called Collingridge dilemma: on the one hand, impacts of new technologies cannot be easily predicted until the technology is extensively developed and widely used; on the other hand, control or change of a technology is difficult as soon as it is widely used. It emphasizes on the fact that technologies, in their early stage, are unpredictable with regards to their implications and rather tough to regulate or control once it has been widely accepted by the society. Shaping or directing this technology is the desired direction becomes difficult for the authorities at this period of time. There have been several approaches put in place in order to tackle this dilemma, one of the common ones being "anticipation." In this approach, authorities and assessors "anticipate ethical impacts of a technology ("technomoral scenarios"), being too speculative to be reliable, or on ethically regulating technological developments ("sociotechnical experiments"), discarding anticipation of the future implications."
Technology assessments, which are a form of cost–benefit analysis, are a medium for decision makers to evaluate and analyze solutions with regards to the particular technology assessment, and choose a best possible option which is cost effective and obeys the authoritative and budgetary requirements. However, they are difficult if not impossible to carry out in an objective manner since subjective decisions and value judgments have to be made regarding a number of complex issues such as (a) the boundaries of the analysis (i.e., what costs are internalized and externalized), (b) the selection of appropriate indicators of potential positive and negative consequences of the new technology, (c) the monetization of non-market values, and (d) a wide range of ethical perspectives. Consequently, most technology assessments are neither objective nor value-neutral exercises but instead are greatly influenced and biased by the values of the most powerful stakeholders, which are in many cases the developers and proponents (i.e., corporations and governments) of new technologies under consideration. In the most extreme view, as expressed by Ian Barbour in '’Technology, Environment, and Human Values'’, technology assessment is "a one-sided apology for contemporary technology by people with a stake in its continuation."

Overall, technology assessment is a very broad field which reaches beyond just technology and industrial phenomenons. It handles the assessment of effects, consequences, and risks of a technology, but also is a forecasting function looking into the projection of opportunities and skill development as an input into strategic planning." Some of the major fields of TA are: information technology, hydrogen technologies, nuclear technology, molecular nanotechnology, pharmacology, organ transplants, gene technology, artificial intelligence, the Internet and many more. Health technology assessment is related, but profoundly different, despite the similarity in the name.

The following types of concepts of TA are those that are most visible and practiced. There are, however, a number of further TA forms that are only proposed as concepts in the literature or are the label used by a particular TA institution.

Many TA institutions are members of the European Parliamentary Technology Assessment (EPTA) network, some are working for the STOA panel of the European Parliament and formed the European Technology Assessment Group (ETAG).




</doc>
<doc id="29816" url="https://en.wikipedia.org/wiki?curid=29816" title="Technology">
Technology

Technology ("science of craft", from Greek , "techne", "art, skill, cunning of hand"; and , "-logia") is the sum of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation. Technology can be the knowledge of techniques, processes, and the like, or it can be embedded in machines to allow for operation without detailed knowledge of their workings. Systems (e.g. machines) applying technology by taking an input, changing it according to the system's use, and then producing an outcome are referred to as technology systems or technological systems.

The simplest form of technology is the development and use of basic tools. The prehistoric discovery of how to control fire and the later Neolithic Revolution increased the available sources of food, and the invention of the wheel helped humans to travel in and control their environment. Developments in historic times, including the printing press, the telephone, and the Internet, have lessened physical barriers to communication and allowed humans to interact freely on a global scale.

Technology has many effects. It has helped develop more advanced economies (including today's global economy) and has allowed the rise of a leisure class. Many technological processes produce unwanted by-products known as pollution and deplete natural resources to the detriment of Earth's environment. Innovations have always influenced the values of a society and raised new questions in the ethics of technology. Examples include the rise of the notion of efficiency in terms of human productivity, and the challenges of bioethics.

Philosophical debates have arisen over the use of technology, with disagreements over whether technology improves the human condition or worsens it. Neo-Luddism, anarcho-primitivism, and similar reactionary movements criticize the pervasiveness of technology, arguing that it harms the environment and alienates people; proponents of ideologies such as transhumanism and techno-progressivism view continued technological progress as beneficial to society and the human condition.

The use of the term "technology" has changed significantly over the last 200 years. Before the 20th century, the term was uncommon in English, and it was used either to refer to the description or study of the useful arts or to allude to technical education, as in the Massachusetts Institute of Technology (chartered in 1861).

The term "technology" rose to prominence in the 20th century in connection with the Second Industrial Revolution. The term's meanings changed in the early 20th century when American social scientists, beginning with Thorstein Veblen, translated ideas from the German concept of "" into "technology." In German and other European languages, a distinction exists between "technik" and "technologie" that is absent in English, which usually translates both terms as "technology." By the 1930s, "technology" referred not only to the study of the industrial arts but to the industrial arts themselves.

In 1937, the American sociologist Read Bain wrote that "technology includes all tools, machines, utensils, weapons, instruments, housing, clothing, communicating and transporting devices and the skills by which we produce and use them." Bain's definition remains common among scholars today, especially social scientists. Scientists and engineers usually prefer to define technology as applied science, rather than as the things that people make and use. More recently, scholars have borrowed from European philosophers of "technique" to extend the meaning of technology to various forms of instrumental reason, as in Foucault's work on technologies of the self ("techniques de soi").

Dictionaries and scholars have offered a variety of definitions. The "Merriam-Webster Learner's Dictionary" offers a definition of the term: "the use of science in industry, engineering, etc., to invent useful things or to solve problems" and "a machine, piece of equipment, method, etc., that is created by technology." Ursula Franklin, in her 1989 "Real World of Technology" lecture, gave another definition of the concept; it is "practice, the way we do things around here." The term is often used to imply a specific field of technology, or to refer to high technology or just consumer electronics, rather than technology as a whole. Bernard Stiegler, in "Technics and Time, 1", defines technology in two ways: as "the pursuit of life by means other than life," and as "organized inorganic matter."

Technology can be most broadly defined as the entities, both material and immaterial, created by the application of mental and physical effort in order to achieve some value. In this usage, technology refers to tools and machines that may be used to solve real-world problems. It is a far-reaching term that may include simple tools, such as a crowbar or wooden spoon, or more complex machines, such as a space station or particle accelerator. Tools and machines need not be material; virtual technology, such as computer software and business methods, fall under this definition of technology. W. Brian Arthur defines technology in a similarly broad way as "a means to fulfill a human purpose."

The word "technology" can also be used to refer to a collection of techniques. In this context, it is the current state of humanity's knowledge of how to combine resources to produce desired products, to solve problems, fulfill needs, or satisfy wants; it includes technical methods, skills, processes, techniques, tools and raw materials. When combined with another term, such as "medical technology" or "space technology," it refers to the state of the respective field's knowledge and tools. "State-of-the-art technology" refers to the high technology available to humanity in any field.
Technology can be viewed as an activity that forms or changes culture. Additionally, technology is the application of math, science, and the arts for the benefit of life as it is known. A modern example is the rise of communication technology, which has lessened barriers to human interaction and as a result has helped spawn new subcultures; the rise of cyberculture has at its basis the development of the Internet and the computer. Not all technology enhances culture in a creative way; technology can also help facilitate political oppression and war via tools such as guns. As a cultural activity, technology predates both science and engineering, each of which formalize some aspects of technological endeavor.

The distinction between science, engineering, and technology is not always clear. Science is systematic knowledge of the physical or material world gained through observation and experimentation. Technologies are not usually exclusively products of science, because they have to satisfy requirements such as utility, usability, and safety.

Engineering is the goal-oriented process of designing and making tools and systems to exploit natural phenomena for practical human means, often (but not always) using results and techniques from science. The development of technology may draw upon many fields of knowledge, including scientific, engineering, mathematical, linguistic, and historical knowledge, to achieve some practical result.

Technology is often a consequence of science and engineering, although technology as a human activity precedes the two fields. For example, science might study the flow of electrons in electrical conductors by using already-existing tools and knowledge. This new-found knowledge may then be used by engineers to create new tools and machines such as semiconductors, computers, and other forms of advanced technology. In this sense, scientists and engineers may both be considered technologists; the three fields are often considered as one for the purposes of research and reference.

The exact relations between science and technology, in particular, have been debated by scientists, historians, and policymakers in the late 20th century, in part because the debate can inform the funding of basic and applied science. In the immediate wake of World War II, for example, it was widely considered in the United States that technology was simply "applied science" and that to fund basic science was to reap technological results in due time. An articulation of this philosophy could be found explicitly in Vannevar Bush's treatise on postwar science policy, "Science – The Endless Frontier": "New products, new industries, and more jobs require continuous additions to knowledge of the laws of nature ... This essential new knowledge can be obtained only through basic scientific research." In the late-1960s, however, this view came under direct attack, leading towards initiatives to fund science for specific tasks (initiatives resisted by the scientific community). The issue remains contentious, though most analysts resist the model that technology is a result of scientific research.

The use of tools by early humans was partly a process of discovery and of evolution. Early humans evolved from a species of foraging hominids which were already bipedal, with a brain mass approximately one third of modern humans. Tool use remained relatively unchanged for most of early human history. Approximately 50,000 years ago, the use of tools and complex set of behaviors emerged, believed by many archaeologists to be connected to the emergence of fully modern language.

Hominids started using primitive stone tools millions of years ago. The earliest stone tools were little more than a fractured rock, but approximately 75,000 years ago, pressure flaking provided a way to make much finer work.

The discovery and use of fire, a simple energy source with many profound uses, was a turning point in the technological evolution of humankind. The exact date of its discovery is not known; evidence of burnt animal bones at the Cradle of Humankind suggests that the domestication of fire occurred before 1 Ma; scholarly consensus indicates that "Homo erectus" had controlled fire by between 500 and 400 ka. Fire, fueled with wood and charcoal, allowed early humans to cook their food to increase its digestibility, improving its nutrient value and broadening the number of foods that could be eaten.

Other technological advances made during the Paleolithic era were clothing and shelter; the adoption of both technologies cannot be dated exactly, but they were a key to humanity's progress. As the Paleolithic era progressed, dwellings became more sophisticated and more elaborate; as early as 380 ka, humans were constructing temporary wood huts. Clothing, adapted from the fur and hides of hunted animals, helped humanity expand into colder regions; humans began to migrate
out of Africa by 200 ka and into other continents such as Eurasia.

Human's technological ascent began in earnest in what is known as the Neolithic Period ("New Stone Age"). The invention of polished stone axes was a major advance that allowed forest clearance on a large scale to create farms. This use of polished stone axes increased greatly in the Neolithic, but were originally used in the preceding Mesolithic in some areas such as Ireland. Agriculture fed larger populations, and the transition to sedentism allowed simultaneously raising more children, as infants no longer needed to be carried, as nomadic ones must. Additionally, children could contribute labor to the raising of crops more readily than they could to the hunter-gatherer economy.

With this increase in population and availability of labor came an increase in labor specialization. What triggered the progression from early Neolithic villages to the first cities, such as Uruk, and the first civilizations, such as Sumer, is not specifically known; however, the emergence of increasingly hierarchical social structures and specialized labor, of trade and war amongst adjacent cultures, and the need for collective action to overcome environmental challenges such as irrigation, are all thought to have played a role.

Continuing improvements led to the furnace and bellows and provided, for the first time, the ability to smelt and forge gold, copper, silver, and lead native metals found in relatively pure form in nature. The advantages of copper tools over stone, bone, and wooden tools were quickly apparent to early humans, and native copper was probably used from near the beginning of Neolithic times (about 10 ka). Native copper does not naturally occur in large amounts, but copper ores are quite common and some of them produce metal easily when burned in wood or charcoal fires. Eventually, the working of metals led to the discovery of alloys such as bronze and brass (about 4000 BCE). The first uses of iron alloys such as steel dates to around 1800 BCE.

Meanwhile, humans were learning to harness other forms of energy. The earliest known use of wind power is the sailing ship; the earliest record of a ship under sail is that of a Nile boat dating to the 8th-millennium BCE. From prehistoric times, Egyptians probably used the power of the annual flooding of the Nile to irrigate their lands, gradually learning to regulate much of it through purposely built irrigation channels and "catch" basins. The ancient Sumerians in Mesopotamia used a complex system of canals and levees to divert water from the Tigris and Euphrates rivers for irrigation.

According to archaeologists, the wheel was invented around 4000 BCE probably independently and nearly simultaneously in Mesopotamia (in present-day Iraq), the Northern Caucasus (Maykop culture) and Central Europe. Estimates on when this may have occurred range from 5500 to 3000 BCE with most experts putting it closer to 4000 BCE. The oldest artifacts with drawings depicting wheeled carts date from about 3500 BCE; however, the wheel may have been in use for millennia before these drawings were made. More recently, the oldest-known wooden wheel in the world was found in the Ljubljana marshes of Slovenia.

The invention of the wheel revolutionized trade and war. It did not take long to discover that wheeled wagons could be used to carry heavy loads. The ancient Sumerians used the potter's wheel and may have invented it. A stone pottery wheel found in the city-state of Ur dates to around 3429 BCE, and even older fragments of wheel-thrown pottery have been found in the same area. Fast (rotary) potters' wheels enabled early mass production of pottery, but it was the use of the wheel as a transformer of energy (through water wheels, windmills, and even treadmills) that revolutionized the application of nonhuman power sources. The first two-wheeled carts were derived from travois and were first used in Mesopotamia and Iran in around 3000 BCE.

The oldest known constructed roadways are the stone-paved streets of the city-state of Ur, dating to circa 4000 BCE and timber roads leading through the swamps of Glastonbury, England, dating to around the same time period. The first long-distance road, which came into use around 3500 BCE, spanned 1,500 miles from the Persian Gulf to the Mediterranean Sea, but was not paved and was only partially maintained. In around 2000 BCE, the Minoans on the Greek island of Crete built a fifty-kilometer (thirty-mile) road leading from the palace of Gortyn on the south side of the island, through the mountains, to the palace of Knossos on the north side of the island. Unlike the earlier road, the Minoan road was completely paved.

Ancient Minoan private homes had running water. A bathtub virtually identical to modern ones was unearthed at the Palace of Knossos. Several Minoan private homes also had toilets, which could be flushed by pouring water down the drain. The ancient Romans had many public flush toilets, which emptied into an extensive sewage system. The primary sewer in Rome was the Cloaca Maxima; construction began on it in the sixth century BCE and it is still in use today.

The ancient Romans also had a complex system of aqueducts, which were used to transport water across long distances. The first Roman aqueduct was built in 312 BCE. The eleventh and final ancient Roman aqueduct was built in 226 CE. Put together, the Roman aqueducts extended over 450 kilometers, but less than seventy kilometers of this was above ground and supported by arches.

Innovations continued through the Middle Ages with innovations such as silk, the horse collar and horseshoes in the first few hundred years after the fall of the Roman Empire. Medieval technology saw the use of simple machines (such as the lever, the screw, and the pulley) being combined to form more complicated tools, such as the wheelbarrow, windmills and clocks. The Renaissance brought forth many of these innovations, including the printing press (which facilitated the greater communication of knowledge), and technology became increasingly associated with science, beginning a cycle of mutual advancement. The advancements in technology in this era allowed a more steady supply of food, followed by the wider availability of consumer goods.
Starting in the United Kingdom in the 18th century, the Industrial Revolution was a period of great technological discovery, particularly in the areas of agriculture, manufacturing, mining, metallurgy, and transport, driven by the discovery of steam power. Technology took another step in a second industrial revolution with the harnessing of electricity to create such innovations as the electric motor, light bulb, and countless others. Scientific advancement and the discovery of new concepts later allowed for powered flight and advancements in medicine, chemistry, physics, and engineering. The rise in technology has led to skyscrapers and broad urban areas whose inhabitants rely on motors to transport them and their food supply. Communication was also greatly improved with the invention of the telegraph, telephone, radio and television. The late 19th and early 20th centuries saw a revolution in transportation with the invention of the airplane and automobile.
The 20th century brought a host of innovations. In physics, the discovery of nuclear fission has led to both nuclear weapons and nuclear power. Computers were also invented and later miniaturized using transistors and integrated circuits. Information technology subsequently led to the creation of the Internet, which ushered in the current Information Age. Humans have also been able to explore space with satellites (later used for telecommunication) and in manned missions going all the way to the moon. In medicine, this era brought innovations such as open-heart surgery and later stem cell therapy along with new medications and treatments.

Complex manufacturing and construction techniques and organizations are needed to make and maintain these new technologies, and entire industries have arisen to support and develop succeeding generations of increasingly more complex tools. Modern technology increasingly relies on training and education – their designers, builders, maintainers, and users often require sophisticated general and specific training. Moreover, these technologies have become so complex that entire fields have been created to support them, including engineering, medicine, and computer science, and other fields have been made more complex, such as construction, transportation, and architecture.

Generally, technicism is the belief in the utility of technology for improving human societies. Taken to an extreme, technicism "reflects a fundamental attitude which seeks to control reality, to resolve all problems with the use of scientific–technological methods and tools." In other words, human beings will someday be able to master all problems and possibly even control the future using technology. Some, such as Stephen V. Monsma, connect these ideas to the abdication of religion as a higher moral authority.

Optimistic assumptions are made by proponents of ideologies such as transhumanism and singularitarianism, which view technological development as generally having beneficial effects for the society and the human condition. In these ideologies, technological development is morally good.

Transhumanists generally believe that the point of technology is to overcome barriers, and that what we commonly refer to as the human condition is just another barrier to be surpassed.

Singularitarians believe in some sort of "accelerating change"; that the rate of technological progress accelerates as we obtain more technology, and that this will culminate in a "Singularity" after artificial general intelligence is invented in which progress is nearly infinite; hence the term. Estimates for the date of this Singularity vary, but prominent futurist Ray Kurzweil estimates the Singularity will occur in 2045.

Kurzweil is also known for his history of the universe in six epochs: (1) the physical/chemical epoch, (2) the life epoch, (3) the human/brain epoch, (4) the technology epoch, (5) the artificial intelligence epoch, and (6) the universal colonization epoch. Going from one epoch to the next is a Singularity in its own right, and a period of speeding up precedes it. Each epoch takes a shorter time, which means the whole history of the universe is one giant Singularity event.

Some critics see these ideologies as examples of scientism and techno-utopianism and fear the notion of human enhancement and technological singularity which they support. Some have described Karl Marx as a techno-optimist.

On the somewhat skeptical side are certain philosophers like Herbert Marcuse and John Zerzan, who believe that technological societies are inherently flawed. They suggest that the inevitable result of such a society is to become evermore technological at the cost of freedom and psychological health.

Many, such as the Luddites and prominent philosopher Martin Heidegger, hold serious, although not entirely, deterministic reservations about technology (see "The Question Concerning Technology"). According to Heidegger scholars Hubert Dreyfus and Charles Spinosa, "Heidegger does not oppose technology. He hopes to reveal the essence of technology in a way that 'in no way confines us to a stultified compulsion to push on blindly with technology or, what comes to the same thing, to rebel helplessly against it.' Indeed, he promises that 'when we once open ourselves expressly to the essence of technology, we find ourselves unexpectedly taken into a freeing claim.' What this entails is a more complex relationship to technology than either techno-optimists or techno-pessimists tend to allow."

Some of the most poignant criticisms of technology are found in what are now considered to be dystopian literary classics such as Aldous Huxley's "Brave New World", Anthony Burgess's "A Clockwork Orange", and George Orwell's "Nineteen Eighty-Four". In Goethe's "Faust", Faust selling his soul to the devil in return for power over the physical world is also often interpreted as a metaphor for the adoption of industrial technology. More recently, modern works of science fiction such as those by Philip K. Dick and William Gibson and films such as "Blade Runner" and "Ghost in the Shell" project highly ambivalent or cautionary attitudes toward technology's impact on human society and identity.

The late cultural critic Neil Postman distinguished tool-using societies from technological societies and from what he called "technopolies," societies that are dominated by the ideology of technological and scientific progress to the exclusion or harm of other cultural practices, values, and world-views.

Darin Barney has written about technology's impact on practices of citizenship and democratic culture, suggesting that technology can be construed as (1) an object of political debate, (2) a means or medium of discussion, and (3) a setting for democratic deliberation and citizenship. As a setting for democratic culture, Barney suggests that technology tends to make ethical questions, including the question of what a good life consists in, nearly impossible because they already give an answer to the question: a good life is one that includes the use of more and more technology.

Nikolas Kompridis has also written about the dangers of new technology, such as genetic engineering, nanotechnology, synthetic biology, and robotics. He warns that these technologies introduce unprecedented new challenges to human beings, including the possibility of the permanent alteration of our biological nature. These concerns are shared by other philosophers, scientists and public intellectuals who have written about similar issues (e.g. Francis Fukuyama, Jürgen Habermas, William Joy, and Michael Sandel).

Another prominent critic of technology is Hubert Dreyfus, who has published books such as "On the Internet" and "What Computers Still Can't Do".

A more infamous anti-technological treatise is "", written by the Unabomber Ted Kaczynski and printed in several major newspapers (and later books) as part of an effort to end his bombing campaign of the techno-industrial infrastructure. There are also subcultures that disapprove of some or most technology, such as self-identified off-gridders.

The notion of appropriate technology was developed in the 20th century by thinkers such as E.F. Schumacher and Jacques Ellul to describe situations where it was not desirable to use very new technologies or those that required access to some centralized infrastructure or parts or skills imported from elsewhere. The ecovillage movement emerged in part due to this concern.

"This section mainly focuses on American concerns even if it can reasonably be generalized to other Western countries. "

In his article, Jared Bernstein, a Senior Fellow at the Center on Budget and Policy Priorities, questions the widespread idea that automation, and more broadly, technological advances, have mainly contributed to this growing labor market problem.
His thesis appears to be a third way between optimism and skepticism. Essentially, he stands for a neutral approach of the linkage between technology and American issues concerning unemployment and declining wages.

He uses two main arguments to defend his point.
First, because of recent technological advances, an increasing number of workers are losing their jobs. Yet, scientific evidence fails to clearly demonstrate that technology has displaced so many workers that it has created more problems than it has solved. Indeed, automation threatens repetitive jobs but higher-end jobs are still necessary because they complement technology and manual jobs that "requires flexibility judgment and common sense" remain hard to replace with machines. Second, studies have not shown clear links between recent technology advances and the wage trends of the last decades.

Therefore, according to Bernstein, instead of focusing on technology and its hypothetical influences on current American increasing unemployment and declining wages, one needs to worry more about "bad policy that fails to offset the imbalances in demand, trade, income, and opportunity."

For people who use both the Internet and mobile devices in excessive quantities it is likely for them to experience fatigue and over exhaustion as a result of disruptions in their sleeping patterns. Continuous studies have shown that increased BMI and weight gain are associated with people who spend long hours online and not exercising frequently. Heavy Internet use is also displayed in the school lower grades of those who use it in excessive amounts. It has also been noted that the use of mobile phones whilst driving has increased the occurrence of road accidents — particularly amongst teen drivers. Statistically, teens reportedly have fourfold the number of road traffic incidents as those who are 20 years or older, and a very high percentage of adolescents write (81%) and read (92%) texts while driving. In this context, mass media and technology have a negative impact on people, on both their mental and physical health.

Thomas P. Hughes stated that because technology has been considered as a key way to solve problems, we need to be aware of its complex and varied characters to use it more efficiently. What is the difference between a wheel or a compass and cooking machines such as an oven or a gas stove? Can we consider all of them, only a part of them, or none of them as technologies?

Technology is often considered too narrowly; according to Hughes, "Technology is a creative process involving human ingenuity". This definition's emphasis on creativity avoids unbounded definitions that may mistakenly include cooking "technologies," but it also highlights the prominent role of humans and therefore their responsibilities for the use of complex technological systems.

Yet, because technology is everywhere and has dramatically changed landscapes and societies, Hughes argues that engineers, scientists, and managers have often believed that they can use technology to shape the world as they want. They have often supposed that technology is easily controllable and this assumption has to be thoroughly questioned. For instance, Evgeny Morozov particularly challenges two concepts: "Internet-centrism" and "solutionism." Internet-centrism refers to the idea that our society is convinced that the Internet is one of the most stable and coherent forces. Solutionism is the ideology that every social issue can be solved thanks to technology and especially thanks to the internet. In fact, technology intrinsically contains uncertainties and limitations. According to Alexis Madrigal's review of Morozov's theory, to ignore it will lead to "unexpected consequences that could eventually cause more damage than the problems they seek to address." Benjamin R. Cohen and Gwen Ottinger also discussed the multivalent effects of technology.

Therefore, recognition of the limitations of technology, and more broadly, scientific knowledge, is needed – especially in cases dealing with environmental justice and health issues. Ottinger continues this reasoning and argues that the ongoing recognition of the limitations of scientific knowledge goes hand in hand with scientists and engineers’ new comprehension of their role. Such an approach of technology and science "[require] technical professionals to conceive of their roles in the process differently. [They have to consider themselves as] collaborators in research and problem solving rather than simply providers of information and technical solutions."

The use of basic technology is also a feature of other animal species apart from humans. These include primates such as chimpanzees, some dolphin communities, and crows. Considering a more generic perspective of technology as ethology of active environmental conditioning and control, we can also refer to animal examples such as beavers and their dams, or bees and their honeycombs.

The ability to make and use tools was once considered a defining characteristic of the genus Homo. However, the discovery of tool construction among chimpanzees and related primates has discarded the notion of the use of technology as unique to humans. For example, researchers have observed wild chimpanzees using tools for foraging: some of the tools used include leaf sponges, termite fishing probes, pestles and levers. West African chimpanzees also use stone hammers and anvils for cracking nuts, as do capuchin monkeys of Boa Vista, Brazil.

Theories of technology often attempt to predict the future of technology based on the high technology and science of the time. As with all predictions of the future, however, technology is uncertain.

In 2005, futurist Ray Kurzweil predicted that the future of technology would mainly consist of an overlapping "GNR Revolution" of genetics, nanotechnology and robotics, with robotics being the most important of the three.



</doc>
<doc id="59091880" url="https://en.wikipedia.org/wiki?curid=59091880" title="Multimodal anthropology">
Multimodal anthropology

Multimodal anthropology is an emerging subfield of social cultural anthropology that encompasses anthropological research and knowledge production across multiple traditional and new media platforms and practices including film, video, photography, theatre, design, podcast, mobile apps, interactive games, web-based social networking, immersive 360 video and augmented reality. As characterized in American Anthropologist"," multimodal anthropology is an "anthropology that works across multiple media, but one that also engages in public anthropology and collaborative anthropology through a field of differentially linked media platforms" (Collins, Durington & Gill). A multimodal approach also encourages anthropologist to reconsider the ways in which they conduct their research, to pay close attention to the role various media technologies and digital devices plays in the lives of their interlocutors, and how they these technologies redefine what fieldwork looks like.

Multimodal anthropology is not a new concept. It has been a fundamental part of anthropological research and fieldwork from the early days of the disciple. Anthropologists have been experimenting with different forms media technologies throughout the twentieth century whenever confronted with the limitation of text-based ethnography. Multimodal is a term that has readily been used since the 1970s in varied disciplines as psychotherapy, phonetics, genetics, literature and medicine to characterize different approaches to carrying out scientific research that involves to a certain degree, thinking outside of the box. In the early 1990s, semioticians used the terms to discuss different forms of communication across different media, eventually including digital media.

Technological advances in the later part of the twentieth century, the accessibility to photography, film cameras and audio recorders led to the emergence of visual anthropology as a sub discipline dedicated to the study and production of ethnographic photography, film and media. Building in this legacy, multimodal anthropology seeks to expand the boundaries of visual anthropology to incorporate emerging technologies of twenty-first century including mobile networking, social media, geo-mapping, virtual reality, podcasting, interactive design, along with other traditional forms of learning and knowledge production like art and drawing that were often sidelined within visual anthropology, such as interactive gaming, theatre, performance, graphic novels, ethnofiction and experimental ethnography. As Samuel Collins, Matthew Durington and Harjant Gill note in their introductory essay on title "Multimodality: An Invitation," published in American Anthropologist, "multimodal anthropologies does not attempt – or desire – to supplant visual anthropology. Rather it seeks to include traditional forms of visual anthropology while simultaneously broadening the purview of the discipline to engage in variety of media forms that exist today."

In 2018 the journal 'entanglements: experiments in multimodal ethnography' was first published, aiming to explore and advance the subfield. The journal is online and open access and is co-edited by Melissa Nolas and Christos Varvantakis. In the inaugural editorial the editors stated that "we aim to engage with some of the challenges and questions that contemporary multimodal ethnographic practice throws up: What knowledge do multimodal and multimedia encounters generate? What languages are available to researchers to describe the coming together of different modes and media? What are the everyday practices involved in such convergences and divergences? How might these encounters themselves be described?" Furthermore, "research is often an attempt to disentangle everyday experiences, those of our interlocutors as well as our encounters with them, and multimodality is no exception here. The analytical approaches of the social sciences tend towards the creation of order out of complexity asking us to categorise and organise our experiences and data in issues, themes, narratives and discourses. The messy actuality of practice, with its sensory dimensions and emotional hues, is often lost in this process (Ingold 2011). What if a different logic guided our analytical and practice endeavours?"



</doc>
<doc id="6504692" url="https://en.wikipedia.org/wiki?curid=6504692" title="Outline of technology">
Outline of technology

The following outline is provided as an overview of and topical guide to technology:

Technology – collection of tools, including machinery, modifications, arrangements and procedures used by humans. Engineering is the discipline that seeks to study and design new technologies. Technologies significantly affect human as well as other animal species' ability to control and adapt to their natural environments.




History of technology






Potential technology of the future includes:

Hypothetical technology – 

Philosophy of technology – 











Fictional technology – 









</doc>
<doc id="58306941" url="https://en.wikipedia.org/wiki?curid=58306941" title="Technology readiness level">
Technology readiness level

Technology readiness levels (TRLs) are a method for estimating the maturity of technologies during the acquisition phase of a program, developed at NASA during the 1970s. The use of TRLs enables consistent, uniform discussions of technical maturity across different types of technology. A technology's TRL is determined during a Technology Readiness Assessment (TRA) that examines program concepts, technology requirements, and demonstrated technology capabilities. TRLs are based on a scale from 1 to 9 with 9 being the most mature technology. The US Department of Defense has used the scale for procurement since the early 2000s. By 2008 the scale was also in use at the European Space Agency (ESA), as evidenced by their handbook.

The European Commission advised EU-funded research and innovation projects to adopt the scale in 2010. TRLs were consequently used in 2014 in the EU Horizon 2020 program. In 2013, the TRL scale was further canonized by the ISO 16290:2013 standard. A comprehensive approach and discussion of TRLs has been published by the European Association of Research and Technology Organisations (EARTO). Extensive criticism of the adoption of TRL scale by the European Union was published in The Innovation Journal, stating that the "concreteness and sophistication of the TRL scale gradually diminished as its usage spread outside its original context (space programs)".

Technology Readiness Levels were originally conceived at NASA in 1974 and formally defined in 1989. The original definition included seven levels, but in the 1990s NASA adopted the current nine-level scale that subsequently gained widespread acceptance.

Original NASA TRL Definitions (1989)

The TRL methodology was originated by Stan Sadin at NASA Headquarters in 1974. At that time, Ray Chase was the JPL Propulsion Division representative on the Jupiter Orbiter design team. At the suggestion of Stan Sadin, Mr Chase used this methodology to assess the technology readiness of the proposed JPL Jupiter Orbiter spacecraft design. Later Mr Chase spent a year at NASA Headquarters helping Mr Sadin institutionalize the TRL methodology. Mr Chase joined ANSER in 1978, where he used the TRL methodology to evaluate the technology readiness of proposed Air Force development programs. He published several articles during the 1980s and 90s on reusable launch vehicles utilizing the TRL methodology. These documented an expanded version of the methodology that included design tools, test facilities, and manufacturing readiness on the Air Force Have Not program. The Have Not program manager, Greg Jenkins, and Ray Chase published the expanded version of the TRL methodology, which included design and manufacturing. Leon McKinney and Mr Chase used the expanded version to assess the technology readiness of the ANSER team's Highly Reusable Space Transportation ("HRST") concept. ANSER also created an adapted version of the TRL methodology for proposed Homeland Security Agency programs.

The United States Air Force adopted the use of Technology Readiness Levels in the 1990s.

In 1995, John C. Mankins, NASA, wrote a paper that discussed NASA's use of TRL, extended the scale, and proposed expanded descriptions for each TRL. In 1999, the United States General Accounting Office produced an influential report that examined the differences in technology transition between the DOD and private industry. It concluded that the DOD takes greater risks and attempts to transition emerging technologies at lesser degrees of maturity than does private industry. The GAO concluded that use of immature technology increased overall program risk. The GAO recommended that the DOD make wider use of Technology Readiness Levels as a means of assessing technology maturity prior to transition. In 2001, the Deputy Under Secretary of Defense for Science and Technology issued a memorandum that endorsed use of TRLs in new major programs. Guidance for assessing technology maturity was incorporated into the "Defense Acquisition Guidebook". Subsequently, the DOD developed detailed guidance for using TRLs in the 2003 DOD Technology Readiness Assessment Deskbook.

Because of their relevance to Habitation, 'Habitation Readiness Levels (HRL)' were formed by a group of NASA engineers (Jan Connolly, Kathy Daues, Robert Howard, and Larry Toups). They have been created to address habitability requirements and design aspects in correlation with already established and widely used standards by different agencies, including NASA TRLs.

The European Space Agency adopted the TRL scale in the mid-2000s. Its handbook closely follows the NASA definition of TRLs. The universal usage of TRL in EU policy was proposed in the final report of the first High Level Expert Group on Key Enabling Technologies, and it was indeed implemented in the subsequent EU framework program, called H2020, running from 2013 to 2020. This means not only space and weapons programs, but everything from nanotechnology to informatics and communication technology.

The current nine-point NASA scale is:

The TRLs in Europe are as follows:

A "Technology Readiness Level Calculator" was developed by the United States Air Force. This tool is a standard set of questions implemented in Microsoft Excel that produces a graphical display of the TRLs achieved. This tool is intended to provide a snapshot of technology maturity at a given point in time.

The "Technology Program Management Model" was developed by the United States Army. The TPMM is a TRL-gated high-fidelity activity model that provides a flexible management tool to assist Technology Managers in planning, managing, and assessing their technologies for successful technology transition. The model provides a core set of activities including systems engineering and program management tasks that are tailored to the technology development and management goals. This approach is comprehensive, yet it consolidates the complex activities that are relevant to the development and transition of a specific technology program into one integrated model.

The primary purpose of using technology readiness levels is to help management in making decisions concerning the development and transitioning of technology. It should be viewed as one of several tools that are needed to manage the progress of research and development activity within an organization.

Among the advantages of TRLs:


Some of the characteristics of TRLs that limit their utility:


Current TRL models tend to disregard negative and obsolescence factors. There have been suggestions made for incorporating such factors into assessments.

For complex technologies that incorporate various development stages, a more detailed scheme called the Technology Readiness Pathway Matrix has been developed going from basic units to applications in society. This tool aims to show that a readiness level of a technology is based on a less linear process but on a more complex pathway through its application in society.





</doc>
<doc id="62028272" url="https://en.wikipedia.org/wiki?curid=62028272" title="Trust Technology">
Trust Technology

Trust Technology also known as TrustTech is any type of tech that enhances and propagates trust in personal, social, and business settings. It is the creation, facilitation, stabilization, and quantification of trust between people.

TrustTech facilitates dynamic systems of inter-personal relationships. It maintains the balance of community systems, as well as commercial and social relationships between people.

TrustTech involves companies, platforms, and services that are made possible by trusting relationships between people. The term "TrustTech" was coined by Javelyn Technologies, and it encompasses the mission of all its companies, particularly "Ognio" which is a hyperlocal PropTech platform.

TrustTech is the result of technological advancements which make more people participate in trust relations in a new way. Previously, face-to-face contact, letters, and storytelling were the primary means of transferring knowledge. Because technology is evolving, the relationships of person-to-person and between users and technology changes, people are now hyper-connected. Furthermore,the geospatial context where relationships take place is urbanising, as the UN predicts that 50% of the global population will live in urban environments by 2050. People have moved from interaction in the physical world to the virtual one, and they, therefore, need a way to create confidence in truth and trustworthiness in an online environment.

The utility of TrustTech is based upon the need for trust in human relationships and businesses which remains despite an increase in anonymity, driven by the increasing urbanisation and digitization of daily life. TrustTech responds to the desire to verify the reliability of individuals, groups of people, businesses and services. New systems, technologies, and business models are built around this new requirement for trust distribution.

TrustTech helps to build more trust in personal and business situations through allowing people to make more relationships. It also enables people to maintain dynamic relationships based on trust. TrustTech is about the evolution of human interaction in densely populated places and in relation to new technology and the role of trust in that context.

TrustTech is part of a broader sphere of systems of trust. For example, some systems focus on mitigating trust and reducing perceived risk. Contract law is an example of such a system. The checks and balances in politics and government are an example of other systems of mitigating trust.

TrustTech is about technological systems of trust. There are technologies that focus on mitigating trust or increasing trust. "Ognio" falls into the latter subcategory because it’s about building rapport between people in hyperlocal spaces. Apps like Trustpilot and Yelp could also be considered types of TrustTech that gather and disseminate information among large groups of people in a reliable manner.

TrustTech also works differently in different industries. Fintech, Insurtech and Regtech are closely related and highly regulated industries. They function efficiently because of trust created by heavy regulation.

Blockchain, a new kind of TrustTech, posed a radical disruption to these established industries. Blockchain is anonymous and fully transparent, posing a potentially more trustworthy alternative to traditional finance. TrustTech can dramatically alter the course of industries.

There are companies that could be described as TrustTech. Listed in the following categories are some of them:







The future of TrustTech touches on areas such as Artificial Intelligence, Cybernetics, Machine learning, Transhumanism, and the ethics of trust in relation to these immanent technologies.



</doc>
<doc id="52048331" url="https://en.wikipedia.org/wiki?curid=52048331" title="Property technology">
Property technology

Property technology (or proptech, also called real estate technology) is the application of information technology and platform economics to real estate markets.

Some goals of real estate technology include reducing paperwork or making transactions quicker and more efficient, it is often thought of as overlapping with financial technology. Contemporary digital real estate technologies could therefore include property management using digital dashboards, smart home technology, research and analytics, listing services/tech-enabled brokerages, mobile applications, residential and commercial lending, 3D-modeling for online portals, automation, crowdfunding real estate projects, shared spaces management, as well as organizing, analyzing, and extracting key data from lengthy rental documents.

There are currently many startups trying to target every segment of the property market chain, attempting to disrupt and improve how the current market players (developers, buyers, sellers, renters, investors, and real estate professionals) design, construct, market, discover, transact and operate real estate. These startups have been supported by seed funding and investment from a range of sources, including some specialist real estate technology venture capital funds.

In the first six months of 2019, $12.9 billion was poured into real-estate tech startups by venture investors, which surpassed the $12.7 billion record for all of 2017. In 2015, real estate tech reached record funding and deals levels, with more than $1.7bn deployed globally across more than 190 deals. This represents a 50% increase year-over-year and a whopping 821% increase in funding compared to 2011′s total. Deal activity also soared, growing 378% with respect to 2011′s total, and 12% year-over-year. This investment appeared to increase further in 2017 to £8.5bn.

Advances in the residential side of real estate technology encompass a number of target areas, but generally aim to reduce friction in the purchase, sale, or rental of a property. Areas of focus include finding a home, selling a home, financing a purchase, closing on a property (including valuation, title & escrow, and insurance), managing a property, managing loans, and mortgage lending software.


</doc>
<doc id="63359203" url="https://en.wikipedia.org/wiki?curid=63359203" title="Dimensions in Testimony">
Dimensions in Testimony

Dimensions in Testimony is a collection of 3D interactive genocide survivor testimonies, produced by USC Shoah Foundation in order to preserve the conversational experience of asking survivors questions about their life and hearing responses in real time, therefore preserving history through first-person narrative.

Using techniques in physical production and post production, individuals who have witnessed some of the most difficult times in human history are interviewed about their lives and a variety of topics, and natural language processing allows those interviews to become interactive exhibitions and displays in museums, educational centers, and other points of interest. 

Included in the collection are a series of Holocaust survivors, as well as two World War II Liberators and a survivor of the Nanjing Massacre. To date, testimonies have been conducted in English, Spanish, Hebrew, German, Mandarin, Russian and Swedish. An in-depth evaluation project created by USC Shoah Foundation in 2016 showed the technology to be a "valuable education tool".

The project was conceptualized by Heather Maio of Conscience Display and was created in partnership with USC Shoah Foundation and USC's Institute for Creative Technologies. In 2012, the team created a proof of concept for an interactive biography of a genocide survivor, then called "New Dimensions in Testimony". The proof of concept was conducted with survivor Pinchas Gutter, who would go on to film the pilot testimony for the project in April 2014. This pilot would become Dimensions In Testimony's first permanent installation, premiering at the Illinois Holocaust Museum and Education Center in 2015.""We survivors feel that once we are gone, our story is gone...[now] I’m hoping that many, many years from now, people will still be able to speak with me, that I will be able to answer questions for them, that I’ll make the Holocaust more than just a story.”" -Holocaust Survivor Aaron Elster, whose Dimensions in Testimony biography was recorded in 2015

Production for a single interview typically requires a 5-day process, in which the survivor is asked a series of questions, commonly within a rig that is able to film on green screen from multiple angles at once. Between 2013 and 2017, testimonies were filmed within a 116-camera dome at the Institute of Creative Technologies in Playa Vista, CA. In 2018, USC Shoah Foundation developed a mobile rig that allows production crews to travel around the world and film aging survivors in their hometowns volumetrically. Filming from multiple angles “future-proofs” the technology in the hopes that in the future, each testimony might be able to be projected as a hologram using projection display techniques that have yet to be invented.

Thousands of questions are asked and answered over the course of a single interview. To ensure continuity for the duration of the interactive experience, survivors are required to wear the same clothing for each day of interviews and return to a common resting position following each response.

Each interview includes an extensive list of topics that cover life before, during and after conflict as well as off-topic responses in order to have the wide range of information needed to facilitate conversational interactions. Natural language processing and speech recognition allow for the system to map an automated response that best fits a user's question. To maintain usability of each interview as a primary source, USC Shoah Foundation does not animate, edit, or manipulate the video footage of the interviewee's response.

In 2017, independent filmmaker Davina Pardo documented the production process in a 15-minute documentary short entitled "116 Cameras" and an accompanying Opinion piece in the New York Times. The film followed the production of the Dimensions in Testimony interview of Eva Schloss, a Holocaust survivor from Vienna, Austria.

In 2020, American news magazine 60 Minutes ran two segments on Dimensions in Testimony, airing on Sunday, April 5.


</doc>
<doc id="31880" url="https://en.wikipedia.org/wiki?curid=31880" title="Universe">
Universe

The universe () is all of space and time and their contents, including planets, stars, galaxies, and all other forms of matter and energy. While the spatial size of the entire universe is unknown, it is possible to measure the size of the observable universe, which is currently estimated to be 93 billion light-years in diameter. In various multiverse hypotheses, "a universe" is one of many causally disconnected constituent parts of a larger multiverse, which itself comprises all of space and time and its contents; as a consequence, ‘the universe’ and ‘the multiverse’ are synonymous in such theories.

The earliest cosmological models of the universe were developed by ancient Greek and Indian philosophers and were geocentric, placing Earth at the center. Over the centuries, more precise astronomical observations led Nicolaus Copernicus to develop the heliocentric model with the Sun at the center of the Solar System. In developing the law of universal gravitation, Isaac Newton built upon Copernicus' work as well as Johannes Kepler's laws of planetary motion and observations by Tycho Brahe.

Further observational improvements led to the realization that the Sun is one of hundreds of billions of stars in the Milky Way, which is one of at least hundreds of billions of galaxies in the universe. Many of the stars in our galaxy have planets. At the largest scale, galaxies are distributed uniformly and the same in all directions, meaning that the universe has neither an edge nor a center. At smaller scales, galaxies are distributed in clusters and superclusters which form immense filaments and voids in space, creating a vast foam-like structure. Discoveries in the early 20th century have suggested that the universe had a beginning and that space has been expanding since then, and is currently still expanding at an increasing rate.

The Big Bang theory is the prevailing cosmological description of the development of the universe. According to estimation of this theory, space and time emerged together ago and the energy and matter initially present have become less dense as the universe expanded. After an initial accelerated expansion called the inflationary epoch at around 10 seconds, and the separation of the four known fundamental forces, the universe gradually cooled and continued to expand, allowing the first subatomic particles and simple atoms to form. Dark matter gradually gathered, forming a foam-like structure of filaments and voids under the influence of gravity. Giant clouds of hydrogen and helium were gradually drawn to the places where dark matter was most dense, forming the first galaxies, stars, and everything else seen today. It is possible to see objects that are now further away than 13.799 billion light-years because space itself has expanded, and it is still expanding today. This means that objects which are now up to 46.5 billion light-years away can still be seen in their distant past, because in the past, when their light was emitted, they were much closer to Earth.

From studying the movement of galaxies, it has been discovered that the universe contains much more matter than is accounted for by visible objects; stars, galaxies, nebulas and interstellar gas. This unseen matter is known as dark matter ("dark" means that there is a wide range of strong indirect evidence that it exists, but we have not yet detected it directly). The ΛCDM model is the most widely accepted model of our universe. It suggests that about [2015] of the mass and energy in the universe is a cosmological constant (or, in extensions to ΛCDM, other forms of dark energy, such as a scalar field) which is responsible for the current expansion of space, and about [2015] is dark matter. Ordinary ('baryonic') matter is therefore only [2015] of the physical universe. Stars, planets, and visible gas clouds only form about 6% of ordinary matter, or about 0.29% of the entire universe.

There are many competing hypotheses about the ultimate fate of the universe and about what, if anything, preceded the Big Bang, while other physicists and philosophers refuse to speculate, doubting that information about prior states will ever be accessible. Some physicists have suggested various multiverse hypotheses, in which our universe might be one among many universes that likewise exist.

The physical universe is defined as all of space and time (collectively referred to as spacetime) and their contents. Such contents comprise all of energy in its various forms, including electromagnetic radiation and matter, and therefore planets, moons, stars, galaxies, and the contents of intergalactic space. The universe also includes the physical laws that influence energy and matter, such as conservation laws, classical mechanics, and relativity.

The universe is often defined as "the totality of existence", or everything that exists, everything that has existed, and everything that will exist. In fact, some philosophers and scientists support the inclusion of ideas and abstract concepts—such as mathematics and logic—in the definition of the universe. The word "universe" may also refer to concepts such as "the cosmos", "the world", and "nature".

The word "universe" derives from the Old French word "univers", which in turn derives from the Latin word "universum". The Latin word was used by Cicero and later Latin authors in many of the same senses as the modern English word is used.

A term for "universe" among the ancient Greek philosophers from Pythagoras onwards was , "tò pân" ("the all"), defined as all matter and all space, and , "tò hólon" ("all things"), which did not necessarily include the void. Another synonym was , "ho kósmos" (meaning the world, the cosmos). Synonyms are also found in Latin authors ("totum", "mundus", "natura") and survive in modern languages, e.g., the German words "Das All", "Weltall", and "Natur" for "universe". The same synonyms are found in English, such as everything (as in the theory of everything), the cosmos (as in cosmology), the world (as in the many-worlds interpretation), and nature (as in natural laws or natural philosophy).

The prevailing model for the evolution of the universe is the Big Bang theory. The Big Bang model states that the earliest state of the universe was an extremely hot and dense one, and that the universe subsequently expanded and cooled. The model is based on general relativity and on simplifying assumptions such as homogeneity and isotropy of space. A version of the model with a cosmological constant (Lambda) and cold dark matter, known as the Lambda-CDM model, is the simplest model that provides a reasonably good account of various observations about the universe. The Big Bang model accounts for observations such as the correlation of distance and redshift of galaxies, the ratio of the number of hydrogen to helium atoms, and the microwave radiation background.

The initial hot, dense state is called the Planck epoch, a brief period extending from time zero to one Planck time unit of approximately 10 seconds. During the Planck epoch, all types of matter and all types of energy were concentrated into a dense state, and gravity—currently the weakest by far of the four known forces—is believed to have been as strong as the other fundamental forces, and all the forces may have been unified. Since the Planck epoch, space has been expanding to its present scale, with a very short but intense period of cosmic inflation believed to have occurred within the first 10 seconds. This was a kind of expansion different from those we can see around us today. Objects in space did not physically move; instead the metric that defines space itself changed. Although objects in spacetime cannot move faster than the speed of light, this limitation does not apply to the metric governing spacetime itself. This initial period of inflation is believed to explain why space appears to be very flat, and much larger than light could travel since the start of the universe.

Within the first fraction of a second of the universe's existence, the four fundamental forces had separated. As the universe continued to cool down from its inconceivably hot state, various types of subatomic particles were able to form in short periods of time known as the quark epoch, the hadron epoch, and the lepton epoch. Together, these epochs encompassed less than 10 seconds of time following the Big Bang. These elementary particles associated stably into ever larger combinations, including stable protons and neutrons, which then formed more complex atomic nuclei through nuclear fusion. This process, known as Big Bang nucleosynthesis, only lasted for about 17 minutes and ended about 20 minutes after the Big Bang, so only the fastest and simplest reactions occurred. About 25% of the protons and all the neutrons in the universe, by mass, were converted to helium, with small amounts of deuterium (a form of hydrogen) and traces of lithium. Any other element was only formed in very tiny quantities. The other 75% of the protons remained unaffected, as hydrogen nuclei.

After nucleosynthesis ended, the universe entered a period known as the photon epoch. During this period, the universe was still far too hot for matter to form neutral atoms, so it contained a hot, dense, foggy plasma of negatively charged electrons, neutral neutrinos and positive nuclei. After about 377,000 years, the universe had cooled enough that electrons and nuclei could form the first stable atoms. This is known as recombination for historical reasons; in fact electrons and nuclei were combining for the first time. Unlike plasma, neutral atoms are transparent to many wavelengths of light, so for the first time the universe also became transparent. The photons released ("decoupled") when these atoms formed can still be seen today; they form the cosmic microwave background (CMB).

As the universe expands, the energy density of electromagnetic radiation decreases more quickly than does that of matter because the energy of a photon decreases with its wavelength. At around 47,000 years, the energy density of matter became larger than that of photons and neutrinos, and began to dominate the large scale behavior of the universe. This marked the end of the radiation-dominated era and the start of the matter-dominated era.

In the earliest stages of the universe, tiny fluctuations within the universe's density led to concentrations of dark matter gradually forming. Ordinary matter, attracted to these by gravity, formed large gas clouds and eventually, stars and galaxies, where the dark matter was most dense, and voids where it was least dense. After around 100 - 300 million years, the first stars formed, known as Population III stars. These were probably very massive, luminous, non metallic and short-lived. They were responsible for the gradual reionization of the universe between about 200-500 million years and 1 billion years, and also for seeding the universe with elements heavier than helium, through stellar nucleosynthesis. The universe also contains a mysterious energy—possibly a scalar field—called dark energy, the density of which does not change over time. After about 9.8 billion years, the universe had expanded sufficiently so that the density of matter was less than the density of dark energy, marking the beginning of the present dark-energy-dominated era. In this era, the expansion of the universe is accelerating due to dark energy.

Of the four fundamental interactions, gravitation is the dominant at astronomical length scales. Gravity's effects are cumulative; by contrast, the effects of positive and negative charges tend to cancel one another, making electromagnetism relatively insignificant on astronomical length scales. The remaining two interactions, the weak and strong nuclear forces, decline very rapidly with distance; their effects are confined mainly to sub-atomic length scales.

The universe appears to have much more matter than antimatter, an asymmetry possibly related to the CP violation. This imbalance between matter and antimatter is partially responsible for the existence of all matter existing today, since matter and antimatter, if equally produced at the Big Bang, would have completely annihilated each other and left only photons as a result of their interaction. The universe also appears to have neither net momentum nor angular momentum, which follows accepted physical laws if the universe is finite. These laws are Gauss's law and the non-divergence of the stress-energy-momentum pseudotensor.

The size of the universe is somewhat difficult to define. According to the general theory of relativity, far regions of space may never interact with ours even in the lifetime of the universe due to the finite speed of light and the ongoing expansion of space. For example, radio messages sent from Earth may never reach some regions of space, even if the universe were to exist forever: space may expand faster than light can traverse it.

Distant regions of space are assumed to exist and to be part of reality as much as we are, even though we can never interact with them. The spatial region that we can affect and be affected by is the observable universe. The observable universe depends on the location of the observer. By traveling, an observer can come into contact with a greater region of spacetime than an observer who remains still. Nevertheless, even the most rapid traveler will not be able to interact with all of space. Typically, the observable universe is taken to mean the portion of the universe that is observable from our vantage point in the Milky Way.

The proper distance—the distance as would be measured at a specific time, including the present—between Earth and the edge of the observable universe is 46 billion light-years (14 billion parsecs), making the diameter of the observable universe about 93 billion light-years (28 billion parsecs). The distance the light from the edge of the observable universe has travelled is very close to the age of the universe times the speed of light, , but this does not represent the distance at any given time because the edge of the observable universe and the Earth have since moved further apart. For comparison, the diameter of a typical galaxy is 30,000 light-years (9,198 parsecs), and the typical distance between two neighboring galaxies is 3 million light-years (919.8 kiloparsecs). As an example, the Milky Way is roughly 100,000–180,000 light-years in diameter, and the nearest sister galaxy to the Milky Way, the Andromeda Galaxy, is located roughly 2.5 million light-years away.

Because we cannot observe space beyond the edge of the observable universe, it is unknown whether the size of the universe in its totality is finite or infinite. Estimates for the total size of the universe, if finite, reach as high as formula_1 megaparsecs, implied by one resolution of the No-Boundary Proposal.

Astronomers calculate the age of the universe by assuming that the Lambda-CDM model accurately describes the evolution of the Universe from a very uniform, hot, dense primordial state to its present state and measuring the cosmological parameters which constitute the model. This model is well understood theoretically and supported by recent high-precision astronomical observations such as WMAP and Planck. Commonly, the set of observations fitted includes the cosmic microwave background anisotropy, the brightness/redshift relation for Type Ia supernovae, and large-scale galaxy clustering including the baryon acoustic oscillation feature. Other observations, such as the Hubble constant, the abundance of galaxy clusters, weak gravitational lensing and globular cluster ages, are generally consistent with these, providing a check of the model, but are less accurately measured at present. Assuming that the Lambda-CDM model is correct, the measurements of the parameters using a variety of techniques by numerous experiments yield a best value of the age of the universe as of 2015 of 13.799 ± 0.021 billion years.
Over time, the universe and its contents have evolved; for example, the relative population of quasars and galaxies has changed and space itself has expanded. Due to this expansion, scientists on Earth can observe the light from a galaxy 30 billion light-years away even though that light has traveled for only 13 billion years; the very space between them has expanded. This expansion is consistent with the observation that the light from distant galaxies has been redshifted; the photons emitted have been stretched to longer wavelengths and lower frequency during their journey. Analyses of Type Ia supernovae indicate that the spatial expansion is accelerating.

The more matter there is in the universe, the stronger the mutual gravitational pull of the matter. If the universe were "too" dense then it would re-collapse into a gravitational singularity. However, if the universe contained too "little" matter then the self-gravity would be too weak for astronomical structures, like galaxies or planets, to form. Since the Big Bang, the universe has expanded monotonically. Perhaps unsurprisingly, our universe has just the right mass-energy density, equivalent to about 5 protons per cubic metre, which has allowed it to expand for the last 13.8 billion years, giving time to form the universe as observed today.

There are dynamical forces acting on the particles in the universe which affect the expansion rate. Before 1998, it was expected that the expansion rate would be decreasing as time went on due to the influence of gravitational interactions in the universe; and thus there is an additional observable quantity in the universe called the deceleration parameter, which most cosmologists expected to be positive and related to the matter density of the universe. In 1998, the deceleration parameter was measured by two different groups to be negative, approximately -0.55, which technically implies that the second derivative of the cosmic scale factor formula_2 has been positive in the last 5-6 billion years. This acceleration does not, however, imply that the Hubble parameter is currently increasing; see deceleration parameter for details.

Spacetimes are the arenas in which all physical events take place. The basic elements of spacetimes are events. In any given spacetime, an event is defined as a unique position at a unique time. A spacetime is the union of all events (in the same way that a line is the union of all of its points), formally organized into a manifold.

The universe appears to be a smooth spacetime continuum consisting of three spatial dimensions and one temporal (time) dimension (an event in the spacetime of the physical universe can therefore be identified by a set of four coordinates: ("x", "y", "z", "t") ). On the average, space is observed to be very nearly flat (with a curvature close to zero), meaning that Euclidean geometry is empirically true with high accuracy throughout most of the Universe. Spacetime also appears to have a simply connected topology, in analogy with a sphere, at least on the length-scale of the observable universe. However, present observations cannot exclude the possibilities that the universe has more dimensions (which is postulated by theories such as the string theory) and that its spacetime may have a multiply connected global topology, in analogy with the cylindrical or toroidal topologies of two-dimensional spaces. The spacetime of the universe is usually interpreted from a Euclidean perspective, with space as consisting of three dimensions, and time as consisting of one dimension, the "fourth dimension". By combining space and time into a single manifold called Minkowski space, physicists have simplified a large number of physical theories, as well as described in a more uniform way the workings of the universe at both the supergalactic and subatomic levels.

Spacetime events are not absolutely defined spatially and temporally but rather are known to be relative to the motion of an observer. Minkowski space approximates the universe without gravity; the pseudo-Riemannian manifolds of general relativity describe spacetime with matter and gravity.

General relativity describes how spacetime is curved and bent by mass and energy (gravity). The topology or geometry of the universe includes both local geometry in the observable universe and global geometry. Cosmologists often work with a given space-like slice of spacetime called the comoving coordinates. The section of spacetime which can be observed is the backward light cone, which delimits the cosmological horizon. The cosmological horizon (also called the particle horizon or the light horizon) is the maximum distance from which particles can have traveled to the observer in the age of the universe. This horizon represents the boundary between the observable and the unobservable regions of the universe. The existence, properties, and significance of a cosmological horizon depend on the particular cosmological model.

An important parameter determining the future evolution of the universe theory is the density parameter, Omega (Ω), defined as the average matter density of the universe divided by a critical value of that density. This selects one of three possible geometries depending on whether Ω is equal to, less than, or greater than 1. These are called, respectively, the flat, open and closed universes.

Observations, including the Cosmic Background Explorer (COBE), Wilkinson Microwave Anisotropy Probe (WMAP), and Planck maps of the CMB, suggest that the universe is infinite in extent with a finite age, as described by the Friedmann–Lemaître–Robertson–Walker (FLRW) models. These FLRW models thus support inflationary models and the standard model of cosmology, describing a flat, homogeneous universe presently dominated by dark matter and dark energy.

The universe may be "fine-tuned"; the Fine-tuned universe hypothesis is the proposition that the conditions that allow the existence of observable life in the universe can only occur when certain universal fundamental physical constants lie within a very narrow range of values, so that if any of several fundamental constants were only slightly different, the universe would have been unlikely to be conducive to the establishment and development of matter, astronomical structures, elemental diversity, or life as it is understood. The proposition is discussed among philosophers, scientists, theologians, and proponents of creationism.

The universe is composed almost completely of dark energy, dark matter, and ordinary matter. Other contents are electromagnetic radiation (estimated to constitute from 0.005% to close to 0.01% of the total mass-energy of the universe) and antimatter.

The proportions of all types of matter and energy have changed over the history of the universe. The total amount of electromagnetic radiation generated within the universe has decreased by 1/2 in the past 2 billion years. Today, ordinary matter, which includes atoms, stars, galaxies, and life, accounts for only 4.9% of the contents of the Universe. The present overall density of this type of matter is very low, roughly 4.5 × 10 grams per cubic centimetre, corresponding to a density of the order of only one proton for every four cubic metres of volume. The nature of both dark energy and dark matter is unknown. Dark matter, a mysterious form of matter that has not yet been identified, accounts for 26.8% of the cosmic contents. Dark energy, which is the energy of empty space and is causing the expansion of the universe to accelerate, accounts for the remaining 68.3% of the contents.
Matter, dark matter, and dark energy are distributed homogeneously throughout the universe over length scales longer than 300 million light-years or so. However, over shorter length-scales, matter tends to clump hierarchically; many atoms are condensed into stars, most stars into galaxies, most galaxies into clusters, superclusters and, finally, large-scale galactic filaments. The observable universe contains more than 2 trillion (10) galaxies and, overall, as many as an estimated stars (more stars than all the grains of sand on planet Earth). Typical galaxies range from dwarfs with as few as ten million (10) stars up to giants with one trillion (10) stars. Between the larger structures are voids, which are typically 10–150 Mpc (33 million–490 million ly) in diameter. The Milky Way is in the Local Group of galaxies, which in turn is in the Laniakea Supercluster. This supercluster spans over 500 million light-years, while the Local Group spans over 10 million light-years. The Universe also has vast regions of relative emptiness; the largest known void measures 1.8 billion ly (550 Mpc) across.

The observable universe is isotropic on scales significantly larger than superclusters, meaning that the statistical properties of the universe are the same in all directions as observed from Earth. The universe is bathed in highly isotropic microwave radiation that corresponds to a thermal equilibrium blackbody spectrum of roughly 2.72548 kelvins. The hypothesis that the large-scale universe is homogeneous and isotropic is known as the cosmological principle. A universe that is both homogeneous and isotropic looks the same from all vantage points and has no center.

An explanation for why the expansion of the universe is accelerating remains elusive. It is often attributed to "dark energy", an unknown form of energy that is hypothesized to permeate space. On a mass–energy equivalence basis, the density of dark energy (~ 7 × 10 g/cm) is much less than the density of ordinary matter or dark matter within galaxies. However, in the present dark-energy era, it dominates the mass–energy of the universe because it is uniform across space.

Two proposed forms for dark energy are the cosmological constant, a "constant" energy density filling space homogeneously, and scalar fields such as quintessence or moduli, "dynamic" quantities whose energy density can vary in time and space. Contributions from scalar fields that are constant in space are usually also included in the cosmological constant. The cosmological constant can be formulated to be equivalent to vacuum energy. Scalar fields having only a slight amount of spatial inhomogeneity would be difficult to distinguish from a cosmological constant.

Dark matter is a hypothetical kind of matter that is invisible to the entire electromagnetic spectrum, but which accounts for most of the matter in the universe. The existence and properties of dark matter are inferred from its gravitational effects on visible matter, radiation, and the large-scale structure of the universe. Other than neutrinos, a form of hot dark matter, dark matter has not been detected directly, making it one of the greatest mysteries in modern astrophysics. Dark matter neither emits nor absorbs light or any other electromagnetic radiation at any significant level. Dark matter is estimated to constitute 26.8% of the total mass–energy and 84.5% of the total matter in the universe.

The remaining 4.9% of the mass–energy of the universe is ordinary matter, that is, atoms, ions, electrons and the objects they form. This matter includes stars, which produce nearly all of the light we see from galaxies, as well as interstellar gas in the interstellar and intergalactic media, planets, and all the objects from everyday life that we can bump into, touch or squeeze. As a matter of fact, the great majority of ordinary matter in the universe is unseen, since visible stars and gas inside galaxies and clusters account for less than 10 per cent of the ordinary matter contribution to the mass-energy density of the universe.

Ordinary matter commonly exists in four states (or phases): solid, liquid, gas, and plasma. However, advances in experimental techniques have revealed other previously theoretical phases, such as Bose–Einstein condensates and fermionic condensates.

Ordinary matter is composed of two types of elementary particles: quarks and leptons. For example, the proton is formed of two up quarks and one down quark; the neutron is formed of two down quarks and one up quark; and the electron is a kind of lepton. An atom consists of an atomic nucleus, made up of protons and neutrons, and electrons that orbit the nucleus. Because most of the mass of an atom is concentrated in its nucleus, which is made up of baryons, astronomers often use the term "baryonic matter" to describe ordinary matter, although a small fraction of this "baryonic matter" is electrons.

Soon after the Big Bang, primordial protons and neutrons formed from the quark–gluon plasma of the early universe as it cooled below two trillion degrees. A few minutes later, in a process known as Big Bang nucleosynthesis, nuclei formed from the primordial protons and neutrons. This nucleosynthesis formed lighter elements, those with small atomic numbers up to lithium and beryllium, but the abundance of heavier elements dropped off sharply with increasing atomic number. Some boron may have been formed at this time, but the next heavier element, carbon, was not formed in significant amounts. Big Bang nucleosynthesis shut down after about 20 minutes due to the rapid drop in temperature and density of the expanding universe. Subsequent formation of heavier elements resulted from stellar nucleosynthesis and supernova nucleosynthesis.

Ordinary matter and the forces that act on matter can be described in terms of elementary particles. These particles are sometimes described as being fundamental, since they have an unknown substructure, and it is unknown whether or not they are composed of smaller and even more fundamental particles. Of central importance is the Standard Model, a theory that is concerned with electromagnetic interactions and the weak and strong nuclear interactions. The Standard Model is supported by the experimental confirmation of the existence of particles that compose matter: quarks and leptons, and their corresponding "antimatter" duals, as well as the force particles that mediate interactions: the photon, the W and Z bosons, and the gluon. The Standard Model predicted the existence of the recently discovered Higgs boson, a particle that is a manifestation of a field within the universe that can endow particles with mass. Because of its success in explaining a wide variety of experimental results, the Standard Model is sometimes regarded as a "theory of almost everything". The Standard Model does not, however, accommodate gravity. A true force-particle "theory of everything" has not been attained.

A hadron is a composite particle made of quarks held together by the strong force. Hadrons are categorized into two families: baryons (such as protons and neutrons) made of three quarks, and mesons (such as pions) made of one quark and one antiquark. Of the hadrons, protons are stable, and neutrons bound within atomic nuclei are stable. Other hadrons are unstable under ordinary conditions and are thus insignificant constituents of the modern universe. From approximately 10 seconds after the Big Bang, during a period is known as the hadron epoch, the temperature of the universe had fallen sufficiently to allow quarks to bind together into hadrons, and the mass of the universe was dominated by hadrons. Initially the temperature was high enough to allow the formation of hadron/anti-hadron pairs, which kept matter and antimatter in thermal equilibrium. However, as the temperature of the universe continued to fall, hadron/anti-hadron pairs were no longer produced. Most of the hadrons and anti-hadrons were then eliminated in particle-antiparticle annihilation reactions, leaving a small residual of hadrons by the time the universe was about one second old.

A lepton is an elementary, half-integer spin particle that does not undergo strong interactions but is subject to the Pauli exclusion principle; no two leptons of the same species can be in exactly the same state at the same time. Two main classes of leptons exist: charged leptons (also known as the "electron-like" leptons), and neutral leptons (better known as neutrinos). Electrons are stable and the most common charged lepton in the universe, whereas muons and taus are unstable particle that quickly decay after being produced in high energy collisions, such as those involving cosmic rays or carried out in particle accelerators. Charged leptons can combine with other particles to form various composite particles such as atoms and positronium. The electron governs nearly all of chemistry, as it is found in atoms and is directly tied to all chemical properties. Neutrinos rarely interact with anything, and are consequently rarely observed. Neutrinos stream throughout the universe but rarely interact with normal matter.

The lepton epoch was the period in the evolution of the early universe in which the leptons dominated the mass of the universe. It started roughly 1 second after the Big Bang, after the majority of hadrons and anti-hadrons annihilated each other at the end of the hadron epoch. During the lepton epoch the temperature of the universe was still high enough to create lepton/anti-lepton pairs, so leptons and anti-leptons were in thermal equilibrium. Approximately 10 seconds after the Big Bang, the temperature of the universe had fallen to the point where lepton/anti-lepton pairs were no longer created. Most leptons and anti-leptons were then eliminated in annihilation reactions, leaving a small residue of leptons. The mass of the universe was then dominated by photons as it entered the following photon epoch.

A photon is the quantum of light and all other forms of electromagnetic radiation. It is the force carrier for the electromagnetic force, even when static via virtual photons. The effects of this force are easily observable at the microscopic and at the macroscopic level because the photon has zero rest mass; this allows long distance interactions. Like all elementary particles, photons are currently best explained by quantum mechanics and exhibit wave–particle duality, exhibiting properties of waves and of particles.

The photon epoch started after most leptons and anti-leptons were annihilated at the end of the lepton epoch, about 10 seconds after the Big Bang. Atomic nuclei were created in the process of nucleosynthesis which occurred during the first few minutes of the photon epoch. For the remainder of the photon epoch the universe contained a hot dense plasma of nuclei, electrons and photons. About 380,000 years after the Big Bang, the temperature of the Universe fell to the point where nuclei could combine with electrons to create neutral atoms. As a result, photons no longer interacted frequently with matter and the universe became transparent. The highly redshifted photons from this period form the cosmic microwave background. Tiny variations in temperature and density detectable in the CMB were the early "seeds" from which all subsequent structure formation took place.
General relativity is the geometric theory of gravitation published by Albert Einstein in 1915 and the current description of gravitation in modern physics. It is the basis of current cosmological models of the universe. General relativity generalizes special relativity and Newton's law of universal gravitation, providing a unified description of gravity as a geometric property of space and time, or spacetime. In particular, the curvature of spacetime is directly related to the energy and momentum of whatever matter and radiation are present. The relation is specified by the Einstein field equations, a system of partial differential equations. In general relativity, the distribution of matter and energy determines the geometry of spacetime, which in turn describes the acceleration of matter. Therefore, solutions of the Einstein field equations describe the evolution of the universe. Combined with measurements of the amount, type, and distribution of matter in the universe, the equations of general relativity describe the evolution of the universe over time.

With the assumption of the cosmological principle that the universe is homogeneous and isotropic everywhere, a specific solution of the field equations that describes the universe is the metric tensor called the Friedmann–Lemaître–Robertson–Walker metric,
where ("r", θ, φ) correspond to a spherical coordinate system. This metric has only two undetermined parameters. An overall dimensionless length scale factor "R" describes the size scale of the universe as a function of time; an increase in "R" is the expansion of the universe. A curvature index "k" describes the geometry. The index "k" is defined so that it can take only one of three values: 0, corresponding to flat Euclidean geometry; 1, corresponding to a space of positive curvature; or −1, corresponding to a space of positive or negative curvature. The value of "R" as a function of time "t" depends upon "k" and the cosmological constant "Λ". The cosmological constant represents the energy density of the vacuum of space and could be related to dark energy. The equation describing how "R" varies with time is known as the Friedmann equation after its inventor, Alexander Friedmann.

The solutions for "R(t)" depend on "k" and "Λ", but some qualitative features of such solutions are general. First and most importantly, the length scale "R" of the universe can remain constant "only" if the universe is perfectly isotropic with positive curvature ("k"=1) and has one precise value of density everywhere, as first noted by Albert Einstein. However, this equilibrium is unstable: because the universe is known to be inhomogeneous on smaller scales, "R" must change over time. When "R" changes, all the spatial distances in the universe change in tandem; there is an overall expansion or contraction of space itself. This accounts for the observation that galaxies appear to be flying apart; the space between them is stretching. The stretching of space also accounts for the apparent paradox that two galaxies can be 40 billion light-years apart, although they started from the same point 13.8 billion years ago and never moved faster than the speed of light.

Second, all solutions suggest that there was a gravitational singularity in the past, when "R" went to zero and matter and energy were infinitely dense. It may seem that this conclusion is uncertain because it is based on the questionable assumptions of perfect homogeneity and isotropy (the cosmological principle) and that only the gravitational interaction is significant. However, the Penrose–Hawking singularity theorems show that a singularity should exist for very general conditions. Hence, according to Einstein's field equations, "R" grew rapidly from an unimaginably hot, dense state that existed immediately following this singularity (when "R" had a small, finite value); this is the essence of the Big Bang model of the universe. Understanding the singularity of the Big Bang likely requires a quantum theory of gravity, which has not yet been formulated.

Third, the curvature index "k" determines the sign of the mean spatial curvature of spacetime averaged over sufficiently large length scales (greater than about a billion light-years). If "k"=1, the curvature is positive and the universe has a finite volume. A universe with positive curvature is often visualized as a three-dimensional sphere embedded in a four-dimensional space. Conversely, if "k" is zero or negative, the universe has an infinite volume. It may seem counter-intuitive that an infinite and yet infinitely dense universe could be created in a single instant at the Big Bang when "R"=0, but exactly that is predicted mathematically when "k" does not equal 1. By analogy, an infinite plane has zero curvature but infinite area, whereas an infinite cylinder is finite in one direction and a torus is finite in both. A toroidal universe could behave like a normal universe with periodic boundary conditions.

The ultimate fate of the universe is still unknown, because it depends critically on the curvature index "k" and the cosmological constant "Λ". If the universe were sufficiently dense, "k" would equal +1, meaning that its average curvature throughout is positive and the universe will eventually recollapse in a Big Crunch, possibly starting a new universe in a Big Bounce. Conversely, if the universe were insufficiently dense, "k" would equal 0 or −1 and the universe would expand forever, cooling off and eventually reaching the Big Freeze and the heat death of the universe. Modern data suggests that the rate of expansion of the universe is not decreasing, as originally expected, but increasing; if this continues indefinitely, the universe may eventually reach a Big Rip. Observationally, the universe appears to be flat ("k" = 0), with an overall density that is very close to the critical value between recollapse and eternal expansion.

Some speculative theories have proposed that our universe is but one of a set of disconnected universes, collectively denoted as the multiverse, challenging or enhancing more limited definitions of the universe. Scientific multiverse models are distinct from concepts such as alternate planes of consciousness and simulated reality.

Max Tegmark developed a four-part classification scheme for the different types of multiverses that scientists have suggested in response to various Physics problems. An example of such multiverses is the one resulting from the chaotic inflation model of the early universe. Another is the multiverse resulting from the many-worlds interpretation of quantum mechanics. In this interpretation, parallel worlds are generated in a manner similar to quantum superposition and decoherence, with all states of the wave functions being realized in separate worlds. Effectively, in the many-worlds interpretation the multiverse evolves as a universal wavefunction. If the Big Bang that created our multiverse created an ensemble of multiverses, the wave function of the ensemble would be entangled in this sense.

The least controversial category of multiverse in Tegmark's scheme is . The multiverses of this level are composed by distant spacetime events "in our own universe". If space is infinite, or sufficiently large and uniform, identical instances of the history of Earth's entire Hubble volume occur every so often, simply by chance. Tegmark calculated that our nearest so-called doppelgänger, is 10 metres away from us (a double exponential function larger than a googolplex). In principle, it would be impossible to scientifically verify the existence of an identical Hubble volume. However, this existence does follow as a fairly straightforward consequence 

It is possible to conceive of disconnected spacetimes, each existing but unable to interact with one another. An easily visualized metaphor of this concept is a group of separate soap bubbles, in which observers living on one soap bubble cannot interact with those on other soap bubbles, even in principle. According to one common terminology, each "soap bubble" of spacetime is denoted as a "universe", whereas our particular spacetime is denoted as "the universe", just as we call our moon "the Moon". The entire collection of these separate spacetimes is denoted as the multiverse. With this terminology, different "universes" are not causally connected to each other. In principle, the other unconnected "universes" may have different dimensionalities and topologies of spacetime, different forms of matter and energy, and different physical laws and physical constants, although such possibilities are purely speculative. Others consider each of several bubbles created as part of chaotic inflation to be separate "universes", though in this model these universes all share a causal origin.

Historically, there have been many ideas of the cosmos (cosmologies) and its origin (cosmogonies). Theories of an impersonal universe governed by physical laws were first proposed by the Greeks and Indians. Ancient Chinese philosophy encompassed the notion of the universe including both all of space and all of time. Over the centuries, improvements in astronomical observations and theories of motion and gravitation led to ever more accurate descriptions of the universe. The modern era of cosmology began with Albert Einstein's 1915 general theory of relativity, which made it possible to quantitatively predict the origin, evolution, and conclusion of the universe as a whole. Most modern, accepted theories of cosmology are based on general relativity and, more specifically, the predicted Big Bang.

Many cultures have stories describing the origin of the world and universe. Cultures generally regard these stories as having some truth. There are however many differing beliefs in how these stories apply amongst those believing in a supernatural origin, ranging from a god directly creating the universe as it is now to a god just setting the "wheels in motion" (for example via mechanisms such as the big bang and evolution).

Ethnologists and anthropologists who study myths have developed various classification schemes for the various themes that appear in creation stories. For example, in one type of story, the world is born from a world egg; such stories include the Finnish epic poem "Kalevala", the Chinese story of Pangu or the Indian Brahmanda Purana. In related stories, the universe is created by a single entity emanating or producing something by him- or herself, as in the Tibetan Buddhism concept of Adi-Buddha, the ancient Greek story of Gaia (Mother Earth), the Aztec goddess Coatlicue myth, the ancient Egyptian god Atum story, and the Judeo-Christian Genesis creation narrative in which the Abrahamic God created the universe. In another type of story, the universe is created from the union of male and female deities, as in the Maori story of Rangi and Papa. In other stories, the universe is created by crafting it from pre-existing materials, such as the corpse of a dead god—as from Tiamat in the Babylonian epic "Enuma Elish" or from the giant Ymir in Norse mythology—or from chaotic materials, as in Izanagi and Izanami in Japanese mythology. In other stories, the universe emanates from fundamental principles, such as Brahman and Prakrti, the creation myth of the Serers, or the yin and yang of the Tao.

The pre-Socratic Greek philosophers and Indian philosophers developed some of the earliest philosophical concepts of the universe. The earliest Greek philosophers noted that appearances can be deceiving, and sought to understand the underlying reality behind the appearances. In particular, they noted the ability of matter to change forms (e.g., ice to water to steam) and several philosophers proposed that all the physical materials in the world are different forms of a single primordial material, or "arche". The first to do so was Thales, who proposed this material to be water. Thales' student, Anaximander, proposed that everything came from the limitless "apeiron". Anaximenes proposed the primordial material to be air on account of its perceived attractive and repulsive qualities that cause the "arche" to condense or dissociate into different forms. Anaxagoras proposed the principle of "Nous" (Mind), while Heraclitus proposed fire (and spoke of "logos"). Empedocles proposed the elements to be earth, water, air and fire. His four-element model became very popular. Like Pythagoras, Plato believed that all things were composed of number, with Empedocles' elements taking the form of the Platonic solids. Democritus, and later philosophers—most notably Leucippus—proposed that the universe is composed of indivisible atoms moving through a void (vacuum), although Aristotle did not believe that to be feasible because air, like water, offers resistance to motion. Air will immediately rush in to fill a void, and moreover, without resistance, it would do so indefinitely fast.

Although Heraclitus argued for eternal change, his contemporary Parmenides made the radical suggestion that all change is an illusion, that the true underlying reality is eternally unchanging and of a single nature. Parmenides denoted this reality as (The One). Parmenides' idea seemed implausible to many Greeks, but his student Zeno of Elea challenged them with several famous paradoxes. Aristotle responded to these paradoxes by developing the notion of a potential countable infinity, as well as the infinitely divisible continuum. Unlike the eternal and unchanging cycles of time, he believed that the world is bounded by the celestial spheres and that cumulative stellar magnitude is only finitely multiplicative.

The Indian philosopher Kanada, founder of the Vaisheshika school, developed a notion of atomism and proposed that light and heat were varieties of the same substance. In the 5th century AD, the Buddhist atomist philosopher Dignāga proposed atoms to be point-sized, durationless, and made of energy. They denied the existence of substantial matter and proposed that movement consisted of momentary flashes of a stream of energy.

The notion of temporal finitism was inspired by the doctrine of creation shared by the three Abrahamic religions: Judaism, Christianity and Islam. The Christian philosopher, John Philoponus, presented the philosophical arguments against the ancient Greek notion of an infinite past and future. Philoponus' arguments against an infinite past were used by the early Muslim philosopher, Al-Kindi (Alkindus); the Jewish philosopher, Saadia Gaon (Saadia ben Joseph); and the Muslim theologian, Al-Ghazali (Algazel).

Astronomical models of the universe were proposed soon after astronomy began with the Babylonian astronomers, who viewed the universe as a flat disk floating in the ocean, and this forms the premise for early Greek maps like those of Anaximander and Hecataeus of Miletus.

Later Greek philosophers, observing the motions of the heavenly bodies, were concerned with developing models of the universe-based more profoundly on empirical evidence. The first coherent model was proposed by Eudoxus of Cnidos. According to Aristotle's physical interpretation of the model, celestial spheres eternally rotate with uniform motion around a stationary Earth. Normal matter is entirely contained within the terrestrial sphere.

"De Mundo" (composed before 250 BC or between 350 and 200 BC), stated, "Five elements, situated in spheres in five regions, the less being in each case surrounded by the greater—namely, earth surrounded by water, water by air, air by fire, and fire by ether—make up the whole universe".

This model was also refined by Callippus and after concentric spheres were abandoned, it was brought into nearly perfect agreement with astronomical observations by Ptolemy. The success of such a model is largely due to the mathematical fact that any function (such as the position of a planet) can be decomposed into a set of circular functions (the Fourier modes). Other Greek scientists, such as the Pythagorean philosopher Philolaus, postulated (according to Stobaeus account) that at the center of the universe was a "central fire" around which the Earth, Sun, Moon and Planets revolved in uniform circular motion.

The Greek astronomer Aristarchus of Samos was the first known individual to propose a heliocentric model of the universe. Though the original text has been lost, a reference in Archimedes' book "The Sand Reckoner" describes Aristarchus's heliocentric model. Archimedes wrote:

You, King Gelon, are aware the universe is the name given by most astronomers to the sphere the center of which is the center of the Earth, while its radius is equal to the straight line between the center of the Sun and the center of the Earth. This is the common account as you have heard from astronomers. But Aristarchus has brought out a book consisting of certain hypotheses, wherein it appears, as a consequence of the assumptions made, that the universe is many times greater than the universe just mentioned. His hypotheses are that the fixed stars and the Sun remain unmoved, that the Earth revolves about the Sun on the circumference of a circle, the Sun lying in the middle of the orbit, and that the sphere of fixed stars, situated about the same center as the Sun, is so great that the circle in which he supposes the Earth to revolve bears such a proportion to the distance of the fixed stars as the center of the sphere bears to its surface

Aristarchus thus believed the stars to be very far away, and saw this as the reason why stellar parallax had not been observed, that is, the stars had not been observed to move relative each other as the Earth moved around the Sun. The stars are in fact much farther away than the distance that was generally assumed in ancient times, which is why stellar parallax is only detectable with precision instruments. The geocentric model, consistent with planetary parallax, was assumed to be an explanation for the unobservability of the parallel phenomenon, stellar parallax. The rejection of the heliocentric view was apparently quite strong, as the following passage from Plutarch suggests ("On the Apparent Face in the Orb of the Moon"):

Cleanthes [a contemporary of Aristarchus and head of the Stoics] thought it was the duty of the Greeks to indict Aristarchus of Samos on the charge of impiety for putting in motion the Hearth of the Universe [i.e. the Earth], ... supposing the heaven to remain at rest and the Earth to revolve in an oblique circle, while it rotates, at the same time, about its own axis

The only other astronomer from antiquity known by name who supported Aristarchus's heliocentric model was Seleucus of Seleucia, a Hellenistic astronomer who lived a century after Aristarchus. According to Plutarch, Seleucus was the first to prove the heliocentric system through reasoning, but it is not known what arguments he used. Seleucus' arguments for a heliocentric cosmology were probably related to the phenomenon of tides. According to Strabo (1.1.9), Seleucus was the first to state that the tides are due to the attraction of the Moon, and that the height of the tides depends on the Moon's position relative to the Sun. Alternatively, he may have proved heliocentricity by determining the constants of a geometric model for it, and by developing methods to compute planetary positions using this model, like what Nicolaus Copernicus later did in the 16th century. During the Middle Ages, heliocentric models were also proposed by the Indian astronomer Aryabhata, and by the Persian astronomers Albumasar and Al-Sijzi.

The Aristotelian model was accepted in the Western world for roughly two millennia, until Copernicus revived Aristarchus's perspective that the astronomical data could be explained more plausibly if the Earth rotated on its axis and if the Sun were placed at the center of the universe.

As noted by Copernicus himself, the notion that the Earth rotates is very old, dating at least to Philolaus (c. 450 BC), Heraclides Ponticus (c. 350 BC) and Ecphantus the Pythagorean. Roughly a century before Copernicus, the Christian scholar Nicholas of Cusa also proposed that the Earth rotates on its axis in his book, "On Learned Ignorance" (1440). Al-Sijzi also proposed that the Earth rotates on its axis. Empirical evidence for the Earth's rotation on its axis, using the phenomenon of comets, was given by Tusi (1201–1274) and Ali Qushji (1403–1474).

This cosmology was accepted by Isaac Newton, Christiaan Huygens and later scientists. Edmund Halley (1720) and Jean-Philippe de Chéseaux (1744) noted independently that the assumption of an infinite space filled uniformly with stars would lead to the prediction that the nighttime sky would be as bright as the Sun itself; this became known as Olbers' paradox in the 19th century. Newton believed that an infinite space uniformly filled with matter would cause infinite forces and instabilities causing the matter to be crushed inwards under its own gravity. This instability was clarified in 1902 by the Jeans instability criterion. One solution to these paradoxes is the Charlier Universe, in which the matter is arranged hierarchically (systems of orbiting bodies that are themselves orbiting in a larger system, "ad infinitum") in a fractal way such that the universe has a negligibly small overall density; such a cosmological model had also been proposed earlier in 1761 by Johann Heinrich Lambert. A significant astronomical advance of the 18th century was the realization by Thomas Wright, Immanuel Kant and others of nebulae.

In 1919, when the Hooker Telescope was completed, the prevailing view still was that the universe consisted entirely of the Milky Way Galaxy. Using the Hooker Telescope, Edwin Hubble identified Cepheid variables in several spiral nebulae and in 1922–1923 proved conclusively that Andromeda Nebula and Triangulum among others, were entire galaxies outside our own, thus proving that universe consists of a multitude of galaxies.

The modern era of physical cosmology began in 1917, when Albert Einstein first applied his general theory of relativity to model the structure and dynamics of the universe.

Footnotes
Citations



</doc>
<doc id="9649" url="https://en.wikipedia.org/wiki?curid=9649" title="Energy">
Energy

In physics, energy is the quantitative property that must be transferred to an object in order to perform work on, or to heat, the object. Energy is a conserved quantity; the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The SI unit of energy is the joule, which is the energy transferred to an object by the work of moving it a distance of 1 metre against a force of 1 newton.

Common forms of energy include the kinetic energy of a moving object, the potential energy stored by an object's position in a force field (gravitational, electric or magnetic), the elastic energy stored by stretching solid objects, the chemical energy released when a fuel burns, the radiant energy carried by light, and the thermal energy due to an object's temperature.

Mass and energy are closely related. Due to mass–energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object's total mass just as it increases its total energy. For example, after heating an object, its increase in energy could be measured as a small increase in mass, with a sensitive enough scale.

Living organisms require energy to stay alive, such as the energy humans get from food. Human civilization requires energy to function, which it gets from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The processes of Earth's climate and ecosystem are driven by the radiant energy Earth receives from the sun and the geothermal energy contained within the earth.

The total energy of a system can be subdivided and classified into potential energy, kinetic energy, or combinations of the two in various ways. Kinetic energy is determined by the movement of an object – or the composite motion of the components of an object – and potential energy reflects the potential of an object to have motion, and generally is a function of the position of an object within a field or may be stored in the field itself.

While these two categories are sufficient to describe all forms of energy, it is often convenient to refer to particular combinations of potential and kinetic energy as its own form. For example, macroscopic mechanical energy is the sum of translational and rotational kinetic and potential energy in a system neglects the kinetic energy due to temperature, and nuclear energy which combines utilize potentials from the nuclear force and the weak force), among others.

The word "energy" derives from the , which possibly appears for the first time in the work of Aristotle in the 4th century BC. In contrast to the modern definition, energeia was a qualitative philosophical concept, broad enough to include ideas such as happiness and pleasure.

In the late 17th century, Gottfried Leibniz proposed the idea of the , or living force, which defined as the product of the mass of an object and its velocity squared; he believed that total "vis viva" was conserved. To account for slowing due to friction, Leibniz theorized that thermal energy consisted of the random motion of the constituent parts of matter, although it would be more than a century until this was generally accepted. The modern analog of this property, kinetic energy, differs from "vis viva" only by a factor of two.

In 1807, Thomas Young was possibly the first to use the term "energy" instead of "vis viva", in its modern sense. Gustave-Gaspard Coriolis described "kinetic energy" in 1829 in its modern sense, and in 1853, William Rankine coined the term "potential energy". The law of conservation of energy was also first postulated in the early 19th century, and applies to any isolated system. It was argued for some years whether heat was a physical substance, dubbed the caloric, or merely a physical quantity, such as momentum. In 1845 James Prescott Joule discovered the link between mechanical work and the generation of heat.

These developments led to the theory of conservation of energy, formalized largely by William Thomson (Lord Kelvin) as the field of thermodynamics. Thermodynamics aided the rapid development of explanations of chemical processes by Rudolf Clausius, Josiah Willard Gibbs, and Walther Nernst. It also led to a mathematical formulation of the concept of entropy by Clausius and to the introduction of laws of radiant energy by Jožef Stefan. According to Noether's theorem, the conservation of energy is a consequence of the fact that the laws of physics do not change over time. Thus, since 1918, theorists have understood that the law of conservation of energy is the direct mathematical consequence of the translational symmetry of the quantity conjugate to energy, namely time.

In 1843, Joule independently discovered the mechanical equivalent in a series of experiments. The most famous of them used the "Joule apparatus": a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle.

In the International System of Units (SI), the unit of energy is the joule, named after James Prescott Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British Thermal Units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units.

The SI unit of energy rate (energy per unit time) is the watt, which is a joule per second. Thus, one joule is one watt-second, and 3600 joules equal one watt-hour. The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce.

In classical mechanics, energy is a conceptually and mathematically useful property, as it is a conserved quantity. Several formulations of mechanics have been developed using energy as a core concept.

Work, a function of energy, is force times distance.

This says that the work (formula_2) is equal to the line integral of the force F along a path "C"; for details see the mechanical work article. Work and thus energy is frame dependent. For example, consider a ball being hit by a bat. In the center-of-mass reference frame, the bat does no work on the ball. But, in the reference frame of the person swinging the bat, considerable work is done on the ball.

The total energy of a system is sometimes called the Hamiltonian, after William Rowan Hamilton. The classical equations of motion can be written in terms of the Hamiltonian, even for highly complex or abstract systems. These classical equations have remarkably direct analogs in nonrelativistic quantum mechanics.

Another energy-related concept is called the Lagrangian, after Joseph-Louis Lagrange. This formalism is as fundamental as the Hamiltonian, and both can be used to derive the equations of motion or be derived from them. It was invented in the context of classical mechanics, but is generally useful in modern physics. The Lagrangian is defined as the kinetic energy "minus" the potential energy. Usually, the Lagrange formalism is mathematically more convenient than the Hamiltonian for non-conservative systems (such as systems with friction).

Noether's theorem (1918) states that any differentiable symmetry of the action of a physical system has a corresponding conservation law. Noether's theorem has become a fundamental tool of modern theoretical physics and the calculus of variations. A generalisation of the seminal formulations on constants of motion in Lagrangian and Hamiltonian mechanics (1788 and 1833, respectively), it does not apply to systems that cannot be modeled with a Lagrangian; for example, dissipative systems with continuous symmetries need not have a corresponding conservation law.

In the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structure, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants. A reaction is said to be exothermic or exergonic if the final state is lower on the energy scale than the initial state; in the case of endothermic reactions the situation is the reverse. Chemical reactions are almost invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The "speed" of a chemical reaction (at given temperature "T") is related to the activation energy "E" by the Boltzmann's population factor ethat is the probability of molecule to have energy greater than or equal to "E" at the given temperature "T". This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction can be provided in the form of thermal energy.

In biology, energy is an attribute of all biological systems from the biosphere to the smallest living organism. Within an organism it is responsible for growth and development of a biological cell or an organelle of a biological organism. Energy used in respiration is mostly stored in molecular oxygen and can be unlocked by reactions with molecules of substances such as carbohydrates (including sugars), lipids, and proteins stored by cells. In human terms, the human equivalent (H-e) (Human energy conversion) indicates, for a given amount of energy expenditure, the relative quantity of energy needed for human metabolism, assuming an average human energy expenditure of 12,500 kJ per day and a basal metabolic rate of 80 watts. For example, if our bodies run (on average) at 80 watts, then a light bulb running at 100 watts is running at 1.25 human equivalents (100 ÷ 80) i.e. 1.25 H-e. For a difficult task of only a few seconds' duration, a person can put out thousands of watts, many times the 746 watts in one official horsepower. For tasks lasting a few minutes, a fit human can generate perhaps 1,000 watts. For an activity that must be sustained for an hour, output drops to around 300; for an activity kept up all day, 150 watts is about the maximum. The human equivalent assists understanding of energy flows in physical and biological systems by expressing energy units in human terms: it provides a "feel" for the use of a given amount of energy.

Sunlight's radiant energy is also captured by plants as "chemical potential energy" in photosynthesis, when carbon dioxide and water (two low-energy compounds) are converted into carbohydrates, lipids, and proteins and high-energy compounds like oxygen and ATP. Carbohydrates, lipids, and proteins can release the energy of oxygen, which is utilized by living organisms as an electron acceptor. Release of the energy stored during photosynthesis as heat or light may be triggered suddenly by a spark, in a forest fire, or it may be made available more slowly for animal or human metabolism, when organic molecules are ingested, and catabolism is triggered by enzyme action.

Any living organism relies on an external source of energy – radiant energy from the Sun in the case of green plants, chemical energy in some form in the case of animals – to be able to grow and reproduce. The daily 1500–2000 Calories (6–8 MJ) recommended for a human adult are taken as a combination of oxygen and food molecules, the latter mostly carbohydrates and fats, of which glucose (CHO) and stearin (CHO) are convenient examples. The food molecules are oxidised to carbon dioxide and water in the mitochondria
and some of the energy is used to convert ADP into ATP.
The rest of the chemical energy in O and the carbohydrate or fat is converted into heat: the ATP is used as a sort of "energy currency", and some of the chemical energy it contains is used for other metabolism when ATP reacts with OH groups and eventually splits into ADP and phosphate (at each stage of a metabolic pathway, some chemical energy is converted into heat). Only a tiny fraction of the original chemical energy is used for work:

It would appear that living organisms are remarkably inefficient (in the physical sense) in their use of the energy they receive (chemical or radiant energy), and it is true that most real machines manage higher efficiencies. In growing organisms the energy that is converted to heat serves a vital purpose, as it allows the organism tissue to be highly ordered with regard to the molecules it is built from. The second law of thermodynamics states that energy (and matter) tends to become more evenly spread out across the universe: to concentrate energy (or matter) in one specific place, it is necessary to spread out a greater amount of energy (as heat) across the remainder of the universe ("the surroundings"). Simpler organisms can achieve higher energy efficiencies than more complex ones, but the complex organisms can occupy ecological niches that are not available to their simpler brethren. The conversion of a portion of the chemical energy to heat at each step in a metabolic pathway is the physical reason behind the pyramid of biomass observed in ecology: to take just the first step in the food chain, of the estimated 124.7 Pg/a of carbon that is fixed by photosynthesis, 64.3 Pg/a (52%) are used for the metabolism of green plants, i.e. reconverted into carbon dioxide and heat.

In geology, continental drift, mountain ranges, volcanoes, and earthquakes are phenomena that can be explained in terms of energy transformations in the Earth's interior, while meteorological phenomena like wind, rain, hail, snow, lightning, tornadoes and hurricanes are all a result of energy transformations brought about by solar energy on the atmosphere of the planet Earth.

Sunlight may be stored as gravitational potential energy after it strikes the Earth, as (for example) water evaporates from oceans and is deposited upon mountains (where, after being released at a hydroelectric dam, it can be used to drive turbines or generators to produce electricity). Sunlight also drives many weather phenomena, save those generated by volcanic events. An example of a solar-mediated weather event is a hurricane, which occurs when large unstable areas of warm ocean, heated over months, give up some of their thermal energy suddenly to power a few days of violent air movement.

In a slower process, radioactive decay of atoms in the core of the Earth releases heat. This thermal energy drives plate tectonics and may lift mountains, via orogenesis. This slow lifting represents a kind of gravitational potential energy storage of the thermal energy, which may be later released to active kinetic energy in landslides, after a triggering event. Earthquakes also release stored elastic potential energy in rocks, a store that has been produced ultimately from the same radioactive heat sources. Thus, according to present understanding, familiar events such as landslides and earthquakes release energy that has been stored as potential energy in the Earth's gravitational field or elastic strain (mechanical potential energy) in rocks. Prior to this, they represent release of energy that has been stored in heavy atoms since the collapse of long-destroyed supernova stars created these atoms.

In cosmology and astronomy the phenomena of stars, nova, supernova, quasars and gamma-ray bursts are the universe's highest-output energy transformations of matter. All stellar phenomena (including solar activity) are driven by various kinds of energy transformations. Energy in such transformations is either from gravitational collapse of matter (usually molecular hydrogen) into various classes of astronomical objects (stars, black holes, etc.), or from nuclear fusion (of lighter elements, primarily hydrogen). The nuclear fusion of hydrogen in the Sun also releases another store of potential energy which was created at the time of the Big Bang. At that time, according to theory, space expanded and the universe cooled too rapidly for hydrogen to completely fuse into heavier elements. This meant that hydrogen represents a store of potential energy that can be released by fusion. Such a fusion process is triggered by heat and pressure generated from gravitational collapse of hydrogen clouds when they produce stars, and some of the fusion energy is then transformed into sunlight.

In quantum mechanics, energy is defined in terms of the energy operator
as a time derivative of the wave function. The Schrödinger equation equates the energy operator to the full energy of a particle or a system. Its results can be considered as a definition of measurement of energy in quantum mechanics. The Schrödinger equation describes the space- and time-dependence of a slowly changing (non-relativistic) wave function of quantum systems. The solution of this equation for a bound system is discrete (a set of permitted states, each characterized by an energy level) which results in the concept of quanta. In the solution of the Schrödinger equation for any oscillator (vibrator) and for electromagnetic waves in a vacuum, the resulting energy states are related to the frequency by Planck's relation: formula_3 (where formula_4 is Planck's constant and formula_5 the frequency). In the case of an electromagnetic wave these energy states are called quanta of light or photons.

When calculating kinetic energy (work to accelerate a massive body from zero speed to some finite speed) relativistically – using Lorentz transformations instead of Newtonian mechanics – Einstein discovered an unexpected by-product of these calculations to be an energy term which does not vanish at zero speed. He called it rest energy: energy which every massive body must possess even when being at rest. The amount of energy is directly proportional to the mass of the body:

where

For example, consider electron–positron annihilation, in which the rest energy of these two individual particles (equivalent to their rest mass) is converted to the radiant energy of the photons produced in the process. In this system the matter and antimatter (electrons and positrons) are destroyed and changed to non-matter (the photons). However, the total mass and total energy do not change during this interaction. The photons each have no rest mass but nonetheless have radiant energy which exhibits the same inertia as did the two original particles. This is a reversible process – the inverse process is called pair creation – in which the rest mass of particles is created from the radiant energy of two (or more) annihilating photons.

In general relativity, the stress–energy tensor serves as the source term for the gravitational field, in rough analogy to the way mass serves as the source term in the non-relativistic Newtonian approximation.

Energy and mass are manifestations of one and the same underlying physical property of a system. This property is responsible for the inertia and strength of gravitational interaction of the system ("mass manifestations"), and is also responsible for the potential ability of the system to perform work or heating ("energy manifestations"), subject to the limitations of other physical laws.

In classical physics, energy is a scalar quantity, the canonical conjugate to time. In special relativity energy is also a scalar (although not a Lorentz scalar but a time component of the energy–momentum 4-vector). In other words, energy is invariant with respect to rotations of space, but not invariant with respect to rotations of space-time (= boosts).

Energy may be transformed between different forms at various efficiencies. Items that transform between these forms are called transducers. Examples of transducers include a battery, from chemical energy to electric energy; a dam: gravitational potential energy to kinetic energy of moving water (and the blades of a turbine) and ultimately to electric energy through an electric generator; or a heat engine, from heat to work.

Examples of energy transformation include generating electric energy from heat energy via a steam turbine, or lifting an object against gravity using electrical energy driving a crane motor. Lifting against gravity performs mechanical work on the object and stores gravitational potential energy in the object. If the object falls to the ground, gravity does mechanical work on the object which transforms the potential energy in the gravitational field to the kinetic energy released as heat on impact with the ground. Our Sun transforms nuclear potential energy to other forms of energy; its total mass does not decrease due to that in itself (since it still contains the same total energy even if in different forms), but its mass does decrease when the energy escapes out to its surroundings, largely as radiant energy.

There are strict limits to how efficiently heat can be converted into work in a cyclic process, e.g. in a heat engine, as described by Carnot's theorem and the second law of thermodynamics. However, some energy transformations can be quite efficient. The direction of transformations in energy (what kind of energy is transformed to what other kind) is often determined by entropy (equal energy spread among all available degrees of freedom) considerations. In practice all energy transformations are permitted on a small scale, but certain larger transformations are not permitted because it is statistically unlikely that energy or matter will randomly move into more concentrated forms or smaller spaces.

Energy transformations in the universe over time are characterized by various kinds of potential energy that has been available since the Big Bang later being "released" (transformed to more active types of energy such as kinetic or radiant energy) when a triggering mechanism is available. Familiar examples of such processes include nuclear decay, in which energy is released that was originally "stored" in heavy isotopes (such as uranium and thorium), by nucleosynthesis, a process ultimately using the gravitational potential energy released from the gravitational collapse of supernovae, to store energy in the creation of these heavy elements before they were incorporated into the solar system and the Earth. This energy is triggered and released in nuclear fission bombs or in civil nuclear power generation. Similarly, in the case of a chemical explosion, chemical potential energy is transformed to kinetic energy and thermal energy in a very short time. Yet another example is that of a pendulum. At its highest points the kinetic energy is zero and the gravitational potential energy is at maximum. At its lowest point the kinetic energy is at maximum and is equal to the decrease of potential energy. If one (unrealistically) assumes that there is no friction or other losses, the conversion of energy between these processes would be perfect, and the pendulum would continue swinging forever.

Energy is also transferred from potential energy (formula_8) to kinetic energy (formula_9) and then back to potential energy constantly. This is referred to as conservation of energy. In this closed system, energy cannot be created or destroyed; therefore, the initial energy and the final energy will be equal to each other. This can be demonstrated by the following:

The equation can then be simplified further since formula_10 (mass times acceleration due to gravity times the height) and formula_11 (half mass times velocity squared). Then the total amount of energy can be found by adding formula_12.

Energy gives rise to weight when it is trapped in a system with zero momentum, where it can be weighed. It is also equivalent to mass, and this mass is always associated with it. Mass is also equivalent to a certain amount of energy, and likewise always appears associated with it, as described in mass-energy equivalence. The formula "E" = "mc"², derived by Albert Einstein (1905) quantifies the relationship between rest-mass and rest-energy within the concept of special relativity. In different theoretical frameworks, similar formulas were derived by J.J. Thomson (1881), Henri Poincaré (1900), Friedrich Hasenöhrl (1904) and others (see Mass-energy equivalence#History for further information).

Part of the rest energy (equivalent to rest mass) of matter may be converted to other forms of energy (still exhibiting mass), but neither energy nor mass can be destroyed; rather, both remain constant during any process. However, since formula_13 is extremely large relative to ordinary human scales, the conversion of an everyday amount of rest mass (for example, 1 kg) from rest energy to other forms of energy (such as kinetic energy, thermal energy, or the radiant energy carried by light and other radiation) can liberate tremendous amounts of energy (~formula_14 joules = 21 megatons of TNT), as can be seen in nuclear reactors and nuclear weapons. Conversely, the mass equivalent of an everyday amount energy is minuscule, which is why a loss of energy (loss of mass) from most systems is difficult to measure on a weighing scale, unless the energy loss is very large. Examples of large transformations between rest energy (of matter) and other forms of energy (e.g., kinetic energy into particles with rest mass) are found in nuclear physics and particle physics.

Thermodynamics divides energy transformation into two kinds: reversible processes and irreversible processes. An irreversible process is one in which energy is dissipated (spread) into empty energy states available in a volume, from which it cannot be recovered into more concentrated forms (fewer quantum states), without degradation of even more energy. A reversible process is one in which this sort of dissipation does not happen. For example, conversion of energy from one type of potential field to another, is reversible, as in the pendulum system described above. In processes where heat is generated, quantum states of lower energy, present as possible excitations in fields between atoms, act as a reservoir for part of the energy, from which it cannot be recovered, in order to be converted with 100% efficiency into other forms of energy. In this case, the energy must partly stay as heat, and cannot be completely recovered as usable energy, except at the price of an increase in some other kind of heat-like increase in disorder in quantum states, in the universe (such as an expansion of matter, or a randomisation in a crystal).

As the universe evolves in time, more and more of its energy becomes trapped in irreversible states (i.e., as heat or other kinds of increases in disorder). This has been referred to as the inevitable thermodynamic heat death of the universe. In this heat death the energy of the universe does not change, but the fraction of energy which is available to do work through a heat engine, or be transformed to other usable forms of energy (through the use of generators attached to heat engines), grows less and less.

The fact that energy can be neither created nor be destroyed is called the law of conservation of energy. In the form of the first law of thermodynamics, this states that a closed system's energy is constant unless energy is transferred in or out by work or heat, and that no energy is lost in transfer. The total inflow of energy into a system must equal the total outflow of energy from the system, plus the change in the energy contained within the system. Whenever one measures (or calculates) the total energy of a system of particles whose interactions do not depend explicitly on time, it is found that the total energy of the system always remains constant.

While heat can always be fully converted into work in a reversible isothermal expansion of an ideal gas, for cyclic processes of practical interest in heat engines the second law of thermodynamics states that the system doing work always loses some energy as waste heat. This creates a limit to the amount of heat energy that can do work in a cyclic process, a limit called the available energy. Mechanical and other forms of energy can be transformed in the other direction into thermal energy without such limitations. The total energy of a system can be calculated by adding up all forms of energy in the system.

Richard Feynman said during a 1961 lecture:
Most kinds of energy (with gravitational energy being a notable exception) are subject to strict local conservation laws as well. In this case, energy can only be exchanged between adjacent regions of space, and all observers agree as to the volumetric density of energy in any given space. There is also a global law of conservation of energy, stating that the total energy of the universe cannot change; this is a corollary of the local law, but not vice versa.

This law is a fundamental principle of physics. As shown rigorously by Noether's theorem, the conservation of energy is a mathematical consequence of translational symmetry of time, a property of most phenomena below the cosmic scale that makes them independent of their locations on the time coordinate. Put differently, yesterday, today, and tomorrow are physically indistinguishable. This is because energy is the quantity which is canonical conjugate to time. This mathematical entanglement of energy and time also results in the uncertainty principle - it is impossible to define the exact amount of energy during any definite time interval. The uncertainty principle should not be confused with energy conservation - rather it provides mathematical limits to which energy can in principle be defined and measured.

Each of the basic forces of nature is associated with a different type of potential energy, and all types of potential energy (like all other types of energy) appears as system mass, whenever present. For example, a compressed spring will be slightly more massive than before it was compressed. Likewise, whenever energy is transferred between systems by any mechanism, an associated mass is transferred with it.

In quantum mechanics energy is expressed using the Hamiltonian operator. On any time scales, the uncertainty in the energy is by

which is similar in form to the Heisenberg Uncertainty Principle (but not really mathematically equivalent thereto, since "H" and "t" are not dynamically conjugate variables, neither in classical nor in quantum mechanics).

In particle physics, this inequality permits a qualitative understanding of virtual particles which carry momentum, exchange by which and with real particles, is responsible for the creation of all known fundamental forces (more accurately known as fundamental interactions). Virtual photons (which are simply lowest quantum mechanical energy state of photons) are also responsible for electrostatic interaction between electric charges (which results in Coulomb law), for spontaneous radiative decay of exited atomic and nuclear states, for the Casimir force, for van der Waals bond forces and some other observable phenomena.

Energy transfer can be considered for the special case of systems which are closed to transfers of matter. The portion of the energy which is transferred by conservative forces over a distance is measured as the work the source system does on the receiving system. The portion of the energy which does not do work during the transfer is called heat. Energy can be transferred between systems in a variety of ways. Examples include the transmission of electromagnetic energy via photons, physical collisions which transfer kinetic energy, and the conductive transfer of thermal energy.

Energy is strictly conserved and is also locally conserved wherever it can be defined. In thermodynamics, for closed systems, the process of energy transfer is described by the first law:

where formula_16 is the amount of energy transferred, formula_2  represents the work done on the system, and formula_18 represents the heat flow into the system. As a simplification, the heat term, formula_18, is sometimes ignored, especially when the thermal efficiency of the transfer is high.

This simplified equation is the one used to define the joule, for example.

Beyond the constraints of closed systems, open systems can gain or lose energy in association with matter transfer (both of these process are illustrated by fueling an auto, a system which gains in energy thereby, without addition of either work or heat). Denoting this energy by formula_16, one may write

Internal energy is the sum of all microscopic forms of energy of a system. It is the energy needed to create the system. It is related to the potential energy, e.g., molecular structure, crystal structure, and other geometric aspects, as well as the motion of the particles, in form of kinetic energy. Thermodynamics is chiefly concerned with changes in internal energy and not its absolute value, which is impossible to determine with thermodynamics alone.

The first law of thermodynamics asserts that energy (but not necessarily thermodynamic free energy) is always conserved and that heat flow is a form of energy transfer. For homogeneous systems, with a well-defined temperature and pressure, a commonly used corollary of the first law is that, for a system subject only to pressure forces and heat transfer (e.g., a cylinder-full of gas) without chemical changes, the differential change in the internal energy of the system (with a "gain" in energy signified by a positive quantity) is given as

where the first term on the right is the heat transferred into the system, expressed in terms of temperature "T" and entropy "S" (in which entropy increases and the change d"S" is positive when the system is heated), and the last term on the right hand side is identified as work done on the system, where pressure is "P" and volume "V" (the negative sign results since compression of the system requires work to be done on it and so the volume change, d"V", is negative when work is done on the system).

This equation is highly specific, ignoring all chemical, electrical, nuclear, and gravitational forces, effects such as advection of any form of energy other than heat and pV-work. The general formulation of the first law (i.e., conservation of energy) is valid even in situations in which the system is not homogeneous. For these cases the change in internal energy of a "closed" system is expressed in a general form by

where formula_23 is the heat supplied to the system and formula_24 is the work applied to the system.

The energy of a mechanical harmonic oscillator (a mass on a spring) is alternatively kinetic and potential energy. At two points in the oscillation cycle it is entirely kinetic, and at two points it is entirely potential. Over the whole cycle, or over many cycles, net energy is thus equally split between kinetic and potential. This is called equipartition principle; total energy of a system with many degrees of freedom is equally split among all available degrees of freedom.

This principle is vitally important to understanding the behaviour of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between "new" and "old" degrees. This mathematical result is called the second law of thermodynamics. The second law of thermodynamics is valid only for systems which are near or in equilibrium state. For non-equilibrium systems, the laws governing system's behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way to maximize its entropy production.




</doc>
<doc id="38714" url="https://en.wikipedia.org/wiki?curid=38714" title="World">
World

The World is Planet Earth and all life on it, including human civilization. In a philosophical context, the "world" is the whole of the physical Universe, or an ontological world (the "world" of an individual). In a theological context, the "world" is the material or the profane sphere, as opposed to the celestial, spiritual, transcendent or sacred spheres. "End of the world" scenarios refer to the end of human history, often in religious contexts.

The history of the World is commonly understood as the history of humanity spanning the major geopolitical developments of about five millennia, from the first civilizations to the present. In terms such as world religion, world language, world government, and world war, the term "world" suggests an international or intercontinental scope without necessarily implying participation of every part of the world.

The world population is the sum of all human populations at any time; similarly, the world economy is the sum of the economies of all societies or countries, especially in the context of globalization. Terms such as "world championship", "gross world product", and "world flags" imply the sum or combination of all sovereign states.

The English word "world" comes from the Old English "weorold (-uld), weorld, worold (-uld, -eld)", a compound of "wer" "man" and "eld" "age," which thus means roughly "Age of Man."
The Old English is a reflex of the Common Germanic "*wira-alđiz", also reflected in Old Saxon "werold", Old Dutch "werilt", Old High German "weralt", Old Frisian "warld" and Old Norse "verǫld" (whence the Icelandic "veröld").

The corresponding word in Latin is "mundus", literally "clean, elegant", itself a loan translation of Greek "cosmos" "orderly arrangement." While the Germanic word thus reflects a mythological notion of a "domain of Man" (compare Midgard), presumably as opposed to the divine sphere on the one hand and the chthonic sphere of the underworld on the other, the Greco-Latin term expresses a notion of creation as an act of establishing order out of chaos.

"World" distinguishes the entire planet or population from any particular country or region: "world affairs" pertain not just to one place but to the whole world, and "world history" is a field of history that examines events from a global (rather than a national or a regional) perspective. "Earth", on the other hand, refers to the planet as a physical entity, and distinguishes it from other planets and physical objects.

"World" was also classically used to mean the material universe, or the cosmos: "The worlde is an apte frame of heauen and earthe, and all other naturall thinges contained in them." The earth was often described as "the center of the world".

The term can also be used attributively, to mean "global", or "relating to the whole world", forming usages such as world community or world canonical texts.

By extension, a "world" may refer to any planet or heavenly body, especially when it is thought of as inhabited, especially in the context of science fiction or futurology.

"World", in its original sense, when qualified, can also refer to a particular domain of human experience.


In philosophy, the term "world" has several possible meanings. In some contexts, it refers to everything that makes up reality or the physical universe. In others, it can mean have a specific ontological sense (see world disclosure). While clarifying the concept of world has arguably always been among the basic tasks of Western philosophy, this theme appears to have been raised explicitly only at the start of the twentieth century and has been the subject of continuous debate. The question of what the world is has by no means been settled.

The traditional interpretation of Parmenides' work is that he argued that the everyday perception of reality of the physical world (as described in "doxa") is mistaken, and that the reality of the world is 'One Being' (as described in aletheia): an unchanging, ungenerated, indestructible whole.

In his Allegory of the Cave, Plato distinguishes between forms and ideas and imagines two distinct worlds: the sensible world and the intelligible world.

In Georg Wilhelm Friedrich Hegel's philosophy of history, the expression "Weltgeschichte ist Weltgericht" (World History is a tribunal that judges the World) is used to assert the view that History is what judges men, their actions and their opinions. Science is born from the desire to transform the World in relation to Man; its final end is technical application.

"The World as Will and Representation" is the central work of Arthur Schopenhauer.
Schopenhauer saw the human will as our one window to the world behind the representation; the Kantian thing-in-itself. He believed, therefore, that we could gain knowledge about the thing-in-itself, something Kant said was impossible, since the rest of the relationship between representation and thing-in-itself could be understood by analogy to the relationship between human will and human body.

Two definitions that were both put forward in the 1920s, however, suggest the range of available opinion. "The world is everything that is the case," wrote Ludwig Wittgenstein in his influential "Tractatus Logico-Philosophicus", first published in 1921. This definition would serve as the basis of logical positivism, with its assumption that there is exactly one world, consisting of the totality of facts, regardless of the interpretations that individual people may make of them.

Martin Heidegger, meanwhile, argued that "the surrounding world is different for each of us, and notwithstanding that we move about in a common world". The world, for Heidegger, was that into which we are always already "thrown" and with which we, as beings-in-the-world, must come to terms. His conception of "world disclosure" was most notably elaborated in his 1927 work "Being and Time".

In response, Sigmund Freud proposed that we do not move about in a common world, but a common thought process. He believed that all the actions of a person are motivated by one thing: lust. This led to numerous theories about reactionary consciousness.

Some philosophers, often inspired by David Lewis, argue that metaphysical concepts such as possibility, probability, and necessity are best analyzed by comparing "the" world to a range of possible worlds; a view commonly known as modal realism.

Mythological cosmologies often depict the world as centered on an "axis mundi" and delimited by a boundary such as a world ocean, a world serpent or similar. In some religions, worldliness (also called carnality) is that which relates to this world as opposed to other worlds or realms.

In Buddhism, the world means society, as distinct from the monastery. It refers to the material world, and to worldly gain such as wealth, reputation, jobs, and war. The spiritual world would be the path to enlightenment, and changes would be sought in what we could call the psychological realm.

In Christianity, the term often connotes the concept of the fallen and corrupt world order of human society, in contrast to the World to Come. The world is frequently cited alongside "the flesh" and "the Devil" as a source of temptation that Christians should flee. Monks speak of striving to be ""in" this world, but not "of" this world"—as Jesus said—and the term "worldhood" has been distinguished from "monkhood", the former being the status of merchants, princes, and others who deal with "worldly" things.

This view is clearly expressed by king Alfred the Great of England (d. 899) in his famous Preface to the "Cura Pastoralis":
Although Hebrew and Greek words meaning "world" are used in Scripture with the normal variety of senses, many examples of its use in this particular sense can be found in the teachings of Jesus according to the Gospel of John, e.g. 7:7, 8:23, 12:25, 14:17, 15:18-19, 17:6-25, 18:36. In contrast, a relatively newer concept is Catholic imagination.

"Contemptus mundi" is the name given to the recognition that the world, in all its vanity, is nothing more than a futile attempt to hide from God by stifling our desire for the good and the holy. This view has been criticized as a "pastoral of fear" by modern historian Jean Delumeau.

During the Second Vatican Council, there was a novel attempt to develop a positive theological view of the World, which is illustrated by the pastoral optimism of the constitutions "Gaudium et spes", "Lumen gentium", "Unitatis redintegratio" and "Dignitatis humanae".

In Eastern Christian monasticism or asceticism, the world of mankind is driven by passions. Therefore, the passions of the World are simply called "the world". Each of these passions are a link to the world of mankind or order of human society. Each of these passions must be overcome in order for a person to receive salvation (theosis). The process of theosis is a personal relationship with God. This understanding is taught within the works of ascetics like Evagrius Ponticus, and the most seminal ascetic works read most widely by Eastern Christians, the Philokalia and the Ladder of Divine Ascent (the works of Evagrius and John Climacus are also contained within the Philokalia). At the highest level of world transcendence is hesychasm which culminates into the Vision of God.

"Orbis Catholicus" is a Latin phrase meaning "Catholic world", per the expression Urbi et Orbi, and refers to that area of Christendom under papal supremacy. It is somewhat similar to the phrases secular world, Jewish world and Islamic world.

"Dunya" derives from the root word "dana" that means to bring near. In that sense, "dunya" is "what is brought near".

Hinduism is an Indian religion and "dharma", or a way of life, widely practised in the Indian subcontinent. It includes a number of Indian religious traditions with a loose sense of interconnection, as different from Jainism and Buddhism, and (since medieval and modern times) Islam and Christianity. Hinduism has been called the oldest religion in the world.




</doc>
<doc id="1777495" url="https://en.wikipedia.org/wiki?curid=1777495" title="Global change">
Global change

Global change refers to planetary-scale changes in the Earth system. The system consists of the land, oceans, atmosphere, polar regions, life, the planet's natural cycles and deep Earth processes. These constituent parts influence one another. The Earth system now includes human society, so global change also refers to large-scale changes in society.

More completely, the term "global change" encompasses: population, climate, the economy, resource use, energy development, transport, communication, land use and land cover, urbanization, globalization, atmospheric circulation, ocean circulation, the carbon cycle, the nitrogen cycle, the water cycle and other cycles, sea ice loss, sea-level rise, food webs, biological diversity, pollution, health, over fishing, and more.

In 1980, a group of scientists led by Swedish meteorologist Bert Bolin set up an international program called the World Climate Research Programme (WCRP), to determine whether the climate was changing, whether climate could be predicted and whether humans were in some way responsible for the change. The programme was sponsored by the World Meteorological Organization and the International Council for Science (ICSU). As time went on, there was a growing realisation that climate change was one part of a larger phenomenon, global change. In 1987, a team of researchers, led again by Bert Bolin, James McCarthy, Paul Crutzen, H. Oeschger and others, successfully argued for an international research programme to investigate global change. This programme, sponsored by ICSU, is the International Geosphere-Biosphere Programme (IGBP). The programme has eight projects investigating different parts of the Earth system and links between them.

IGBP, WCRP and a third programme, the International Human Dimensions Programme (IHDP, founded in 1996), spearheaded a landmark science conference held in Amsterdam in 2001. The conference, "Challenges of a Changing Earth: Global Change Open Science Conference", led to the Amsterdam Declaration which stated, "In addition to the threat of significant climate change, there is growing concern over the ever-increasing human modification of other aspects of the global environment and the consequent implications for human well-being. Basic goods and services supplied by the planetary life support system, such as food, water, clean air and an environment conducive to human health, are being affected increasingly by global change."

The declaration goes on to say, "The international global change programmes urge governments, public and private institutions and people of the world to agree that an ethical framework for global stewardship and strategies for Earth System management are urgently needed."

Many nations now have their own global change programmes and institutes, for example the US Global Change Research Program and the UK's Quantifying and Understanding the Earth System (QUEST) programme. And since the Amsterdam conference another international programme focusing on biodiversity has been set up, DIVERSITAS. These programmes form the Earth System Science Partnership.

In 2012, these international programmes held another major science conference in London, Planet Under Pressure: new knowledge towards solutions.

In the past, the main drivers of global change have been solar variation, plate tectonics, volcanism, proliferation and abatement of life, meteorite impact, resource depletion, changes in Earth's orbit around the sun and changes in the tilt of Earth on its axis. There is overwhelming evidence that now the main driver of planetary-scale change, or global change, is the growing human population's demand for energy, food, goods, services and information, and its disposal of its waste products. In the last 250 years, global change has caused climate change, widespread species extinctions, fish-stock collapse, desertification, ocean acidification, ozone depletion, pollution, and other large-scale shifts.

Scientists working on the International Geosphere-Biosphere Programme have said that Earth is now operating in a "no analogue" state. Measurements of Earth system processes, past and present, have led to the conclusion that the planet has moved well outside the range of natural variability in the last half million years at least. "Homo sapiens" have been around for about 200,000 years.

What this means for the planet and society remains unclear. But, in the last 20 years there has been an enormous international research effort to understand global change and the Earth system. An aim of this research is to work out if there are planetary boundaries and are we approaching them. Scientists, international governmental organizations and lobbying organizations like World Wide Fund for Nature argue that current consumption levels, particularly in developed countries, are not sustainable because there is a very real danger they will push the planet into a new state. What this new state might look like is still being debated, but sea levels are likely to rise several meters, the pH of the oceans, a measure of its acidity, is likely to drop farther than it has in 20 million years, and global atmospheric and ocean circulations may shift markedly. The major cycles – carbon, nitrogen, sulfur, phosphorus, water – and other important parameters would alter, bringing drought to some places, floods to others. Governments will no longer be able to take for granted the relative environmental stability that has allowed human society to flourish and led to rapid globalization. Most of the population of the planet will be affected. The re-insurance industry is already taking measures to protect its interests and maximize profits as turbulent times approach.

Humans have always altered their environment. The advent of agriculture around 10000 years ago led to a radical change in land use that still continues. But, the relatively small human population had little impact on a global scale until the start of the industrial revolution in 1750. This event, followed by the invention of the Haber-Bosch process in 1909, which allowed large-scale manufacture of fertilizers, led directly to rapid changes to many of the planet's most important physical, chemical and biological processes.

The 1950s marked a shift in gear: global change began accelerating. Between 1950 and 2010, the population more than doubled. In that time, rapid expansion of international trade coupled with upsurges in capital flows and new technologies, particularly information and communication technologies, led to national economies becoming more fully integrated. There was a tenfold increase in economic activity and the world's human population became more tightly connected than ever before. The period saw sixfold increases in water use and river damming. About 70 percent of the world's freshwater resource is now used for agriculture. This rises to 90 percent in India and China. Half of the Earth's land surface had now been domesticated. By 2010, urban population, for the first time, exceeded rural population. And there has been a fivefold increase in fertilizer use. Indeed, manufactured reactive nitrogen from fertilizer production and industry now exceeds global terrestrial production of reactive nitrogen. Without artificial fertilizers there would not be enough food to sustain a population of seven billion people.

These changes to the human sub-system have a direct influence on all components of the Earth system. The chemical composition of the atmosphere has changed significantly. Concentrations of important greenhouse gases, carbon dioxide, methane and nitrous oxide are rising fast. Over Antarctica a large hole in the ozone layer appeared. Fisheries collapsed: most of the world's fisheries are now fully or over-exploited. Thirty percent of tropical rainforests disappeared.

In 2000, Nobel prize-winning scientist Paul Crutzen announced the scale of change is so great that in just 250 years, human society has pushed the planet into a new geological era: the Anthropocene. This name has stuck and there are calls for the Anthropocene to be adopted officially. If it is, it may be the shortest of all geological eras. Evidence suggests that if human activities continue to change components of the Earth system, which are all interlinked, this could heave the Earth system out of one state and into a new state.

Global change in a societal context encompasses social, cultural, technological, political, economic and legal change. Terms closely related to global change and society are globalization and global integration. Globalization began with long-distance trade and urbanism. The first record of long distance trading routes is in the third millennium BC. Sumerians in Mesopotamia traded with settlers in the Indus Valley, in modern-day India.

Since 1750, but more significantly, since the 1950s, global integration has accelerated. This era has witnessed incredible global changes in communications, transportation, and computer technology. Ideas, cultures, people, goods, services and money move around the planet with ease. This new global interconnectedness and free flow of information has radically altered notions of other cultures, conflicts, religions and taboos. Now, social movements can and do form at a planetary scale.

Evidence, if more were needed, of the link between social and environmental global change came with the 2008-2009 global financial crisis. The crisis pushed the planet's main economic powerhouses, the United States, Europe and much of Asia into recession. According to the Global Carbon Project, global atmospheric emissions of carbon dioxide fell from an annual growth rate of around 3.4% between 2000 and 2008, to a growth rate of about 2% in 2008.

Humans are altering the planet's biogeochemical cycles in a largely unregulated way with limited knowledge of the consequences. Without steps to effectively manage the Earth system – the planet's physical, chemical, biological and social components – it is likely there will be severe impacts on people and ecosystems. Perhaps the largest concern is that a component of the Earth system, for example, an ocean circulation, the Amazon rainforest, or Arctic sea ice, will reach a tipping point and flip from its current state to another state: flowing to not flowing, rainforest to savanna, or ice to no ice. A domino effect could ensue with other components of the Earth system changing state rapidly.

Intensive research over the last 20 years has shown that tipping points do exist in the Earth system, and wide-scale change can be rapid – a matter of decades. Potential tipping points have been identified and attempts have been made to quantify thresholds. But to date, the best efforts can only identify loosely defined "planetary boundaries" beyond which tipping points exist but their precise locations remain elusive.

There have been calls for a better way to manage the environment on a planetary scale, sometimes referred to as managing "Earth's life support system". The United Nations was formed to stop wars and provide a platform for dialogue between countries. It was not created to avoid major environmental catastrophe on regional or global scales. But several international environmental conventions exist under the UN, including the Framework Convention on Climate Change, Montreal Protocol, Convention to Combat Desertification, and Convention on Biological Diversity. Additionally, the UN has two bodies charged with coordinating environmental and development activities, the United Nations Environment Programme (UNEP) and the United Nations Development Programme (UNDP).

In 2004, the IGBP published "Global Change and the Earth System, a planet under pressure." The publication's executive summary concluded: "An overall, comprehensive, internally consistent strategy for stewardship of the Earth system is required". It stated that a research goal is to define and maintain a stable equilibrium in the global environment.

In 2007, France called for UNEP to be replaced by a new and more powerful organization called the "United Nations Environment Organization". The rationale was that UNEP's status as a "programme", rather than an "organization" in the tradition of the World Health Organization or the World Meteorological Organization, weakened it to the extent that it was no longer fit for purpose given current knowledge of the state of the planet.



</doc>
<doc id="8163829" url="https://en.wikipedia.org/wiki?curid=8163829" title="World to come">
World to come

The world to come, age to come, and heaven on Earth are eschatological phrases reflecting the belief that the current world or current age is flawed or cursed and will be replaced in the future by a better world, age, or paradise. The concept is related to but differs from the concepts of heaven, the afterlife, and the Kingdom of God in that heaven is another place or state generally seen as above the world, the afterlife is generally an individual's life after death, and the Kingdom of God could be in the present (such as realized eschatology) or the future.

The following section reviews religions chronologically, from oldest to most recent, although the chronology of ancient religions is not known with certainty. Later dates are more certain than earlier dates.

In Hindu eschatology the current age is the Kali Yuga, a period of decline. Kalki ('Destroyer of Filth') will appear to purge all evil, beginning a golden age of Satya Yuga.

There have been a range of dates predicted, purportedly from different methods of calculation. Pothuluru Veerabrahmendra, for example, wrote 400 years ago in his "Divya Maha Kala Gnana," or 'Divine Knowledge of the Time,' that Kalki would arrive when the moon, sun, Venus and Jupiter entered the same sign. This is not a rare occurrence and last happened in early 2012, passing without event. Although, since around 2012 the world has seen a very significant increase of violence on a global scale as well as very significant political unrest and turmoil across the whole world. The time of arrival of Kalki has not been consistently asserted by astrologers.

In Christianity, the phrase is found in the Nicene Creed (current Ecumenical version): "We look for the resurrection of the dead, and the life of the world to come." It is also found in the King James Version of the New Testament at , , , , . Other related expressions are "age to come" which is typically found in more recent translations, Kingdom of God, Messianic Age, Millennial Age, The New Earth and New Jerusalem, and dispensation of the fulness of times and possibly also eternal life.

"HaOlam HaBa", or "the world to come", is an important part of Jewish eschatology, although Judaism concentrates on the importance of "HaOlam HaZeh" ("this world"). The afterlife is known as "Olam haBa", "Gan Eden" (the Heavenly Garden of Eden) and "Gehinom". According to the Talmud, any non-Jew who lives according to the Seven Laws of Noah is regarded as a "Ger toshav" (righteous gentile), and is assured of a place in the world to come, the final reward of the righteous.

In the 19th century book "Legends of the Jews", Louis Ginzberg compiled Jewish legends found in rabbinic literature. Among the legends are ones about the world to come and the two Gardens of Eden. The world to come is called Paradise, and it is said to have a double gate made of carbuncle that is guarded by 600,000 shining angels. Seven clouds of glory overshadow Paradise, and under them, in the center of Paradise, stands the tree of life. The tree of life overshadows Paradise too, and it has fifteen thousand different tastes and aromas that winds blow all across Paradise. Under the tree of life are many pairs of canopies, one of stars and the other of sun and moon, while a cloud of glory separates the two. In each pair of canopies sits a rabbinic scholar who explains the Torah to one. When one enters Paradise one is proffered by Michael (archangel) to God on the altar of the temple of the heavenly Jerusalem, whereupon one is transfigured into an angel (the ugliest person becomes as beautiful and shining as "the grains of a silver pomegranate upon which fall the rays of the sun"). The angels that guard Paradise's gate adorn one in seven clouds of glory, crown one with gems and pearls and gold, place eight myrtles in one's hand, and praise one for being righteous while leading one to a garden of eight hundred roses and myrtles that is watered by many rivers. In the garden is one's canopy, its beauty according to one's merit, but each canopy has four rivers - milk, honey, wine, and balsam - flowing out from it, and has a golden vine and thirty shining pearls hanging from it. Under each canopy is a table of gems and pearls attended to by sixty angels. The light of Paradise is the light of the righteous people therein. Each day in Paradise one wakes up a child and goes to bed an elder to enjoy the pleasures of childhood, youth, adulthood, and old age. In each corner of Paradise is a forest of 800,000 trees, the least among the trees greater than the best herbs and spices, attended to by 800,000 sweetly singing angels. Paradise is divided into seven paradises, each one 120,000 miles long and wide. Depending on one's merit, one joins one of the paradises: the first is made of glass and cedar and is for converts to Judaism; the second is of silver and cedar and is for penitents; the third is of silver and gold, gems and pearls, and is for the patriarchs, Moses and Aaron, the Israelites that left Egypt and lived in the wilderness, and the kings of Israel; the fourth is of rubies and olive wood and is for the holy and steadfast in faith; the fifth is like the third, except a river flows through it and its bed was woven by Eve and angels, and it is for the Messiah and Elijah; and the sixth and seventh divisions are not described, except that they are respectively for those who died doing a pious act and for those who died from an illness in expiation for Israel's sins. 

Beyond Paradise, according to Legends of the Jews, is the higher Gan Eden, where God is enthroned and explains the Torah to its inhabitants. The higher Gan Eden contains three hundred ten worlds and is divided into seven compartments. The compartments are not described, though it is implied that each compartment is greater than the previous one and is joined based on one's merit. The first compartment is for Jewish martyrs, the second for those who drowned, the third for "Rabbi Johanan ben Zakkai and his disciples," the fourth for those whom the cloud of glory carried off, the fifth for penitents, the sixth for youths who have never sinned; and the seventh for the poor who lived decently and studied the Torah.

In Zoroastrian eschatology, the world to come is the "frashokereti", where the "saoshyant" will bring about a resurrection of the dead in the bodies they had before they died. This is followed by a last judgment. The "yazatas" Airyaman and Atar will melt the metal in the hills and mountains, and the molten metal will then flow across the earth like a river. All humankind—both the living and the resurrected dead—will be required to wade through that river, but for the righteous ("ashavan") it will seem to be a river of warm milk, while the wicked will be burned. The river will then flow down to hell, where it will annihilate Angra Mainyu and the last vestiges of wickedness in the universe.



</doc>
<doc id="803597" url="https://en.wikipedia.org/wiki?curid=803597" title="Ecumene">
Ecumene

The ecumene (US) or oecumene (UK; , "oikouménē",  "inhabited") was an ancient Greek term for the known, the inhabited, or the habitable world. Under the Roman Empire, it came to refer to civilization as well as the secular and religious imperial administration. In present usage, it is most often used in the context of "ecumenical" and describes the Christian Church as a unified whole, or the unified modern world civilization. It is also used in cartography to describe a type of world map ("mappa mundi") used in late Antiquity and the Middle Ages.

The Greek term cited above is the feminine present middle participle of the verb ("oikéō", "to inhabit") and is a clipped form of ("oikouménē gē", "inhabited world").

Eratosthenes of Cyrene (276–196 BC) deduced the circumference of the Earth with remarkable accuracy (within 10% of the correct value). The Greek cartographer Crates created a globe about 150 BC. Claudius Ptolemy (83–161) calculated the Earth's surface in his "Geography" and described the inhabited portion as spanning 180 degrees of longitude (from the Fortunate Isles in the west to Serae and Serica (China) in the east) and about 80 degrees of latitude (from Thule in the north to anti-Meroë below the equator). Ptolemy was well aware that the Romans knew only about a quarter of the globe and his erroneous belief that the Indian Ocean was landlocked led to expectation of a terra incognita ("unknown land"). In fact, symmetry led him to expect that there should be three other continents to balance the ecumene: Perioeci ( "beside the ecumene"), Antoeci ("opposite the ecumene") and the Antipodes (“opposite the feet”).

The cameo Gemma Augustea includes a Roman artistic personification of Oikoumene as she crowns an emperor, probably Augustus, perhaps for bringing peace to the (Roman) world.
The word was adopted within Christianity after Constantine the Great's assembly of a synod of bishops from all over the world at the First Council of Nicaea in 325.

By that time, the Greek term had come to refer more specifically to the civilized world and then simply the Roman Empire. This usage continued after the Diocletian Reforms and the Byzantine emperors used it to refer to their imperial administration. Constantinople was the "Ecumenical City" and, after 586, the Patriarch of Constantinople was known as the "Ecumenical Patriarch of Constantinople". Pope Gregory I objected to the adoption of this style by John IV of Constantinople, as it implied a universal jurisdiction he believed illegal to anyone. His Fifth Epistle berates John for having "attempted to seize upon a new name, whereby the hearts of all your brethren might have come to take offence", despite the title having been granted at the emperor Maurice's behest.

The name continues to be borne by the Greek Orthodox patriarchs, although with the more restricted sense that they are the bishops of the former imperial capital.

Especially in the 20th century, the term has been employed to refer to unified Christian Church which is the ultimate goal of Ecumenism, a movement to promote cooperation among the various Christian denominations. The movement is not accepted by many Christian groups. The work of ecumenism takes place in the form of negotiations conducted between committees of various denominations and also through the deliberations of inter-denominational organizations such as the World Council of Churches. Relevant issues include Baptism, the Eucharist and Ministry.

In the context of cultural history, Lewis Mumford used the term "ecumene" in an academic sense in his work, "Technics and Civilization" (1934). William H. McNeill later popularized it in his "Rise of the West" (1963), suggesting that a single global ecumene emerged through the dominance of European political institutions, science, technology, and economic forms from the late 18th century onwards. One could argue that prior to the great voyages of discovery carried out by Christopher Columbus, Vasco da Gama, and Ferdinand Magellan, there were originally two separate ecumenes—one covering the Old World and one the New. The Spanish conquistadores fused these two ecumenes to form a single integrated "world system".

Peter Sloterdijk uses the terms "First Ecumene" and "Second Ecumene" in his book "In the World Interior of Capital" (2014, original German: "Im Weltinnenraum des Kapitals", 2005). Sloterdijk takes these terms directly from the work of Eric Voegelin, specifically from "Order and History" vol. 4, "The Ecumenic Age" (1974), which he quotes.

Note that the term "ecumene" can differ depending on the viewpoint from which it is perceived: for example, the Ancient Babylonians and the Ancient Greeks would each have known a different area of the world (though their worlds may have overlapped). Compare image to the right.

The term is used in cartography and the historical cartography to describe a type of symbolic, schematic world map made in late Antiquity and the Middle Ages.



</doc>
<doc id="188480" url="https://en.wikipedia.org/wiki?curid=188480" title="International community">
International community

The international community is a phrase used in geopolitics and international relations to refer to a broad group of people and governments of the world. It does not literally refer to all nations or states in the world. The term is typically used to imply the existence of a common point of view towards such matters as specific issues of human rights. Activists, politicians and commentators often use the term in calling for action to be taken; e.g., action against what is in their opinion political repression in a target country.

The term is commonly used to imply legitimacy and consensus for a point of view on a disputed issue; e.g., to enhance the credibility of a majority vote in the United Nations General Assembly.

Noam Chomsky alleges that the use of the term is used to refer to the United States and its allies and client states, as well as allies in the media of those states. British scholar and academic Martin Jacques says: "We all know what is meant by the term 'international community', don't we? It's the west, of course, nothing more, nothing less. Using the term 'international community' is a way of dignifying the west, of globalising it, of making it sound more respectable, more neutral and high-faluting."



</doc>
<doc id="29071145" url="https://en.wikipedia.org/wiki?curid=29071145" title="World news">
World news

World news or international news or even foreign coverage is the news media jargon for news from abroad, about a country or a global subject. For journalism, it is a branch that deals with news either sent by foreign correspondents or news agencies, or – more recently – information that is gathered or researched through distance communication technologies, such as telephone, satellite TV or the internet.

Although in most of the English-speaking world this field is not usually regarded as a specific specialization for journalists, it is so in nearly all the world. Particularly in the United States, there is a blurred distinction between world news and "national" news when they include directly the national government or national institutions, such as wars in which the US are involved or summits of multilateral organizations in which the US are a member.

At the birth of modern journalism, most news were foreign, as registered by the courants of the 17th century in West and Central Europe, such as the "Daily Courant" (England), the "Nieuwe Tijudinger" (Antwerp), the "Relation" (Strasbourg), the "Avisa Relation oder Zeitung" (Wolfenbüttel) and the "Courante Uyt Italien, Duytsland & C." (Amsterdam). Since these papers were aimed at bankers and merchants, they brought mostly news from other markets, which usually meant other nations. In any case, it is worthy to remark that nation-states were still incipient in 17th-century Europe.

From the 19th century on, with newspapers already established in Europe, the United States and a few other countries, innovations in telecommunications such as the telegraph made news from abroad easier to be spread. The first news agencies were then founded, like AFP (France), Reuters (UK), Wolff (currently DPA, Germany) and the AP (US).

War journalism is one of the best known subfields of world news (although war coverage can be national for the media of belligerent countries themselves).

There are essentially two types of reporters who do foreign reporting: the foreign correspondent (full-time reporter employed by a news source) and the special envoy (sent abroad to cover a specific subject, temporarily stationed in a location).

The correspondent is a reporter based in a foreign city (often the capital of a country) covering a region, a country or sometimes even an entire continent. He or she regularly files stories to the news editor. He/she gathers materials for these stories from local officials, members of the community, and the local media, as well as from events he/she directly witnesses. Correspondents typically stay in touch with the local community and maintain contacts with other journalists and correspondents in order to identify strategic sources in the government, among diplomats, members of the military and other organizations on the ground who may provide important information.

The number of foreign correspondents has dropped significantly over the past 20 years or more. Often, a media company is either uninterested or unable to afford to support a single correspondent, such as in many developing countries. In some places, they cannot obtain visas due to political constraints, or otherwise dangerous conditions prohibit a media company from stationing a reporter there. In recent years, the drop in foreign correspondents has been due to cutbacks within media companies (often, but not always, a result of economics alone). Among English language newspapers, only eight daily newspapers have full-time correspondents in more than ten foreign stations, four from the US, three from the UK and one from India: 

35 – "Wall Street Journal" (US): Baghdad, Bangkok, Beijing, Beirut, Berlin, Brussels, Buenos Aires, Dubai, Frankfurt, Hong Kong, Istanbul, Jakarta, Jerusalem, Johannesburg, Kabul, Kuala Lumpur, Lagos, London, Manila, Mexico City, Moscow, Mumbai, New Delhi, Paris, Prague, Rio de Janeiro, Rome, São Paulo, Seoul, Shanghai, Singapore, Taipei, Tokyo, Toronto, Zurich

24 – "New York Times" (US): Baghdad, Beijing, Beirut, Berlin, Cairo, Caracas, Dakar, Hong Kong, Islamabad, Jakarta, Jerusalem, Johannesburg, Kabul, London, Mexico City, Moscow, Mumbai, Nairobi, New Delhi, Paris, Rome, São Paulo, Shanghai, Tokyo

19 – "Financial Times" (UK): Beijing, Berlin, Bombay, Brussels, Dubai, Frankfurt, Hong Kong, Jakarta, Jerusalem, Moscow, Mumbai, New Delhi, New York, Paris, Taipei, Tokyo, Shanghai, Sydney, Washington

17 – "Washington Post" (US): Baghdad, Beijing, Berlin, Bogotá, Cairo, Islamabad, Jerusalem, Kabul, London, Mexico City, Moscow, Nairobi, New Delhi, Paris, Shanghai, Tehran, Tokyo

15 – "The Guardian" (UK): Accra, Bangkok, Beijing, Berlin, Brussels, Kabul, Islamabad, Jerusalem, Los Angeles, Madrid, New York, Paris, Rome, Tehran, Tokyo

13 – "The Daily Telegraph" (UK): Beijing, Brussels, Jerusalem, Kabul, Los Angeles, Moscow, Nairobi, New Delhi, New York, Paris, Shanghai, Sydney, Washington

13 – "Los Angeles Times" (US): Baghdad, Beijing, Beirut, Cairo, Islamabad, Jerusalem, Johannesburg, Kabul, London, Mexico City, Moscow, New Delhi, Seoul

12 – "The Hindu" (India): Addis Ababa, Beijing, Colombo, Dhaka, Dubai, Islamabad, Kathmandu, London, Moscow, Paris, Singapore, Washington 

When reporters working abroad have no permanent labor contract with media outlets, they are called stringers. Since they have no salary, stringers usually produce material for several different companies at once.

A news agency is an organization of journalists established to supply news reports to news organizations: newspapers, magazines, and radio and television broadcasters. Such an agency may also be referred to as a wire service, newswire or news service. The bulk of major news agency services contains foreign news.

The major news agencies generally prepare hard news stories and feature articles that can be used by other news organizations with little or no modification, and then sell them to other news organizations. They provide these articles in bulk electronically through wire services (originally they used telegraphy; today they frequently use the Internet). Corporations, individuals, analysts and intelligence agencies may also subscribe.




</doc>
<doc id="50406244" url="https://en.wikipedia.org/wiki?curid=50406244" title="Global news flow">
Global news flow

Global news flow (also referred to as international news flow) is a field of study that deals with the news coverage of events in foreign countries. It describes and explains the flow of news from one country to another.

Studies on global news flow typically attempt to understand why certain countries are more newsworthy than others.. Along the years it has been found that the economic power of countries plays a particularly crucial role in their news prominence as well as the presence of international news agencies. Thus, the US has been found to be very prominent in news mentions around the world (18%), followed by China, Western European and Middle Eastern countries (about 3-5% each).

The unequal representation of the world and the under-representation of developing countries have been already of a great concern at least since the 1950s, since they influence the way people perceive the world and the image of countries. This problem was later addressed in the MacBride report, and his set of recommendations for a New World Information and Communication Order. The unequal representation of the world has been also linked to the World System Theory, and the unequal economic structure of the world.

Recent empirical studies show that among online news websites and news aggregators the unequal representation of the world has been perpetuated and even further intensified. Economically powerful countries, as well as their opponent countries (mainly in the Middle East and Asia) get the most news coverage around the world.



</doc>
<doc id="35305141" url="https://en.wikipedia.org/wiki?curid=35305141" title="International communication">
International communication

International communication (also referred to as the "study of global communication" or transnational communication) is the communication practice that occurs across international borders. The need for international communication was due to the increasing effects and influences of globalization. As a field of study, international communication is a branch of communication studies, concerned with the scope of "government-to-government", "business-to-business", and "people-to-people" interactions at a global level. Currently, international communication is being taught at colleges across the United States. Due to the increasingly globalized market, employees who possess the ability to effectively communicate across cultures are in high demand. International communication "encompasses political, economic, social, cultural and military concerns".

Efficient communication networks played crucial roles in establishing ancient imperial authority and international trade. The extent of empire could be used as an 'indication of the efficiency of communication'. Ancient empires such as Rome, Persia and China, all utilized writing in collecting information and dispersing, creating enormous postal and dispatch systems. As early as in fifteenth century, news had been disseminated trans-nationally in Europe. 'The wheat traders of Venice, the silver traders of Antwerp, the merchants of Nuremberg and their trading partners shared economic newsletters and created common values and beliefs in the rights of capital.'

In 1837, Samuel Morse invented telegraph. The telegraph worked by transmitting electrical signals over a wire laid between stations. It was the first mode of communication to eliminate the effect of distance, allowing for a near instantaneous connection. Given its speed and reliability in delivering information, telegraph offered opportunities for capital and military expansion. It also increased market integration. It did so by lowering the cost of trade by increasing the capacity utilization of shipping. As showed in Table 1.1, the establishment of cable hardware signifies global power order in late nineteenth and early twentieth century.

Table 1.1 Cabling the world
The newspaper industry and international telegraph networks mutually facilitated each other. Telegraph communications drastically altered the way in which news was produced. The individual items of modern newspapers became no longer selected on the basis of spatial proximity, but following newly emerging journalistic criteria of news relevance. As the supply and demand of the newspaper industry rapidly increased in the nineteenth century, news agencies were established successively. 

The French Havas Agency was founded in 1835, the German agency Wolffin in 1849, and the British Reuters in 1851. These three European agencies began as financial-data services for bankers, but eventually started to operate internationally and extended their coverage to world news. They were all subsidized by their respective governments. By 1866, national news agencies were beginning to rise in many European countries. While they covered and sold news locally, they relied on the major services for coverage and sales abroad. 

The global media and news agencies have played a fundamental role in contemporary globalization, making possible the feeling of instant communication and the experience of global connection. They have played a pioneering role in the use of new technologies, such as the telegraph, which have altered the nature of news. Technological innovation continues to be a major area of competition between global news agencies. 

Western countries seized the chances to implement radio communication after the first radio transmissions of human voice in 1902. But the two mechanisms of radio broadcasting were distinctively different. In the USA, the Radio Act of 1927 confirmed its status as an advertising-funded commercial enterprise, while in Britain, the public broadcasting pioneer British Broadcasting Corporation set up in the same year. During the First World War and the Second World War, radio broadcasting played a significant role in both domestic public opinion management and international diplomacy propaganda abroad. 

Even in the Cold War times, this radio-dominated international communication still featured in propaganda respective ideologies. The prominent example is the Voice of America, which ran a global network to indoctrinate "American dream" to its international audience. Radio also played an important role in the ideological confrontation between the east and the west. Broadcasts could penetrate the "Iron Curtain" and directly address the "enemy", which was extremely important in the early days of the Cold War. Western broadcasting offered an alternative channel for the flow of new information and ideas. Around a one third of Soviet urban adults and about half of East European adults were regular listeners of Western broadcasts at the time. 

Shortwave transmission sites, known as "number stations" were used by both the United States and Soviet governments to send propaganda to foreign countries. They were also a secure means of sending coded messages to intelligence officers operating in other countries. As long as an agent had the station, the air time, and encryption code, he could receive a one-time message that only he could understand. 

Not only Western countries have been impacted by communication through the use of radio broadcasting. An example of this is the 1994 Rwandan Genocide. In April of 1994, a plane carrying the presidents of Rwanda and neighboring Burundi crashed under mysterious circumstances. This sparked a massing killing spree that took place over the next three months and left over a million Rwandans dead. The Rwandan media have been accused of inciting hatred that led to violence by using an ethical framework to report a political struggle, as well as spreading fear, rumors, and panic. They also incited ordinary citizens to take part in the massacres. Through its broadcasts, popular radio station RTLM attracted unemployed youth and Interhahamwe militia, a far-right organization. 

Since the cold war officially ended in 1990, the intense relations of super powers halted with the collapse of the Soviet Union, and the emergence of the Third World countries, the unequally developed communication order can no longer exist. The Third World called for ceasing their marginalized communication status. Especially when international communications stepped into the information age, 'the convergence of telecommunication and computing and the ability to move all type of data – pictures, words, sounds – via the Internet have revolutionized international information exchange.'

When communicating internationally it is important to take culture into consideration. Though English has become the language of business, many businesses fail to recognize that the language used does not determine how business is conducted. Therefore, it is important to understand that intercultural and international communication are interchangeable. Effective communication between international business partners is critical for global success, and underlying national and organizational cultural differences in international business-related relationships can create hurdles to effective communication, which can hinder performance. 

As a tourist it may be acceptable to maintain the cultural norms from a country of origin when visiting, though attempting to adapt would be appreciated. However, when conducting business it is important to recognize cultural differences, especially when communicating. At the turn of the century there was a large amount of research based on the needs of those that travel abroad in order to commercialize products or services. The list of researchers includes Hofstede, 1991; Storti, 1994; Ansari & Jackson, 1995; Cushner & Brislin, 1996; Adler, 1997; Mead, 1998; and Marx, 1999. From those studies Gibson's volume becomes an important source of information for business professionals interested in succeeding internationally. As explained by Douglas Storey, there was a change in style and strategy of American diplomacy since 1979 after the first addition of Glen Fisher's book appeared.

Despite the reason for international communication it is important to understand that international communication is not limited to the language spoken during communication.

There are two broadly conceived approaches to the creation of international communications regulations. The first would be internationalizing a minimum standard by agreement among the parties. The second is to allow the parties to denote exceptions for specific points about which they may be unable to reach agreement. Though the second approach falls short of uniformity it permits higher standards by allowing some parties to opt out.

International communication is widely spread and multilayered in contemporary society, however it is not considered as a separate academic discipline because of its overlapping with other subjects. International communication is 'a topic field rather than a discipline field' and international communication studies is a mode of 'organizing inquiry'.

John D. H. Downing proposed ten categories within which international communication should be conducted

Mehdi Semati listed the wide range of research subjects in international communication, which includes, but not limited to the following.

Hamid Mowlana stated four key interrelated approaches to international communication

One of the most obvious manifestations of international communication are world news, when the media of one country cover news from abroad. But, apart from journalism, international communication also occurs in other areas (culture, technology, sciences) and the nature of the "information" that is circulated can be classified in a wide variety of categories, such as cultural (music, films, sports, TV shows from one country to another), scientific (research papers published abroad, scientific exchange or cooperation), and intelligence (diplomacy reports, international espionage, etc.).

Typically the study of international communication includes a deep attention to the circulation of news among different countries (and the resulting imbalances, from which came the concept of news flow), the power of media organizations (such as conglomerates and news agencies), issues such as cultural imperialism and media imperialism, and the political role that international cooperation can have in enhancing the media industry (and society as a whole) in a given region, such as proposed by development communication or communication for development.

Some renowned scholars in international communication include Wilbur Schramm, Ithiel de Sola Pool, Johan Galtung, Anthony Smith, Robert Stevenson, Jeremy Tunstall, Armand Mattelart, Oliver Boyd-Barrett, Ali Mohammadi, Annabelle Sreberny, Cees J. Hamelink, Daya Kishan Thussu and Chris Paterson. The "International Communication Gazette" and the "Journal of International Communication" are reference journals in this field.

The Second World War was a catalyst for international communication. Analytical tools for communications research are used to mobilize domestic public support for war, to understand enemy propaganda, and to develop psychological warfare techniques to influence the morale and opinions of allies and enemies. The Rockefeller Foundation convened and funded a communications seminar every month from 1939 to 1940 years at the New York headquarters. The initial purpose was to bring together leading scholars interested in communication to provide theoretical guidance for future communication studies, including Lasswell and Lazarsfeld. When the United States entered the war at the end of 1941, with the outbreak of the European economic crisis, communication research became an important factor in discussing government policies.

Media development can be said to be independent media created by private interventions during the transition period through international intervention. Even before the emergence of technology, communication has been at the forefront of relationship building and business development. Today, newer advancements like texting and messaging apps have allowed for even more efficient international communication. 

New Media: Internet and Wireless Communication.

In the 1980s and 1990s, with the establishment and development of fiberoptic cables, satellites and the Internet, and the gradual proliferation are eroding space and time barriers and increasing speed, and reducing the cost of transmitting various information. This trend has pushed international communication to globalization.




</doc>
<doc id="13305402" url="https://en.wikipedia.org/wiki?curid=13305402" title="Global brain">
Global brain

The global brain is a neuroscience-inspired and futurological vision of the planetary information and communications technology network that interconnects all humans and their technological artifacts. As this network stores ever more information, takes over ever more functions of coordination and communication from traditional organizations, and becomes increasingly intelligent, it increasingly plays the role of a brain for the planet Earth.

Proponents of the global brain hypothesis claim that the Internet increasingly ties its users together into a single information processing system that functions as part of the collective nervous system of the planet. The intelligence of this network is collective or distributed: it is not centralized or localized in any particular individual, organization or computer system. Therefore, no one can command or control it. Rather, it self-organizes or emerges from the dynamic networks of interactions between its components. This is a property typical of complex adaptive systems.

The World-wide web in particular resembles the organization of a brain with its webpages (playing a role similar to neurons) connected by hyperlinks (playing a role similar to synapses), together forming an associative network along which information propagates. This analogy becomes stronger with the rise of social media, such as Facebook, where links between personal pages represent relationships in a social network along which information propagates from person to person.
Such propagation is similar to the spreading activation that neural networks in the brain use to process information in a parallel, distributed manner.

Although some of the underlying ideas were already expressed by Nikola Tesla in the late 19th century and were written about by many others before him, the term “global brain” was coined in 1982 by Peter Russell in his book "The Global Brain". How the Internet might be developed to achieve this was set out in 1986. The first peer-reviewed article on the subject was published by Gottfried Mayer-Kress in 1995, while the first algorithms that could turn the world-wide web into a collectively intelligent network were proposed by Francis Heylighen and Johan Bollen in 1996.

Reviewing the strands of intellectual history that contributed to the global brain hypothesis, Francis Heylighen distinguishes four perspectives: "“organicism”", "“encyclopedism”", "“emergentism”" and "“evolutionary cybernetics”". He asserts that these developed in relative independence but now are converging in his own scientific re-formulation.

In the 19th century, the sociologist Herbert Spencer saw society as a social organism and reflected about its need for a nervous system. Entomologist William Wheeler developed the concept of the ant colony as a spatially extended organism, and in the 1930s he coined the term superorganism to describe such an entity. This concept was later adopted by thinkers such as Gregory Stock in his book Metaman and Joel de Rosnay to describe planetary society as a superorganism.

The mental aspects of such an organic system at the planetary level were perhaps first broadly elaborated by palaeontologist and Jesuit priest Pierre Teilhard de Chardin. In 1945, he described a coming “planetisation” of humanity, which he saw as the next phase of accelerating human “socialisation”. Teilhard described both socialization and planetization as irreversible, irresistible processes of "macrobiological development" culminating in the emergence of a noosphere, or global mind (see Emergentism below).

The more recent living systems theory describes both organisms and social systems in terms of the "critical subsystems" ("organs") they need to contain in order to survive, such as an internal transport system, a resource reserve, and a decision-making system. This theory has inspired several thinkers, including Peter Russell and Francis Heylighen to define the global brain as the network of information processing subsystems for the planetary social system.

In the perspective of encyclopedism, the emphasis is on developing a universal knowledge network. The first systematic attempt to create such an integrated system of the world's knowledge was the 18th century "Encyclopédie" of Denis Diderot and Jean le Rond d'Alembert. However, by the end of the 19th century, the amount of knowledge had become too large to be published in a single synthetic volume. To tackle this problem, Paul Otlet founded the science of documentation, now called information science. In the 1930s he envisaged a World Wide Web-like system of associations between documents and telecommunication links that would make all the world's knowledge available immediately to anybody. H. G. Wells proposed a similar vision of a collaboratively developed world encyclopedia that would be constantly updated by a global university-like institution. He called this a World Brain, as it would function as a continuously updated memory for the planet, although the image of humanity acting informally as a more organic global brain is a recurring motif in other of his works.

Tim Berners-Lee, the inventor of the World Wide Web, too, was inspired by the free-associative possibilities of the brain for his invention. The brain can link different kinds of information without any apparent link otherwise; Berners-Lee thought that computers could become much more powerful if they could imitate this functioning, i.e. make links between any arbitrary piece of information. The most powerful implementation of encyclopedism to date is Wikipedia, which integrates the associative powers of the world-wide-web with the collective intelligence of its millions of contributors, approaching the ideal of a global memory. The Semantic web, also first proposed by Berners-Lee, is a system of protocols to make the pieces of knowledge and their links readable by machines, so that they could be used to make automatic inferences, thus providing this brain-like network with some capacity for autonomous "thinking" or reflection.

This approach focuses on the emergent aspects of the evolution and development of complexity, including the spiritual, psychological, and moral-ethical aspects of the global brain, and is at present the most speculative approach. The global brain is here seen as a natural and emergent process of planetary evolutionary development. Here again Pierre Teilhard de Chardin attempted a synthesis of science, social values, and religion in his The Phenomenon of Man, which argues that the "telos" (drive, purpose) of universal evolutionary process is the development of greater levels of both complexity and consciousness. Teilhard proposed that if life persists then planetization, as a biological process producing a global brain, would necessarily also produce a global mind, a new level of planetary consciousness and a technologically supported network of thoughts which he called the "noosphere". Teilhard's proposed technological layer for the noosphere can be interpreted as an early anticipation of the Internet and the Web.

Physicist and philosopher Peter Russell elaborates a similar view, and stresses the importance of personal spiritual growth, in order to build and to achieve synergy with the spiritual dimension of the emerging superorganism. This approach is most popular in New Age circles, which emphasize growth in consciousness rather than scientific modelling or the implementation of technological and social systems.

Systems theorists and cyberneticists commonly describe the emergence of a higher order system in evolutionary development as a “metasystem transition” (a concept introduced by Valentin Turchin) or a “major evolutionary transition”. Such a metasystem consists of a group of subsystems that work together in a coordinated, goal-directed manner. It is as such much more powerful and intelligent than its constituent systems. Francis Heylighen has argued that the global brain is an emerging metasystem with respect to the level of individual human intelligence, and investigated the specific evolutionary mechanisms that promote this transition

In this scenario, the Internet fulfils the role of the network of “nerves” that interconnect the subsystems and thus coordinates their activity. The cybernetic approach makes it possible to develop mathematical models and simulations of the processes of self-organization through which such coordination and collective intelligence emerges.

In 1994 Kevin Kelly, in his popular book "", posited the emergence of a "hive mind" from a discussion of cybernetics and evolutionary biology.

In 1996, Francis Heylighen and Ben Goertzel founded the Global Brain group, a discussion forum grouping most of the researchers that had been working on the subject of the global brain to further investigate this phenomenon. The group organized the first international conference on the topic in 2001 at the Vrije Universiteit Brussel.

After a period of relative neglect, the Global Brain idea has recently seen a resurgence in interest, in part due to talks given on the topic by Tim O'Reilly, the Internet forecaster who popularized the term Web 2.0, and Yuri Milner, the social media investor. In January 2012, the Global Brain Institute (GBI) was founded at the Vrije Universiteit Brussel to develop a mathematical theory of the “brainlike” propagation of information across the Internet. In the same year, Thomas W. Malone and collaborators from the MIT Center for Collective Intelligence have started to explore how the global brain could be “programmed” to work more effectively, using mechanisms of collective intelligence. The complexity scientist Dirk Helbing and his NervousNet group have recently started developing a "Planetary Nervous System", which includes a "Global Participatory Platform", as part of the large-scale FuturICT project, thus preparing some of the groundwork for a Global Brain.

In July 2017 Elon Musk founded the company Neuralink, which aims to create a Neural Lace, which is a concept invented by the novelist Iain M. Banks and basically refers to a machine interface woven into the brain, to allow the user to access all available human information. A core driver behind this business idea is Musk’s argument that human beings soon have to embrace brain implants to stay relevant in a world which, he believes, will soon be dominated by artificial intelligence. The firm raised $27m from 12 Investors in 2017 .

A common criticism of the idea that humanity would become directed by a global brain is that this would reduce individual diversity and freedom, and lead to mass surveillance. This criticism is inspired by totalitarian forms of government, as exemplified by George Orwell's character of "Big Brother". It is also inspired by the analogy between collective intelligence or swarm intelligence and insect societies, such as beehives and ant colonies, in which individuals are essentially interchangeable. In a more extreme view, the global brain has been compared with the Borg, the race of collectively thinking cyborgs conceived by the Star Trek science fiction franchise.

Global brain theorists reply that the emergence of distributed intelligence would lead to the exact opposite of this vision. The reason is that effective collective intelligence requires diversity of opinion, decentralization and individual independence, as demonstrated by James Surowiecki in his book "The Wisdom of Crowds". Moreover, a more distributed form of decision-making would decrease the power of governments, corporations or political leaders, thus increasing democratic participation and reducing the dangers of totalitarian control.




For more references, check the GBI bibliography:



</doc>
<doc id="24860432" url="https://en.wikipedia.org/wiki?curid=24860432" title="Global network">
Global network

A global network is any communication network which spans the entire Earth. The term, as used in this article refers in a more restricted way to "bidirectional" communication networks, and to technology-based networks. Early networks such as international mail and unidirectional communication networks, such as radio and television, are described elsewhere.

The first global network was established using electrical telegraphy and global span was achieved in 1899. The telephony network was the second to achieve global status, in the 1950s. More recently, interconnected IP networks (principally the Internet, with estimated 2.5 billion users worldwide in 2014 ), and the GSM mobile communication network (with over 6 billion worldwide users in 2014) form the largest global networks of all.

Setting up global networks requires immensely costly and lengthy efforts lasting for decades. Elaborate interconnections, switching and routing devices, laying out physical carriers of information, such as land and submarine cables and earth stations must be set in operation. In addition, international communication protocols, legislation and agreements are involved.

Global networks might also refer to networks of individuals (such as scientists), communities (such as cities) and organizations (such as civil organizations) worldwide which, for instance, might have formed for the management, mitigation and resolval of global issues.

Communication satellites are an important part of global networks. However, there are specific low Earth orbit (LEO) global satellite constellations, such as Iridium, Globalstar and Orbcomm, which are comprised by dozens of similar satellites which are put in orbit at regularly spaced positions and form a mesh network, sometimes sending and receiving information directly among themselves. Using VSAT technology, satellite internet access has become possible.

It is estimated that 80% of the global mobile market uses the GSM standard, present in more than 212 countries and territories. Its ubiquity makes international roaming very common between mobile phone operators, enabling subscribers to use their phones in many parts of the world. In order to achieve this, these networks must be interconnected by way of peering arrangements, and therefore the GSM network is a truly global one.

The telegraph and telex communication networks have been phased out, so interconnection among existing global networks arise at several points, such as between the voice telephony and digital data networks, and between these and satellite networks. Many applications run now on several networks, such as VoIP (voice over IP). Mobile communication (voice and data) networks are also intimately intertwined, because the majority of 21st century cell phones have both voice and data (internet navigation and emailing) capabilities.

Digital global networks require huge carrying capacity in the main backbones. This is currently achieved by fiber optic cables.

The Canadian sociologist Marshall McLuhan was the first to forecast the huge impact of the matrix of global networks upon society, coining the term global village. His work, however, related to radio and television networks, which are broadcast (unidirectional) networks, thus predating the much larger impact of the internet.

Global networks have revolutionized human communication several times. The first to do so was the electrical telegraph. Its impact was so large that it has been dubbed the Victorian Internet. It was expanded many times in its coverage with the advent of radiotelegraphy, and with text messaging using telex machines.

The Internet and mobile communication networks have made possible entirely new forms of social interaction, activities and organizing, thanks to its basic features such as widespread usability and access, and instant communication from any connected point to another. Thus, its social impact has been, and still is, enormous. Finally, the impact on governance have been significant facilitating the emergence of 'transnational policy networks' 


</doc>
<doc id="26692723" url="https://en.wikipedia.org/wiki?curid=26692723" title="Study of global communication">
Study of global communication

The study of global communication is an interdisciplinary field focusing on global communication, or the ways that people connect, share, relate and mobilize across geographic, political, economic, social and cultural divides. Global communication implies a transfer of knowledge and ideas from centers of power to peripheries and the imposition of a new intercultural hegemony by means of the "soft power" of global news and entertainment.

With the end of the twentieth century and the turn of a new millennium, the global arena and the field of international communication were undergoing significant changes. Some authors started to use the term global communication because it goes beyond the bounds of individual states and emphasizes communication between and among peoples across borders and, importantly, the rise of transnational media corporations.

International communication traditionally refers to communication between and among nation-states and connotes issues of national sovereignty, control of national information resources, and the supremacy of national governments.

Nevertheless, earlier International communication theories have failed to develop models or research agendas that match the reality of the contemporary role of global communication . The old theories only explain part of the global picture and the theories of modernization, dependency, and cultural imperialism have failed to satisfactorily explain global communication.

The term "global", implies a declining role of the state and state sovereignty. As a term, "international" has within it notions of bilateral or multilateral decisions. "Global" could be seen as an aspiration, also as a fear, of the weakening of the state. In addition, global may imply something more pervasive, more geographically inclusive than international. 

The study of global communication increased dramatically after World War II due to military considerations coupled with their economic and political implications. Earlier attempts at theorizing have failed to develop models or research agendas that match the reality of the contemporary role of global communication .

More global communication research was written in the decade from 1945–1955; most of the research of the 1950s dealt with propaganda and the cold war. By 1970, global communication research had grown to include a great variety of subjects, especially comparative mass communication systems, communication and national development and propaganda and public opinion.

From the point of view of global communication scholars, previous theories of modernization, dependency, and cultural imperialism have failed to satisfactorily explain global communication. The old theories only explain part of the global picture.

The emergence of global communication technologies may be considered the origin of the field of global communication in the nineteenth century. Numerous technical advances such as the creation of a new major global communication phenomenon, convergence, digital environments and the internet are some of the major engines driving the change from international communication to global communication.

With the collapse of the Soviet Union, the shadow of Cold War has lifted to reveal shifting political, economic, and cultural alliances and conflicts. The increasing importance of these currents, especially in the cultural sphere, demands a reconsideration of the nature of the international communication field within the rubric of international relations.

Three key players are usually recognized as the founders of the international news agencies. In 1835, Charles-Louis Havas created the world's first news agency; In 1849, Bernhard Wolff started publishing stock market news and daily reports from Paris, London, Amsterdam, and Frankfurt; In 1849, Paul Julius Freiherr von Reuter established his own commercial service, the Reuter agency, and organized a worldwide exchange of news in 1870.

In 1859, Reuter, Havas and the German Wolff agency reached an agreement to exchange news from all over the world, which was known as the League of Allied Agencies, or the " Ring Combination". In 1848, American News Agency Associated Press was founded and was formally admitted into the "Ring Combination" in 1887.

There are some major factors that point to the growing importance of global communication in the world of the twenty-first century:



Transcultural Political Economy is a concept that is presented in Global Communications by Paula Chakravartty and Yeuzhi Zhao. This concept looks at global communications and media studies in three major areas: global flows of information and culture, decentralizing the conceptual parameters of global information and media studies, and the normative debates in global communications in the context of neoliberalism. Transcultural Political Economy is a multidisciplinary study that focuses on the tensions between political economy and cultural studies. It "integrate[s] institutional and cultural analyzes and address urgent questions in global communications in the context of economic integration, empire formation, and the tensions associated with adapting new privatized technologies, neoliberalized and globalized institutional structures, and hybrid cultural forms and practices". Transcultural Political Economy addresses the issues surrounding the practice of neoliberalism and its creation of unequal power structures within the world system. 
Globalization theory was popularized in the 1990s as a model for understanding global communication. The concept of globalization inspired a number of theories from various schools of thought in communication studies that each emphasize different aspects of globalization. Many globalization theories highlight actors in the business sector as leaders in the processes of global integration. Transnationalizing business is often celebrated as progression toward a more interconnected world. Globalization theories are often associated with theories of modernity. Some scholars view globalization as the social, political, economic, and cultural integration of societies into a capitalist system; Others see globalization as a successor to modernity, while some see it as an iteration of imperialism. Some question the usefulness and legitimacy of globalization theory, arguing that it does not adequately conceptualize current international relations or function as a lens through which to examine everyday events. Many scholars criticize globalization theories as overzealous toward and unrealistic about the extent of global integration. Some scholars criticize social theorists for offering opinions and predictions based on theory with little practical evidence. In contrast, some scholars work to dispute the pessimistic views of globalization theory.

World-system theory is a macro-sociological perspective that seeks to explain the dynamics of the "capitalist world economy" as a "total social system". A world-system is what Wallerstein terms a "world-economy", integrated through the market rather than a political centre, in which two or more regions are interdependent with respect to necessities like food, fuel, and two or more polities compete for domination without the emergence of one single centre forever. World-system theory was first articulated by Immanuel Wallerstein. There are three major sources of the world-system theory which conceived by Wallerstein: the Annales school's general methodology, Marx's focus on accumulation process and competitive class struggles and so on, and dependence theory's neo-Marxist explanation of development processes.

Referring to the transnational division of labor, world-system divides the world into core countries, peripheral countries, semi-peripheral countries and external areas. The core countries usually developed a strong central governments, extensive bureaucracies and large mercenary armies, which permit the local bourgeoisie to obtain control over international commerce and extract capital surpluses from the trade for benefits. The peripheral countries often lack strong central governments or been controlled by core countries, they export raw materials and rely on coercive labor practices. Semi-peripheries which served as buffers between the core and the peripheries. They retain limited but declining access to international banking and the production of high-cost high-quality manufactured goods.[3] External areas such as Russia maintain their own economic systems, they want to remain outside the modern world economy.

The theory of modernization was developed by Daniel Lerner (1958) in the "Passing of traditional society." Lerner's description of "modernised" is an individual having the ability to be empathetic and being able to see oneself in another person's situation. This concept has come from the transition of traditional societies to modern societies, where modern societies is distinctively industrial, urban, literate, and participant. This theory looks at development in a linear fashion, concluding that nations need to develop into a modern society to make it a sustainable and flourishing nation. Developing modernized societies include technological advancement, and developing media sectors to help create a participatory culture. 
"See also:" Post-structuralism, imperialism, modernity,

Post-colonialism is a theoretical approach to looking at literature that examines the colonizer-colonized experience. It deals with the adaptation of formerly colonized nations and their development in cultural, political, economical aspects. Some Notable theoreticians include: Frantz Fanon, Edward Said, Gayatri Spivak, R Siva Kumar, Dipesh Chakrabarty, Derek Gregory.

Cultural imperialism is a mighty civilization exerts culture influence over another. Less economically prominent cultures often import culture from Western countries, which have the economic means to produce a majority of the world's cultural media, mostly via the global transmission of media. The weak civilization adopts the mighty civilization's customs, philosophies, worldviews and general ways of life. The theoretical foundations of the academic study of cultural imperialism mostly come from Michel Foucault's concept of biopower, governmentality and Edward Saïd's concept of Post-colonialism, which theories see cultural imperialism as the cultural legacy of colonialism or forms of Western hegemony. Media effect study which integrated with political-economy traditional is the core argument of cultural imperialism. There are two opposite effects of media study. The negative one is that Western media imposes socio-political conflicts to the developing country and the latter one's resistance to the media effects to preserve their traditional cultural identities. The positive effects are the issues of the process of civilization such as women's right or racial equality with exposing to Western media. Now the term of cultural imperialism usually refers to America's global culture expansion to the rest of world, which include brand name products, video media, fast food and so on.

Communication for Development (C4D) is a praxis oriented aspect of global communication studies that approaches global development with a focus on action and participation for social change enacted through communication systems. C4D underlines "voice, citizenship and collective action" as central values that promote citizen-led development where the visiting party provides guidance rather than direction within the host community. C4D often incorporates bottom-up theories of social change with the aim to create sustainable change which is believed to be more likely to occur if the efforts are planned, implemented, and sustained by community members themselves. Some development workers and academics suggest that a shared definition of communication for development should be clarified, because disagreement within the field can detract from the characteristics that most scholars view as central to current development, including participatory action research (PAR). Many C4D projects revolve around media systems as a central site for social change, which differentiates C4D from other approaches to development. Theories behind C4D highlight that development projects should be contextually situated and that communication technology will affect different types of social change accordingly.

Global media studies is a field of media study in a global scope. Media study deals with the content, history and effects of media. Media study often draws on theories and methods from the disciplines of cultural studies, rhetoric, philosophy, communication studies, feminist theory, political economy and sociology. Among these study approaches, political economic analysis is non-ignorable in understanding the current media and communication developments. But the political economic research has become more resilient because of stronger empirical studies, and the potential connections to policy-making and alternative praxis.

Each country has its own distinct media ecosystem. The media of mainland China is state-run, so the political subjects are under the strict regulations set by the government while other areas such as sports, finance, and increasingly lucrative entertainment industry face less regulation from government. Canada has a well-developed media sector, but the mass media is threatened by the direct outcome of American economic and cultural imperialism which hinder the form of Canada's media identity. Many of the media in America are controlled by large for-profit corporations who reap revenues from advertisings, subscriptions and the sale of copyrighted materials. Currently, six corporations (Comcast, The Walt Disney Company, News Corporation, Time Warner, Viacom and CBS Corporation) have controlled roughly 90% of the America media. Such figures come from the policies of the federal government or the tendency to natural monopolies in the industry.

Immanuel Wallerstein's world system theory develops a basic framework to understand global power shifts in the rise of the modern world. Wallerstein proposes four different categories: core, semi-periphery, periphery, and external, in terms of different region's relative position in the world system. The core regions are the ones that benefited the most from the capitalist world economy, such as England and France. The peripheral areas relied on and exported raw materials to the core, such as Eastern Europe and Latin America. The semi-peripheries are either core regions in decline or peripheries attempting to improve their relative position in the world system, such as Portugal and Spain. The external areas managed to remain outside the modern world economy, such as Russia.

There are two basic types of global power shifts in the 21st century. One is traditional power transition amongst states, which follows Wallerstein's world system theory. For instance, the global power shifts from the West to the East since the rise of Asia. The other is power diffusion, the way that power move from states to non-states actors. For instance, "climate change, drug trade, financial flows, pandemics, all these things that cross borders outsider the control of governments."

Public sphere theory, attributed to Jurgen Habermas, is a theory that in its basic premise conceives of democratic governments as those that can stand criticism that comes from public spheres. Public spheres are places, physical or imagined, where people discuss any kind of topic, particularly topics of a societal or political nature. Global public sphere is, therefore, a public that is made of people from across the globe, who come together to discuss and act on issues that concern them. The concept of global public sphere is linked to the shift of public sphere, from restricted to nation-state, to made of individuals and groups connected across as well as within borders.

Since Plato, it can be argued that philosophers have been thinking about versions of a common space for all people to debate in; however, a global public sphere that can fit the description above began to appear much later. In the second half of the 20th century, the legacy of World War II and technological advancements created a new sense of the global and started the economic and political phenomena that we now call globalization. This includes the expansion of humankind into space, which gave individuals the sense of a global unity, the growth of satellite technology, which allowed for people across the globe to view the same television channels, and the internet, which can provide access to an unprecedented amount of information and spaces to connect with other people.

The term "culture industry" appeared in the post-war period. At that time, culture and industry were argued to be opposites. Cultural industries" are also referred to as the "Creative industries.

In the present day, there remain different interpretations of culture as an industry. For some, cultural industries are simply those industries that produce cultural goods and services.

In the United Nations Educational, Scientific and Cultural Organization (UNESCO), the cultural industries are regarded as those industries that "combine the creation, production and commercialization of contents which are intangible and cultural in nature. These contents are typically protected by copyright and they can take the form of goods or services". According to UNESCO, an essential part of cultural industries is that they are "central in promoting and maintaining cultural diversity and in ensuring democratic access to culture". "Cultural industries" combines the cultural and economic, which gives the cultural industries a distinctive profile.

In France, the "cultural industries" have recently been defined as a set of economic activities that combine the functions of conception, creation and production of culture with more industrial functions in the large-scale manufacture and commercialization cultural products.

In Canada, economic activities involved in the preservation of heritage are also included in the definition of culture.

Since the rise of the cultural industries has occurred simultaneously with economic globalization, cultural industries have close connections with globalization and global communication.

Herbert Schiller argued that the 'entertainment, communications and information (ECI) complex were having a direct impact on culture and human consciousness. As Schiller argued, the result of transnational corporate expansion is the perpetuation of cultural imperialism, defined as "the sum of the processes by which a society is brought into the modern world system and how its dominating stratum is attracted, pressured, forced, and sometimes bribed into shaping social institutions to correspond to, or even promote, the values and structures of the dominating centre of the system".

The second wave of transnational corporate expansion, which began in the 1970s with the emergence of Export Processing Zones in developing countries, is focused on the development of global production networks. This process was described as a "new international division of labour" (NIDL) by the German political economists Frӧbel et al. (1980).

Ernst and Kim have argued that GPNs are changing the nature of the multinational corporation itself, from "stand alone overseas investment projects, to "global network flagships" that integrate their dispersed supply, knowledge and customer bases into global and regional production networks", entailing a shift from top-down hierarchical models of corporate control to increasingly networked and collective forms of organization.

The largest firms in media and media-related industries have a very high international profile. Global media empires such as Disney, News Corporation, Time-Warner and Viacom-CBS now derive 25-45 per cent of their revenues outside of the United States.

It is often argued that the global media are dominated by a small number of powerful media conglomerates. Edward S. Herman and Robert W. McChesney (1997) argued that the global media were "dominated by three or four dozen large transnational corporations (TNCs) with fewer than ten mostly US-based media conglomerates towering over the global market." Similarly, Manfred Steger has observed that " to a very large extent, the global cultural flows of our time are generated and directed by global media empires that rely on powerful communication technologies to spread their message." He also argued that during the last two decades, a few very large TNCs would come to dominate the global market for entertainment, news, television, and film.

Diaspora is often confused with exodus. Diasporas are minority groups that have a sense of connection with a larger community outside of the borders they currently inhabit, and through diasporic media create a sense of a larger identity and community, whether imagined or real. In scholarly work about diaspora in communication studies, the view of nation and culture as interchangeable terms is no longer prevalent. Stuart Hall theorized of hybridity, which he distinguished from "old style pluralism", "nomadic voyaging of the postmodern", and "global homogenization". Hybridity is the retention of an original identity and strong ties to an original country and tradition, but with the understanding that there is no unchanged, ideal nation of the past that they can return to. To be hybrid is to also adapt to a new culture and tradition without simply assimilating in it, but rather negotiating a place between the "original" and "new" cultures. In Communication studies, diaspora is discussed as the identity that unifies people across time and space, sometimes existing in physical spaces and other times existing in imagined 'non-spaces'. However, it has been argued that the concept of 'diaspora' implies ethnic homogeneity and essentializes identity to only ethnicity. One of the most cited and well-known works in the field of diasporic media is Hamid Naficy's work on exiled Iranian Americans' creation of cable television in the United States.

Diasporic media refer to media that address the needs of particular ethnic, religious, and/or linguistic groups that live in multicultural settings . Diasporic media can be in the diaspora's traditional language or in another language, and they can include news or media from the "origin" country or they can contain the diaspora's local news or media. Diasporic media can be created in radio, television, film, music, in newspapers, magazines, and other publishing, as well as online. It can be argued that the development and spread of satellite television is an instrumental element of the growth of diasporic media today. Satellite television allowed migrants to access the news and popular culture from their homeland, as well as allowing people who speak the same language to access the same channels that might be produced outside of the "homeland"

Contemporary studies of diaspora show that diasporic media are part of the change in the tendency Immanuel Wallerstein described in his world systems theory. The world systems theory postulates that much of the flow of people in the world has been from the 'periphery', or economically-developing states, towards the centre; which are often metropolitan, economically-wealthy states that grew their wealth in colonialist entrepreneurship. However, contrary to the movement of people, the flow of information (including media products), has tended to be from the centre to the periphery.

The advancement of media and technology have played the pivotal role in process of globalization and global communication. Cable television, ISDN, digitalization, direct broadcast satellites as well as the Internet have created a situation where vast amounts of information can be transferred around the globe in a matter of seconds.

During the early 20th century, telegraph, telephony, and radio started the process of global communication. As media technologies developed intensely, they were thought to create, in Marshall McLuhan’ s famous words, a ‘‘global village.’’ The launch of Sputnik, the world’ s first artificial satellite, on October 4, 1957, marked the beginning of technologies that would further interconnect the world. The first live global television broadcast occurred when Neil Armstrong stepped onto the moon in July 1969. In November 1972, pay TV caused expansion of cable when Service Electric offered Home Box Office over its cable system. By 2000, over direct broadcast satellite, a household could receive channels from all over the world. Now with the World Wide Web, smart phones, tablet devices, smart televisions and other digital media devices, billions of people are now able to access media content that was once tied to particular communications media (print, broadcast) or platforms (newspapers, magazines, radio, television, cinema).

Justice in communication studies includes, but is not limited to, the concern with democratic process and fostering democratic publics . Jurgen Habermas theorized of public sphere (in "The Structural Transformation of the Public Sphere") as the space that is created whenever matters of common concern are discussed between the state and civil society. Thus, public sphere includes not only the media, but also public protest in the form of marches, demonstrations, et cetera. There are, however, critiques of political economy in whose view it is impossible to work within the current system to produce democratic publics. Such a critique is that produced by Karl Marx, who saw institutions such as parliament, the state, the 'acceptable' public sphere, economic enterprises, and so on as structurally produced and perpetuated by a capitalist system, and thus they can not be mobilized to change it. In such a system, there can only be illusory justice, which is fair only within the logic of the system. This illusion of justice is produced through dominating ideology.

Another issue of justice in communication studies is the question of decolonizing research methods and theoretical discourse . The idea of decolonizing research comes from a rejection of the functionalist approach, which assumed that research can be conducted in a vacuum, free of ideology or the researcher's biases. This approach assumed cultures to be unchanging, homogenous, and isolated from each other. The purpose of decolonizing research and discourse is to 'uncloak' research as an unbiased power structure, and produce research that is more self-aware. The approach in decolonizing research methods attempts to create methodologies that treat the people in the study as participants or partners, rather than subjects - which is a term that in itself carries strong connotations of colonialism. Decolonizing research also involves moving away from Eurocentric models that are assumed to work anywhere else, and instead to create work that is more useful in local contexts. Decolonial approaches specifically seek to produce knowledge about the mechanisms and effects of colonialism. These approaches allow former subjects to 'talk back', which is a reflection of independent agency, on the colonizer's own terms of research, rather than to be 'given' a voice, which is an unequal power structure.



</doc>
